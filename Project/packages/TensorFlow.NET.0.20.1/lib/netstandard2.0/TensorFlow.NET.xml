<?xml version="1.0"?>
<doc>
    <assembly>
        <name>TensorFlow.NET</name>
    </assembly>
    <members>
        <member name="T:Tensorflow.c_api">
            <summary>
            C API for TensorFlow.
            Port from tensorflow\c\c_api.h
            
            The API leans towards simplicity and uniformity instead of convenience
            since most usage will be by language specific wrappers.
            
            The params type mapping between c_api and .NET
            TF_XX** => ref IntPtr (TF_Operation** op) => (ref IntPtr op)
            TF_XX* => IntPtr (TF_Graph* graph) => (IntPtr graph)
            struct => struct (TF_Output output) => (TF_Output output)
            struct* => struct[] (TF_Output* output) => (TF_Output[] output)
            struct* => struct* for ref
            const char* => string
            int32_t => int
            int64_t* => long[]
            size_t* => ulong[]
            size_t* => ref ulong
            void* => IntPtr
            string => IntPtr c_api.StringPiece(IntPtr)
            unsigned char => byte
            </summary>
        </member>
        <member name="M:Tensorflow.c_api.TF_OperationGetAttrMetadata(System.IntPtr,System.String,Tensorflow.SafeStatusHandle)">
            <summary>
            Fills in `value` with the value of the attribute `attr_name`.  `value` must
            point to an array of length at least `max_length` (ideally set to
            TF_AttrMetadata.total_size from TF_OperationGetAttrMetadata(oper,
            attr_name)).
            </summary>
            <param name="oper">TF_Operation*</param>
            <param name="attr_name">const char*</param>
            <param name="status">TF_Status*</param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_OperationGetAttrString(System.IntPtr,System.String,System.IntPtr,System.UInt32,Tensorflow.SafeStatusHandle)">
            <summary>
            Fills in `value` with the value of the attribute `attr_name`.  `value` must
            point to an array of length at least `max_length` (ideally set to
            TF_AttrMetadata.total_size from TF_OperationGetAttrMetadata(oper,
            attr_name)). 
            </summary>
            <param name="oper">TF_Operation*</param>
            <param name="attr_name">const char*</param>
            <param name="value">void* </param>
            <param name="max_length">size_t</param>
            <param name="status">TF_Status*</param>
        </member>
        <member name="M:Tensorflow.c_api.TF_OperationGetAttrValueProto(System.IntPtr,System.String,Tensorflow.SafeBufferHandle,Tensorflow.SafeStatusHandle)">
            <summary>
            Sets `output_attr_value` to the binary-serialized AttrValue proto
            representation of the value of the `attr_name` attr of `oper`.
            </summary>
            <param name="oper"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_SetAttrShape(System.IntPtr,System.String,System.Int64[],System.Int32)">
            <summary>
            Set `num_dims` to -1 to represent "unknown rank".
            </summary>
            <param name="desc"></param>
            <param name="attr_name"></param>
            <param name="dims"></param>
            <param name="num_dims"></param>
        </member>
        <member name="M:Tensorflow.c_api.TF_SetAttrString(System.IntPtr,System.String,System.String,System.UInt32)">
            <summary>
            Call some TF_SetAttr*() function for every attr that is not
            inferred from an input and doesn't have a default value you wish to
            keep.
            
            `value` must point to a string of length `length` bytes.
            </summary>
            <param name="desc">TF_OperationDescription*</param>
            <param name="attr_name">const char*</param>
            <param name="value">const void*</param>
            <param name="length">size_t</param>
        </member>
        <member name="M:Tensorflow.c_api.TF_SetAttrStringList(System.IntPtr,System.String,System.IntPtr[],System.UInt32[],System.Int32)">
            <summary>
            
            </summary>
            <param name="desc"></param>
            <param name="attr_name"></param>
            <param name="values"></param>
            <param name="lengths"></param>
            <param name="num_values"></param>
        </member>
        <member name="M:Tensorflow.c_api.TF_NewBuffer">
            <summary>
            Useful for passing *out* a protobuf.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_NewBufferFromString(System.IntPtr,System.UInt64)">
            <summary>
            Makes a copy of the input and sets an appropriate deallocator.  Useful for
            passing in read-only, input protobufs.
            </summary>
            <param name="proto">const void*</param>
            <param name="proto_len">size_t</param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_SetDevice(System.IntPtr,System.String)">
            <summary>
            Specify the device for `desc`.  Defaults to empty, meaning unconstrained.
            </summary>
            <param name="desc"></param>
            <param name="device"></param>
        </member>
        <member name="M:Tensorflow.c_api.TF_DeviceListCount(Tensorflow.Device.SafeDeviceListHandle)">
            <summary>
            Counts the number of elements in the device list.
            </summary>
            <param name="list">TF_DeviceList*</param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_DeviceListType(Tensorflow.Device.SafeDeviceListHandle,System.Int32,Tensorflow.SafeStatusHandle)">
            <summary>
            Retrieves the type of the device at the given index.
            </summary>
            <param name="list">TF_DeviceList*</param>
            <param name="index">int</param>
            <param name="status">TF_Status*</param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_DeleteDeviceList(System.IntPtr)">
            <summary>
            Deallocates the device list.
            </summary>
            <param name="list">TF_DeviceList*</param>
        </member>
        <member name="M:Tensorflow.c_api.TFE_TensorHandleCopyToDevice(Tensorflow.Eager.SafeTensorHandleHandle,Tensorflow.Eager.SafeContextHandle,System.String,Tensorflow.SafeStatusHandle)">
            <summary>
            Create a new TFE_TensorHandle with the same contents as 'h' but placed
            in the memory of the device name 'device_name'.
            </summary>
            <param name="h">TFE_TensorHandle*</param>
            <param name="ctx">TFE_Context*</param>
            <param name="device_name">char*</param>
            <param name="status">TF_Status*</param>
            <returns>TFE_TensorHandle*</returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_DeviceListName(Tensorflow.Device.SafeDeviceListHandle,System.Int32,Tensorflow.SafeStatusHandle)">
            <summary>
            Retrieves the full name of the device (e.g. /job:worker/replica:0/...)
            </summary>
            <param name="list">TF_DeviceList*</param>
            <param name="index"></param>
            <param name="status">TF_Status*</param>
        </member>
        <member name="M:Tensorflow.c_api.TF_DeviceListNameImpl(Tensorflow.Device.SafeDeviceListHandle,System.Int32,Tensorflow.SafeStatusHandle)">
            <summary>
            Retrieves the full name of the device (e.g. /job:worker/replica:0/...)
            The return value will be a pointer to a null terminated string. The caller
            must not modify or delete the string. It will be deallocated upon a call to
            TF_DeleteDeviceList.
            </summary>
            <param name="list">TF_DeviceList*</param>
            <param name="index"></param>
            <param name="status">TF_Status*</param>
        </member>
        <member name="M:Tensorflow.c_api.TFE_NewContextOptions">
            <summary>
            Return a new options object.
            </summary>
            <returns>TFE_ContextOptions*</returns>
        </member>
        <member name="M:Tensorflow.c_api.TFE_DeleteContextOptions(System.IntPtr)">
            <summary>
            Destroy an options object.
            </summary>
            <param name="options">TFE_ContextOptions*</param>
        </member>
        <member name="M:Tensorflow.c_api.TFE_OpGetAttrType(Tensorflow.Eager.SafeOpHandle,System.String,System.Byte@,Tensorflow.SafeStatusHandle)">
            <summary>
            
            </summary>
            <param name="op">TFE_Op*</param>
            <param name="attr_name">const char*</param>
            <param name="is_list">unsigned char*</param>
            <param name="status">TF_Status*</param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TFE_OpGetInputLength(Tensorflow.Eager.SafeOpHandle,System.String,Tensorflow.SafeStatusHandle)">
            <summary>
            Returns the length (number of tensors) of the input argument `input_name`
            found in the provided `op`.
            </summary>
            <param name="op">TFE_Op*</param>
            <param name="input_name">const char*</param>
            <param name="status">TF_Status*</param>
        </member>
        <member name="M:Tensorflow.c_api.TFE_OpGetOutputLength(Tensorflow.Eager.SafeOpHandle,System.String,Tensorflow.SafeStatusHandle)">
            <summary>
            Returns the length (number of tensors) of the output argument `output_name`
            found in the provided `op`.
            </summary>
            <param name="op"></param>
            <param name="input_name"></param>
            <param name="status"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TFE_OpAddInputList(Tensorflow.Eager.SafeOpHandle,Tensorflow.Eager.SafeTensorHandleHandle[],System.Int32,Tensorflow.SafeStatusHandle)">
            <summary>
            
            </summary>
            <param name="op">TFE_Op*</param>
            <param name="inputs">TFE_TensorHandle**</param>
            <param name="num_inputs">int</param>
            <param name="status">TF_Status*</param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TFE_NewContext(Tensorflow.Eager.SafeContextOptionsHandle,Tensorflow.SafeStatusHandle)">
            <summary>
            
            </summary>
            <param name="opts">const TFE_ContextOptions*</param>
            <param name="status">TF_Status*</param>
            <returns>TFE_Context*</returns>
        </member>
        <member name="M:Tensorflow.c_api.TFE_ContextAddFunction(Tensorflow.Eager.SafeContextHandle,System.IntPtr,Tensorflow.SafeStatusHandle)">
            <summary>
            Adds a function (created from TF_GraphToFunction or
            TF_FunctionImportFunctionDef) to the context, allowing it to be executed with
            TFE_Execute by creating an op with the same name as the function.
            </summary>
            <param name="ctx"></param>
            <param name="function"></param>
            <param name="status"></param>
        </member>
        <member name="M:Tensorflow.c_api.TFE_ContextRemoveFunction(Tensorflow.Eager.SafeContextHandle,System.String,Tensorflow.SafeStatusHandle)">
            <summary>
            Removes a function from the context. Once removed, you can no longer
            TFE_Execute it or TFE_Execute any TFE_Op which has it as an attribute or any
            other function which calls it as an attribute.
            </summary>
            <param name="ctx"></param>
            <param name="name"></param>
            <param name="status"></param>
        </member>
        <member name="M:Tensorflow.c_api.TFE_ContextHasFunction(Tensorflow.Eager.SafeContextHandle,System.String)">
            <summary>
            Checks whether a function is registered under `name`.
            </summary>
            <param name="ctx"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TFE_DeleteContext(System.IntPtr)">
            <summary>
            
            </summary>
            <param name="ctx">TFE_Context*</param>
        </member>
        <member name="M:Tensorflow.c_api.TFE_Execute(Tensorflow.Eager.SafeOpHandle,Tensorflow.Eager.SafeTensorHandleHandle[],System.Int32@,Tensorflow.SafeStatusHandle)">
            <summary>
            Execute the operation defined by <paramref name="op"/> and return handles to computed
            tensors in <paramref name="retvals"/>.
            </summary>
            <remarks>
            Upon successful return, the first <paramref name="num_retvals"/> slots in <paramref name="retvals"/> will
            contain handle instances which the caller is responsible for disposing once they are no longer in use.
            </remarks>
            <param name="op"></param>
            <param name="retvals"></param>
            <param name="num_retvals"></param>
            <param name="status"></param>
        </member>
        <member name="M:Tensorflow.c_api.TFE_Execute(Tensorflow.Eager.SafeOpHandle,System.IntPtr*,System.Int32@,Tensorflow.SafeStatusHandle)">
            <summary>
            Execute the operation defined by 'op' and return handles to computed
            tensors in `retvals`.
            </summary>
            <param name="op">TFE_Op*</param>
            <param name="retvals">TFE_TensorHandle**</param>
            <param name="num_retvals">int*</param>
            <param name="status">TF_Status*</param>
        </member>
        <member name="M:Tensorflow.c_api.TFE_NewOp(Tensorflow.Eager.SafeContextHandle,System.String,Tensorflow.SafeStatusHandle)">
            <summary>
            
            </summary>
            <param name="ctx">TFE_Context*</param>
            <param name="op_or_function_name">const char*</param>
            <param name="status">TF_Status*</param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TFE_OpReset(Tensorflow.Eager.SafeOpHandle,System.String,System.String,Tensorflow.SafeStatusHandle)">
            <summary>
            Resets `op_to_reset` with `op_or_function_name` and `raw_device_name`. This
            is for performance optimization by reusing an exiting unused op rather than
            creating a new op every time. If `raw_device_name` is `NULL` or empty, it
            does not set the device name. If it's not `NULL`, then it attempts to parse
            and set the device name. It's effectively `TFE_OpSetDevice`, but it is faster
            than separately calling it because if the existing op has the same
            `raw_device_name`, it skips parsing and just leave as it is.
            </summary>
            <param name="op_to_reset">TFE_Op*</param>
            <param name="op_or_function_name">const char*</param>
            <param name="raw_device_name">const char*</param>
            <param name="status">TF_Status*</param>
        </member>
        <member name="M:Tensorflow.c_api.TFE_DeleteOp(System.IntPtr)">
            <summary>
            
            </summary>
            <param name="op">TFE_Op*</param>
        </member>
        <member name="M:Tensorflow.c_api.TFE_OpSetAttrType(Tensorflow.Eager.SafeOpHandle,System.String,Tensorflow.TF_DataType)">
            <summary>
            
            </summary>
            <param name="op">TFE_Op*</param>
            <param name="attr_name">const char*</param>
            <param name="value">TF_DataType</param>
        </member>
        <member name="M:Tensorflow.c_api.TFE_OpSetAttrShape(Tensorflow.Eager.SafeOpHandle,System.String,System.Int64[],System.Int32,Tensorflow.SafeStatusHandle)">
            <summary>
            
            </summary>
            <param name="op">TFE_Op*</param>
            <param name="attr_name">const char*</param>
            <param name="dims">const int64_t*</param>
            <param name="num_dims">const int</param>
            <param name="out_status">TF_Status*</param>
        </member>
        <member name="M:Tensorflow.c_api.TFE_OpSetAttrString(Tensorflow.Eager.SafeOpHandle,System.String,System.String,System.UInt32)">
            <summary>
            
            </summary>
            <param name="op">TFE_Op*</param>
            <param name="attr_name">const char*</param>
            <param name="value">const void*</param>
            <param name="length">size_t</param>
        </member>
        <member name="M:Tensorflow.c_api.TFE_OpSetDevice(Tensorflow.Eager.SafeOpHandle,System.String,Tensorflow.SafeStatusHandle)">
            <summary>
            
            </summary>
            <param name="op"></param>
            <param name="device_name"></param>
            <param name="status"></param>
        </member>
        <member name="M:Tensorflow.c_api.TFE_OpAddInput(Tensorflow.Eager.SafeOpHandle,Tensorflow.Eager.SafeTensorHandleHandle,Tensorflow.SafeStatusHandle)">
            <summary>
            
            </summary>
            <param name="op">TFE_Op*</param>
            <param name="h">TFE_TensorHandle*</param>
            <param name="status">TF_Status*</param>
        </member>
        <member name="M:Tensorflow.c_api.TFE_NewTensorHandle(System.IntPtr,Tensorflow.SafeStatusHandle)">
            <summary>
            
            </summary>
            <param name="t">const tensorflow::Tensor&amp;</param>
            <returns>TFE_TensorHandle*</returns>
        </member>
        <member name="M:Tensorflow.c_api.TFE_ContextOptionsSetAsync(Tensorflow.Eager.SafeContextOptionsHandle,System.Byte)">
            <summary>
            Sets the default execution mode (sync/async). Note that this can be
            overridden per thread using TFE_ContextSetExecutorForThread.
            </summary>
            <param name="opts">TFE_ContextOptions*</param>
            <param name="enable">unsigned char</param>
        </member>
        <member name="M:Tensorflow.c_api.TFE_TensorHandleDataType(Tensorflow.Eager.SafeTensorHandleHandle)">
            <summary>
            
            </summary>
            <param name="h">TFE_TensorHandle*</param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TFE_TensorHandleResolve(Tensorflow.Eager.SafeTensorHandleHandle,Tensorflow.SafeStatusHandle)">
            <summary>
            This function will block till the operation that produces `h` has
            completed. The memory returned might alias the internal memory used by
            TensorFlow.
            </summary>
            <param name="h">TFE_TensorHandle*</param>
            <param name="status">TF_Status*</param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TFE_TensorHandleNumDims(Tensorflow.Eager.SafeTensorHandleHandle,Tensorflow.SafeStatusHandle)">
            <summary>
            This function will block till the operation that produces `h` has completed.
            </summary>
            <param name="h">TFE_TensorHandle*</param>
            <param name="status">TF_Status*</param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TFE_TensorHandleDeviceName(Tensorflow.Eager.SafeTensorHandleHandle,Tensorflow.SafeStatusHandle)">
            <summary>
            Returns the device of the operation that produced `h`. If `h` was produced by
            a copy, returns the destination device of the copy. Note that the returned
            device name is not always the device holding the tensor handle's memory. If
            you want the latter, use TFE_TensorHandleBackingDeviceName. This function
            will block till the operation that produces `h` has completed.
            </summary>
            <param name="h">TFE_TensorHandle*</param>
            <param name="status">TF_Status*</param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TFE_TensorHandleBackingDeviceName(Tensorflow.Eager.SafeTensorHandleHandle,Tensorflow.SafeStatusHandle)">
            <summary>
            Returns the name of the device in whose memory `h` resides.
            </summary>
            <param name="h">TFE_TensorHandle*</param>
            <param name="status">TF_Status*</param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TFE_ContextListDevices(Tensorflow.Eager.SafeContextHandle,Tensorflow.SafeStatusHandle)">
            <summary>
            
            </summary>
            <param name="ctx">TFE_Context*</param>
            <param name="status">TF_Status*</param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TFE_DeleteTensorHandle(System.IntPtr)">
            <summary>
            
            </summary>
            <param name="h">TFE_TensorHandle*</param>
        </member>
        <member name="M:Tensorflow.c_api.TFE_DeleteEagerTensor(System.IntPtr)">
            <summary>
            
            </summary>
            <param name="h">TFE_TensorHandle*</param>
        </member>
        <member name="M:Tensorflow.c_api.TFE_NewExecutor(System.Boolean)">
            <summary>
            Creates a new eager Executor. Nodes in one executor are guaranteed to be
            executed in sequence. Assigning nodes to different executors allows executing
            nodes in parallel.
            </summary>
            <param name="is_async"></param>
            <returns>TFE_Executor*</returns>
        </member>
        <member name="M:Tensorflow.c_api.TFE_DeleteExecutor(System.IntPtr)">
            <summary>
            Deletes the eager Executor without waiting for enqueued nodes. Please call
            TFE_ExecutorWaitForAllPendingNodes before calling this API if you want to
            make sure all nodes are finished.
            </summary>
            <param name="executor">TFE_Executor*</param>
        </member>
        <member name="M:Tensorflow.c_api.TFE_ExecutorWaitForAllPendingNodes(Tensorflow.Eager.SafeExecutorHandle,Tensorflow.SafeStatusHandle)">
            <summary>
            Causes the calling thread to block till all ops dispatched in this executor
            have been executed. Note that "execution" here refers to kernel execution /
            scheduling of copies, etc. Similar to sync execution, it doesn't guarantee
            that lower level device queues (like GPU streams) have been flushed.
            
            This call may not block for execution of ops enqueued concurrently with this
            call.
            </summary>
            <param name="executor">TFE_Executor*</param>
            <param name="status">TF_Status*</param>
        </member>
        <member name="M:Tensorflow.c_api.TFE_ContextSetExecutorForThread(Tensorflow.Eager.SafeContextHandle,Tensorflow.Eager.SafeExecutorHandle)">
            <summary>
            Sets a custom Executor for current thread. All nodes created by this thread
            will be added to this Executor. It will override current executor.
            </summary>
            <param name="ctx"></param>
            <param name="executor"></param>
        </member>
        <member name="M:Tensorflow.c_api.TFE_ContextGetExecutorForThread(Tensorflow.Eager.SafeContextHandle)">
            <summary>
            Returns the Executor for current thread.
            </summary>
            <param name="ctx"></param>
            <returns>TFE_Executor*</returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_FunctionToFunctionDef(System.IntPtr,Tensorflow.SafeBufferHandle,Tensorflow.SafeStatusHandle)">
            <summary>
            Write out a serialized representation of `func` (as a FunctionDef protocol
            message) to `output_func_def` (allocated by TF_NewBuffer()).
            `output_func_def`'s underlying buffer will be freed when TF_DeleteBuffer()
            is called.
            </summary>
            <param name="func"></param>
            <param name="output_func_def"></param>
            <param name="status"></param>
        </member>
        <member name="M:Tensorflow.c_api.TF_AddGradientsWithPrefix(System.IntPtr,System.String,Tensorflow.TF_Output[],System.Int32,Tensorflow.TF_Output[],System.Int32,Tensorflow.TF_Output[],Tensorflow.SafeStatusHandle,System.IntPtr[])">
            <summary>
            Adds operations to compute the partial derivatives of sum of `y`s w.r.t `x`s,
            i.e., d(y_1 + y_2 + ...)/dx_1, d(y_1 + y_2 + ...)/dx_2...
            This is a variant of TF_AddGradients that allows to caller to pass a custom
            name prefix to the operations added to a graph to compute the gradients.
            </summary>
            <param name="g">TF_Graph*</param>
            <param name="prefix">const char*</param>
            <param name="y">TF_Output*</param>
            <param name="ny">int</param>
            <param name="x">TF_Output*</param>
            <param name="nx">int</param>
            <param name="dx">TF_Output*</param>
            <param name="status">TF_Status*</param>
            <param name="dy">TF_Output*</param>
        </member>
        <member name="M:Tensorflow.c_api.TF_DeleteGraph(System.IntPtr)">
            <summary>
            Destroy an options object.  Graph will be deleted once no more
            TFSession's are referencing it.
            </summary>
            <param name="graph"></param>
        </member>
        <member name="M:Tensorflow.c_api.TF_DeleteImportGraphDefOptions(System.IntPtr)">
            <summary>
            
            </summary>
            <param name="opts">TF_ImportGraphDefOptions*</param>
        </member>
        <member name="M:Tensorflow.c_api.TF_DeleteImportGraphDefResults(System.IntPtr)">
            <summary>
            Deletes a results object returned by TF_GraphImportGraphDefWithResults().
            </summary>
            <param name="results"></param>
        </member>
        <member name="M:Tensorflow.c_api.TF_GraphGetTensorShape(System.IntPtr,Tensorflow.TF_Output,System.Int64[],System.Int32,Tensorflow.SafeStatusHandle)">
            <summary>
            Returns the shape of the Tensor referenced by `output` in `graph`
            into `dims`. `dims` must be an array large enough to hold `num_dims`
            entries (e.g., the return value of TF_GraphGetTensorNumDims).
            </summary>
            <param name="graph"></param>
            <param name="output"></param>
            <param name="dims"></param>
            <param name="num_dims"></param>
            <param name="status"></param>
        </member>
        <member name="M:Tensorflow.c_api.TF_GraphImportGraphDefWithReturnOutputs(System.IntPtr,Tensorflow.SafeBufferHandle,Tensorflow.SafeImportGraphDefOptionsHandle,System.IntPtr,System.Int32,Tensorflow.SafeStatusHandle)">
             <summary>
             Import the graph serialized in `graph_def` into `graph`.
             Convenience function for when only return outputs are needed.
            
             `num_return_outputs` must be the number of return outputs added (i.e. the
             result of TF_ImportGraphDefOptionsNumReturnOutputs()).  If
             `num_return_outputs` is non-zero, `return_outputs` must be of length
             `num_return_outputs`. Otherwise it can be null.
             </summary>
             <param name="graph">TF_Graph* graph</param>
             <param name="graph_def">const TF_Buffer*</param>
             <param name="options">const TF_ImportGraphDefOptions*</param>
             <param name="return_outputs">TF_Output*</param>
             <param name="num_return_outputs">int</param>
             <param name="status">TF_Status*</param>
        </member>
        <member name="M:Tensorflow.c_api.TF_GraphImportGraphDefWithResults(System.IntPtr,Tensorflow.SafeBufferHandle,Tensorflow.SafeImportGraphDefOptionsHandle,Tensorflow.SafeStatusHandle)">
            <summary>
            Import the graph serialized in `graph_def` into `graph`.  Returns nullptr and
            a bad status on error. Otherwise, returns a populated
            TF_ImportGraphDefResults instance. The returned instance must be deleted via
            TF_DeleteImportGraphDefResults().
            </summary>
            <param name="graph">TF_Graph*</param>
            <param name="graph_def">const TF_Buffer*</param>
            <param name="options">const TF_ImportGraphDefOptions*</param>
            <param name="status">TF_Status*</param>
            <returns>TF_ImportGraphDefResults*</returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_GraphImportGraphDef(System.IntPtr,Tensorflow.SafeBufferHandle,Tensorflow.SafeImportGraphDefOptionsHandle,Tensorflow.SafeStatusHandle)">
            <summary>
            Import the graph serialized in `graph_def` into `graph`.
            </summary>
            <param name="graph">TF_Graph*</param>
            <param name="graph_def">TF_Buffer*</param>
            <param name="options">TF_ImportGraphDefOptions*</param>
            <param name="status">TF_Status*</param>
        </member>
        <member name="M:Tensorflow.c_api.TF_GraphNextOperation(System.IntPtr,System.UInt32@)">
            <summary>
            Iterate through the operations of a graph.
            </summary>
            <param name="graph"></param>
            <param name="pos"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_GraphOperationByName(System.IntPtr,System.String)">
            <summary>
            Returns the operation in the graph with `oper_name`. Returns nullptr if
            no operation found.
            </summary>
            <param name="graph"></param>
            <param name="oper_name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_GraphSetTensorShape(System.IntPtr,Tensorflow.TF_Output,System.Int64[],System.Int32,Tensorflow.SafeStatusHandle)">
            <summary>
            Sets the shape of the Tensor referenced by `output` in `graph` to
            the shape described by `dims` and `num_dims`.
            </summary>
        </member>
        <member name="M:Tensorflow.c_api.TF_GraphToGraphDef(System.IntPtr,Tensorflow.SafeBufferHandle,Tensorflow.SafeStatusHandle)">
            <summary>
            Write out a serialized representation of `graph` (as a GraphDef protocol
            message) to `output_graph_def` (allocated by TF_NewBuffer()).
            </summary>
            <param name="graph">TF_Graph*</param>
            <param name="output_graph_def">TF_Buffer*</param>
            <param name="status">TF_Status*</param>
        </member>
        <member name="M:Tensorflow.c_api.TF_GraphGetTensorNumDims(System.IntPtr,Tensorflow.TF_Output,Tensorflow.SafeStatusHandle)">
            <summary>
            Returns the number of dimensions of the Tensor referenced by `output`
            in `graph`.
            
            If the number of dimensions in the shape is unknown, returns -1.
            </summary>
            <param name="graph"></param>
            <param name="output"></param>
            <param name="status"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_ImportGraphDefOptionsAddControlDependency(Tensorflow.SafeImportGraphDefOptionsHandle,System.IntPtr)">
            <summary>
            Cause the imported graph to have a control dependency on `oper`. `oper`
            should exist in the graph being imported into.
            </summary>
            <param name="opts"></param>
            <param name="oper"></param>
        </member>
        <member name="M:Tensorflow.c_api.TF_ImportGraphDefOptionsAddInputMapping(Tensorflow.SafeImportGraphDefOptionsHandle,System.String,System.Int32,Tensorflow.TF_Output)">
            <summary>
            Set any imported nodes with input `src_name:src_index` to have that input
            replaced with `dst`. `src_name` refers to a node in the graph to be imported,
            `dst` references a node already existing in the graph being imported into.
            `src_name` is copied and has no lifetime requirements.
            </summary>
            <param name="opts">TF_ImportGraphDefOptions*</param>
            <param name="src_name">const char*</param>
            <param name="src_index">int</param>
            <param name="dst">TF_Output</param>
        </member>
        <member name="M:Tensorflow.c_api.TF_ImportGraphDefOptionsAddReturnOperation(Tensorflow.SafeImportGraphDefOptionsHandle,System.String)">
            <summary>
            Add an operation in `graph_def` to be returned via the `return_opers` output
            parameter of TF_GraphImportGraphDef(). `oper_name` is copied and has no
            lifetime requirements.
            </summary>
            <param name="opts">TF_ImportGraphDefOptions* opts</param>
            <param name="oper_name">const char*</param>
        </member>
        <member name="M:Tensorflow.c_api.TF_ImportGraphDefOptionsAddReturnOutput(Tensorflow.SafeImportGraphDefOptionsHandle,System.String,System.Int32)">
            <summary>
            Add an output in `graph_def` to be returned via the `return_outputs` output
            parameter of TF_GraphImportGraphDef(). If the output is remapped via an input
            mapping, the corresponding existing tensor in `graph` will be returned.
            `oper_name` is copied and has no lifetime requirements.
            </summary>
            <param name="opts">TF_ImportGraphDefOptions*</param>
            <param name="oper_name">const char*</param>
            <param name="index">int</param>
        </member>
        <member name="M:Tensorflow.c_api.TF_ImportGraphDefOptionsNumReturnOperations(Tensorflow.SafeImportGraphDefOptionsHandle)">
            <summary>
            Returns the number of return operations added via
            TF_ImportGraphDefOptionsAddReturnOperation().
            </summary>
            <param name="opts"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_ImportGraphDefOptionsNumReturnOutputs(Tensorflow.SafeImportGraphDefOptionsHandle)">
            <summary>
            Returns the number of return outputs added via
            TF_ImportGraphDefOptionsAddReturnOutput().
            </summary>
            <param name="opts">const TF_ImportGraphDefOptions*</param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_ImportGraphDefOptionsRemapControlDependency(Tensorflow.SafeImportGraphDefOptionsHandle,System.String,System.IntPtr)">
            <summary>
            Set any imported nodes with control input `src_name` to have that input
            replaced with `dst`. `src_name` refers to a node in the graph to be imported,
            `dst` references an operation already existing in the graph being imported
            into. `src_name` is copied and has no lifetime requirements. 
            </summary>
            <param name="opts">TF_ImportGraphDefOptions*</param>
            <param name="src_name">const char*</param>
            <param name="dst">TF_Operation*</param>
        </member>
        <member name="M:Tensorflow.c_api.TF_ImportGraphDefOptionsSetPrefix(Tensorflow.SafeImportGraphDefOptionsHandle,System.String)">
            <summary>
            Set the prefix to be prepended to the names of nodes in `graph_def` that will
            be imported into `graph`. `prefix` is copied and has no lifetime
            requirements.
            </summary>
            <param name="ops"></param>
        </member>
        <member name="M:Tensorflow.c_api.TF_ImportGraphDefOptionsSetUniquifyNames(Tensorflow.SafeImportGraphDefOptionsHandle,System.Char)">
            <summary>
            Set whether to uniquify imported operation names. If true, imported operation
            names will be modified if their name already exists in the graph. If false,
            conflicting names will be treated as an error. Note that this option has no
            effect if a prefix is set, since the prefix will guarantee all names are
            unique. Defaults to false.
            </summary>
            <param name="ops">TF_ImportGraphDefOptions*</param>
            <param name="uniquify_prefix">unsigned char</param>
        </member>
        <member name="M:Tensorflow.c_api.TF_ImportGraphDefResultsReturnOperations(Tensorflow.SafeImportGraphDefResultsHandle,System.Int32@,Tensorflow.TF_Operation@)">
            <summary>
            Fetches the return operations requested via
            TF_ImportGraphDefOptionsAddReturnOperation(). The number of fetched
            operations is returned in `num_opers`. The array of return operations is
            returned in `opers`. `*opers` is owned by and has the lifetime of `results`.
            </summary>
            <param name="results">TF_ImportGraphDefResults*</param>
            <param name="num_opers">int*</param>
            <param name="opers">TF_Operation***</param>
        </member>
        <member name="M:Tensorflow.c_api.TF_ImportGraphDefResultsReturnOutputs(Tensorflow.SafeImportGraphDefResultsHandle,System.Int32@,System.IntPtr@)">
            <summary>
            Fetches the return outputs requested via
            TF_ImportGraphDefOptionsAddReturnOutput(). The number of fetched outputs is
            returned in `num_outputs`. The array of return outputs is returned in
            `outputs`. `*outputs` is owned by and has the lifetime of `results`.
            </summary>
            <param name="results">TF_ImportGraphDefResults* results</param>
            <param name="num_outputs">int*</param>
            <param name="outputs">TF_Output**</param>
        </member>
        <member name="M:Tensorflow.c_api.TF_LoadSessionFromSavedModel(Tensorflow.SafeSessionOptionsHandle,System.IntPtr,System.String,System.String[],System.Int32,System.IntPtr,Tensorflow.TF_Buffer@,Tensorflow.SafeStatusHandle)">
            <summary>
            This function creates a new TF_Session (which is created on success) using
            `session_options`, and then initializes state (restoring tensors and other
            assets) using `run_options`.
            </summary>
            <param name="session_options">const TF_SessionOptions*</param>
            <param name="run_options">const TF_Buffer*</param>
            <param name="export_dir">const char*</param>
            <param name="tags">const char* const*</param>
            <param name="tags_len">int</param>
            <param name="graph">TF_Graph*</param>
            <param name="meta_graph_def">TF_Buffer*</param>
            <param name="status">TF_Status*</param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_GraphSetOutputHandleShapesAndTypes(System.IntPtr,Tensorflow.TF_Output,System.Int32,System.IntPtr[],System.Int32[],Tensorflow.DataType[],Tensorflow.SafeStatusHandle)">
            <summary>
            Set the shapes and types of the output's handle.
            </summary>
            <param name="graph">TF_Graph*</param>
            <param name="output">TF_Output</param>
            <param name="num_shapes_and_types">int</param>
            <param name="shapes">const int64_t**</param>
            <param name="ranks">const int*</param>
            <param name="types">const TF_DataType*</param>
            <param name="status">TF_Status*</param>
        </member>
        <member name="M:Tensorflow.c_api.TF_UpdateEdge(System.IntPtr,Tensorflow.TF_Output,Tensorflow.TF_Input,Tensorflow.SafeStatusHandle)">
            <summary>
            Updates 'dst' to consume 'new_src'.
            </summary>
            <param name="graph">TF_Graph*</param>
            <param name="new_src"></param>
            <param name="dst"></param>
            <param name="status">TF_Status*</param>
        </member>
        <member name="M:Tensorflow.c_api.TF_ColocateWith(System.IntPtr,System.IntPtr)">
             <summary>
             Request that `desc` be co-located on the device where `op`
             is placed.
            
             Use of this is discouraged since the implementation of device placement is
             subject to change. Primarily intended for internal libraries 
             </summary>
             <param name="desc"></param>
             <param name="op"></param>
        </member>
        <member name="M:Tensorflow.c_api.TF_GetAllOpList">
            <summary>
            Get the OpList of all OpDefs defined in this address space.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_AddInput(System.IntPtr,Tensorflow.TF_Output)">
            <summary>
            For inputs that take a single tensor.
            </summary>
            <param name="desc">TF_OperationDescription*</param>
            <param name="input">TF_Output</param>
        </member>
        <member name="M:Tensorflow.c_api.TF_AddControlInput(System.IntPtr,System.IntPtr)">
            <summary>
            Call once per control input to `desc`.
            </summary>
            <param name="desc">TF_OperationDescription*</param>
            <param name="input">TF_Operation*</param>
        </member>
        <member name="M:Tensorflow.c_api.AddControlInput(System.IntPtr,System.IntPtr,System.IntPtr)">
            <summary>
            
            </summary>
            <param name="graph">TF_Graph*</param>
            <param name="op">TF_Operation*</param>
            <param name="input">TF_Operation*</param>
        </member>
        <member name="M:Tensorflow.c_api.RemoveAllControlInputs(System.IntPtr,System.IntPtr)">
            <summary>
            
            </summary>
            <param name="graph">TF_Graph*</param>
            <param name="op">TF_Operation*</param>
        </member>
        <member name="M:Tensorflow.c_api.TF_AddInputList(System.IntPtr,Tensorflow.TF_Output[],System.Int32)">
            <summary>
            For inputs that take a list of tensors.
            inputs must point to TF_Output[num_inputs].
            </summary>
            <param name="desc"></param>
            <param name="inputs"></param>
        </member>
        <member name="M:Tensorflow.c_api.TF_NewOperation(System.IntPtr,System.String,System.String)">
            <summary>
            Operation will only be added to *graph when TF_FinishOperation() is
            called (assuming TF_FinishOperation() does not return an error).
            *graph must not be deleted until after TF_FinishOperation() is
            called.
            </summary>
            <param name="graph">TF_Graph*</param>
            <param name="opType">const char*</param>
            <param name="oper_name">const char*</param>
            <returns>TF_OperationDescription*</returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_OperationGetControlInputs(System.IntPtr,System.IntPtr,System.Int32)">
            <summary>
            Get list of all control inputs to an operation.  `control_inputs` must
            point to an array of length `max_control_inputs` (ideally set to
            TF_OperationNumControlInputs(oper)).  Returns the number of control
            inputs (should match TF_OperationNumControlInputs(oper)).
            </summary>
            <param name="oper">TF_Operation*</param>
            <param name="control_inputs">TF_Operation**</param>
            <param name="max_control_inputs"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_OperationGetControlOutputs(System.IntPtr,System.IntPtr,System.Int32)">
            <summary>
            Get the list of operations that have `*oper` as a control input.
            `control_outputs` must point to an array of length at least
            `max_control_outputs` (ideally set to
            TF_OperationNumControlOutputs(oper)). Beware that a concurrent
            modification of the graph can increase the number of control
            outputs.  Returns the number of control outputs (should match
            TF_OperationNumControlOutputs(oper)).
            </summary>
            <param name="oper">TF_Operation*</param>
            <param name="control_outputs">TF_Operation**</param>
            <param name="max_control_outputs"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_OperationInput(Tensorflow.TF_Input)">
            <summary>
            TF_Output producer = TF_OperationInput(consumer);
            There is an edge from producer.oper's output (given by
            producer.index) to consumer.oper's input (given by consumer.index).
            </summary>
            <param name="oper_in"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_OperationNumControlInputs(System.IntPtr)">
            <summary>
            Get the number of control inputs to an operation.
            </summary>
            <param name="oper"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_OperationNumControlOutputs(System.IntPtr)">
            <summary>
            Get the number of operations that have `*oper` as a control input.
            </summary>
            <param name="oper"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_OperationOutputNumConsumers(Tensorflow.TF_Output)">
            <summary>
            Get the number of current consumers of a specific output of an
            operation.  Note that this number can change when new operations
            are added to the graph.
            </summary>
            <param name="oper_out"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_OperationOutputConsumers(Tensorflow.TF_Output,System.IntPtr,System.Int32)">
            <summary>
            Get list of all current consumers of a specific output of an
            operation.  `consumers` must point to an array of length at least
            `max_consumers` (ideally set to
            TF_OperationOutputNumConsumers(oper_out)).  Beware that a concurrent
            modification of the graph can increase the number of consumers of
            an operation.  Returns the number of output consumers (should match
            TF_OperationOutputNumConsumers(oper_out)).
            </summary>
            <param name="oper_out">TF_Output</param>
            <param name="consumers">TF_Input*</param>
            <param name="max_consumers">int</param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_DeleteSession(System.IntPtr,Tensorflow.SafeStatusHandle)">
             <summary>
             Destroy a session object.
            
             Even if error information is recorded in *status, this call discards all
             local resources associated with the session.  The session may not be used
             during or after this call (and the session drops its reference to the
             corresponding graph). 
             </summary>
             <param name="session">TF_Session*</param>
             <param name="status">TF_Status*</param>
        </member>
        <member name="M:Tensorflow.c_api.TF_DeleteSessionOptions(System.IntPtr)">
            <summary>
            Destroy an options object.
            </summary>
            <param name="opts">TF_SessionOptions*</param>
        </member>
        <member name="M:Tensorflow.c_api.TF_NewSession(System.IntPtr,Tensorflow.SafeSessionOptionsHandle,Tensorflow.SafeStatusHandle)">
            <summary>
            Return a new execution session with the associated graph, or NULL on
            error. Does not take ownership of any input parameters.
            </summary>
            <param name="graph">TF_Graph*</param>
            <param name="opts">const TF_SessionOptions*</param>
            <param name="status">TF_Status*</param>
            <returns>TF_Session*</returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_NewSessionOptions">
            <summary>
            Return a new options object.
            </summary>
            <returns>TF_SessionOptions*</returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_SessionRun(System.IntPtr,Tensorflow.TF_Buffer*,Tensorflow.TF_Output[],System.IntPtr[],System.Int32,Tensorflow.TF_Output[],System.IntPtr[],System.Int32,System.IntPtr[],System.Int32,System.IntPtr,Tensorflow.SafeStatusHandle)">
             <summary>
             Run the graph associated with the session starting with the supplied inputs
             (inputs[0,ninputs-1] with corresponding values in input_values[0,ninputs-1]).
            
             Any NULL and non-NULL value combinations for (`run_options`,
             `run_metadata`) are valid.
            
                - `run_options` may be NULL, in which case it will be ignored; or
                  non-NULL, in which case it must point to a `TF_Buffer` containing the
                  serialized representation of a `RunOptions` protocol buffer.
                - `run_metadata` may be NULL, in which case it will be ignored; or
                  non-NULL, in which case it must point to an empty, freshly allocated
                  `TF_Buffer` that may be updated to contain the serialized representation
                  of a `RunMetadata` protocol buffer.
            
             The caller retains ownership of `input_values` (which can be deleted using
             TF_DeleteTensor). The caller also retains ownership of `run_options` and/or
             `run_metadata` (when not NULL) and should manually call TF_DeleteBuffer on
             them.
            
             On success, the tensors corresponding to outputs[0,noutputs-1] are placed in
             output_values[]. Ownership of the elements of output_values[] is transferred
             to the caller, which must eventually call TF_DeleteTensor on them.
            
             On failure, output_values[] contains NULLs.
             </summary>
             <param name="session">TF_Session*</param>
             <param name="run_options">const TF_Buffer*</param>
             <param name="inputs">const TF_Output*</param>
             <param name="input_values">TF_Tensor* const*</param>
             <param name="ninputs">int</param>
             <param name="outputs">const TF_Output*</param>
             <param name="output_values">TF_Tensor**</param>
             <param name="noutputs">int</param>
             <param name="target_opers">const TF_Operation* const*</param>
             <param name="ntargets">int</param>
             <param name="run_metadata">TF_Buffer*</param>
             <param name="status">TF_Status*</param>
        </member>
        <member name="M:Tensorflow.c_api.TF_SetConfig(Tensorflow.SafeSessionOptionsHandle,System.IntPtr,System.UInt64,Tensorflow.SafeStatusHandle)">
            <summary>
            Set the config in TF_SessionOptions.options.
            config should be a serialized tensorflow.ConfigProto proto.
            If config was not parsed successfully as a ConfigProto, record the
            error information in *status.
            </summary>
            <param name="options">TF_SessionOptions*</param>
            <param name="proto">const void*</param>
            <param name="proto_len">size_t</param>
            <param name="status">TF_Status*</param>
        </member>
        <member name="M:Tensorflow.c_api.TF_DeleteStatus(System.IntPtr)">
            <summary>
            Delete a previously created status object.
            </summary>
            <param name="s"></param>
        </member>
        <member name="M:Tensorflow.c_api.TF_GetCode(Tensorflow.SafeStatusHandle)">
            <summary>
            Return the code record in *s.
            </summary>
            <param name="s"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_Message(Tensorflow.SafeStatusHandle)">
            <summary>
            Return a pointer to the (null-terminated) error message in *s.
            The return value points to memory that is only usable until the next
            mutation to *s.  Always returns an empty string if TF_GetCode(s) is TF_OK.
            </summary>
            <param name="s"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_NewStatus">
            <summary>
            Return a new status object.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_SetStatus(Tensorflow.SafeStatusHandle,Tensorflow.TF_Code,System.String)">
            <summary>
            Record &lt;code, msg> in *s.  Any previous information is lost.
            A common use is to clear a status: TF_SetStatus(s, TF_OK, "");
            </summary>
            <param name="s"></param>
            <param name="code"></param>
            <param name="msg"></param>
        </member>
        <member name="M:Tensorflow.c_api.TF_AllocateTensor(Tensorflow.TF_DataType,System.Int64[],System.Int32,System.UInt64)">
            <summary>
            Allocate and return a new Tensor.
            </summary>
            <param name="dtype">TF_DataType</param>
            <param name="dims">const int64_t*</param>
            <param name="num_dims">int</param>
            <param name="len">size_t</param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_DataTypeSize(Tensorflow.TF_DataType)">
            <summary>
            returns the sizeof() for the underlying type corresponding to the given TF_DataType enum value.
            </summary>
            <param name="dt"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_DeleteTensor(System.IntPtr)">
            <summary>
            Destroy a tensor.
            </summary>
            <param name="tensor"></param>
        </member>
        <member name="M:Tensorflow.c_api.TF_Dim(System.IntPtr,System.Int32)">
            <summary>
            Return the length of the tensor in the "dim_index" dimension.
            REQUIRES: 0 &lt;= dim_index &lt; TF_NumDims(tensor)
            </summary>
            <param name="tensor"></param>
            <param name="dim_index"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_NewTensor(Tensorflow.TF_DataType,System.Int64[],System.Int32,System.IntPtr,System.UIntPtr,Tensorflow.c_api.Deallocator,Tensorflow.c_api.DeallocatorArgs@)">
            <summary>
            Return a new tensor that holds the bytes data[0,len-1]
            </summary>
            <param name="dataType"></param>
            <param name="dims"></param>
            <param name="num_dims"></param>
            <param name="data"></param>
            <param name="len">num_bytes, ex: 6 * sizeof(float)</param>
            <param name="deallocator"></param>
            <param name="deallocator_arg"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_NewTensor(Tensorflow.TF_DataType,System.Int64[],System.Int32,System.IntPtr,System.UInt64,Tensorflow.c_api.Deallocator,System.IntPtr)">
            <summary>
            Return a new tensor that holds the bytes data[0,len-1]
            </summary>
            <param name="dataType"></param>
            <param name="dims"></param>
            <param name="num_dims"></param>
            <param name="data"></param>
            <param name="len">num_bytes, ex: 6 * sizeof(float)</param>
            <param name="deallocator"></param>
            <param name="deallocator_arg"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_NewTensor(Tensorflow.TF_DataType,System.Int64[],System.Int32,System.IntPtr,System.UInt64)">
            <summary>
            Return a new tensor that holds the bytes data[0,len-1]
            </summary>
            <param name="dataType"></param>
            <param name="dims"></param>
            <param name="num_dims"></param>
            <param name="data"></param>
            <param name="len">num_bytes, ex: 6 * sizeof(float)</param>
        </member>
        <member name="M:Tensorflow.c_api.TF_NewTensor(Tensorflow.TF_DataType,System.Int64[],System.Int32,System.Void*,System.UInt64)">
            <summary>
            Return a new tensor that holds the bytes data[0,len-1]
            </summary>
            <param name="dataType"></param>
            <param name="dims"></param>
            <param name="num_dims"></param>
            <param name="data"></param>
            <param name="len">num_bytes, ex: 6 * sizeof(float)</param>
        </member>
        <member name="M:Tensorflow.c_api.TF_NumDims(System.IntPtr)">
            <summary>
            Return the number of dimensions that the tensor has.
            </summary>
            <param name="tensor"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_TensorByteSize(System.IntPtr)">
            <summary>
            Return the size of the underlying data in bytes.
            </summary>
            <param name="tensor"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_TensorData(System.IntPtr)">
            <summary>
            Return a pointer to the underlying data buffer.
            </summary>
            <param name="tensor"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_TensorMaybeMove(System.IntPtr)">
            <summary>
            Deletes `tensor` and returns a new TF_Tensor with the same content if
            possible. Returns nullptr and leaves `tensor` untouched if not.
            </summary>
            <param name="tensor"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_TensorType(System.IntPtr)">
            <summary>
            Return the type of a tensor element.
            </summary>
            <param name="tensor"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_StringEncodedSize(System.UInt64)">
            <summary>
            Return the size in bytes required to encode a string `len` bytes long into a
            TF_STRING tensor.
            </summary>
            <param name="len">size_t</param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_StringEncode(System.Byte*,System.UInt64,System.Byte*,System.UInt64,Tensorflow.SafeStatusHandle)">
            <summary>
            Encode the string `src` (`src_len` bytes long) into `dst` in the format
            required by TF_STRING tensors. Does not write to memory more than `dst_len`
            bytes beyond `*dst`. `dst_len` should be at least
            TF_StringEncodedSize(src_len).
            </summary>
            <param name="src">const char*</param>
            <param name="src_len">size_t</param>
            <param name="dst">char*</param>
            <param name="dst_len">size_t</param>
            <param name="status">TF_Status*</param>
            <returns>On success returns the size in bytes of the encoded string.</returns>
        </member>
        <member name="M:Tensorflow.c_api.TF_StringDecode(System.Byte*,System.UInt64,System.Byte**,System.UInt64@,Tensorflow.SafeStatusHandle)">
            <summary>
            Decode a string encoded using TF_StringEncode.
            </summary>
            <param name="src">const char*</param>
            <param name="src_len">size_t</param>
            <param name="dst">const char**</param>
            <param name="dst_len">size_t*</param>
            <param name="status">TF_Status*</param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.c_api.MonoPInvokeCallbackAttribute">
            <summary>
            This attribute can be applied to callback functions that will be invoked
            from unmanaged code to managed code.
            </summary>
            <remarks>
            <code>
            [TensorFlow.MonoPInvokeCallback (typeof (BufferReleaseFunc))]
            internal static void MyFreeFunc (IntPtr data, IntPtr length){..}
            </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.c_api.MonoPInvokeCallbackAttribute.#ctor(System.Type)">
            <summary>
            Use this constructor to annotate the type of the callback function that 
            will be invoked from unmanaged code.
            </summary>
            <param name="t">T.</param>
        </member>
        <member name="F:Tensorflow.tensorflow.newaxis">
            <summary>
            A convenient alias for None, useful for indexing arrays.
            </summary>
        </member>
        <member name="F:Tensorflow.tensorflow.ellipsis">
            <summary>
            A convenient alias for ...
            </summary>
        </member>
        <member name="M:Tensorflow.tensorflow.batch_to_space_nd``1(``0,System.Int32[],System.Int32[0:,0:],System.String)">
            <summary>
            BatchToSpace for N-D tensors of type T.
            </summary>
            <typeparam name="T"></typeparam>
            <param name="input"></param>
            <param name="block_shape"></param>
            <param name="crops"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.boolean_mask``2(``0,``1,System.String,System.Int32)">
            <summary>
            Apply boolean mask to tensor.
            </summary>
            <typeparam name="T1"></typeparam>
            <typeparam name="T2"></typeparam>
            <param name="tensor">N-D tensor.</param>
            <param name="mask">K-D boolean tensor, K &lt;= N and K must be known statically.</param>
            <param name="name"></param>
            <param name="axis">A 0-D int Tensor representing the axis in tensor to mask from. </param>
            <returns>(N-K+1)-dimensional tensor populated by entries in tensor corresponding to True values in mask.</returns>
        </member>
        <member name="M:Tensorflow.tensorflow.broadcast_to(Tensorflow.Tensor,Tensorflow.TensorShape,System.String)">
            <summary>
            Broadcast an array for a compatible shape.
            </summary>
            <param name="input"></param>
            <param name="shape"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.concat(System.Collections.Generic.IList{Tensorflow.Tensor},System.Int32,System.String)">
            <summary>
            Concatenates tensors along one dimension.
            </summary>
            <param name="values">A list of `Tensor` objects or a single `Tensor`.</param>
            <param name="axis"></param>
            <param name="name"></param>
            <returns>A `Tensor` resulting from concatenation of the input tensors.</returns>
        </member>
        <member name="M:Tensorflow.tensorflow.expand_dims(Tensorflow.Tensor,System.Int32,System.String,System.Int32)">
            <summary>
            Inserts a dimension of 1 into a tensor's shape.
            </summary>
            <param name="input"></param>
            <param name="axis"></param>
            <param name="name"></param>
            <param name="dim"></param>
            <returns>
            A `Tensor` with the same data as `input`, but its shape has an additional
            dimension of size 1 added.
            </returns>
        </member>
        <member name="M:Tensorflow.tensorflow.fill``1(Tensorflow.Tensor,``0,System.String)">
            <summary>
            Creates a tensor filled with a scalar value.
            </summary>
            <param name="dims"></param>
            <param name="value"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.identity(Tensorflow.Tensor,System.String)">
            <summary>
            Return a tensor with the same shape and contents as input.
            </summary>
            <param name="input"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.gather(Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.Int32)">
            <summary>
            Gather slices from params axis axis according to indices.
            </summary>
            <param name="params"></param>
            <param name="indices"></param>
            <param name="name"></param>
            <param name="axis"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.where``2(Tensorflow.Tensor,``0,``1,System.String)">
            <summary>
            Return the elements, either from `x` or `y`, depending on the `condition`.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.transpose``1(``0,System.Int32[],System.String,System.Boolean)">
            <summary>
            Transposes `a`. Permutes the dimensions according to `perm`.
            </summary>
            <param name="a"></param>
            <param name="perm"></param>
            <param name="name"></param>
            <param name="conjugate"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.reverse(Tensorflow.Tensor,System.Int32[],System.String)">
            <summary>
            Reverses specific dimensions of a tensor.
            </summary>
            <param name="tensor"></param>
            <param name="axis"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.rank(Tensorflow.Tensor,System.String)">
            <summary>
            Returns the rank of a tensor.
            </summary>
            <param name="input"></param>
            <param name="name"></param>
            <returns>Returns a 0-D `int32` `Tensor` representing the rank of `input`.</returns>
        </member>
        <member name="M:Tensorflow.tensorflow.slice``2(Tensorflow.Tensor,``0[],``1[],System.String)">
            <summary>
            Extracts a slice from a tensor.
            </summary>
            <param name="input">A `Tensor`.</param>
            <param name="begin">An `int32` or `int64` `Tensor`.</param>
            <param name="size">An `int32` or `int64` `Tensor`.</param>
            <param name="name">A name for the operation (optional).</param>
            <returns>A `Tensor` the same type as `input`.</returns>
        </member>
        <member name="M:Tensorflow.tensorflow.stack(System.Object,System.Int32,System.String)">
            <summary>
            Stacks a list of rank-`R` tensors into one rank-`(R+1)` tensor.
            </summary>
            <param name="values"></param>
            <param name="axis"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.ones_like(Tensorflow.Tensor,Tensorflow.TF_DataType,System.String,System.Boolean)">
            <summary>
            Creates a tensor with all elements set to 1.
            </summary>
            <param name="tensor"></param>
            <param name="dtype"></param>
            <param name="name">A name for the operation (optional).</param>
            <param name="optimize">
            if true, attempt to statically determine the shape of 'tensor' and
            encode it as a constant.
            </param>
            <returns>A `Tensor` with all elements set to 1.</returns>
        </member>
        <member name="M:Tensorflow.tensorflow.pad(Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.String,System.Int32)">
            <summary>
            Pads a tensor
            </summary>
            <param name="tensor"></param>
            <param name="paddings"></param>
            <param name="mode"></param>
            <param name="name"></param>
            <param name="constant_values"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.placeholder_with_default``1(``0,System.Int32[],System.String)">
            <summary>
            A placeholder op that passes through `input` when its output is not fed.
            </summary>
            <typeparam name="T"></typeparam>
            <param name="input">A `Tensor`. The default value to produce when output is not fed.</param>
            <param name="shape">
            A `tf.TensorShape` or list of `int`s. The (possibly partial) shape of
            the tensor.
            </param>
            <param name="name">A name for the operation (optional).</param>
            <returns>A `Tensor`. Has the same type as `input`.</returns>
        </member>
        <member name="M:Tensorflow.tensorflow.shape(Tensorflow.Tensor,System.String,Tensorflow.TF_DataType)">
            <summary>
            Returns the shape of a tensor.
            </summary>
            <param name="input"></param>
            <param name="name"></param>
            <param name="out_type"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.stack(Tensorflow.Tensor[],System.Int32,System.String)">
            <summary>
            Stacks a list of rank-`R` tensors into one rank-`(R+1)` tensor.
            </summary>
            <param name="values"></param>
            <param name="axis"></param>
            <param name="name"></param>
            <returns>A stacked `Tensor` with the same type as `values`.</returns>
        </member>
        <member name="M:Tensorflow.tensorflow.unstack(Tensorflow.Tensor,System.Nullable{System.Int32},System.Int32,System.String)">
            <summary>
            Unpacks the given dimension of a rank-`R` tensor into rank-`(R-1)` tensors.
            </summary>
            <param name="value"></param>
            <param name="num"></param>
            <param name="axis"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.zeros_like(Tensorflow.Tensor,Tensorflow.TF_DataType,System.String,System.Boolean)">
            <summary>
            Creates a tensor with all elements set to zero.
            </summary>
            <param name="tensor"></param>
            <param name="dtype"></param>
            <param name="name"></param>
            <param name="optimize"></param>
            <returns>A `Tensor` with all elements set to zero.</returns>
        </member>
        <member name="M:Tensorflow.tensorflow.stop_gradient(Tensorflow.Tensor,System.String)">
            <summary>
            Stops gradient computation.
            </summary>
            <param name="x"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.group``1(``0[],System.String)">
            <summary>
            Create an op that groups multiple operations.
            </summary>
            <typeparam name="T"></typeparam>
            <param name="inputs"></param>
            <param name="name"></param>
            <returns>An Operation that executes all its inputs.</returns>
        </member>
        <member name="M:Tensorflow.tensorflow.dynamic_stitch(Tensorflow.Tensor[],Tensorflow.Tensor[],System.String)">
            <summary>
            Interleave the values from the data tensors into a single tensor.
            </summary>
            <param name="indices"></param>
            <param name="data"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.dynamic_partition(Tensorflow.Tensor,Tensorflow.Tensor,System.Int32,System.String)">
            <summary>
            Partitions `data` into `num_partitions` tensors using indices from `partitions`.
            </summary>
            <param name="data"></param>
            <param name="partitions"></param>
            <param name="num_partitions">The number of partitions to output.</param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.assert_equal``2(``0,``1,System.Object[],System.String,System.String)">
            <summary>
            Assert the condition `x == y` holds element-wise.
            </summary>
            <typeparam name="T1"></typeparam>
            <typeparam name="T2"></typeparam>
            <param name="t1"></param>
            <param name="t2"></param>
            <param name="data"></param>
            <param name="message"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.GradientTape(System.Boolean,System.Boolean)">
            <summary>
            Record operations for automatic differentiation.
            </summary>
            <param name="persistent"></param>
            <param name="watch_accessed_variables"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.peak_default_graph">
            <summary>
                Equivalent to <see cref="M:Tensorflow.tensorflow.get_default_graph"/> but does not create a new graph if it there is none.
            </summary>
        </member>
        <member name="M:Tensorflow.tensorflow.Graph">
             <summary>
                 Creates a new graph.
             </summary>
            <remarks>Has no interaction with graph defaulting. Equivalent to new Graph();</remarks>
        </member>
        <member name="M:Tensorflow.tensorflow.image_internal.crop_and_resize(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.Single,System.String)">
            <summary>
            Extracts crops from the input image tensor and resizes them using bilinear sampling or nearest neighbor sampling (possibly with aspect ratio change) to a common output size specified by crop_size. This is more general than the crop_to_bounding_box op which extracts a fixed size slice from the input image and does not allow resizing or aspect ratio change.
            Returns a tensor with crops from the input image at positions defined at the bounding box locations in boxes.The cropped boxes are all resized(with bilinear or nearest neighbor interpolation) to a fixed size = [crop_height, crop_width].The result is a 4 - D tensor[num_boxes, crop_height, crop_width, depth].The resizing is corner aligned. In particular, if boxes = [[0, 0, 1, 1]], the method will give identical results to using tf.image.resize_bilinear() or tf.image.resize_nearest_neighbor() (depends on the method argument) with align_corners = True.
            </summary>
            <param name="image">A Tensor. Must be one of the following types: uint8, uint16, int8, int16, int32, int64, half, float32, float64. A 4-D tensor of shape [batch, image_height, image_width, depth]. Both image_height and image_width need to be positive.</param>
            <param name="boxes">A Tensor of type float32. A 2-D tensor of shape [num_boxes, 4]. The i-th row of the tensor specifies the coordinates of a box in the box_ind[i] image and is specified in normalized coordinates [y1, x1, y2, x2]. A normalized coordinate value of y is mapped to the image coordinate at y * (image_height - 1), so as the [0, 1] interval of normalized image height is mapped to [0, image_height - 1] in image height coordinates. We do allow y1 > y2, in which case the sampled crop is an up-down flipped version of the original image. The width dimension is treated similarly. Normalized coordinates outside the [0, 1] range are allowed, in which case we use extrapolation_value to extrapolate the input image values.</param>
            <param name="box_ind">A Tensor of type int32. A 1-D tensor of shape [num_boxes] with int32 values in [0, batch). The value of box_ind[i] specifies the image that the i-th box refers to.</param>
            <param name="crop_size">A Tensor of type int32. A 1-D tensor of 2 elements, size = [crop_height, crop_width]. All cropped image patches are resized to this size. The aspect ratio of the image content is not preserved. Both crop_height and crop_width need to be positive.</param>
            <param name="method">An optional string from: "bilinear", "nearest". Defaults to "bilinear". A string specifying the sampling method for resizing. It can be either "bilinear" or "nearest" and default to "bilinear". Currently two sampling methods are supported: Bilinear and Nearest Neighbor.</param>
            <param name="extrapolation_value">An optional float. Defaults to 0. Value used for extrapolation, when applicable.</param>
            <param name="name">A name for the operation (optional).</param>
            <returns>A 4-D tensor of shape [num_boxes, crop_height, crop_width, depth].</returns>
        </member>
        <member name="M:Tensorflow.tensorflow.image_internal.is_jpeg(Tensorflow.Tensor,System.String)">
            <summary>
            Convenience function to check if the 'contents' encodes a JPEG image.
            </summary>
            <param name="contents"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.image_internal.resize_nearest_neighbor``1(Tensorflow.Tensor,``0,System.Boolean,System.String,System.Boolean)">
            <summary>
            Resize `images` to `size` using nearest neighbor interpolation.
            </summary>
            <param name="images"></param>
            <param name="size"></param>
            <param name="align_corners"></param>
            <param name="name"></param>
            <param name="half_pixel_centers"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.variance_scaling_initializer(System.Single,System.String,System.Boolean,System.Nullable{System.Int32},Tensorflow.TF_DataType)">
            <summary>
            Initializer capable of adapting its scale to the shape of weights tensors.
            </summary>
            <param name="factor"></param>
            <param name="mode"></param>
            <param name="uniform"></param>
            <param name="seed"></param>
            <param name="dtype"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.layers_internal.batch_normalization(Tensorflow.Tensor,System.Int32,System.Single,System.Single,System.Boolean,System.Boolean,Tensorflow.IInitializer,Tensorflow.IInitializer,Tensorflow.IInitializer,Tensorflow.IInitializer,Tensorflow.Tensor,System.Boolean,System.String,System.Boolean,System.Single)">
            <summary>
            Functional interface for the batch normalization layer.
            http://arxiv.org/abs/1502.03167
            </summary>
            <param name="inputs"></param>
            <param name="axis"></param>
            <param name="momentum"></param>
            <param name="epsilon"></param>
            <param name="center"></param>
            <param name="scale"></param>
            <param name="beta_initializer"></param>
            <param name="gamma_initializer"></param>
            <param name="moving_mean_initializer"></param>
            <param name="moving_variance_initializer"></param>
            <param name="training"></param>
            <param name="trainable"></param>
            <param name="name"></param>
            <param name="renorm"></param>
            <param name="renorm_momentum"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.layers_internal.max_pooling2d(Tensorflow.Tensor,System.Int32[],System.Int32[],System.String,System.String,System.String)">
            <summary>
            Max pooling layer for 2D inputs (e.g. images).
            </summary>
            <param name="inputs">The tensor over which to pool. Must have rank 4.</param>
            <param name="pool_size"></param>
            <param name="strides"></param>
            <param name="padding"></param>
            <param name="data_format"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.layers_internal.dense(Tensorflow.Tensor,System.Int32,Tensorflow.Keras.Activation,System.Boolean,Tensorflow.IInitializer,Tensorflow.IInitializer,System.Boolean,System.String,System.Nullable{System.Boolean})">
            <summary>
                Densely-connected layer class. aka fully-connected<br></br>
                `outputs = activation(inputs * kernel + bias)`
            </summary>
            <param name="inputs"></param>
            <param name="units">Python integer, dimensionality of the output space.</param>
            <param name="activation"></param>
            <param name="use_bias">Boolean, whether the layer uses a bias.</param>
            <param name="kernel_initializer"></param>
            <param name="bias_initializer"></param>
            <param name="trainable"></param>
            <param name="name"></param>
            <param name="reuse"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.layers_internal.flatten(Tensorflow.Tensor,System.String,System.String)">
            <summary>
                Flattens an input tensor while preserving the batch axis (axis 0).
            </summary>
            <param name="inputs">Tensor input.</param>
            <param name="name">The name of the layer.</param>
            <param name="data_format">
                A string, one of `channels_last` (default) or `channels_first`. <br></br>
                The ordering of the dimensions in the inputs. <br></br>
                `channels_last` corresponds to inputs with shape <br></br>
                `(batch, height, width, channels)` while `channels_first` corresponds to <br></br>
                inputs with shape `(batch, channels, height, width)`. 
            </param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.acos(Tensorflow.Tensor,System.String)">
            <summary>
            Computes acos of x element-wise.
            </summary>
            <param name="x"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.asin(Tensorflow.Tensor,System.String)">
            <summary>
            Computes asin of x element-wise.
            </summary>
            <param name="x"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.add_n(Tensorflow.Tensor[],System.String)">
            <summary>
            Adds all input tensors element-wise.
            </summary>
            <param name="inputs"></param>
            <param name="name"></param>
            <returns>A `Tensor` of same shape and type as the elements of `inputs`.</returns>
        </member>
        <member name="M:Tensorflow.tensorflow.atan(Tensorflow.Tensor,System.String)">
            <summary>
            Computes atan of x element-wise.
            </summary>
            <param name="x"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.ceil(Tensorflow.Tensor,System.String)">
            <summary>
            Returns element-wise smallest integer not less than x.
            </summary>
            <param name="x"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.sin(Tensorflow.Tensor,System.String)">
            <summary>
            Computes sin of x element-wise.
            </summary>
            <param name="x"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.sinh(Tensorflow.Tensor,System.String)">
            <summary>
            Computes hyperbolic sine of x element-wise.
            </summary>
            <param name="x"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.cos(Tensorflow.Tensor,System.String)">
            <summary>
            Computes cos of x element-wise.
            </summary>
            <param name="x"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.cosh(Tensorflow.Tensor,System.String)">
            <summary>
            Computes hyperbolic cosine of x element-wise.
            </summary>
            <param name="x"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.floor(Tensorflow.Tensor,System.String)">
            <summary>
            Returns element-wise largest integer not greater than x.
            </summary>
            <param name="x"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.greater``2(``0,``1,System.String)">
            <summary>
            Returns the truth value of (x > y) element-wise.
            </summary>
            <typeparam name="Tx"></typeparam>
            <typeparam name="Ty"></typeparam>
            <param name="x"></param>
            <param name="y"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.greater_equal``2(``0,``1,System.String)">
            <summary>
            Returns the truth value of (x >= y) element-wise.
            </summary>
            <typeparam name="Tx"></typeparam>
            <typeparam name="Ty"></typeparam>
            <param name="x"></param>
            <param name="y"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.less``2(``0,``1,System.String)">
            <summary>
            Returns the truth value of (x &lt; y) element-wise.
            </summary>
            <typeparam name="Tx"></typeparam>
            <typeparam name="Ty"></typeparam>
            <param name="x"></param>
            <param name="y"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.lgamma(Tensorflow.Tensor,System.String)">
            <summary>
            Computes the log of the absolute value of `Gamma(x)` element-wise.
            </summary>
            <param name="x">A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.</param>
            <param name="name">A name for the operation (optional).</param>
            <returns>A `Tensor`. Has the same type as `x`.</returns>
        </member>
        <member name="M:Tensorflow.tensorflow.less_equal``2(``0,``1,System.String)">
            <summary>
            Returns the truth value of (x &lt;= y) element-wise.
            </summary>
            <typeparam name="Tx"></typeparam>
            <typeparam name="Ty"></typeparam>
            <param name="x"></param>
            <param name="y"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.log1p(Tensorflow.Tensor,System.String)">
            <summary>
            Computes natural logarithm of (1 + x) element-wise.
            </summary>
            <param name="x"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow._clip_by_value(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
            Clips tensor values to a specified min and max.
            </summary>
            <param name="t"></param>
            <param name="clip_value_min"></param>
            <param name="clip_value_max"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.clip_by_value``2(Tensorflow.Tensor,``0,``1,System.String)">
            <summary>
               Clips tensor values to a specified min and max.
            </summary>
            <param name="t">
               A <c>Tensor</c>.
            </param>
            <param name="clip_value_min">
               A 0-D (scalar) <c>Tensor</c>, or a <c>Tensor</c> with the same shape
               as <c>t</c>. The minimum value to clip by.
            </param>
            <param name="clip_value_max">
               A 0-D (scalar) <c>Tensor</c>, or a <c>Tensor</c> with the same shape
               as <c>t</c>. The maximum value to clip by.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ClipByValue'.
            </param>
            <returns>
               A clipped <c>Tensor</c> with the same shape as input 't'.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Given a tensor <c>t</c>, this operation returns a tensor of the same type and
               shape as <c>t</c> with its values clipped to <c>clip_value_min</c> and <c>clip_value_max</c>.
               Any values less than <c>clip_value_min</c> are set to <c>clip_value_min</c>. Any values
               greater than <c>clip_value_max</c> are set to <c>clip_value_max</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.tensorflow.subtract(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
            return x - y
            </summary>
            <param name="x"></param>
            <param name="y"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.atan2(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
            Computes arctangent of `y/x` element-wise, respecting signs of the arguments.
            </summary>
            <param name="y"></param>
            <param name="x"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.max``2(``0,``1,System.Boolean,System.String)">
            <summary>
            Computes the maximum of elements across dimensions of a tensor.
            </summary>
            <typeparam name="Tx"></typeparam>
            <typeparam name="Ty"></typeparam>
            <param name="input"></param>
            <param name="axis"></param>
            <param name="keep_dims"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.min``2(``0,``1,System.Boolean,System.String)">
            <summary>
            Computes the minimum of elements across dimensions of a tensor.
            </summary>
            <typeparam name="Tx"></typeparam>
            <typeparam name="Ty"></typeparam>
            <param name="input"></param>
            <param name="axis"></param>
            <param name="keep_dims"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.maximum``2(``0,``1,System.String)">
            <summary>
            Returns the max of x and y (i.e. x > y ? x : y) element-wise.
            </summary>
            <typeparam name="T1"></typeparam>
            <typeparam name="T2"></typeparam>
            <param name="x"></param>
            <param name="y"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.minimum``2(``0,``1,System.String)">
            <summary>
            Returns the min of x and y (i.e. x &lt; y ? x : y) element-wise.
            </summary>
            <typeparam name="T1"></typeparam>
            <typeparam name="T2"></typeparam>
            <param name="x"></param>
            <param name="y"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.multiply``2(``0,``1,System.String)">
            <summary>
            return x * y
            </summary>
            <typeparam name="Tx"></typeparam>
            <typeparam name="Ty"></typeparam>
            <param name="x"></param>
            <param name="y"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.not_equal``2(``0,``1,System.String)">
            <summary>
            Returns the truth value of (x != y) element-wise.
            </summary>
            <param name="x"></param>
            <param name="y"></param>
            <param name="name"></param>
            <returns>A `Tensor` of type bool with the same size as that of x or y.</returns>
        </member>
        <member name="M:Tensorflow.tensorflow.div(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
            Divides x / y elementwise (using Python 2 division operator semantics).
            </summary>
            <param name="x"></param>
            <param name="y"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.floordiv(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
            Divides `x / y` elementwise, rounding toward the most negative integer.
            </summary>
            <param name="x"></param>
            <param name="y"></param>
            <param name="name"></param>
            <returns>`x / y` rounded down.</returns>
        </member>
        <member name="M:Tensorflow.tensorflow.truediv(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
            Divides x / y elementwise (using Python 3 division operator semantics).
            </summary>
            <param name="x"></param>
            <param name="y"></param>
            <param name="name"></param>
            <returns>`x / y` evaluated in floating point.</returns>
        </member>
        <member name="M:Tensorflow.tensorflow.reduce_any(Tensorflow.Tensor,System.Int32[],System.Boolean,System.String)">
            <summary>
            Computes the "logical or" of elements across dimensions of a tensor.
            </summary>
            <param name="input_tensor">The boolean tensor to reduce.</param>
            <param name="axis">The dimensions to reduce.</param>
            <param name="keepdims">If true, retains reduced dimensions with length 1.</param>
            <param name="name"></param>
            <returns>The reduced tensor.</returns>
        </member>
        <member name="M:Tensorflow.tensorflow.reduce_all(Tensorflow.Tensor,System.Int32[],System.Boolean,System.String)">
            <summary>
            Computes the "logical and" of elements across dimensions of a tensor.
            </summary>
            <param name="input_tensor"></param>
            <param name="axis"></param>
            <param name="keepdims"></param>
            <param name="name"></param>
            <returns>The reduced tensor.</returns>
        </member>
        <member name="M:Tensorflow.tensorflow.reduce_prod(Tensorflow.Tensor,System.Int32[],System.Boolean,System.String)">
            <summary>
            Computes the product of elements across dimensions of a tensor.
            </summary>
            <param name="input_tensor"></param>
            <param name="axis"></param>
            <param name="keepdims"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.reduce_sum(Tensorflow.Tensor[],System.Nullable{System.Int32},System.Boolean,System.String)">
            <summary>
            Computes the sum of elements across dimensions of a tensor.
            </summary>
            <param name="input_tensors"></param>
            <param name="axis"></param>
            <param name="keepdims"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.reduce_sum(Tensorflow.Tensor,System.Nullable{System.Int32},System.Nullable{System.Int32},System.Boolean,System.String)">
            <summary>
            Computes the sum of elements across dimensions of a tensor.
            </summary>
            <param name="input"></param>
            <param name="axis"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.reduce_max(Tensorflow.Tensor,System.Int32[],System.Boolean,System.String)">
            <summary>
            Computes the maximum of elements across dimensions of a tensor.
            </summary>
            <param name="input_tensor"></param>
            <param name="axis"></param>
            <param name="keepdims"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.nn_internal.dropout(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Int32},System.String,System.Nullable{System.Single})">
            <summary>
            Computes dropout.
            </summary>
            <param name="x">A floating point tensor.</param>
            <param name="keep_prob">(deprecated) A deprecated alias for `(1-rate)`.</param>
            <param name="noise_shape"></param>
            <param name="seed">Used to create random seeds.</param>
            <param name="name"></param>
            <param name="rate">A scalar `Tensor` with the same type as `x`.</param>
            <returns>A Tensor of the same shape of `x`.</returns>
        </member>
        <member name="M:Tensorflow.tensorflow.nn_internal.dynamic_rnn(Tensorflow.RnnCell,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType,System.Nullable{System.Int32},System.Boolean,System.Boolean)">
            <summary>
            Creates a recurrent neural network specified by RNNCell `cell`.
            </summary>
            <param name="cell">An instance of RNNCell.</param>
            <param name="inputs">The RNN inputs.</param>
            <param name="dtype"></param>
            <param name="swap_memory"></param>
            <param name="time_major"></param>
            <returns>A pair (outputs, state)</returns>
        </member>
        <member name="M:Tensorflow.tensorflow.nn_internal.lrn(Tensorflow.Tensor,System.Int32,System.Int32,System.Int32,System.Single,System.String)">
            <summary>
            Local Response Normalization.
            </summary>
            <param name="input"></param>
            <param name="depth_radius"></param>
            <param name="bias"></param>
            <param name="alpha"></param>
            <param name="beta"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.nn_internal.sparse_softmax_cross_entropy_with_logits(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
            Computes sparse softmax cross entropy between `logits` and `labels`.
            </summary>
            <param name="labels"></param>
            <param name="logits"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.nn_internal.softmax_cross_entropy_with_logits(Tensorflow.Tensor,Tensorflow.Tensor,System.Int32,System.String)">
            <summary>
            Computes softmax cross entropy between `logits` and `labels`.
            </summary>
            <param name="labels"></param>
            <param name="logits"></param>
            <param name="dim"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.nn_internal.sigmoid``1(``0,System.String)">
            <summary>
            Computes sigmoid of `x` element-wise.
            Specifically, `y = 1 / (1 + exp(-x))`.
            </summary>
            <typeparam name="T"></typeparam>
            <param name="x"></param>
            <param name="name">A name for the operation (optional).</param>
            <returns>A Tensor with the same type as `x`.</returns>
        </member>
        <member name="M:Tensorflow.tensorflow.init_scope">
            <summary>
            A context manager that lifts ops out of control-flow scopes and function-building graphs.
            </summary>
        </member>
        <member name="M:Tensorflow.tensorflow.name_scope(System.String,System.String,System.Object)">
            <summary>
            Returns a context manager that creates hierarchical names for operations.
            </summary>
            <param name="name">The name argument that is passed to the op function.</param>
            <param name="default_name">The default name to use if the name argument is None.</param>
            <param name="values">The list of Tensor arguments that are passed to the op function.</param>
            <returns>The scope name.</returns>
        </member>
        <member name="M:Tensorflow.tensorflow.no_op(System.String)">
            <summary>
            Does nothing. Only useful as a placeholder for control edges.
            </summary>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.map_fn(System.Func{Tensorflow.Tensor,Tensorflow.Tensor},Tensorflow.Tensor,Tensorflow.TF_DataType,System.Int32,System.Boolean,System.Boolean,System.Boolean,System.String)">
            <summary>
            map on the list of tensors unpacked from `elems` on dimension 0.
            </summary>
            <param name="fn"></param>
            <param name="elems"></param>
            <param name="dtype"></param>
            <param name="parallel_iterations"></param>
            <param name="back_prop"></param>
            <param name="swap_memory"></param>
            <param name="infer_shape"></param>
            <param name="name"></param>
            <returns>A tensor or (possibly nested) sequence of tensors.</returns>
        </member>
        <member name="M:Tensorflow.tensorflow.PaddingFIFOQueue(System.Int32,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String[],System.String,System.String)">
            <summary>
            A FIFOQueue that supports batching variable-sized tensors by padding.
            </summary>
            <param name="capacity"></param>
            <param name="dtypes"></param>
            <param name="shapes"></param>
            <param name="names"></param>
            <param name="shared_name"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.FIFOQueue(System.Int32,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String[],System.String,System.String)">
            <summary>
            A queue implementation that dequeues elements in first-in first-out order.
            </summary>
            <param name="capacity"></param>
            <param name="dtypes"></param>
            <param name="shapes"></param>
            <param name="names"></param>
            <param name="shared_name"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.PriorityQueue(System.Int32,Tensorflow.TF_DataType,Tensorflow.TensorShape,System.String,System.String)">
            <summary>
            Creates a queue that dequeues elements in a first-in first-out order.
            </summary>
            <param name="capacity"></param>
            <param name="dtype"></param>
            <param name="shape"></param>
            <param name="shared_name"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.Random.normal(Tensorflow.TensorShape,System.Single,System.Single,Tensorflow.TF_DataType,System.Nullable{System.Int32},System.String)">
            <summary>
            Outputs random values from a normal distribution.
            </summary>
            <param name="shape"></param>
            <param name="mean"></param>
            <param name="stddev"></param>
            <param name="dtype"></param>
            <param name="seed"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.Random.truncated_normal(Tensorflow.TensorShape,System.Single,System.Single,Tensorflow.TF_DataType,System.Nullable{System.Int32},System.String)">
            <summary>
            Outputs random values from a truncated normal distribution.
            </summary>
            <param name="shape"></param>
            <param name="mean"></param>
            <param name="stddev"></param>
            <param name="dtype"></param>
            <param name="seed"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.random_shuffle(Tensorflow.Tensor,System.Nullable{System.Int32},System.String)">
            <summary>
            Randomly shuffles a tensor along its first dimension.
            </summary>
            <param name="value"></param>
            <param name="seed"></param>
            <param name="name"></param>
            <returns>
            A tensor of same shape and type as value, shuffled along its 
            first dimension.
            </returns>
        </member>
        <member name="M:Tensorflow.tensorflow.sparse_to_dense``1(Tensorflow.Tensor,Tensorflow.TensorShape,``0,``0,System.Boolean,System.String)">
            <summary>
            Converts a sparse representation into a dense tensor.
            </summary>
            <typeparam name="T"></typeparam>
            <param name="sparse_indices"></param>
            <param name="output_shape"></param>
            <param name="sparse_values"></param>
            <param name="default_value"></param>
            <param name="validate_indices"></param>
            <param name="name"></param>
            <returns>Dense `Tensor` of shape `output_shape`.  Has the same type as `sparse_values`.</returns>
        </member>
        <member name="M:Tensorflow.tensorflow.StringsApi.substr(Tensorflow.Tensor,System.Int32,System.Int32,System.String,System.String)">
            <summary>
            Return substrings from `Tensor` of strings.
            </summary>
            <param name="input"></param>
            <param name="pos"></param>
            <param name="len"></param>
            <param name="name"></param>
            <param name="uint"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.split(Tensorflow.Tensor,System.Int32,Tensorflow.Tensor,System.String)">
            <summary>
            Splits a tensor into sub tensors.
            </summary>
            <param name="value">The Tensor to split.</param>
            <param name="num_split">Either an integer indicating the number of splits along split_dim or a 1-D integer
            Tensor or Python list containing the sizes of each output tensor along split_dim.
            If a scalar then it must evenly divide value.shape[axis]; otherwise the sum of sizes along the split dimension must match that of the value.</param>
            <param name="axis">An integer or scalar int32 Tensor. The dimension along which to split. Must be in the range [-rank(value), rank(value)). Defaults to 0.</param>
            <param name="name">A name for the operation (optional)</param>
            <returns>if num_or_size_splits is a scalar returns num_or_size_splits Tensor objects;
            if num_or_size_splits is a 1-D Tensor returns num_or_size_splits.get_shape[0] Tensor objects resulting from splitting value.</returns>
        </member>
        <member name="M:Tensorflow.tensorflow.variables_initializer(Tensorflow.IVariableV1[],System.String)">
            <summary>
            Returns an Op that initializes a list of variables.
            </summary>
            <param name="var_list">List of `Variable` objects to initialize.</param>
            <param name="name">Optional name for the returned operation.</param>
            <returns>An Op that run the initializers of all the specified variables.</returns>
        </member>
        <member name="M:Tensorflow.tensorflow.trainable_variables(System.String)">
            <summary>
            Returns all variables created with `trainable=True`.
            </summary>
            <param name="scope"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensorflow.constant(System.Object,Tensorflow.TF_DataType,Tensorflow.TensorShape,System.String)">
            <summary>
            
            </summary>
            <param name="value"></param>
            <param name="dtype"></param>
            <param name="shape"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Binding">
            <summary>
            Binding utilities to mimic python functions.
            </summary>
        </member>
        <member name="F:Tensorflow.Binding.None">
            <summary>
                Alias to null, similar to python's None.
                For TensorShape, please use Unknown
            </summary>
        </member>
        <member name="F:Tensorflow.Binding.Unknown">
            <summary>
            Used for TensorShape None
            </summary>
            
        </member>
        <member name="T:Tensorflow.Buffer">
            <summary>
                Represents a TF_Buffer that can be passed to Tensorflow.
            </summary>
        </member>
        <member name="P:Tensorflow.Buffer.DangerousBuffer">
            <remarks>
            <inheritdoc cref="T:Tensorflow.Util.SafeHandleLease" path="/devdoc/usage"/>
            </remarks>
        </member>
        <member name="P:Tensorflow.Buffer.DangerousMemoryBlock">
             <summary>
                 The memory block representing this buffer.
             </summary>
             <remarks>
             <para>The deallocator is set to null.</para>
            
             <inheritdoc cref="T:Tensorflow.Util.SafeHandleLease" path="/devdoc/usage"/>
             </remarks>
        </member>
        <member name="P:Tensorflow.Buffer.Length">
            <summary>
                The bytes length of this buffer.
            </summary>
        </member>
        <member name="M:Tensorflow.Buffer.ToArray">
            <summary>
                Copies this buffer's contents onto a <see cref="T:System.Byte"/> array.
            </summary>
        </member>
        <member name="T:Tensorflow.Clustering.KMeans">
            <summary>
            Creates the graph for k-means clustering.
            </summary>
        </member>
        <member name="T:Tensorflow.Clustering._InitializeClustersOpFactory">
            <summary>
            Internal class to create the op to initialize the clusters.
            </summary>
        </member>
        <member name="T:Tensorflow.Contexts.Context">
            <summary>
            Environment in which eager operations execute.
            </summary>
        </member>
        <member name="M:Tensorflow.Contexts.Context.ensure_initialized">
            <summary>
            Initialize handle and devices if not already done so.
            </summary>
        </member>
        <member name="M:Tensorflow.Contexts.Context.executing_eagerly">
            <summary>
            Checks whether the current thread has eager execution enabled.
            </summary>
            <returns></returns>
        </member>
        <member name="P:Tensorflow.Contexts.ContextSwitch.IsBuildingFunction">
            <summary>
            Whether the context is building a function.
            </summary>
        </member>
        <member name="P:Tensorflow.Contexts.ContextSwitch.EnterContextFn">
            <summary>
            A callable that executes the context switch.
            </summary>
        </member>
        <member name="T:Tensorflow.Contexts.ContextSwitchStack">
            <summary>
            Match the semantics of DefaultGraphStack
            </summary>
        </member>
        <member name="T:Tensorflow.Contrib.Train.HParams">
            <summary>
            Class to hold a set of hyperparameters as name-value pairs.
            </summary>
        </member>
        <member name="T:Tensorflow.BatchDataset">
            <summary>
            A `Dataset` that batches contiguous elements from its input.
            </summary>
        </member>
        <member name="M:Tensorflow.DatasetManager.from_tensor(NumSharp.NDArray)">
            <summary>
            Creates a `Dataset` with a single element, comprising the given tensors.
            </summary>
            <param name="tensors"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Datasets`1.GetNextBatch(NumSharp.NDArray,NumSharp.NDArray,System.Int32,System.Int32)">
            <summary>
            selects a few number of images determined by the batch_size variable (if you don't know why, read about Stochastic Gradient Method)
            </summary>
            <param name="x"></param>
            <param name="y"></param>
            <param name="start"></param>
            <param name="end"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.DatasetV2">
            <summary>
            Abstract class representing a dataset with no inputs.
            </summary>
        </member>
        <member name="M:Tensorflow.IDatasetV2.cache(System.String)">
            <summary>
            Caches the elements in this dataset.
            </summary>
            <param name="filename"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.IDatasetV2.repeat(System.Int32)">
            <summary>
            
            </summary>
            <param name="count"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.IDatasetV2.shard(System.Int32,System.Int32)">
            <summary>
            Creates a `Dataset` that includes only 1/`num_shards` of this dataset.
            </summary>
            <param name="num_shards">The number of shards operating in parallel</param>
            <param name="index">The worker index</param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.IDatasetV2.skip(System.Int32)">
            <summary>
            Creates a `Dataset` that skips `count` elements from this dataset.
            </summary>
            <param name="count"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.IDatasetV2.apply_options">
            <summary>
            Apply options, such as optimization configuration, to the dataset.
            </summary>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.IteratorResourceDeleter">
            <summary>
            An object which cleans up an iterator resource handle.
            </summary>
        </member>
        <member name="T:Tensorflow.MapDataset">
            <summary>
            A `Dataset` that maps a function over elements in its input.
            </summary>
        </member>
        <member name="T:Tensorflow.ModelDataset">
            <summary>
            A `Dataset` that acts as an identity, and models performance.
            </summary>
        </member>
        <member name="T:Tensorflow.OptimizeDataset">
            <summary>
            A `Dataset` that acts as an identity, and applies optimizations.
            </summary>
        </member>
        <member name="T:Tensorflow.OwnedIterator">
            <summary>
            An iterator producing tf.Tensor objects from a tf.data.Dataset.
            </summary>
        </member>
        <member name="T:Tensorflow.PrefetchDataset">
            <summary>
            Creates a `Dataset` that prefetches elements from this dataset.
            </summary>
        </member>
        <member name="T:Tensorflow.RepeatDataset">
            <summary>
            A `Dataset` that repeats its input several times.
            </summary>
        </member>
        <member name="T:Tensorflow.ShardDataset">
            <summary>
            A `Dataset` for sharding its input.
            </summary>
        </member>
        <member name="T:Tensorflow.ShuffleDataset">
            <summary>
            Randomly shuffles the elements of this dataset.
            </summary>
        </member>
        <member name="T:Tensorflow.SkipDataset">
            <summary>
            A `Dataset` skipping the first `count` elements from its input.
            </summary>
        </member>
        <member name="T:Tensorflow.TensorDataset">
            <summary>
            A `Dataset` with a single element.
            </summary>
        </member>
        <member name="T:Tensorflow.UnaryDataset">
            <summary>
            Abstract class representing a dataset with one input.
            </summary>
        </member>
        <member name="T:Tensorflow.UnaryUnchangedStructureDataset">
            <summary>
            Represents a unary dataset with the same input and output structure.
            </summary>
        </member>
        <member name="T:Tensorflow.DisposableObject">
            <summary>
            Abstract class for disposable object allocated in unmanaged runtime.
            </summary>
        </member>
        <member name="M:Tensorflow.DisposableObject.DisposeManagedResources">
            <summary>
                Dispose any managed resources.
            </summary>
            <remarks>Equivalent to what you would perform inside <see cref="M:Tensorflow.DisposableObject.Dispose"/></remarks>
        </member>
        <member name="M:Tensorflow.DisposableObject.DisposeUnmanagedResources(System.IntPtr)">
            <summary>
                Dispose any unmanaged resources related to given <paramref name="handle"/>.
            </summary>
        </member>
        <member name="M:Tensorflow.DisposableObject.EnsureNotDisposed">
            <summary>
                If <see cref="F:Tensorflow.DisposableObject._handle"/> is <see cref="F:System.IntPtr.Zero"/> then throws <see cref="T:System.ObjectDisposedException"/>
            </summary>
            <exception cref="T:System.ObjectDisposedException">When <see cref="F:Tensorflow.DisposableObject._handle"/> is <see cref="F:System.IntPtr.Zero"/></exception>
        </member>
        <member name="T:Tensorflow.Eager.EagerRunner">
            <summary>
            Eager mode runner
            </summary>
            <summary>
            python\eager\pywrap_tfe_src.cc
            </summary>
            <summary>
            python\eager\pywrap_tfe_src.cc
            </summary>
            <summary>
            python\eager\pywrap_tfe_src.cc
            </summary>
            <summary>
            python\eager\pywrap_tfe_src.cc
            </summary>
        </member>
        <member name="M:Tensorflow.Eager.EagerRunner.Execute(Tensorflow.Contexts.Context,System.String,System.Int32,Tensorflow.Tensor[],System.Object[],System.String)">
            <summary>
            Execute a TensorFlow operation.
            </summary>
            <param name="op_name">
            Name of the TensorFlow operation (see REGISTER_OP in C++ code) to 
            execute.
            </param>
            <param name="num_outputs">
            The number of outputs of the operation to fetch.
            </param>
            <param name="inputs">
            A list of inputs to the operation. Each entry should be a Tensor, or
            a value which can be passed to the Tensor constructor to create one.
            </param>
            <param name="attrs">
            A tuple with alternating string attr names and attr values for this
            operation.
            </param>
            <param name="ctx">The value of context.context().</param>
            <param name="name">Customized name for the operation.</param>
            <returns>List of output Tensor objects. The list is empty if there are no outputs</returns>
        </member>
        <member name="M:Tensorflow.Eager.EagerRunner.AddInputToOp(System.Object,System.Boolean,Tensorflow.OpDef.Types.ArgDef,System.Collections.Generic.List{System.Object},System.Collections.Generic.List{Tensorflow.Tensor},Tensorflow.Eager.SafeOpHandle,Tensorflow.Status)">
            <summary>
            Adds input and type attr to the op, and to the list of flattened
            inputs/attrs.
            </summary>
            <param name="inputs"></param>
            <param name="add_type_attr"></param>
            <param name="input_arg"></param>
            <param name="op"></param>
            <param name="status"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Eager.EagerRunner.SetOpAttrWithDefaults(Tensorflow.Contexts.Context,Tensorflow.Eager.SafeOpHandle,Tensorflow.OpDef.Types.AttrDef,System.String,System.Object,System.Collections.Generic.Dictionary{System.String,System.Int64},Tensorflow.Status)">
            <summary>
            This function will set the op attrs required. If an attr has the value of
            None, then it will read the AttrDef to get the default value and set that
            instead. Any failure in this function will simply fall back to the slow
            path.
            </summary>
            <param name="ctx"></param>
            <param name="op"></param>
            <param name="attr"></param>
            <param name="attr_name"></param>
            <param name="attr_value"></param>
            <param name="attr_list_sizes"></param>
            <param name="status"></param>
        </member>
        <member name="T:Tensorflow.TensorflowException">
            <summary>
                Serves as a base class to all exceptions of Tensorflow.NET.
            </summary>
        </member>
        <member name="M:Tensorflow.TensorflowException.#ctor">
            <summary>Initializes a new instance of the <see cref="T:System.Exception"></see> class.</summary>
        </member>
        <member name="M:Tensorflow.TensorflowException.#ctor(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)">
            <summary>Initializes a new instance of the <see cref="T:System.Exception"></see> class with serialized data.</summary>
            <param name="info">The <see cref="T:System.Runtime.Serialization.SerializationInfo"></see> that holds the serialized object data about the exception being thrown.</param>
            <param name="context">The <see cref="T:System.Runtime.Serialization.StreamingContext"></see> that contains contextual information about the source or destination.</param>
            <exception cref="T:System.ArgumentNullException">The <paramref name="info">info</paramref> parameter is null.</exception>
            <exception cref="T:System.Runtime.Serialization.SerializationException">The class name is null or <see cref="P:System.Exception.HResult"></see> is zero (0).</exception>
        </member>
        <member name="M:Tensorflow.TensorflowException.#ctor(System.String)">
            <summary>Initializes a new instance of the <see cref="T:System.Exception"></see> class with a specified error message.</summary>
            <param name="message">The message that describes the error.</param>
        </member>
        <member name="M:Tensorflow.TensorflowException.#ctor(System.String,System.Exception)">
            <summary>Initializes a new instance of the <see cref="T:System.Exception"></see> class with a specified error message and a reference to the inner exception that is the cause of this exception.</summary>
            <param name="message">The error message that explains the reason for the exception.</param>
            <param name="innerException">The exception that is the cause of the current exception, or a null reference (Nothing in Visual Basic) if no inner exception is specified.</param>
        </member>
        <member name="M:Tensorflow.Framework.common_shapes.broadcast_shape(Tensorflow.Tensor,Tensorflow.Tensor)">
            <summary>
            Returns the broadcasted shape between `shape_x` and `shape_y
            </summary>
            <param name="shape_x"></param>
            <param name="shape_y"></param>
        </member>
        <member name="M:Tensorflow.Framework.common_shapes._broadcast_shape_helper(Tensorflow.Tensor,Tensorflow.Tensor)">
            <summary>
            Helper functions for is_broadcast_compatible and broadcast_shape.
            </summary>
            <param name="shape_x"> A `TensorShape`</param>
            <param name="shape_y"> A `TensorShape`</param>
            <return> Returns None if the shapes are not broadcast compatible,
            a list of the broadcast dimensions otherwise.
            </return>
        </member>
        <member name="T:Tensorflow.Framework.CompositeTensor">
            <summary>
            Abstract base class for Tensor-like objects that are composed from Tensors.
            </summary>
        </member>
        <member name="T:Tensorflow.Framework.IndexedSlices">
            <summary>
            A sparse representation of a set of tensor slices at given indices.
            </summary>
        </member>
        <member name="T:Tensorflow.Framework.Models.DenseSpec">
            <summary>
            Describes a dense object with shape, dtype, and name.
            </summary>
        </member>
        <member name="T:Tensorflow.Framework.Models.TypeSpec">
            <summary>
            Specifies a TensorFlow value type.
            </summary>
        </member>
        <member name="T:Tensorflow.Framework.SparseTensor`1">
            <summary>
            Represents a sparse tensor.
            </summary>
        </member>
        <member name="M:Tensorflow.graph_util_impl.convert_variables_to_constants(Tensorflow.Session,Tensorflow.GraphDef,System.String[],System.String[],System.String[])">
            <summary>
            Replaces all the variables in a graph with constants of the same values.
            </summary>
            <param name="sess">Active TensorFlow session containing the variables.</param>
            <param name="input_graph_def">GraphDef object holding the network.</param>
            <param name="output_node_names">List of name strings for the result nodes of the graph.</param>
            <param name="variable_names_whitelist"></param>
            <param name="variable_names_blacklist"></param>
            <returns>GraphDef containing a simplified version of the original.</returns>
        </member>
        <member name="M:Tensorflow.graph_util_impl.get_input_name(Tensorflow.NodeDef)">
            <summary>
            Gets the name of the first input. Errors if suffix is not :0.
            </summary>
            <param name="node"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.meta_graph.export_scoped_meta_graph(System.String,Tensorflow.GraphDef,System.Boolean,System.String,System.Boolean,Tensorflow.SaverDef,System.Boolean,System.Boolean,System.Byte[])">
            <summary>
            Returns `MetaGraphDef` proto. Optionally writes it to filename.
            </summary>
            <param name="filename"></param>
            <param name="graph_def"></param>
            <param name="as_text"></param>
            <param name="unbound_inputs_col_name"></param>
            <param name="clear_devices"></param>
            <param name="saver_def"></param>
            <param name="clear_extraneous_savers"></param>
            <param name="strip_default_attrs"></param>
            <param name="meta_info_def"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.meta_graph.ops_used_by_graph_def(Tensorflow.GraphDef)">
            <summary>
            Collect the list of ops used by a graph.
            </summary>
            <param name="graph_def"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Functions.ConcreteFunction">
            <summary>
            
            </summary>
        </member>
        <member name="T:Tensorflow.Gradients.array_grad">
            <summary>
            tensorflow\python\ops\array_grad.py
            </summary>
        </member>
        <member name="M:Tensorflow.Gradients.array_grad._ConcatGradHelper(Tensorflow.Operation,Tensorflow.Tensor,System.Int32,System.Int32,System.Int32)">
            <summary>
            Gradient for concat op.
            </summary>
            <param name="op">An operation.</param>
            <param name="grad">
            `Tensor` or `IndexedSlices` representing the gradients with respect
            to each output of the op.
            </param>
            <param name="start_value_index">An integer index of the first value in the op.inputs.</param>
            <param name="end_value_index">An integer index of the last value in the op.inputs.</param>
            <param name="dim_index">An interger index of concat_dim or axis parameter in op.inputs.</param>
            <returns>
            Tensors representing the partial gradients with respect to each input
            of the op.
            </returns>
        </member>
        <member name="M:Tensorflow.Gradients.array_grad._ExtractInputShapes(Tensorflow.Tensor[])">
            <summary>
            Extract the shapes of a set of input tensors.
            </summary>
            <param name="inputs"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Gradients.array_grad._GatherV2Grad(Tensorflow.Operation,Tensorflow.Tensor[])">
            <summary>
            Gradient for GatherV2 op.
            </summary>
            <param name="op"></param>
            <param name="grads"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Gradients.array_grad._StridedSliceGrad(Tensorflow.Operation,Tensorflow.Tensor[])">
            <summary>
            Gradient for StridedSlice op.
            </summary>
            <param name="op"></param>
            <param name="grads"></param>
            <returns></returns>
        </member>
        <member name="P:Tensorflow.Gradients.BackpropInitialState.tensor_usage_counts">
            <summary>
            Map from tensor ID to how many references still exist for this tensor in
            the tape.
            </summary>
        </member>
        <member name="P:Tensorflow.Gradients.BackpropInitialState.op_missing_tensor">
            <summary>
            Maps from op ID to how many output tensors of this op still need to have
            their gradients computed.
            </summary>
        </member>
        <member name="T:Tensorflow.Gradients.control_flow_grad">
            <summary>
            Gradients for operators defined in control_flow_ops.py.cs
            </summary>
        </member>
        <member name="M:Tensorflow.Gradients.control_flow_grad._SwitchGrad(Tensorflow.Operation,Tensorflow.Tensor[])">
             <summary>
             Gradients for a Switch op is calculated using a Merge op.
            
             If the switch is a loop switch, it will be visited twice. We create
             the merge on the first visit, and update the other input of the merge
             on the second visit. A next_iteration is also added on second visit.
             </summary>
             <returns></returns>
        </member>
        <member name="M:Tensorflow.Gradients.control_flow_grad.merge(Tensorflow.Tensor[],System.String)">
            <summary>
            Returns the value of an available element of `inputs`.
            </summary>
            <param name="inputs"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Gradients.control_flow_grad._MergeGrad(Tensorflow.Operation,Tensorflow.Tensor[])">
            <summary>
            Gradients for a Merge op are calculated using a Switch op.
            </summary>
        </member>
        <member name="M:Tensorflow.Gradients.control_flow_grad._ExitGrad(Tensorflow.Operation,Tensorflow.Tensor[])">
            <summary>
            Gradients for an exit op are calculated using an Enter op.
            </summary>
        </member>
        <member name="M:Tensorflow.Gradients.control_flow_grad._NextIterationGrad(Tensorflow.Operation,Tensorflow.Tensor[])">
             <summary>
             A forward next_iteration is translated into a backprop identity.
            
              Note that the backprop next_iteration is added in switch grad.
             </summary>
        </member>
        <member name="M:Tensorflow.Gradients.control_flow_grad._EnterGrad(Tensorflow.Operation,Tensorflow.Tensor[])">
            <summary>
            Gradients for an Enter are calculated using an Exit op.
            
             For loop variables, grad is the gradient so just add an exit.
             For loop invariants, we need to add an accumulator loop.
            </summary>
        </member>
        <member name="M:Tensorflow.Gradients.control_flow_grad._LoopCondGrad(Tensorflow.Tensor,Tensorflow.Tensor[])">
            <summary>
            Stop backprop for the predicate of a while loop.
            </summary>
        </member>
        <member name="T:Tensorflow.Gradients.GradientTape">
            <summary>
            Record operations for automatic differentiation.
            
            Operations are recorded if they are executed within this context manager and
            at least one of their inputs is being "watched".
            
            Trainable variables (created by `tf.Variable` or `tf.compat.v1.get_variable`,
            where `trainable=True` is default in both cases) are automatically watched.
            Tensors can be manually watched by invoking the `watch` method on this context
            manager.
            </summary>
        </member>
        <member name="M:Tensorflow.Gradients.GradientTape._push_tape">
            <summary>
            Pushes a new tape onto the tape stack.
            </summary>
        </member>
        <member name="M:Tensorflow.Gradients.GradientTape.watch(Tensorflow.Tensor)">
            <summary>
            Marks this tensor to be watched by the given tape.
            </summary>
            <param name="x"></param>
        </member>
        <member name="M:Tensorflow.Gradients.GradientTape.gradient(Tensorflow.Tensor,Tensorflow.Tensor)">
            <summary>
            Computes the gradient using operations recorded in context of this tape.
            </summary>
            <param name="target"></param>
            <param name="source"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Gradients.GradientTape.stop_recording">
            <summary>
            Temporarily stops recording operations on this tape.
            </summary>
        </member>
        <member name="T:Tensorflow.Gradients.math_grad">
            <summary>
            Gradients for operators defined in math_ops.py.
            </summary>
        </member>
        <member name="M:Tensorflow.Gradients.math_grad._AddNGrad(Tensorflow.Operation,Tensorflow.Tensor[])">
            <summary>
            Copies the gradient to all inputs.
            </summary>
            <param name="op"></param>
            <param name="grads"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Gradients.math_grad._ExpGrad(Tensorflow.Operation,Tensorflow.Tensor[])">
            <summary>
            Returns grad * exp(x).
            </summary>
            <param name="op"></param>
            <param name="grads"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Gradients.math_grad._MaxGrad(Tensorflow.Operation,Tensorflow.Tensor[])">
            <summary>
            Gradient for Max.
            </summary>
            <param name="op"></param>
            <param name="grads"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Gradients.math_grad._MinGrad(Tensorflow.Operation,Tensorflow.Tensor[])">
            <summary>
            Gradient for Min.
            </summary>
            <param name="op"></param>
            <param name="grads"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Gradients.math_grad._MaximumGrad(Tensorflow.Operation,Tensorflow.Tensor[])">
            <summary>
            Returns grad*(x > y, x &lt;= y) with type of grad.
            </summary>
            <param name="op"></param>
            <param name="grads"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Gradients.math_grad._MinimumGrad(Tensorflow.Operation,Tensorflow.Tensor[])">
            <summary>
            Returns grad*(x &lt; y, x >= y) with type of grad.
            </summary>
            <param name="op"></param>
            <param name="grads"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Gradients.math_grad._MaximumMinimumGrad(System.Boolean,Tensorflow.Operation,Tensorflow.Tensor)">
            <summary>
            Factor out the code for the gradient of Maximum or Minimum.
            </summary>
            <param name="op"></param>
            <param name="grad"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Gradients.math_grad.SmartBroadcastGradientArgs(Tensorflow.Tensor,Tensorflow.Tensor)">
            <summary>
            Optimized version of `broadcast_gradient_args` that caches results.
            </summary>
            <param name="x"></param>
            <param name="y"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Gradients.math_grad_eager">
            <summary>
            Gradients for operators defined in math_ops.py.
            </summary>
        </member>
        <member name="T:Tensorflow.Gradients.nn_grad">
            <summary>
            
            </summary>
        </member>
        <member name="M:Tensorflow.Gradients.nn_grad._BiasAddGrad(Tensorflow.Operation,Tensorflow.Tensor[])">
            <summary>
            Return the gradients for the 2 inputs of bias_op.
            </summary>
            <param name="op"></param>
            <param name="grads"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Gradients.nn_grad._SoftmaxGrad(Tensorflow.Operation,Tensorflow.Tensor[])">
            <summary>
            The derivative of the softmax nonlinearity.
            </summary>
            <param name="op"></param>
            <param name="grads"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Gradients.nn_grad._SoftmaxCrossEntropyWithLogitsGrad(Tensorflow.Operation,Tensorflow.Tensor[])">
            <summary>
            Gradient function for SoftmaxCrossEntropyWithLogits.
            </summary>
            <param name="op"></param>
            <param name="grads"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Gradients.nn_grad._Conv2DGrad(Tensorflow.Operation,Tensorflow.Tensor[])">
            <summary>
            Gradient function for Conv2D.
            </summary>
            <param name="op"></param>
            <param name="grads"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Gradients.nn_grad._BaseFusedBatchNormGrad(Tensorflow.Operation,System.Int32,Tensorflow.Tensor[])">
            <summary>
            Return the gradients for the 3 inputs of BatchNorm.
            </summary>
            <param name="op"></param>
            <param name="version"></param>
            <param name="grads"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Gradients.nn_grad._TopKGrad(Tensorflow.Operation,Tensorflow.Tensor[])">
            <summary>
            Return the gradients for TopK.
            </summary>
            <param name="op"></param>
            <param name="grads"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Gradients.OpTape`2">
            <summary>
            Map from operation-id to tape entry.
            </summary>
            <typeparam name="BackwardFunction"></typeparam>
            <typeparam name="TapeTensor"></typeparam>
        </member>
        <member name="T:Tensorflow.Gradients.OpTapeEntry`2">
            <summary>
            Represents an entry in the tape.
            </summary>
            <typeparam name="BackwardFunction"></typeparam>
            <typeparam name="TapeTensor"></typeparam>
        </member>
        <member name="T:Tensorflow.Gradients.RegisterNoGradient">
            <summary>
            REGISTER_NO_GRADIENT_OP("");
            </summary>
        </member>
        <member name="F:Tensorflow.Gradients.Tape.call_state_">
            <summary>
            A deque-backed stack, whose element references are not invalidated by
            pushes and pops at the back.
            </summary>
        </member>
        <member name="M:Tensorflow.Gradients.Tape.Watch(System.Int64)">
            <summary>
            Marks this tensor to be watched by the given tape.
            </summary>
            <param name="x"></param>
        </member>
        <member name="M:Tensorflow.Gradients.Tape.PopTape(Tensorflow.Gradients.ITape)">
            <summary>
            Pops the given tape in the stack.
            </summary>
            <param name="tape"></param>
        </member>
        <member name="T:Tensorflow.Gradients.TensorTape">
            <summary>
            Map from tensor_id to internally-defined operation-id of the operation which
            produced this tensor. A value of -1 means that the tensor was directly
            watched and not the result of any operation in the tape.
            </summary>
        </member>
        <member name="M:Tensorflow.gradients_util._DefaultGradYs(Tensorflow.Tensor[],Tensorflow.Tensor[],System.Boolean,System.String)">
            <summary>
            Fill in default values for grad_ys.
            </summary>
            <param name="grad_ys">List of gradients, can contain None.</param>
            <param name="ys">List of tensors.</param>
            <param name="colocate_gradients_with_ops"></param>
            <param name="gradient_uid"></param>
        </member>
        <member name="M:Tensorflow.gradients_util._PendingCount(System.Collections.Generic.List{Tensorflow.Operation},System.Collections.Generic.List{Tensorflow.Operation},System.Boolean,System.Collections.Generic.List{System.Object},Tensorflow.Tensor[])">
            <summary>
            Initialize the pending count for ops between two lists of Operations.
            'pending_count[op]' indicates the number of backprop inputs
            to this operation.
            </summary>
            <param name="to_ops"></param>
            <param name="from_ops"></param>
            <param name="colocate_gradients_with_ops"></param>
            <param name="func_graphs"></param>
            <param name="xs"></param>
        </member>
        <member name="M:Tensorflow.gradients_util._SetGrad(System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.Collections.Generic.List{Tensorflow.Tensor}}},Tensorflow.Tensor,Tensorflow.Tensor)">
            <summary>
            Sets gradient "grad" in "grads" for tensor "t".
            </summary>
            <param name="grads"></param>
            <param name="t"></param>
            <param name="grad"></param>
        </member>
        <member name="M:Tensorflow.gradients_util._MultiDeviceAddN(Tensorflow.Tensor[],System.String)">
            <summary>
            Adds tensors from potentially multiple devices.
            </summary>
            <param name="tensor_list"></param>
            <param name="gradient_uid"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gradients_util._StopOps(System.Collections.Generic.List{Tensorflow.Operation},System.Collections.Generic.List{Tensorflow.Operation},System.Collections.Generic.Dictionary{System.String,System.Int32},Tensorflow.Tensor[])">
            <summary>
            The set of ops that terminate the gradient computation.
            </summary>
            <param name="from_ops">list of Operations.</param>
            <param name="stop_gradient_ops">list of Operations never to backprop through.</param>
            <param name="pending_count">mapping from operation to number of backprop inputs.</param>
            <param name="xs">list of Tensors.</param>
            <returns>The set of operations.</returns>
        </member>
        <member name="M:Tensorflow.gradients_util._MarkReachedOps(System.Collections.Generic.List{Tensorflow.Operation},System.Collections.Generic.List{Tensorflow.Operation},System.Collections.Generic.List{System.Object})">
            <summary>
            Mark all ops reached from "from_ops"
            </summary>
            <param name="from_ops"></param>
            <param name="reached_ops"></param>
            <param name="func_graphs"></param>
        </member>
        <member name="M:Tensorflow.gradients_util._Consumers(Tensorflow.Tensor,System.Collections.Generic.List{System.Object})">
            <summary>
            Returns the consumers of t, crossing closure boundaries where necessary.
            </summary>
            <param name="t"></param>
            <param name="func_graphs"></param>
        </member>
        <member name="M:Tensorflow.gradients_util._UpdatePendingAndEnqueueReady(System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.Collections.Generic.List{Tensorflow.Tensor}}},Tensorflow.Operation,System.Collections.Generic.Queue{Tensorflow.Operation},System.Collections.Generic.Dictionary{System.String,System.Int32},Tensorflow.Operations.ControlFlows.ControlFlowState,Tensorflow.Tensor[])">
            <summary>
            Update pending count for the inputs of op and enqueue ready ops.
            </summary>
            <param name="grads"></param>
            <param name="op"></param>
            <param name="queue"></param>
            <param name="pending_count"></param>
            <param name="loop_state"></param>
            <param name="xs"></param>
        </member>
        <member name="M:Tensorflow.gradients_util._HasAnyNotNoneGrads(System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{System.Collections.Generic.List{Tensorflow.Tensor}}},Tensorflow.Operation)">
            <summary>
            Return true if op has real gradient.
            </summary>
            <param name="grads"></param>
            <param name="op"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.ops.RegisterGradientFunction(System.String,System.Func{Tensorflow.Operation,Tensorflow.Tensor[],Tensorflow.Tensor[]})">
            <summary>
            Regiter new gradient function
            </summary>
            <param name="name">operation type</param>
            <param name="func">function delegate</param>
        </member>
        <member name="M:Tensorflow.ops.get_collection(System.String,System.String)">
            <summary>
            Wrapper for `Graph.get_collection()` using the default graph.
            contains many standard names for collections.
            </summary>
            <param name="key">
            The key for the collection. For example, the `GraphKeys` class
            </param>
            <param name="scope"></param>
            <returns>
            The list of values in the collection with the given `name`, or
            an empty list if no value has been added to that collection. The
            list contains the values in the order under which they were
            collected.
            </returns>
        </member>
        <member name="M:Tensorflow.ops.convert_to_tensor(System.Object,Tensorflow.TF_DataType,System.String,Tensorflow.TF_DataType,Tensorflow.Contexts.Context)">
            <summary>
            Converts the given `value` to a `Tensor`.
            </summary>
            <param name="value"></param>
            <param name="dtype"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.ops.control_dependencies(System.Object[])">
             <summary>
             Wrapper for `Graph.control_dependencies()` using the default graph.
             
             See `tf.Graph.control_dependencies` for more details.
            
             When eager execution is enabled, any callable object in the `control_inputs`
             list will be called.
             </summary>
             <param name="control_inputs">
             A list of `Operation` or `Tensor` objects which
             must be executed or computed before running the operations
             defined in the context.Can also be `None` to clear the control
             dependencies.If eager execution is enabled, any callable object in the
             `control_inputs` list will be called.
             </param>
             <returns>
             A context manager that specifies control dependencies for all
             operations constructed within the context.
             </returns>
        </member>
        <member name="M:Tensorflow.ops._create_c_op``1(Tensorflow.Graph,Tensorflow.NodeDef,``0[],Tensorflow.Operation[])">
            <summary>
            Creates a TF_Operation.
            </summary>
            <param name="graph">a `Graph`.</param>
            <param name="node_def">`node_def_pb2.NodeDef` for the operation to create.</param>
            <param name="inputs">
            A list of `Tensor`s (corresponding to scalar inputs) and lists of
            `Tensor`s (corresponding to sequence inputs, e.g. "int64 * N",
            "list(int64)"). The length of the list should be equal to the number of
            inputs specified by this operation's op def.
            </param>
            <param name="control_inputs">A list of `Operation`s to set as control dependencies.</param>
            <returns>A wrapped TF_Operation*.</returns>
        </member>
        <member name="M:Tensorflow.ops.init_scope">
            <summary>
            A context manager that lifts ops out of control-flow scopes and function-building graphs.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.ops.uid">
            <summary>
            A unique (within this program execution) integer.
            Not thread safe
            </summary>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.ops._eval_using_default_session(Tensorflow.Tensor,Tensorflow.FeedItem[],Tensorflow.Graph,Tensorflow.Session)">
            <summary>
            Uses the default session to evaluate one or more tensors.
            </summary>
            <param name="tensor">A single Tensor, or a list of Tensor objects.</param>
            <param name="feed_dict">
            A dictionary that maps Tensor objects (or tensor names) to lists,
            numpy ndarrays, TensorProtos, or strings.
            </param>
            <param name="graph">The graph in which the tensors are defined.</param>
            <param name="session">A different session to use to evaluate "tensors".</param>
            <returns>
            Either a single numpy ndarray if "tensors" is a single tensor; or a list
            of numpy ndarrays that each correspond to the respective element in
            "tensors".
            </returns>
        </member>
        <member name="M:Tensorflow.ops.prepend_name_scope(System.String,System.String)">
            <summary>
            Prepends name scope to a name.
            </summary>
            <param name="name"></param>
            <param name="import_scope"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.ops.GraphKeys">
            <summary>
            Standard names to use for graph collections.
            The standard library uses various well-known names to collect and
            retrieve values associated with a graph. For example, the
            `tf.Optimizer` subclasses default to optimizing the variables
            collected under `tf.GraphKeys.TRAINABLE_VARIABLES` if none is
            specified, but it is also possible to pass an explicit list of
            variables.
            </summary>
        </member>
        <member name="F:Tensorflow.ops.GraphKeys.CONCATENATED_VARIABLES_">
            <summary>
            Key to collect concatenated sharded variables.
            </summary>
        </member>
        <member name="F:Tensorflow.ops.GraphKeys.TRAINABLE_VARIABLES_">
            <summary>
            the subset of `Variable` objects that will be trained by an optimizer.
            </summary>
        </member>
        <member name="F:Tensorflow.ops.GraphKeys.TRAINABLE_RESOURCE_VARIABLES_">
            <summary>
            Trainable resource-style variables.
            </summary>
        </member>
        <member name="F:Tensorflow.ops.GraphKeys._STREAMING_MODEL_PORTS_">
            <summary>
            Key for streaming model ports.
            </summary>
        </member>
        <member name="F:Tensorflow.ops.GraphKeys.LOSSES_">
            <summary>
            Key to collect losses
            </summary>
        </member>
        <member name="F:Tensorflow.ops.GraphKeys.GLOBAL_VARIABLES_">
            <summary>
            Key to collect Variable objects that are global (shared across machines).
            Default collection for all variables, except local ones.
            </summary>
        </member>
        <member name="F:Tensorflow.ops.GraphKeys._VARIABLE_COLLECTIONS_">
            <summary>
            List of all collections that keep track of variables.
            </summary>
        </member>
        <member name="F:Tensorflow.ops.GraphKeys.SAVEABLE_OBJECTS_">
            <summary>
            Key to collect BaseSaverBuilder.SaveableObject instances for checkpointing.
            </summary>
        </member>
        <member name="F:Tensorflow.ops.GraphKeys.UPDATE_OPS_">
            <summary>
            Key to collect update_ops
            </summary>
        </member>
        <member name="P:Tensorflow.ops.GraphKeys.TRAINABLE_VARIABLES">
            <summary>
            the subset of `Variable` objects that will be trained by an optimizer.
            </summary>
        </member>
        <member name="P:Tensorflow.ops.GraphKeys.TRAINABLE_RESOURCE_VARIABLES">
            <summary>
            Trainable resource-style variables.
            </summary>
        </member>
        <member name="P:Tensorflow.ops.GraphKeys._STREAMING_MODEL_PORTS">
            <summary>
            Key for streaming model ports.
            </summary>
        </member>
        <member name="F:Tensorflow.ops.GraphKeys.LOCAL_VARIABLES">
            <summary>
            Key to collect local variables that are local to the machine and are not
            saved/restored.
            </summary>
        </member>
        <member name="P:Tensorflow.ops.GraphKeys.LOSSES">
            <summary>
            Key to collect losses
            </summary>
        </member>
        <member name="P:Tensorflow.ops.GraphKeys.GLOBAL_VARIABLES">
            <summary>
            Key to collect Variable objects that are global (shared across machines).
            Default collection for all variables, except local ones.
            </summary>
        </member>
        <member name="P:Tensorflow.ops.GraphKeys.SAVEABLE_OBJECTS">
            <summary>
            Key to collect BaseSaverBuilder.SaveableObject instances for checkpointing.
            </summary>
        </member>
        <member name="P:Tensorflow.ops.GraphKeys.UPDATE_OPS">
            <summary>
            Key to collect update_ops
            </summary>
        </member>
        <member name="T:Tensorflow.ops.NameScope">
            <summary>
            Returns a context manager that creates hierarchical names for operations.
            </summary>
        </member>
        <member name="M:Tensorflow.ops.NameScope.op_Implicit(Tensorflow.ops.NameScope)~System.String">
            <summary>
            __enter__()
            </summary>
            <param name="ns"></param>
        </member>
        <member name="P:Tensorflow.ops.IsSingleThreaded">
            <summary>
                Does this library ignore different thread accessing.
            </summary>
            <remarks>https://github.com/SciSharp/TensorFlow.NET/wiki/Multithreading </remarks>
        </member>
        <member name="M:Tensorflow.ops.enforce_singlethreading">
            <summary>
                Forces the library to ignore different thread accessing.
            </summary>
            <remarks>https://github.com/SciSharp/TensorFlow.NET/wiki/Multithreading <br></br>Note that this discards any sessions and graphs used in a multithreaded manner</remarks>
        </member>
        <member name="M:Tensorflow.ops.enforce_multithreading">
            <summary>
                Forces the library to provide a separate <see cref="T:Tensorflow.Session"/> and <see cref="T:Tensorflow.Graph"/> to every different thread accessing.
            </summary>
            <remarks>https://github.com/SciSharp/TensorFlow.NET/wiki/Multithreading <br></br>Note that this discards any sessions and graphs used in a singlethreaded manner</remarks>
        </member>
        <member name="M:Tensorflow.ops.get_default_session">
            <summary>
            Returns the default session for the current thread.
            </summary>
            <returns>The default `Session` being used in the current thread.</returns>
        </member>
        <member name="M:Tensorflow.ops.set_default_session(Tensorflow.Session)">
            <summary>
            Returns the default session for the current thread.
            </summary>
            <returns>The default `Session` being used in the current thread.</returns>
        </member>
        <member name="M:Tensorflow.ops.get_default_graph">
            <summary>                                                                  
                Returns the default graph for the current thread.                      
                                                                                       
                The returned graph will be the innermost graph on which a              
                `Graph.as_default()` context has been entered, or a global default     
                graph if none has been explicitly created.                             
                                                                                       
                NOTE: The default graph is a property of the current thread.If you     
                create a new thread, and wish to use the default graph in that         
                thread, you must explicitly add a `with g.as_default():` in that       
                thread's function.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.ops.reset_default_graph">
            <summary>
                Clears the default graph stack and resets the global default graph.
                
                NOTE: The default graph is a property of the current thread.This
                function applies only to the current thread.Calling this function while
                a `tf.Session` or `tf.InteractiveSession` is active will result in undefined
                behavior. Using any previously created `tf.Operation` or `tf.Tensor` objects
                after calling this function will result in undefined behavior.
            </summary>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Graphs.FuncGraph">
            <summary>
            Graph representing a function body.
            </summary>
        </member>
        <member name="M:Tensorflow.Graphs.FuncGraph.#ctor(System.String)">
            <summary>
            Construct a new FuncGraph.
            </summary>
        </member>
        <member name="T:Tensorflow.DefaultGraphStack">
            <summary>
                Serves as a stack for determining current default graph.
            </summary>
        </member>
        <member name="T:Tensorflow.Graph">
            <summary>
                TensorFlow uses a dataflow graph to represent your computation in terms of the dependencies between individual operations. 
                This leads to a low-level programming model in which you first define the dataflow graph, 
                then create a TensorFlow session to run parts of the graph across a set of local and remote devices.
            </summary>
            <remarks>https://www.tensorflow.org/guide/graphs <br></br>https://www.tensorflow.org/api_docs/python/tf/Graph</remarks>
        </member>
        <member name="M:Tensorflow.Graph._control_dependencies_for_inputs(Tensorflow.ITensorOrOperation[])">
            <summary>
            For an op that takes `input_ops` as inputs, compute control inputs.
            </summary>
            <param name="input_ops">The data input ops for an op to be created.</param>
            <returns>A list of control inputs for the op to be created.</returns>
        </member>
        <member name="M:Tensorflow.Graph.control_dependencies(Tensorflow.ITensorOrOperation[])">
            <summary>
            Returns a context manager that specifies control dependencies.
            
            Use with the `with` keyword to specify that all operations constructed
            within the context should have control dependencies on
            `control_inputs`. 
            </summary>
        </member>
        <member name="M:Tensorflow.Graph.control_dependencies(System.Object[])">
            <summary>
            Returns a context manager that specifies control dependencies.
            
            Use with the `with` keyword to specify that all operations constructed
            within the context should have control dependencies on
            `control_inputs`. 
            </summary>
        </member>
        <member name="M:Tensorflow.Graph._get_control_flow_context">
            <summary>
            Returns the current control flow context.
            </summary>
            <returns>A context object.</returns>
        </member>
        <member name="M:Tensorflow.Graph._set_control_flow_context(Tensorflow.Operations.ControlFlowContext)">
            <summary>
            Sets the current control flow context.
            </summary>
            <param name="ctx">a context object.</param>
        </member>
        <member name="M:Tensorflow.Graph._record_op_seen_by_control_dependencies(Tensorflow.Operation)">
            <summary>
            Record that the given op depends on all registered control dependencies.
            </summary>
        </member>
        <member name="F:Tensorflow.Graph._finalized">
            <summary>
            True if the graph is considered "finalized".  In that case no
            new operations can be added.
            </summary>
        </member>
        <member name="F:Tensorflow.Graph._collections">
            <summary>
            Arbitrary collections of objects.
            </summary>
        </member>
        <member name="M:Tensorflow.Graph.as_default">
            <summary>
            Returns a context manager that makes this `Graph` the default graph.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Graph.unique_name(System.String,System.Boolean)">
            <summary>
            Return a unique operation name for `name`.
            
            Note: You rarely need to call `unique_name()` directly.Most of
            the time you just need to create `with g.name_scope()` blocks to
            generate structured names.
            
            `unique_name` is used to generate structured names, separated by
            `"/"`, to help identify operations when debugging a graph.
            Operation names are displayed in error messages reported by the
            TensorFlow runtime, and in various visualization tools such as
            TensorBoard.
            
            If `mark_as_used` is set to `True`, which is the default, a new
            unique name is created and marked as in use.If it's set to `False`,
            the unique name is returned without actually being marked as used.
            This is useful when the caller simply wants to know what the name
            to be created will be.
            </summary>
            <param name="name">The name for an operation.</param>
            <param name="mark_as_used"> Whether to mark this name as being used.</param>
            <returns>A string to be passed to `create_op()` that will be used
            to name the operation being created.</returns>
        </member>
        <member name="M:Tensorflow.Graph.get_tensor_by_name(System.String)">
            <summary>
            Returns the <see cref="T:Tensorflow.Tensor"/> with the given <paramref name="name"/>.
            This method may be called concurrently from multiple threads.
            </summary>
            <param name="name">The name of the `Tensor` to return.</param>
            <exception cref="T:Tensorflow.KeyError">If <paramref name="name"/> does not correspond to a tensor in this graph.</exception>
            <returns>The `Tensor` with the given <paramref name="name"/>.</returns>
        </member>
        <member name="M:Tensorflow.Graph.OperationByName(System.String)">
            <summary>
                Get operation with given <paramref name="operName"/>
            </summary>
            <exception cref="T:Tensorflow.ValueError">When <paramref name="operName"/> is not found current graph.</exception>
            <exception cref="T:Tensorflow.RuntimeError">When tf.get_default_graph() is not current graph.</exception>
            <example>
                graph.GetOperationByName("CustomInputName");
            </example>
        </member>
        <member name="M:Tensorflow.Graph.get_operation_by_name(System.String)">
            <summary>
            Returns the `Operation` with the given `name`.
            
            This method may be called concurrently from multiple threads.
            </summary>
            <param name="name">The name of the `Operation` to return.</param>
        </member>
        <member name="M:Tensorflow.Graph._create_op_from_tf_operation(System.IntPtr,System.Boolean)">
            <summary>
            Creates an `Operation` in this graph from the supplied TF_Operation.
            
            This method is like create_op() except the new Operation is constructed
            using `c_op`. The returned Operation will have `c_op` as its _c_op
            field.This is used to create Operation objects around TF_Operations created
            indirectly by the C API(e.g.by TF_ImportGraphDef, TF_FinishWhile).
            
            This function does not call Operation._control_flow_post_processing or
            Graph._control_dependencies_for_inputs (since the inputs may not be
            available yet). The caller is responsible for calling these methods.
            </summary>
            <param name="c_op">a wrapped TF_Operation</param>
            <param name="compute_device">(Optional.) If True, device functions will be executed
            to compute the device property of the Operation.</param>
            <returns>An `Operation` object.</returns>
        </member>
        <member name="M:Tensorflow.Graph._add_new_tf_operations(System.Boolean)">
            <summary>
            Creates `Operations` in this graph for any new TF_Operations.
            
            This is useful for when TF_Operations are indirectly created by the C API
            outside of the Operation constructor (e.g. by TF_ImportGraphDef,
            TF_FinishWhile). This ensures there are corresponding Operations for all
            TF_Operations in the underlying TF_Graph.
            </summary>
            <param name="compute_devices"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow._ControlDependenciesController">
            <summary>
            Context manager for `control_dependencies()`
            </summary>
        </member>
        <member name="M:Tensorflow._ControlDependenciesController.#ctor(Tensorflow.Graph,System.Collections.Generic.List{Tensorflow.ITensorOrOperation})">
            <summary>
            Create a new `_ControlDependenciesController`.
            
            A `_ControlDependenciesController` is the context manager for
            `with tf.control_dependencies()` blocks.These normally nest,
            as described in the documentation for `control_dependencies()`.
            
            The `control_inputs` argument list control dependencies that must be
            added to the current set of control dependencies.Because of
            uniquification the set can be empty even if the caller passed a list of
            ops.The special value `None` indicates that we want to start a new
            empty set of control dependencies instead of extending the current set.
            
            In that case we also clear the current control flow context, which is an
            additional mechanism to add control dependencies.
            </summary>
            <param name="graph">The graph that this controller is managing.</param>
            <param name="control_inputs">List of ops to use as control inputs in addition
            to the current control dependencies.None to indicate that
            the dependencies should be cleared.
            </param>
        </member>
        <member name="M:Tensorflow.GraphTransformer.TransformGraph(Tensorflow.GraphDef,System.String[],System.String[],System.String[])">
            <summary>
            Graph Transform Tool
            https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md
            </summary>
            <param name="input_graph_def">GraphDef object containing a model to be transformed</param>
            <param name="inputs">the model inputs</param>
            <param name="outputs">the model outputs</param>
            <param name="transforms">transform names and parameters</param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.ITensorFlowObject.__init__">
            <summary>
            Called when the instance is created.
            </summary>
        </member>
        <member name="T:Tensorflow.ITensorOrOperation">
            <summary>
            in order to limit function return value 
            is Tensor or Operation
            </summary>
        </member>
        <member name="T:Tensorflow.ITensorOrTensorArray">
            <summary>
            in order to limit function return value 
            is Tensor or TensorArray
            </summary>
        </member>
        <member name="M:Tensorflow.IO.GFile.Walk(System.String,System.Boolean)">
            <summary>
            Recursive directory tree generator for directories.
            </summary>
            <param name="top">a Directory name</param>
            <param name="in_order">Traverse in order if True, post order if False.</param>
        </member>
        <member name="F:Tensorflow.Keras.Activations.Linear">
            <summary>
            Linear activation function (pass-through).
            </summary>
        </member>
        <member name="P:Tensorflow.Keras.ArgsDefinition.ConvArgs.Strides">
            <summary>
            specifying the stride length of the convolution.
            </summary>
        </member>
        <member name="P:Tensorflow.Keras.ArgsDefinition.DenseArgs.Units">
            <summary>
            Positive integer, dimensionality of the output space.
            </summary>
        </member>
        <member name="P:Tensorflow.Keras.ArgsDefinition.DenseArgs.Activation">
            <summary>
            Activation function to use.
            </summary>
        </member>
        <member name="P:Tensorflow.Keras.ArgsDefinition.DenseArgs.UseBias">
            <summary>
            Whether the layer uses a bias vector.
            </summary>
        </member>
        <member name="P:Tensorflow.Keras.ArgsDefinition.DenseArgs.KernelInitializer">
            <summary>
            Initializer for the `kernel` weights matrix.
            </summary>
        </member>
        <member name="P:Tensorflow.Keras.ArgsDefinition.DenseArgs.BiasInitializer">
            <summary>
            Initializer for the bias vector.
            </summary>
        </member>
        <member name="P:Tensorflow.Keras.ArgsDefinition.DenseArgs.KernelRegularizer">
            <summary>
            Regularizer function applied to the `kernel` weights matrix.
            </summary>
        </member>
        <member name="P:Tensorflow.Keras.ArgsDefinition.DenseArgs.BiasRegularizer">
            <summary>
            Regularizer function applied to the bias vector.
            </summary>
        </member>
        <member name="P:Tensorflow.Keras.ArgsDefinition.DenseArgs.KernelConstraint">
            <summary>
            Constraint function applied to the `kernel` weights matrix.
            </summary>
        </member>
        <member name="P:Tensorflow.Keras.ArgsDefinition.DenseArgs.BiasConstraint">
            <summary>
            Constraint function applied to the bias vector.
            </summary>
        </member>
        <member name="P:Tensorflow.Keras.ArgsDefinition.DropoutArgs.Rate">
            <summary>
            Float between 0 and 1. Fraction of the input units to drop.
            </summary>
        </member>
        <member name="P:Tensorflow.Keras.ArgsDefinition.DropoutArgs.NoiseShape">
            <summary>
            1D integer tensor representing the shape of the
            binary dropout mask that will be multiplied with the input.
            </summary>
        </member>
        <member name="P:Tensorflow.Keras.ArgsDefinition.DropoutArgs.Seed">
            <summary>
            random seed.
            </summary>
        </member>
        <member name="P:Tensorflow.Keras.ArgsDefinition.LayerArgs.Trainable">
            <summary>
            Indicates whether the layer's weights are updated during training
            and whether the layer's updates are run during training.
            </summary>
        </member>
        <member name="P:Tensorflow.Keras.ArgsDefinition.LayerArgs.DType">
            <summary>
            Only applicable to input layers.
            </summary>
        </member>
        <member name="P:Tensorflow.Keras.ArgsDefinition.LayerArgs.Dynamic">
            <summary>
            Whether the `call` method can be used to build a TF graph without issues.
            This attribute has no effect if the model is created using the Functional
            API. Instead, `model.dynamic` is determined based on the internal layers.
            </summary>
        </member>
        <member name="P:Tensorflow.Keras.ArgsDefinition.LayerArgs.InputShape">
            <summary>
            Only applicable to input layers.
            </summary>
        </member>
        <member name="P:Tensorflow.Keras.ArgsDefinition.LayerArgs.BatchInputShape">
            <summary>
            Only applicable to input layers.
            </summary>
        </member>
        <member name="P:Tensorflow.Keras.ArgsDefinition.LayerArgs.Weights">
            <summary>
            Initial weight values.
            </summary>
        </member>
        <member name="P:Tensorflow.Keras.ArgsDefinition.LayerArgs.ActivityRegularizer">
            <summary>
            Regularizer function applied to the output of the layer(its "activation").
            </summary>
        </member>
        <member name="P:Tensorflow.Keras.ArgsDefinition.Pooling2DArgs.PoolFunction">
            <summary>
            The pooling function to apply, e.g. `tf.nn.max_pool2d`.
            </summary>
        </member>
        <member name="P:Tensorflow.Keras.ArgsDefinition.Pooling2DArgs.PoolSize">
            <summary>
            specifying the size of the pooling window.
            </summary>
        </member>
        <member name="P:Tensorflow.Keras.ArgsDefinition.Pooling2DArgs.Strides">
            <summary>
            specifying the strides of the pooling operation.
            </summary>
        </member>
        <member name="P:Tensorflow.Keras.ArgsDefinition.Pooling2DArgs.Padding">
            <summary>
            The padding method, either 'valid' or 'same'.
            </summary>
        </member>
        <member name="P:Tensorflow.Keras.ArgsDefinition.Pooling2DArgs.DataFormat">
            <summary>
            one of `channels_last` (default) or `channels_first`.
            </summary>
        </member>
        <member name="F:Tensorflow.Keras.BackendImpl.PER_GRAPH_LAYER_NAME_UIDS">
            <summary>
            A global dictionary mapping graph objects to an index of counters used
            for various layer names in each graph.
            Allows to give unique autogenerated names to layers, in a graph-specific way.
            </summary>
        </member>
        <member name="M:Tensorflow.Keras.Datasets.Mnist.load_data">
            <summary>
            Loads the [MNIST dataset](http://yann.lecun.com/exdb/mnist/).
            </summary>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Keras.Engine.DataAdapters.DataHandler">
            <summary>
            Handles iterating over epoch-level `tf.data.Iterator` objects.
            </summary>
        </member>
        <member name="T:Tensorflow.Keras.Engine.DataAdapters.IDataAdapter">
            <summary>
            In TF 2.0, tf.data is the preferred API for user to feed in data. In order
            to simplify the training code path, all the input data object will be
            converted to `tf.data.Dataset` if possible.
            </summary>
        </member>
        <member name="M:Tensorflow.Keras.Engine.DataAdapters.IDataAdapter.CanHandle(Tensorflow.Tensor,Tensorflow.Tensor)">
            <summary>
            Whether the current DataAdapter could handle the input x and y.
            </summary>
            <param name="x">input features</param>
            <param name="y">target labels</param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Keras.Engine.DataAdapters.TensorLikeDataAdapter">
            <summary>
            Adapter that handles Tensor-like objects, e.g. EagerTensor and NumPy.
            </summary>
        </member>
        <member name="T:Tensorflow.Keras.Engine.InputSpec">
            <summary>
            Specifies the ndim, dtype and shape of every input to a layer.
            </summary>
        </member>
        <member name="T:Tensorflow.Keras.Engine.Layer">
            <summary>
            Base layer class.
            A layer is a class implementing common neural networks operations, such
            as convolution, batch norm, etc. These operations require managing weights,
            losses, updates, and inter-layer connectivity.
            </summary>
        </member>
        <member name="F:Tensorflow.Keras.Engine.Layer.args">
            <summary>
            Arguments initialize layer.
            </summary>
        </member>
        <member name="F:Tensorflow.Keras.Engine.Layer.built">
            <summary>
            Indicates whether `build` needs to be called upon layer call, to create
            the layer's weights.
            </summary>
        </member>
        <member name="F:Tensorflow.Keras.Engine.Layer.stateful">
            <summary>
            A stateful layer is a layer whose updates are run during inference too,
            for instance stateful RNNs.
            </summary>
        </member>
        <member name="F:Tensorflow.Keras.Engine.Layer.inputSpec">
            <summary>
            Provides information about which inputs are compatible with the layer.
            </summary>
        </member>
        <member name="M:Tensorflow.Keras.Engine.Layer.Apply(Tensorflow.Tensor,System.Boolean)">
            <summary>
            Wraps `call`, applying pre- and post-processing steps.
            </summary>
            <param name="input"></param>
            <param name="is_training"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Keras.Engine.Model">
            <summary>
            `Model` groups layers into an object with training and inference features.
            </summary>
        </member>
        <member name="M:Tensorflow.Keras.Engine.Model.predict(Tensorflow.Tensor,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32,System.Boolean)">
            <summary>
            Generates output predictions for the input samples.
            </summary>
            <param name="x">Input samples</param>
            <param name="batch_size">Number of samples per batch</param>
            <param name="verbose">Verbosity mode</param>
            <param name="steps">
            Total number of steps (batches of samples)
            before declaring the prediction round finished.
            </param>
            <param name="max_queue_size"></param>
            <param name="workers"></param>
            <param name="use_multiprocessing"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Keras.Engine.Node">
            <summary>
            A `Node` describes the connectivity between two layers.
            
            Each time a layer is connected to some new input,
            a node is added to `layer._inbound_nodes`.
            Each time the output of a layer is used by another layer,
            a node is added to `layer._outbound_nodes`.
            </summary>
        </member>
        <member name="T:Tensorflow.Keras.Engine.Sequential">
            <summary>
            `Sequential` groups a linear stack of layers into a `tf.keras.Model`.
            `Sequential` provides training and inference features on this model.
            </summary>
        </member>
        <member name="M:Tensorflow.Keras.Engine.Sequential.add(Tensorflow.Keras.Engine.Layer)">
            <summary>
            Adds a layer instance on top of the layer stack.
            </summary>
            <param name="layer"></param>
        </member>
        <member name="M:Tensorflow.Keras.Initializers.he_normal(System.Nullable{System.Int32})">
            <summary>
            He normal initializer.
            </summary>
            <param name="seed"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Keras.Layers.Dense">
            <summary>
            Just your regular densely-connected NN layer.
            </summary>
        </member>
        <member name="T:Tensorflow.Keras.Layers.Embedding">
            <summary>
            Turns positive integers (indexes) into dense vectors of fixed size.
            https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding
            </summary>
        </member>
        <member name="T:Tensorflow.Keras.Layers.InputLayer">
            <summary>
            Layer to be used as an entry point into a Network (a graph of layers).
            </summary>
        </member>
        <member name="M:Tensorflow.Keras.Layers.LayersApi.Embedding(System.Int32,System.Int32,Tensorflow.IInitializer,System.Boolean,Tensorflow.TensorShape,System.Int32)">
            <summary>
            Turns positive integers (indexes) into dense vectors of fixed size.
            This layer can only be used as the first layer in a model.
            e.g. [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]
            https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding
            </summary>
            <param name="input_dim">Size of the vocabulary, i.e. maximum integer index + 1.</param>
            <param name="output_dim">Dimension of the dense embedding.</param>
            <param name="embeddings_initializer">Initializer for the embeddings matrix (see keras.initializers).</param>
            <param name="mask_zero"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Keras.Layers.LSTM">
            <summary>
            Long Short-Term Memory layer - Hochreiter 1997.
            
            See [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)
            for details about the usage of RNN API.
            </summary>
        </member>
        <member name="T:Tensorflow.Keras.Layers.Rescaling">
            <summary>
            Multiply inputs by `scale` and adds `offset`.
            </summary>
        </member>
        <member name="T:Tensorflow.Keras.Losses.Loss">
            <summary>
            Loss base class.
            </summary>
        </member>
        <member name="T:Tensorflow.Keras.Optimizers.Adam">
            <summary>
            Optimizer that implements the Adam algorithm.
            Adam optimization is a stochastic gradient descent method that is based on
            adaptive estimation of first-order and second-order moments.
            </summary>
        </member>
        <member name="T:Tensorflow.Keras.Optimizers.OptimizerV2">
            <summary>
            Updated base class for optimizers.
            </summary>
        </member>
        <member name="M:Tensorflow.Keras.Optimizers.OptimizerV2.apply_gradients(System.Collections.Generic.IEnumerable{System.ValueTuple{Tensorflow.Tensor,Tensorflow.ResourceVariable}},System.String,System.Boolean)">
            <summary>
            Apply gradients to variables.
            </summary>
            <param name="grads_and_vars"></param>
            <param name="name"></param>
            <param name="experimental_aggregate_gradients"></param>
        </member>
        <member name="T:Tensorflow.Keras.Optimizers.PolynomialDecay">
            <summary>
            A LearningRateSchedule that uses a polynomial decay schedule.
            </summary>
        </member>
        <member name="T:Tensorflow.Keras.Optimizers.RMSprop">
            <summary>
            Optimizer that implements the RMSprop algorithm.
            </summary>
        </member>
        <!-- Badly formed XML comment ignored for member "M:Tensorflow.Keras.Preprocessings.DatasetUtils.get_training_or_validation_split``2(``0[],``1[],System.Single,System.String)" -->
        <member name="M:Tensorflow.Keras.Preprocessings.DatasetUtils.index_directory(System.String,System.String[],System.String[],System.Boolean,System.Nullable{System.Int32},System.Boolean)">
            <summary>
            Make list of all files in the subdirs of `directory`, with their labels.
            </summary>
            <param name="directory"></param>
            <param name="labels"></param>
            <param name="formats"></param>
            <param name="class_names"></param>
            <param name="shuffle"></param>
            <param name="seed"></param>
            <param name="follow_links"></param>
            <returns>
            file_paths, labels, class_names
            </returns>
        </member>
        <member name="M:Tensorflow.Keras.Preprocessing.image_dataset_from_directory(System.String,System.String,System.String,System.String[],System.String,System.Int32,Tensorflow.TensorShape,System.Boolean,System.Nullable{System.Int32},System.Single,System.String,System.String,System.Boolean)">
            <summary>
            Generates a `tf.data.Dataset` from image files in a directory.
            https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory
            </summary>
            <param name="directory">Directory where the data is located.</param>
            <param name="labels"></param>
            <param name="label_mode"></param>
            <param name="class_names"></param>
            <param name="color_mode"></param>
            <param name="batch_size"></param>
            <param name="image_size"></param>
            <param name="shuffle"></param>
            <param name="seed"></param>
            <param name="validation_split"></param>
            <param name="subset"></param>
            <param name="interpolation"></param>
            <param name="follow_links"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Keras.Sequence.pad_sequences(NumSharp.NDArray,System.Nullable{System.Int32},System.String,System.String,System.String,System.Object)">
            <summary>
            Pads sequences to the same length.
            https://keras.io/preprocessing/sequence/
            https://faroit.github.io/keras-docs/1.2.0/preprocessing/sequence/
            </summary>
            <param name="sequences">List of lists, where each element is a sequence.</param>
            <param name="maxlen">Int, maximum length of all sequences.</param>
            <param name="dtype">Type of the output sequences.</param>
            <param name="padding">String, 'pre' or 'post':</param>
            <param name="truncating">String, 'pre' or 'post'</param>
            <param name="value">Float or String, padding value.</param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Keras.Utils.base_layer_utils.make_variable(Tensorflow.VariableArgs)">
            <summary>
            Adds a new variable to the layer.
            </summary>
            <param name="args"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Keras.Utils.base_layer_utils.unique_layer_name(System.String,System.Collections.Generic.Dictionary{System.ValueTuple{System.String,System.String},System.Int32},System.String[],System.String,System.Boolean)">
            <summary>
            Makes a layer name (or arbitrary string) unique within a TensorFlow graph.
            </summary>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.KerasApi.Input(Tensorflow.TensorShape,System.Int32,Tensorflow.TF_DataType,System.String,System.Boolean,System.Boolean,Tensorflow.Tensor)">
            <summary>
            Instantiate a Keras tensor.
            </summary>
            <param name="shape"></param>
            <param name="batch_size"></param>
            <param name="dtype"></param>
            <param name="name"></param>
            <param name="sparse">
            A boolean specifying whether the placeholder to be created is sparse.
            </param>
            <param name="ragged">
            A boolean specifying whether the placeholder to be created is ragged.
            </param>
            <param name="tensor">
            Optional existing tensor to wrap into the `Input` layer.
            If set, the layer will not create a placeholder tensor.
            </param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Layers.Layer.add_weight(System.String,System.Int32[],Tensorflow.TF_DataType,Tensorflow.IInitializer,System.Nullable{System.Boolean},Tensorflow.VariableSynchronization,Tensorflow.VariableAggregation)">
            <summary>
            Adds a new variable to the layer, or gets an existing one; returns it.
            </summary>
            <param name="name"></param>
            <param name="shape"></param>
            <param name="dtype"></param>
            <param name="initializer"></param>
            <param name="trainable"></param>
            <param name="synchronization"></param>
            <param name="aggregation"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Operations.Activation.softmax.#ctor(System.Int32)">
            <summary>Initializes a new instance of the <see cref="T:System.Object"></see> class.</summary>
        </member>
        <member name="T:Tensorflow.Operations.bitwise_ops">
            <summary>
            Operations for bitwise manipulation of integers.
            https://www.tensorflow.org/api_docs/python/tf/bitwise
            </summary>
        </member>
        <member name="M:Tensorflow.Operations.bitwise_ops.left_shift(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
            Elementwise computes the bitwise left-shift of `x` and `y`.
            https://www.tensorflow.org/api_docs/python/tf/bitwise/left_shift
            </summary>
            <param name="x"></param>
            <param name="y"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Operations.bitwise_ops.right_shift(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
            Elementwise computes the bitwise right-shift of `x` and `y`.
            https://www.tensorflow.org/api_docs/python/tf/bitwise/right_shift
            </summary>
            <param name="x"></param>
            <param name="y"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Operations.bitwise_ops.invert(Tensorflow.Tensor,System.String)">
            <summary>
            Elementwise computes the bitwise inversion of `x`.
            https://www.tensorflow.org/api_docs/python/tf/bitwise/invert
            </summary>
            <param name="x"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Operations.bitwise_ops.bitwise_and(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
            Elementwise computes the bitwise AND of `x` and `y`.
            https://www.tensorflow.org/api_docs/python/tf/bitwise/bitwise_and
            </summary>
            <param name="x"></param>
            <param name="y"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Operations.bitwise_ops.bitwise_or(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
            Elementwise computes the bitwise OR of `x` and `y`.
            https://www.tensorflow.org/api_docs/python/tf/bitwise/bitwise_or
            </summary>
            <param name="x"></param>
            <param name="y"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Operations.bitwise_ops.bitwise_xor(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
            Elementwise computes the bitwise XOR of `x` and `y`.
            https://www.tensorflow.org/api_docs/python/tf/bitwise/bitwise_xor
            </summary>
            <param name="x"></param>
            <param name="y"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Operations.bitwise_ops.unary_op(Tensorflow.Tensor,System.String,System.String)">
            <summary>
            Helper method to invoke unary operator with specified name.
            </summary>
            <param name="x"></param>
            <param name="opName"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Operations.bitwise_ops.binary_op(Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.String)">
            <summary>
            Helper method to invoke binary operator with specified name.
            </summary>
            <param name="x"></param>
            <param name="y"></param>
            <param name="opName"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Operations.CondContext">
            <summary>
            The context for the conditional construct.
            </summary>
        </member>
        <member name="M:Tensorflow.Operations.CondContext.#ctor(Tensorflow.Tensor,Tensorflow.Tensor,System.Int32,System.String,Tensorflow.CondContextDef,System.String)">
            <summary>
            
            </summary>
            <param name="pred">The `boolean` tensor for the conditional predicate.</param>
            <param name="pivot">The predicate tensor in this branch.</param>
            <param name="branch">0 or 1 representing this branch.</param>
            <param name="name">Name of the `CondContext` python object.</param>
            <param name="context_def"></param>
            <param name="import_scope"></param>
        </member>
        <member name="M:Tensorflow.Operations.CondContext.AddValue(Tensorflow.Tensor)">
            <summary>
            Add `val` to the current context and its outer context recursively.
            </summary>
            <param name="val"></param>
        </member>
        <member name="M:Tensorflow.Operations.CondContext.BuildCondBranch``1(System.Func{``0})">
            <summary>
            Add the subgraph defined by fn() to the graph.
            </summary>
        </member>
        <member name="M:Tensorflow.Operations.CondContext._ProcessOutputTensor(Tensorflow.Tensor)">
            <summary>
            Process an output tensor of a conditional branch.
            </summary>
        </member>
        <member name="T:Tensorflow.Operations.ControlFlowContext">
            <summary>
            The base class for control flow context.
            
            The usage pattern is a sequence of(Enter, Exit) followed by a final
            ExitResult.
            
            We maintain the following state for control flow contexts during graph
            construction:
            1. graph has _control_flow_context: the current context used to
            construct new nodes.Changed by ctxt.Enter() and ctxt.Exit()
            2. op has _control_flow_context: the context to which the op belongs.
            Set at the time the op is created.Immutable.
            3. A ControlFlowContext has _outer_context: the context in which this
            context is created.Set at the time a context is created.Immutable.
            4. A ControlFlowContext has _context_stack.
            Pushed and popped by ctxt.Enter() and ctxt.Exit()
            </summary>
        </member>
        <member name="F:Tensorflow.Operations.ControlFlowContext._pivot">
            <summary>
            The predicate tensor in this branch
            </summary>
        </member>
        <member name="F:Tensorflow.Operations.ControlFlowContext._pred">
            <summary>
            The boolean tensor for the cond predicate
            </summary>
        </member>
        <member name="F:Tensorflow.Operations.ControlFlowContext._branch">
            <summary>
            0 or 1 representing this branch
            </summary>
        </member>
        <member name="F:Tensorflow.Operations.ControlFlowContext._external_values">
            <summary>
            The keys are the names of tensors referenced by but external to this
            context. Each value is the Tensor that should be used by this context to
            access the key value (e.g. a switch output guarding a cond input value).
            </summary>
        </member>
        <member name="M:Tensorflow.Operations.ControlFlowContext._init_values_from_proto(Tensorflow.ValuesDef,System.String)">
            <summary>
            Initializes values and external_values from `ValuesDef` protocol buffer.
            </summary>
            <param name="values_def"></param>
            <param name="import_scope"></param>
        </member>
        <member name="M:Tensorflow.Operations.ControlFlowContext.Enter">
            <summary>
            Enter this control flow context.
            </summary>
        </member>
        <member name="M:Tensorflow.Operations.ControlFlowContext.Exit">
            <summary>
            Exit this control flow context.
            </summary>
        </member>
        <member name="M:Tensorflow.Operations.ControlFlowContext.AddOp(Tensorflow.Operation)">
            <summary>
            Add `op` to the current context.
            </summary>
        </member>
        <member name="M:Tensorflow.Operations.ControlFlowContext.AddValue(Tensorflow.Tensor)">
            <summary>
            Add `val` to the current context and its outer context recursively.
            </summary>
            <param name="val"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Operations.ControlFlowContext.AddInnerOp(Tensorflow.Operation)">
            <summary>
            Notifies a scope about an operator added to an inner scope.
            </summary>
            <param name="op"></param>
        </member>
        <member name="M:Tensorflow.Operations.ControlFlowContext._AddOpInternal(Tensorflow.Operation)">
            <summary>
            Add `op` to the current context.
            </summary>
        </member>
        <member name="M:Tensorflow.Operations.ControlFlowContext.IsContainingContext(Tensorflow.Operations.ControlFlowContext,Tensorflow.Operations.ControlFlowContext)">
            <summary>
            Returns true if `maybe_containing_ctxt` is or contains `ctxt`.
            </summary>
        </member>
        <member name="M:Tensorflow.Operations.ControlFlowContext._RemoveExternalControlEdges(Tensorflow.Operation)">
            <summary>
            Remove any external control dependency on this op.
            </summary>
            <param name="op"></param>
        </member>
        <member name="M:Tensorflow.Operations.ControlFlowContext.GetWhileContext">
            <summary>
            Return the while context containing this context
            </summary>
        </member>
        <member name="M:Tensorflow.Operations.ControlFlowContext.from_control_flow_context_def(Tensorflow.ControlFlowContextDef,System.String)">
            <summary>
            Deserializes `context_def` into the appropriate ControlFlowContext.
            </summary>
            <param name="context_def">ControlFlowContextDef proto</param>
            <param name="import_scope">Name scope to add</param>
            <returns>A ControlFlowContext subclass</returns>
        </member>
        <member name="T:Tensorflow.Operations.ControlFlows.ControlFlowState">
            <summary>
            Maintain the mapping from the loops to their grad states.
            </summary>
        </member>
        <member name="M:Tensorflow.Operations.ControlFlows.ControlFlowState.GetGradState(Tensorflow.Operation,System.Boolean)">
            <summary>
            Return the grad state for this op if it's in a forward loop context.
            </summary>
            <param name="op"></param>
            <param name="before"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Operations.ControlFlows.ControlFlowState.ZerosLikeForExit(Tensorflow.Tensor)">
            <summary>
            Create zeros_like gradient for a loop exit.
            </summary>
            <param name="val"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Operations.ControlFlows.GradLoopState">
            <summary>
            The state used for constructing the gradient graph for a while loop.
            </summary>
        </member>
        <member name="F:Tensorflow.Operations.ControlFlows.GradLoopState._forward_context">
            <summary>
            The while loop context for forward.
            </summary>
        </member>
        <member name="F:Tensorflow.Operations.ControlFlows.GradLoopState._outer_grad_state">
            <summary>
            The grad loop state for the outer while loop.
            </summary>
        </member>
        <member name="P:Tensorflow.Operations.ControlFlows.GradLoopState.forward_loop_exits">
            <summary>
            The list of exits of the forward loop.
            </summary>
        </member>
        <member name="P:Tensorflow.Operations.ControlFlows.GradLoopState.pending_exits_count">
            <summary>
            The number of exits we expect to see but haven't.
            </summary>
        </member>
        <member name="M:Tensorflow.Operations.ControlFlows.GradLoopState.AddForwardAccumulator(Tensorflow.Tensor,System.Boolean)">
             <summary>
             Add an accumulator for each forward tensor that is needed in backprop.
             
                This is added to the forward loop at the first time when a tensor
                in the forward loop is used by backprop gradient computation loop.
                We create an accumulator that accumulates the value of tensor at each
                iteration. Called in the control flow context where gradients() is called.
            
                The pseudocode is:
                ```
                  acc = stack();
                  while (_pivot) {
                    acc = stack_push(acc, value);
                  }
               ```
            
                We make sure that the stack push op in one iteration is executed before
                next iteration. This is achieved by adding a control edge from
                `forward_index.op.inputs[0].op` to the push op, and another control
                edge from the push op to either `forward_index.op` or `forward_sync`.
             </summary>
             <param name="value"> The source tensor in forward that is to be accumulated.</param>
             <param name="dead_branch"> True iff the tensor is on a dead branch of a cond.</param>
             <returns>The stack that contains the accumulated history of the tensor.</returns>
        </member>
        <member name="M:Tensorflow.Operations.ControlFlows.GradLoopState.GetRealValue(Tensorflow.Tensor)">
            <summary>
            Get the real value of `value`.
            </summary>
            <param name="value">A tensor to be captured.</param>
            <returns>The same tensor obtained from the saved history.</returns>
        </member>
        <member name="T:Tensorflow.Operations.WhileContext">
            <summary>
            Creates a `WhileContext`.
            </summary>
        </member>
        <member name="M:Tensorflow.Operations.WhileContext.BuildLoop``1(System.Func{Tensorflow.Operations.LoopVar{``0},Tensorflow.Tensor},System.Func{Tensorflow.Operations.LoopVar{``0},Tensorflow.Operations.LoopVar{``0}},Tensorflow.Operations.LoopVar{``0},Tensorflow.TensorShape[],System.Boolean)">
            <summary>
            Add the loop termination condition and body to the graph.
            </summary>
        </member>
        <member name="M:Tensorflow.Operations.WhileContext._BuildLoop``1(System.Func{Tensorflow.Operations.LoopVar{``0},Tensorflow.Tensor},System.Func{Tensorflow.Operations.LoopVar{``0},Tensorflow.Operations.LoopVar{``0}},Tensorflow.Operations.LoopVar{``0},Tensorflow.Tensor[],Tensorflow.TensorShape[])">
            <summary>
            Add the loop termination condition and body to the graph.
            </summary>
            <typeparam name="TItem"></typeparam>
            <param name="pred"></param>
            <param name="body"></param>
            <param name="original_loop_vars"></param>
            <param name="loop_vars"></param>
            <param name="shape_invariants"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Operations.WhileContext._InitializeValues(Tensorflow.Tensor[])">
            <summary>
            Makes the values known to this context.
            </summary>
            <param name="values"></param>
        </member>
        <member name="M:Tensorflow.Operations.WhileContext.AddForwardLoopCounter(Tensorflow.Operations.ControlFlows.GradLoopState)">
            <summary>
            Adds a loop that counts the number of iterations.
            </summary>
            <param name="outer_grad_state">The outer grad state. None if not nested.</param>
            <returns>The number of iterations taken by the forward loop and the loop index.</returns>
        </member>
        <member name="M:Tensorflow.Operations.WhileContext.AddBackpropAccumulator(Tensorflow.Operation,Tensorflow.Tensor)">
            <summary>
            Add an accumulation loop for every loop invariant.
            </summary>
            <param name="op">The Enter op for a loop invariant.</param>
            <param name="grad">The partial gradient of an iteration for a loop invariant.</param>
            <returns>The gradient for a loop invariant.</returns>
        </member>
        <member name="M:Tensorflow.Operations.WhileContext.AddBackpropLoopCounter(Tensorflow.Tensor,Tensorflow.Operations.ControlFlows.GradLoopState)">
            <summary>
            Add the backprop loop that controls the iterations.
            </summary>
            <param name="count">The number of iterations for backprop.</param>
            <param name="outer_grad_state">The outer grad state. None if not nested.</param>
            <returns>The loop index.</returns>
        </member>
        <member name="M:Tensorflow.Operations.WhileContext.AddValue(Tensorflow.Tensor)">
            <summary>
            Add `val` to the current context and its outer context recursively.
            </summary>
            <param name="val"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.abort(System.String,System.Nullable{System.Boolean},System.String)">
            <summary>
               Raise a exception to abort the process when called.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Abort'.
            </param>
            <param name="error_msg">
               A string which is the message associated with the exception.
            </param>
            <param name="exit_without_error">
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               If exit_without_error is true, the process will exit normally,
               otherwise it will exit with a SIGABORT signal.
               
               Returns nothing but an exception.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.abs(Tensorflow.Tensor,System.String)">
            <summary>
               Computes the absolute value of a tensor.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Abs'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Given a tensor <c>x</c>, this operation returns a tensor containing the absolute
               value of each element in <c>x</c>. For example, if x is an input element and y is
               an output element, this operation computes \\(y = |x|\\).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.accumulate_n_v2(Tensorflow.Tensor[],Tensorflow.TensorShape,System.String)">
            <summary>
               Returns the element-wise sum of a list of tensors.
            </summary>
            <param name="inputs">
               A list of <c>Tensor</c> objects, each with same shape and type.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'AccumulateNV2'.
            </param>
            <param name="shape">
               Optional argument
               Shape of elements of <c>inputs</c>.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               <c>tf.accumulate_n_v2</c> performs the same operation as <c>tf.add_n</c>, but does not
               wait for all of its inputs to be ready before beginning to sum. This can
               save memory if inputs are ready at different times, since minimum temporary
               storage is proportional to the output size rather than the inputs size.
               
               Unlike the original <c>accumulate_n</c>, <c>accumulate_n_v2</c> is differentiable.
               
               Returns a <c>Tensor</c> of same shape and type as the elements of <c>inputs</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.accumulator_apply_gradient(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Applies a gradient to a given accumulator.
            </summary>
            <param name="handle">
               The handle to a accumulator.
            </param>
            <param name="local_step">
               The local_step value at which the gradient was computed.
            </param>
            <param name="gradient">
               A tensor of the gradient to be accumulated.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'AccumulatorApplyGradient'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               Does not add if local_step is lesser than the accumulator's global_step.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.accumulator_num_accumulated(Tensorflow.Tensor,System.String)">
            <summary>
               Returns the number of gradients aggregated in the given accumulators.
            </summary>
            <param name="handle">
               The handle to an accumulator.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'AccumulatorNumAccumulated'.
            </param>
            <returns>
               The number of gradients aggregated in the given accumulator.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.accumulator_set_global_step(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Updates the accumulator with a new value for global_step.
            </summary>
            <param name="handle">
               The handle to an accumulator.
            </param>
            <param name="new_global_step">
               The new global_step value to set.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'AccumulatorSetGlobalStep'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               Logs warning if the accumulator's value is already higher than
               new_global_step.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.accumulator_take_gradient(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType,System.String)">
            <summary>
               Extracts the average gradient in the given ConditionalAccumulator.
            </summary>
            <param name="handle">
               The handle to an accumulator.
            </param>
            <param name="num_required">
               Number of gradients required before we return an aggregate.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'AccumulatorTakeGradient'.
            </param>
            <param name="dtype">
               Optional argument
               The data type of accumulated gradients. Needs to correspond to the type
               of the accumulator.
            </param>
            <returns>
               The average of the accumulated gradients.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The op blocks until sufficient (i.e., more than num_required)
               gradients have been accumulated.  If the accumulator has already
               aggregated more than num_required gradients, it returns the average of
               the accumulated gradients.  Also automatically increments the recorded
               global_step in the accumulator by 1, and resets the aggregate to 0.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.acos(Tensorflow.Tensor,System.String)">
            <summary>
               Computes acos of x element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Acos'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.acosh(Tensorflow.Tensor,System.String)">
            <summary>
               Computes inverse hyperbolic cosine of x element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Acosh'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.add(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns x + y element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Add'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               *NOTE*: <c>Add</c> supports broadcasting. <c>AddN</c> does not. More about broadcasting
               [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.add_many_sparse_to_tensors_map(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.String,System.String)">
            <summary>
               Add an <c>N</c>-minibatch <c>SparseTensor</c> to a <c>SparseTensorsMap</c>, return <c>N</c> handles.
            </summary>
            <param name="sparse_indices">
               2-D.  The <c>indices</c> of the minibatch <c>SparseTensor</c>.
               <c>sparse_indices[:, 0]</c> must be ordered values in <c>[0, N)</c>.
            </param>
            <param name="sparse_values">
               1-D.  The <c>values</c> of the minibatch <c>SparseTensor</c>.
            </param>
            <param name="sparse_shape">
               1-D.  The <c>shape</c> of the minibatch <c>SparseTensor</c>.
               The minibatch size <c>N == sparse_shape[0]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'AddManySparseToTensorsMap'.
            </param>
            <param name="container">
               The container name for the <c>SparseTensorsMap</c> created by this op.
            </param>
            <param name="shared_name">
               The shared name for the <c>SparseTensorsMap</c> created by this op.
               If blank, the new Operation's unique name is used.
            </param>
            <returns>
               1-D.  The handles of the <c>SparseTensor</c> now stored in the
               <c>SparseTensorsMap</c>.  Shape: <c>[N]</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               A <c>SparseTensor</c> of rank <c>R</c> is represented by three tensors: <c>sparse_indices</c>,
               <c>sparse_values</c>, and <c>sparse_shape</c>, where
               
              <code>
               sparse_indices.shape[1] == sparse_shape.shape[0] == R
               </code>
               
               An <c>N</c>-minibatch of <c>SparseTensor</c> objects is represented as a <c>SparseTensor</c>
               having a first <c>sparse_indices</c> column taking values between <c>[0, N)</c>, where
               the minibatch size <c>N == sparse_shape[0]</c>.
               
               The input <c>SparseTensor</c> must have rank <c>R</c> greater than 1, and the first
               dimension is treated as the minibatch dimension.  Elements of the <c>SparseTensor</c>
               must be sorted in increasing order of this first dimension.  The stored
               <c>SparseTensor</c> objects pointed to by each row of the output <c>sparse_handles</c>
               will have rank <c>R-1</c>.
               
               The <c>SparseTensor</c> values can then be read out as part of a minibatch by passing
               the given keys as vector elements to <c>TakeManySparseFromTensorsMap</c>.  To ensure
               the correct <c>SparseTensorsMap</c> is accessed, ensure that the same
               <c>container</c> and <c>shared_name</c> are passed to that Op.  If no <c>shared_name</c>
               is provided here, instead use the *name* of the Operation created by calling
               <c>AddManySparseToTensorsMap</c> as the <c>shared_name</c> passed to
               <c>TakeManySparseFromTensorsMap</c>.  Ensure the Operations are colocated.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.add_n(Tensorflow.Tensor[],System.String)">
            <summary>
               Add all input tensors element wise.
            </summary>
            <param name="inputs">
               Must all be the same size and shape.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'AddN'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.add_sparse_to_tensors_map(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.String,System.String)">
            <summary>
               Add a <c>SparseTensor</c> to a <c>SparseTensorsMap</c> return its handle.
            </summary>
            <param name="sparse_indices">
               2-D.  The <c>indices</c> of the <c>SparseTensor</c>.
            </param>
            <param name="sparse_values">
               1-D.  The <c>values</c> of the <c>SparseTensor</c>.
            </param>
            <param name="sparse_shape">
               1-D.  The <c>shape</c> of the <c>SparseTensor</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'AddSparseToTensorsMap'.
            </param>
            <param name="container">
               The container name for the <c>SparseTensorsMap</c> created by this op.
            </param>
            <param name="shared_name">
               The shared name for the <c>SparseTensorsMap</c> created by this op.
               If blank, the new Operation's unique name is used.
            </param>
            <returns>
               0-D.  The handle of the <c>SparseTensor</c> now stored in the
               <c>SparseTensorsMap</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               A <c>SparseTensor</c> is represented by three tensors: <c>sparse_indices</c>,
               <c>sparse_values</c>, and <c>sparse_shape</c>.
               
               This operator takes the given <c>SparseTensor</c> and adds it to a container
               object (a <c>SparseTensorsMap</c>).  A unique key within this container is generated
               in the form of an <c>int64</c>, and this is the value that is returned.
               
               The <c>SparseTensor</c> can then be read out as part of a minibatch by passing
               the key as a vector element to <c>TakeManySparseFromTensorsMap</c>.  To ensure
               the correct <c>SparseTensorsMap</c> is accessed, ensure that the same
               <c>container</c> and <c>shared_name</c> are passed to that Op.  If no <c>shared_name</c>
               is provided here, instead use the *name* of the Operation created by calling
               <c>AddSparseToTensorsMap</c> as the <c>shared_name</c> passed to
               <c>TakeManySparseFromTensorsMap</c>.  Ensure the Operations are colocated.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.add_v2(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns x + y element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'AddV2'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               *NOTE*: <c>Add</c> supports broadcasting. <c>AddN</c> does not. More about broadcasting
               [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.adjust_contrast(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Deprecated. Disallowed in GraphDef version &amp;gt;= 2.
            </summary>
            <param name="images">
            </param>
            <param name="contrast_factor">
            </param>
            <param name="min_value">
            </param>
            <param name="max_value">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'AdjustContrast'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.adjust_contrastv2(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Adjust the contrast of one or more images.
            </summary>
            <param name="images">
               Images to adjust.  At least 3-D.
            </param>
            <param name="contrast_factor">
               A float multiplier for adjusting contrast.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'AdjustContrastv2'.
            </param>
            <returns>
               The contrast-adjusted image or images.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               <c>images</c> is a tensor of at least 3 dimensions.  The last 3 dimensions are
               interpreted as <c>[height, width, channels]</c>.  The other dimensions only
               represent a collection of images, such as <c>[batch, height, width, channels].</c>
               
               Contrast is adjusted independently for each channel of each image.
               
               For each channel, the Op first computes the mean of the image pixels in the
               channel and then adjusts each component of each pixel to
               <c>(x - mean) * contrast_factor + mean</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.adjust_hue(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Adjust the hue of one or more images.
            </summary>
            <param name="images">
               Images to adjust.  At least 3-D.
            </param>
            <param name="delta">
               A float delta to add to the hue.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'AdjustHue'.
            </param>
            <returns>
               The hue-adjusted image or images.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               <c>images</c> is a tensor of at least 3 dimensions.  The last dimension is
               interpretted as channels, and must be three.
               
               The input image is considered in the RGB colorspace. Conceptually, the RGB
               colors are first mapped into HSV. A delta is then applied all the hue values,
               and then remapped back to RGB colorspace.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.adjust_saturation(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Adjust the saturation of one or more images.
            </summary>
            <param name="images">
               Images to adjust.  At least 3-D.
            </param>
            <param name="scale">
               A float scale to add to the saturation.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'AdjustSaturation'.
            </param>
            <returns>
               The hue-adjusted image or images.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               <c>images</c> is a tensor of at least 3 dimensions.  The last dimension is
               interpretted as channels, and must be three.
               
               The input image is considered in the RGB colorspace. Conceptually, the RGB
               colors are first mapped into HSV. A scale is then applied all the saturation
               values, and then remapped back to RGB colorspace.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.all(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Computes the "logical and" of elements across dimensions of a tensor.
            </summary>
            <param name="input">
               The tensor to reduce.
            </param>
            <param name="reduction_indices">
               The dimensions to reduce. Must be in the range
               <c>[-rank(input), rank(input))</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'All'.
            </param>
            <param name="keep_dims">
               If true, retain reduced dimensions with length 1.
            </param>
            <returns>
               The reduced tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Reduces <c>input</c> along the dimensions given in <c>axis</c>. Unless
               <c>keep_dims</c> is true, the rank of the tensor is reduced by 1 for each entry in
               <c>axis</c>. If <c>keep_dims</c> is true, the reduced dimensions are
               retained with length 1.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.all_candidate_sampler(Tensorflow.Tensor,System.Int32,System.Int32,System.Boolean,System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Generates labels for candidate sampling with a learned unigram distribution.
            </summary>
            <param name="true_classes">
               A batch_size * num_true matrix, in which each row contains the
               IDs of the num_true target_classes in the corresponding original label.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'AllCandidateSampler'.
            </param>
            <param name="num_true">
               Optional argument
               Number of true labels per context.
            </param>
            <param name="num_sampled">
               Optional argument
               Number of candidates to produce.
            </param>
            <param name="unique">
               Optional argument
               If unique is true, we sample with rejection, so that all sampled
               candidates in a batch are unique. This requires some approximation to
               estimate the post-rejection sampling probabilities.
            </param>
            <param name="seed">
               If either seed or seed2 are set to be non-zero, the random number
               generator is seeded by the given seed.  Otherwise, it is seeded by a
               random seed.
            </param>
            <param name="seed2">
               An second seed to avoid seed collision.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               sampled_candidates : A vector of length num_sampled, in which each element is
               the ID of a sampled candidate.
               true_expected_count : A batch_size * num_true matrix, representing
               the number of times each candidate is expected to occur in a batch
               of sampled candidates. If unique=true, then this is a probability.
               sampled_expected_count : A vector of length num_sampled, for each sampled
               candidate representing the number of times the candidate is expected
               to occur in a batch of sampled candidates.  If unique=true, then this is a
               probability.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               See explanations of candidate sampling and the data formats at
               go/candidate-sampling.
               
               For each batch, this op picks a single set of sampled candidate labels.
               
               The advantages of sampling candidates per-batch are simplicity and the
               possibility of efficient dense matrix multiplication. The disadvantage is that
               the sampled candidates must be chosen independently of the context and of the
               true labels.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.angle(Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Returns the argument of a complex number.
            </summary>
            <param name="input">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Angle'.
            </param>
            <param name="Tout">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Given a tensor <c>input</c> of complex numbers, this operation returns a tensor of
               type <c>float</c> that is the argument of each element in <c>input</c>. All elements in
               <c>input</c> must be complex numbers of the form \\(a + bj\\), where *a*
               is the real part and *b* is the imaginary part.
               
               The argument returned by this operation is of the form \\(atan2(b, a)\\).
               
               For example:
               
              <code>
               # tensor 'input' is [-2.25 + 4.75j, 3.25 + 5.75j]
               tf.angle(input) ==&amp;gt; [2.0132, 1.056]
              </code>
               
               @compatibility(numpy)
               Equivalent to np.angle.
               @end_compatibility
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.anonymous_iterator(Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               A container for an iterator resource.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'AnonymousIterator'.
            </param>
            <param name="output_types">
               Optional argument
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               A handle to the iterator that can be passed to a "MakeIterator" or
               "IteratorGetNext" op. In contrast to Iterator, AnonymousIterator prevents
               resource sharing by name, and does not keep a reference to the resource
               container.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.any(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Computes the "logical or" of elements across dimensions of a tensor.
            </summary>
            <param name="input">
               The tensor to reduce.
            </param>
            <param name="reduction_indices">
               The dimensions to reduce. Must be in the range
               <c>[-rank(input), rank(input))</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Any'.
            </param>
            <param name="keep_dims">
               If true, retain reduced dimensions with length 1.
            </param>
            <returns>
               The reduced tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Reduces <c>input</c> along the dimensions given in <c>axis</c>. Unless
               <c>keep_dims</c> is true, the rank of the tensor is reduced by 1 for each entry in
               <c>axis</c>. If <c>keep_dims</c> is true, the reduced dimensions are
               retained with length 1.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.apply_ada_max(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' according to the AdaMax algorithm.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="m">
               Should be from a Variable().
            </param>
            <param name="v">
               Should be from a Variable().
            </param>
            <param name="beta1_power">
               Must be a scalar.
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="beta1">
               Momentum factor. Must be a scalar.
            </param>
            <param name="beta2">
               Momentum factor. Must be a scalar.
            </param>
            <param name="epsilon">
               Ridge term. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ApplyAdaMax'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var, m, and v tensors will be protected
               by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <returns>
               Same as "var".
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               m_t &amp;lt;- beta1 * m_{t-1} + (1 - beta1) * g
               v_t &amp;lt;- max(beta2 * v_{t-1}, abs(g))
               variable &amp;lt;- variable - learning_rate / (1 - beta1^t) * m_t / (v_t + epsilon)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.apply_adadelta(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' according to the adadelta scheme.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="accum">
               Should be from a Variable().
            </param>
            <param name="accum_update">
               Should be from a Variable().
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="rho">
               Decay factor. Must be a scalar.
            </param>
            <param name="epsilon">
               Constant factor. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ApplyAdadelta'.
            </param>
            <param name="use_locking">
               If True, updating of the var, accum and update_accum tensors will be protected by
               a lock; otherwise the behavior is undefined, but may exhibit less contention.
            </param>
            <returns>
               Same as "var".
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               accum = rho() * accum + (1 - rho()) * grad.square();
               update = (update_accum + epsilon).sqrt() * (accum + epsilon()).rsqrt() * grad;
               update_accum = rho() * update_accum + (1 - rho()) * update.square();
               var -= update;
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.apply_adagrad(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' according to the adagrad scheme.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="accum">
               Should be from a Variable().
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ApplyAdagrad'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var and accum tensors will be protected
               by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <param name="update_slots">
            </param>
            <returns>
               Same as "var".
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               accum += grad * grad
               var -= lr * grad * (1 / sqrt(accum))
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.apply_adagrad_d_a(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' according to the proximal adagrad scheme.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="gradient_accumulator">
               Should be from a Variable().
            </param>
            <param name="gradient_squared_accumulator">
               Should be from a Variable().
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="l1">
               L1 regularization. Must be a scalar.
            </param>
            <param name="l2">
               L2 regularization. Must be a scalar.
            </param>
            <param name="global_step">
               Training step number. Must be a scalar.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ApplyAdagradDA'.
            </param>
            <param name="use_locking">
               If True, updating of the var and accum tensors will be protected by
               a lock; otherwise the behavior is undefined, but may exhibit less contention.
            </param>
            <returns>
               Same as "var".
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.apply_adam(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' according to the Adam algorithm.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="m">
               Should be from a Variable().
            </param>
            <param name="v">
               Should be from a Variable().
            </param>
            <param name="beta1_power">
               Must be a scalar.
            </param>
            <param name="beta2_power">
               Must be a scalar.
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="beta1">
               Momentum factor. Must be a scalar.
            </param>
            <param name="beta2">
               Momentum factor. Must be a scalar.
            </param>
            <param name="epsilon">
               Ridge term. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ApplyAdam'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var, m, and v tensors will be protected
               by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <param name="use_nesterov">
               If <c>True</c>, uses the nesterov update.
            </param>
            <returns>
               Same as "var".
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               $$lr_t := \text{learning\_rate} * \sqrt{1 - beta_2^t} / (1 - beta_1^t)$$
               $$m_t := beta_1 * m_{t-1} + (1 - beta_1) * g$$
               $$v_t := beta_2 * v_{t-1} + (1 - beta_2) * g * g$$
               $$variable := variable - lr_t * m_t / (\sqrt{v_t} + \epsilon)$$
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.apply_add_sign(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' according to the AddSign update.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="m">
               Should be from a Variable().
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="alpha">
               Must be a scalar.
            </param>
            <param name="sign_decay">
               Must be a scalar.
            </param>
            <param name="beta">
               Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ApplyAddSign'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var and m tensors is
               protected by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <returns>
               Same as "var".
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               m_t &amp;lt;- beta1 * m_{t-1} + (1 - beta1) * g
               update &amp;lt;- (alpha + sign_decay * sign(g) *sign(m)) * g
               variable &amp;lt;- variable - lr_t * update
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.apply_centered_r_m_s_prop(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' according to the centered RMSProp algorithm.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="mg">
               Should be from a Variable().
            </param>
            <param name="ms">
               Should be from a Variable().
            </param>
            <param name="mom">
               Should be from a Variable().
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="rho">
               Decay rate. Must be a scalar.
            </param>
            <param name="momentum">
            </param>
            <param name="epsilon">
               Ridge term. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ApplyCenteredRMSProp'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var, mg, ms, and mom tensors is
               protected by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <returns>
               Same as "var".
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The centered RMSProp algorithm uses an estimate of the centered second moment
               (i.e., the variance) for normalization, as opposed to regular RMSProp, which
               uses the (uncentered) second moment. This often helps with training, but is
               slightly more expensive in terms of computation and memory.
               
               Note that in dense implementation of this algorithm, mg, ms, and mom will
               update even if the grad is zero, but in this sparse implementation, mg, ms,
               and mom will not update in iterations during which the grad is zero.
               
               mean_square = decay * mean_square + (1-decay) * gradient ** 2
               mean_grad = decay * mean_grad + (1-decay) * gradient
               
               Delta = learning_rate * gradient / sqrt(mean_square + epsilon - mean_grad ** 2)
               
               mg &amp;lt;- rho * mg_{t-1} + (1-rho) * grad
               ms &amp;lt;- rho * ms_{t-1} + (1-rho) * grad * grad
               mom &amp;lt;- momentum * mom_{t-1} + lr * grad / sqrt(ms - mg * mg + epsilon)
               var &amp;lt;- var - mom
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.apply_ftrl(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' according to the Ftrl-proximal scheme.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="accum">
               Should be from a Variable().
            </param>
            <param name="linear">
               Should be from a Variable().
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="l1">
               L1 regulariation. Must be a scalar.
            </param>
            <param name="l2">
               L2 regulariation. Must be a scalar.
            </param>
            <param name="lr_power">
               Scaling factor. Must be a scalar.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ApplyFtrl'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var and accum tensors will be protected
               by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <returns>
               Same as "var".
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               accum_new = accum + grad * grad
               linear += grad + (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var
               quadratic = 1.0 / (accum_new^(lr_power) * lr) + 2 * l2
               var = (sign(linear) * l1 - linear) / quadratic if |linear| &amp;gt; l1 else 0.0
               accum = accum_new
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.apply_ftrl_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' according to the Ftrl-proximal scheme.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="accum">
               Should be from a Variable().
            </param>
            <param name="linear">
               Should be from a Variable().
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="l1">
               L1 regulariation. Must be a scalar.
            </param>
            <param name="l2">
               L2 shrinkage regulariation. Must be a scalar.
            </param>
            <param name="l2_shrinkage">
            </param>
            <param name="lr_power">
               Scaling factor. Must be a scalar.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ApplyFtrlV2'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var and accum tensors will be protected
               by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <returns>
               Same as "var".
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               grad_with_shrinkage = grad + 2 * l2_shrinkage * var
               accum_new = accum + grad_with_shrinkage * grad_with_shrinkage
               linear += grad_with_shrinkage +
               (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var
               quadratic = 1.0 / (accum_new^(lr_power) * lr) + 2 * l2
               var = (sign(linear) * l1 - linear) / quadratic if |linear| &amp;gt; l1 else 0.0
               accum = accum_new
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.apply_gradient_descent(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' by subtracting 'alpha' * 'delta' from it.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="alpha">
               Scaling factor. Must be a scalar.
            </param>
            <param name="delta">
               The change.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ApplyGradientDescent'.
            </param>
            <param name="use_locking">
               If <c>True</c>, the subtraction will be protected by a lock;
               otherwise the behavior is undefined, but may exhibit less contention.
            </param>
            <returns>
               Same as "var".
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.apply_momentum(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' according to the momentum scheme. Set use_nesterov = True if you
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="accum">
               Should be from a Variable().
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="momentum">
               Momentum. Must be a scalar.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ApplyMomentum'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var and accum tensors will be protected
               by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <param name="use_nesterov">
               If <c>True</c>, the tensor passed to compute grad will be
               var - lr * momentum * accum, so in the end, the var you get is actually
               var - lr * momentum * accum.
            </param>
            <returns>
               Same as "var".
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               want to use Nesterov momentum.
               
               accum = accum * momentum + grad
               var -= lr * accum
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.apply_power_sign(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' according to the AddSign update.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="m">
               Should be from a Variable().
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="logbase">
               Must be a scalar.
            </param>
            <param name="sign_decay">
               Must be a scalar.
            </param>
            <param name="beta">
               Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ApplyPowerSign'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var and m tensors is
               protected by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <returns>
               Same as "var".
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               m_t &amp;lt;- beta1 * m_{t-1} + (1 - beta1) * g
               update &amp;lt;- exp(logbase * sign_decay * sign(g) * sign(m_t)) * g
               variable &amp;lt;- variable - lr_t * update
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.apply_proximal_adagrad(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' and '*accum' according to FOBOS with Adagrad learning rate.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="accum">
               Should be from a Variable().
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="l1">
               L1 regularization. Must be a scalar.
            </param>
            <param name="l2">
               L2 regularization. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ApplyProximalAdagrad'.
            </param>
            <param name="use_locking">
               If True, updating of the var and accum tensors will be protected by
               a lock; otherwise the behavior is undefined, but may exhibit less contention.
            </param>
            <returns>
               Same as "var".
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               accum += grad * grad
               prox_v = var - lr * grad * (1 / sqrt(accum))
               var = sign(prox_v)/(1+lr*l2) * max{|prox_v|-lr*l1,0}
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.apply_proximal_gradient_descent(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' as FOBOS algorithm with fixed learning rate.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="alpha">
               Scaling factor. Must be a scalar.
            </param>
            <param name="l1">
               L1 regularization. Must be a scalar.
            </param>
            <param name="l2">
               L2 regularization. Must be a scalar.
            </param>
            <param name="delta">
               The change.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ApplyProximalGradientDescent'.
            </param>
            <param name="use_locking">
               If True, the subtraction will be protected by a lock;
               otherwise the behavior is undefined, but may exhibit less contention.
            </param>
            <returns>
               Same as "var".
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               prox_v = var - alpha * delta
               var = sign(prox_v)/(1+alpha*l2) * max{|prox_v|-alpha*l1,0}
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.apply_r_m_s_prop(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' according to the RMSProp algorithm.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="ms">
               Should be from a Variable().
            </param>
            <param name="mom">
               Should be from a Variable().
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="rho">
               Decay rate. Must be a scalar.
            </param>
            <param name="momentum">
            </param>
            <param name="epsilon">
               Ridge term. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ApplyRMSProp'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var, ms, and mom tensors is protected
               by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <returns>
               Same as "var".
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Note that in dense implementation of this algorithm, ms and mom will
               update even if the grad is zero, but in this sparse implementation, ms
               and mom will not update in iterations during which the grad is zero.
               
               mean_square = decay * mean_square + (1-decay) * gradient ** 2
               Delta = learning_rate * gradient / sqrt(mean_square + epsilon)
               
               ms &amp;lt;- rho * ms_{t-1} + (1-rho) * grad * grad
               mom &amp;lt;- momentum * mom_{t-1} + lr * grad / sqrt(ms + epsilon)
               var &amp;lt;- var - mom
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.approximate_equal(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Single},System.String)">
            <summary>
               Returns the truth value of abs(x-y) &amp;lt; tolerance element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ApproximateEqual'.
            </param>
            <param name="tolerance">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.arg_max(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Returns the index with the largest value across dimensions of a tensor.
            </summary>
            <param name="input">
            </param>
            <param name="dimension">
               int32 or int64, must be in the range <c>[-rank(input), rank(input))</c>.
               Describes which dimension of the input Tensor to reduce across. For vectors,
               use dimension = 0.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ArgMax'.
            </param>
            <param name="output_type">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Note that in case of ties the identity of the return value is not guaranteed.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.arg_min(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Returns the index with the smallest value across dimensions of a tensor.
            </summary>
            <param name="input">
            </param>
            <param name="dimension">
               int32 or int64, must be in the range <c>[-rank(input), rank(input))</c>.
               Describes which dimension of the input Tensor to reduce across. For vectors,
               use dimension = 0.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ArgMin'.
            </param>
            <param name="output_type">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Note that in case of ties the identity of the return value is not guaranteed.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.as_string(Tensorflow.Tensor,System.Nullable{System.Int32},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Int32},System.String,System.String)">
            <summary>
               Converts each entry in the given tensor to strings.  Supports many numeric
            </summary>
            <param name="input">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'AsString'.
            </param>
            <param name="precision">
               The post-decimal precision to use for floating point numbers.
               Only used if precision &amp;gt; -1.
            </param>
            <param name="scientific">
               Use scientific notation for floating point numbers.
            </param>
            <param name="shortest">
               Use shortest representation (either scientific or standard) for
               floating point numbers.
            </param>
            <param name="width">
               Pad pre-decimal numbers to this width.
               Applies to both floating point and integer numbers.
               Only used if width &amp;gt; -1.
            </param>
            <param name="fill">
               The value to pad if width &amp;gt; -1.  If empty, pads with spaces.
               Another typical value is '0'.  String cannot be longer than 1 character.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               types and boolean.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.asin(Tensorflow.Tensor,System.String)">
            <summary>
               Computes asin of x element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Asin'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.asinh(Tensorflow.Tensor,System.String)">
            <summary>
               Computes inverse hyperbolic sine of x element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Asinh'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.assert(Tensorflow.Tensor,Tensorflow.Tensor[],System.Nullable{System.Int32},System.String)">
            <summary>
               Asserts that the given condition is true.
            </summary>
            <param name="condition">
               The condition to evaluate.
            </param>
            <param name="data">
               The tensors to print out when condition is false.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Assert'.
            </param>
            <param name="summarize">
               Print this many entries of each tensor.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               If <c>condition</c> evaluates to false, print the list of tensors in <c>data</c>.
               <c>summarize</c> determines how many entries of the tensors to print.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.assign(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.String)">
            <summary>
               Update 'ref' by assigning 'value' to it.
            </summary>
            <param name="referecne">
               Should be from a <c>Variable</c> node. May be uninitialized.
            </param>
            <param name="value">
               The value to be assigned to the variable.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Assign'.
            </param>
            <param name="validate_shape">
               If true, the operation will validate that the shape
               of 'value' matches the shape of the Tensor being assigned to.  If false,
               'ref' will take on the shape of 'value'.
            </param>
            <param name="use_locking">
               If True, the assignment will be protected by a lock;
               otherwise the behavior is undefined, but may exhibit less contention.
            </param>
            <returns>
               = Same as "ref".  Returned as a convenience for operations that want
               to use the new value after the variable has been reset.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation outputs "ref" after the assignment is done.
               This makes it easier to chain operations that need to use the reset value.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.assign_add(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update 'ref' by adding 'value' to it.
            </summary>
            <param name="referecne">
               Should be from a <c>Variable</c> node.
            </param>
            <param name="value">
               The value to be added to the variable.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'AssignAdd'.
            </param>
            <param name="use_locking">
               If True, the addition will be protected by a lock;
               otherwise the behavior is undefined, but may exhibit less contention.
            </param>
            <returns>
               = Same as "ref".  Returned as a convenience for operations that want
               to use the new value after the variable has been updated.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation outputs "ref" after the update is done.
               This makes it easier to chain operations that need to use the reset value.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.assign_add_variable_op(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Adds a value to the current value of a variable.
            </summary>
            <param name="resource">
               handle to the resource in which to store the variable.
            </param>
            <param name="value">
               the value by which the variable will be incremented.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'AssignAddVariableOp'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               Any ReadVariableOp with a control dependency on this op is guaranteed to
               see the incremented value or a subsequent newer one.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.assign_sub(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update 'ref' by subtracting 'value' from it.
            </summary>
            <param name="referecne">
               Should be from a <c>Variable</c> node.
            </param>
            <param name="value">
               The value to be subtracted to the variable.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'AssignSub'.
            </param>
            <param name="use_locking">
               If True, the subtraction will be protected by a lock;
               otherwise the behavior is undefined, but may exhibit less contention.
            </param>
            <returns>
               = Same as "ref".  Returned as a convenience for operations that want
               to use the new value after the variable has been updated.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation outputs "ref" after the update is done.
               This makes it easier to chain operations that need to use the reset value.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.assign_sub_variable_op(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Subtracts a value from the current value of a variable.
            </summary>
            <param name="resource">
               handle to the resource in which to store the variable.
            </param>
            <param name="value">
               the value by which the variable will be incremented.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'AssignSubVariableOp'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               Any ReadVariableOp with a control dependency on this op is guaranteed to
               see the decremented value or a subsequent newer one.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.assign_variable_op(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Assigns a new value to a variable.
            </summary>
            <param name="resource">
               handle to the resource in which to store the variable.
            </param>
            <param name="value">
               the value to set the new tensor to use.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'AssignVariableOp'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               Any ReadVariableOp with a control dependency on this op is guaranteed to return
               this value or a subsequent newer value of the variable.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.atan(Tensorflow.Tensor,System.String)">
            <summary>
               Computes atan of x element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Atan'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.atan2(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes arctangent of <c>y/x</c> element-wise, respecting signs of the arguments.
            </summary>
            <param name="y">
            </param>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Atan2'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This is the angle \( \theta \in [-\pi, \pi] \) such that
               \[ x = r \cos(\theta) \]
               and
               \[ y = r \sin(\theta) \]
               where \(r = \sqrt(x^2 + y^2) \).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.atanh(Tensorflow.Tensor,System.String)">
            <summary>
               Computes inverse hyperbolic tangent of x element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Atanh'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.audio_spectrogram(Tensorflow.Tensor,System.Int32,System.Int32,System.Nullable{System.Boolean},System.String)">
            <summary>
               Produces a visualization of audio data over time.
            </summary>
            <param name="input">
               Float representation of audio data.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'AudioSpectrogram'.
            </param>
            <param name="window_size">
               Optional argument
               How wide the input window is in samples. For the highest efficiency
               this should be a power of two, but other values are accepted.
            </param>
            <param name="stride">
               Optional argument
               How widely apart the center of adjacent sample windows should be.
            </param>
            <param name="magnitude_squared">
               Whether to return the squared magnitude or just the
               magnitude. Using squared magnitude can avoid extra calculations.
            </param>
            <returns>
               3D representation of the audio frequencies as an image.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Spectrograms are a standard way of representing audio information as a series of
               slices of frequency information, one slice for each window of time. By joining
               these together into a sequence, they form a distinctive fingerprint of the sound
               over time.
               
               This op expects to receive audio data as an input, stored as floats in the range
               -1 to 1, together with a window width in samples, and a stride specifying how
               far to move the window between slices. From this it generates a three
               dimensional output. The lowest dimension has an amplitude value for each
               frequency during that time slice. The next dimension is time, with successive
               frequency slices. The final dimension is for the channels in the input, so a
               stereo audio input would have two here for example.
               
               This means the layout when converted and saved as an image is rotated 90 degrees
               clockwise from a typical spectrogram. Time is descending down the Y axis, and
               the frequency decreases from left to right.
               
               Each value in the result represents the square root of the sum of the real and
               imaginary parts of an FFT on the current window of samples. In this way, the
               lowest dimension represents the power of each frequency in the current window,
               and adjacent windows are concatenated in the next dimension.
               
               To get a more intuitive and visual look at what this operation does, you can run
               tensorflow/examples/wav_to_spectrogram to read in an audio file and save out the
               resulting spectrogram as a PNG image.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.audio_summary(Tensorflow.Tensor,Tensorflow.Tensor,System.Single,System.Nullable{System.Int32},System.String)">
            <summary>
               Outputs a <c>Summary</c> protocol buffer with audio.
            </summary>
            <param name="tag">
               Scalar. Used to build the <c>tag</c> attribute of the summary values.
            </param>
            <param name="tensor">
               2-D of shape <c>[batch_size, frames]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'AudioSummary'.
            </param>
            <param name="sample_rate">
               Optional argument
               The sample rate of the signal in hertz.
            </param>
            <param name="max_outputs">
               Max number of batch elements to generate audio for.
            </param>
            <returns>
               Scalar. Serialized <c>Summary</c> protocol buffer.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The summary has up to <c>max_outputs</c> summary values containing audio. The
               audio is built from <c>tensor</c> which must be 3-D with shape <c>[batch_size,
               frames, channels]</c> or 2-D with shape <c>[batch_size, frames]</c>. The values are
               assumed to be in the range of <c>[-1.0, 1.0]</c> with a sample rate of <c>sample_rate</c>.
               
               The <c>tag</c> argument is a scalar <c>Tensor</c> of type <c>string</c>.  It is used to
               build the <c>tag</c> of the summary values:
               
               *  If <c>max_outputs</c> is 1, the summary value tag is '*tag*/audio'.
               *  If <c>max_outputs</c> is greater than 1, the summary value tags are
               generated sequentially as '*tag*/audio/0', '*tag*/audio/1', etc.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.audio_summary_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Int32},System.String)">
            <summary>
               Outputs a <c>Summary</c> protocol buffer with audio.
            </summary>
            <param name="tag">
               Scalar. Used to build the <c>tag</c> attribute of the summary values.
            </param>
            <param name="tensor">
               2-D of shape <c>[batch_size, frames]</c>.
            </param>
            <param name="sample_rate">
               The sample rate of the signal in hertz.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'AudioSummaryV2'.
            </param>
            <param name="max_outputs">
               Max number of batch elements to generate audio for.
            </param>
            <returns>
               Scalar. Serialized <c>Summary</c> protocol buffer.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The summary has up to <c>max_outputs</c> summary values containing audio. The
               audio is built from <c>tensor</c> which must be 3-D with shape <c>[batch_size,
               frames, channels]</c> or 2-D with shape <c>[batch_size, frames]</c>. The values are
               assumed to be in the range of <c>[-1.0, 1.0]</c> with a sample rate of <c>sample_rate</c>.
               
               The <c>tag</c> argument is a scalar <c>Tensor</c> of type <c>string</c>.  It is used to
               build the <c>tag</c> of the summary values:
               
               *  If <c>max_outputs</c> is 1, the summary value tag is '*tag*/audio'.
               *  If <c>max_outputs</c> is greater than 1, the summary value tags are
               generated sequentially as '*tag*/audio/0', '*tag*/audio/1', etc.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.avg_pool(Tensorflow.Tensor,System.Int32[],System.Int32[],System.String,System.String,System.String)">
            <summary>
               Performs average pooling on the input.
            </summary>
            <param name="value">
               4-D with shape <c>[batch, height, width, channels]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'AvgPool'.
            </param>
            <param name="ksize">
               Optional argument
               The size of the sliding window for each dimension of <c>value</c>.
            </param>
            <param name="strides">
               Optional argument
               The stride of the sliding window for each dimension of <c>value</c>.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <param name="data_format">
               Specify the data format of the input and output data. With the
               default format "NHWC", the data is stored in the order of:
               [batch, in_height, in_width, in_channels].
               Alternatively, the format could be "NCHW", the data storage order of:
               [batch, in_channels, in_height, in_width].
            </param>
            <returns>
               The average pooled output tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Each entry in <c>output</c> is the mean of the corresponding size <c>ksize</c>
               window in <c>value</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.avg_pool3d(Tensorflow.Tensor,System.Int32[],System.Int32[],System.String,System.String,System.String)">
            <summary>
               Performs 3D average pooling on the input.
            </summary>
            <param name="input">
               Shape <c>[batch, depth, rows, cols, channels]</c> tensor to pool over.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'AvgPool3D'.
            </param>
            <param name="ksize">
               Optional argument
               1-D tensor of length 5. The size of the window for each dimension of
               the input tensor. Must have <c>ksize[0] = ksize[4] = 1</c>.
            </param>
            <param name="strides">
               Optional argument
               1-D tensor of length 5. The stride of the sliding window for each
               dimension of <c>input</c>. Must have <c>strides[0] = strides[4] = 1</c>.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <param name="data_format">
               The data format of the input and output data. With the
               default format "NDHWC", the data is stored in the order of:
               [batch, in_depth, in_height, in_width, in_channels].
               Alternatively, the format could be "NCDHW", the data storage order is:
               [batch, in_channels, in_depth, in_height, in_width].
            </param>
            <returns>
               The average pooled output tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.avg_pool3d_grad(Tensorflow.Tensor,Tensorflow.Tensor,System.Int32[],System.Int32[],System.String,System.String,System.String)">
            <summary>
               Computes gradients of average pooling function.
            </summary>
            <param name="orig_input_shape">
               The original input dimensions.
            </param>
            <param name="grad">
               Output backprop of shape <c>[batch, depth, rows, cols, channels]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'AvgPool3DGrad'.
            </param>
            <param name="ksize">
               Optional argument
               1-D tensor of length 5. The size of the window for each dimension of
               the input tensor. Must have <c>ksize[0] = ksize[4] = 1</c>.
            </param>
            <param name="strides">
               Optional argument
               1-D tensor of length 5. The stride of the sliding window for each
               dimension of <c>input</c>. Must have <c>strides[0] = strides[4] = 1</c>.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <param name="data_format">
               The data format of the input and output data. With the
               default format "NDHWC", the data is stored in the order of:
               [batch, in_depth, in_height, in_width, in_channels].
               Alternatively, the format could be "NCDHW", the data storage order is:
               [batch, in_channels, in_depth, in_height, in_width].
            </param>
            <returns>
               The backprop for input.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.avg_pool_grad(Tensorflow.Tensor,Tensorflow.Tensor,System.Int32[],System.Int32[],System.String,System.String,System.String)">
            <summary>
               Computes gradients of the average pooling function.
            </summary>
            <param name="orig_input_shape">
               1-D.  Shape of the original input to <c>avg_pool</c>.
            </param>
            <param name="grad">
               4-D with shape <c>[batch, height, width, channels]</c>.  Gradients w.r.t.
               the output of <c>avg_pool</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'AvgPoolGrad'.
            </param>
            <param name="ksize">
               Optional argument
               The size of the sliding window for each dimension of the input.
            </param>
            <param name="strides">
               Optional argument
               The stride of the sliding window for each dimension of the input.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <param name="data_format">
               Specify the data format of the input and output data. With the
               default format "NHWC", the data is stored in the order of:
               [batch, in_height, in_width, in_channels].
               Alternatively, the format could be "NCHW", the data storage order of:
               [batch, in_channels, in_height, in_width].
            </param>
            <returns>
               4-D.  Gradients w.r.t. the input of <c>avg_pool</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.barrier(Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               Defines a barrier that persists across different graph executions.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Barrier'.
            </param>
            <param name="component_types">
               Optional argument
               The type of each component in a value.
            </param>
            <param name="shapes">
               The shape of each component in a value. Each shape must be 1 in the
               first dimension. The length of this attr must be the same as the length of
               component_types.
            </param>
            <param name="capacity">
               The capacity of the barrier.  The default capacity is MAX_INT32,
               which is the largest capacity of the underlying queue.
            </param>
            <param name="container">
               If non-empty, this barrier is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this barrier will be shared under the given name
               across multiple sessions.
            </param>
            <returns>
               The handle to the barrier.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               A barrier represents a key-value map, where each key is a string, and
               each value is a tuple of tensors.
               
               At runtime, the barrier contains 'complete' and 'incomplete'
               elements. A complete element has defined tensors for all components of
               its value tuple, and may be accessed using BarrierTakeMany. An
               incomplete element has some undefined components in its value tuple,
               and may be updated using BarrierInsertMany.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.barrier_close(Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Closes the given barrier.
            </summary>
            <param name="handle">
               The handle to a barrier.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BarrierClose'.
            </param>
            <param name="cancel_pending_enqueues">
               If true, all pending enqueue requests that are
               blocked on the barrier's queue will be canceled. InsertMany will fail, even
               if no new key is introduced.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               This operation signals that no more new elements will be inserted in the
               given barrier. Subsequent InsertMany that try to introduce a new key will fail.
               Subsequent InsertMany operations that just add missing components to already
               existing elements will continue to succeed. Subsequent TakeMany operations will
               continue to succeed if sufficient completed elements remain in the barrier.
               Subsequent TakeMany operations that would block will fail immediately.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.barrier_incomplete_size(Tensorflow.Tensor,System.String)">
            <summary>
               Computes the number of incomplete elements in the given barrier.
            </summary>
            <param name="handle">
               The handle to a barrier.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BarrierIncompleteSize'.
            </param>
            <returns>
               The number of incomplete elements (i.e. those with some of their value
               components not set) in the barrier.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.barrier_insert_many(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32,System.String)">
            <summary>
               For each key, assigns the respective value to the specified component.
            </summary>
            <param name="handle">
               The handle to a barrier.
            </param>
            <param name="keys">
               A one-dimensional tensor of keys, with length n.
            </param>
            <param name="values">
               An any-dimensional tensor of values, which are associated with the
               respective keys. The 0th dimension must have length n.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BarrierInsertMany'.
            </param>
            <param name="component_index">
               Optional argument
               The component of the barrier elements that is being assigned.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               If a key is not found in the barrier, this operation will create a new
               incomplete element. If a key is found in the barrier, and the element
               already has a value at component_index, this operation will fail with
               INVALID_ARGUMENT, and leave the barrier in an undefined state.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.barrier_ready_size(Tensorflow.Tensor,System.String)">
            <summary>
               Computes the number of complete elements in the given barrier.
            </summary>
            <param name="handle">
               The handle to a barrier.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BarrierReadySize'.
            </param>
            <returns>
               The number of complete elements (i.e. those with all of their value
               components set) in the barrier.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.barrier_take_many(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Int32},System.String)">
            <summary>
               Takes the given number of completed elements from a barrier.
            </summary>
            <param name="handle">
               The handle to a barrier.
            </param>
            <param name="num_elements">
               A single-element tensor containing the number of elements to
               take.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BarrierTakeMany'.
            </param>
            <param name="component_types">
               Optional argument
               The type of each component in a value.
            </param>
            <param name="allow_small_batch">
               Allow to return less than num_elements items if barrier is
               already closed.
            </param>
            <param name="wait_for_incomplete">
            </param>
            <param name="timeout_ms">
               If the queue is empty, this operation will block for up to
               timeout_ms milliseconds.
               Note: This option is not supported yet.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               indices : A one-dimensional tensor of indices, with length num_elems.
               These indices refer to the batch in which the values were placed into the
               barrier (starting with MIN_LONG and increasing with each BarrierInsertMany).
               keys : A one-dimensional tensor of keys, with length num_elements.
               values : One any-dimensional tensor per component in a barrier element. All
               values have length num_elements in the 0th dimension.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               This operation concatenates completed-element component tensors along
               the 0th dimension to make a single component tensor.
               
               Elements come out of the barrier when they are complete, and in the order
               in which they were placed into the barrier.  The indices output provides
               information about the batch in which each element was originally inserted
               into the barrier.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.batch(Tensorflow.Tensor[],System.Int32,System.Int32,System.Int32,System.Int32,System.Nullable{System.Int32},System.Int32[],System.String,System.String,System.String,System.String)">
            <summary>
               Batches all input tensors nondeterministically.
            </summary>
            <param name="in_tensors">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Batch'.
            </param>
            <param name="num_batch_threads">
               Optional argument
            </param>
            <param name="max_batch_size">
               Optional argument
            </param>
            <param name="batch_timeout_micros">
               Optional argument
            </param>
            <param name="grad_timeout_micros">
               Optional argument
            </param>
            <param name="max_enqueued_batches">
            </param>
            <param name="allowed_batch_sizes">
            </param>
            <param name="container">
            </param>
            <param name="shared_name">
            </param>
            <param name="batching_queue">
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               batched_tensors :
               batch_index :
               id :
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               When many instances of this Op are being run concurrently with the same
               container/shared_name in the same device, some will output zero-shaped Tensors
               and others will output Tensors of size up to max_batch_size.
               
               All Tensors in in_tensors are batched together (so, for example, labels and
               features should be batched with a single instance of this operation.
               
               Each invocation of batch emits an <c>id</c> scalar which will be used to identify
               this particular invocation when doing unbatch or its gradient.
               
               Each op which emits a non-empty batch will also emit a non-empty batch_index
               Tensor, which, is a [K, 3] matrix where each row contains the invocation's id,
               start, and length of elements of each set of Tensors present in batched_tensors.
               
               Batched tensors are concatenated along the first dimension, and all tensors in
               in_tensors must have the first dimension of the same size.
               
               in_tensors: The tensors to be batched.
               num_batch_threads: Number of scheduling threads for processing batches of work.
               Determines the number of batches processed in parallel.
               max_batch_size: Batch sizes will never be bigger than this.
               batch_timeout_micros: Maximum number of microseconds to wait before outputting
               an incomplete batch.
               allowed_batch_sizes: Optional list of allowed batch sizes. If left empty, does
               nothing. Otherwise, supplies a list of batch sizes, causing the op to pad
               batches up to one of those sizes. The entries must increase monotonically, and
               the final entry must equal max_batch_size.
               grad_timeout_micros: The timeout to use for the gradient. See Unbatch.
               batched_tensors: Either empty tensors or a batch of concatenated Tensors.
               batch_index: If out_tensors is non-empty, has information to invert it.
               container: Controls the scope of sharing of this batch.
               id: always contains a scalar with a unique ID for this invocation of Batch.
               shared_name: Concurrently running instances of batch in the same device with the
               same container and shared_name will batch their elements together. If left
               empty, the op name will be used as the shared name.
               T: the types of tensors to be batched.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.batch_dataset(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Creates a dataset that batches <c>batch_size</c> elements from <c>input_dataset</c>.
            </summary>
            <param name="input_dataset">
            </param>
            <param name="batch_size">
               A scalar representing the number of elements to accumulate in a
               batch.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BatchDataset'.
            </param>
            <param name="output_types">
               Optional argument
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.batch_dataset_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Creates a dataset that batches <c>batch_size</c> elements from <c>input_dataset</c>.
            </summary>
            <param name="input_dataset">
            </param>
            <param name="batch_size">
               A scalar representing the number of elements to accumulate in a batch.
            </param>
            <param name="drop_remainder">
               A scalar representing whether the last batch should be dropped in case its size
               is smaller than desired.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BatchDatasetV2'.
            </param>
            <param name="output_types">
               Optional argument
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.batch_mat_mul(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.String)">
            <summary>
               Multiplies slices of two tensors in batches.
            </summary>
            <param name="x">
               2-D or higher with shape <c>[..., r_x, c_x]</c>.
            </param>
            <param name="y">
               2-D or higher with shape <c>[..., r_y, c_y]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BatchMatMul'.
            </param>
            <param name="adj_x">
               If <c>True</c>, adjoint the slices of <c>x</c>. Defaults to <c>False</c>.
            </param>
            <param name="adj_y">
               If <c>True</c>, adjoint the slices of <c>y</c>. Defaults to <c>False</c>.
            </param>
            <returns>
               3-D or higher with shape <c>[..., r_o, c_o]</c>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Multiplies all slices of <c>Tensor</c> <c>x</c> and <c>y</c> (each slice can be
               viewed as an element of a batch), and arranges the individual results
               in a single output tensor of the same batch size. Each of the
               individual slices can optionally be adjointed (to adjoint a matrix
               means to transpose and conjugate it) before multiplication by setting
               the <c>adj_x</c> or <c>adj_y</c> flag to <c>True</c>, which are by default <c>False</c>.
               
               The input tensors <c>x</c> and <c>y</c> are 2-D or higher with shape <c>[..., r_x, c_x]</c>
               and <c>[..., r_y, c_y]</c>.
               
               The output tensor is 2-D or higher with shape <c>[..., r_o, c_o]</c>, where:
               
               r_o = c_x if adj_x else r_x
               c_o = r_y if adj_y else c_y
               
               It is computed as:
               
               output[..., :, :] = matrix(x[..., :, :]) * matrix(y[..., :, :])
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.batch_norm_with_global_normalization(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Single,System.Boolean,System.String)">
            <summary>
               Batch normalization.
            </summary>
            <param name="t">
               A 4D input Tensor.
            </param>
            <param name="m">
               A 1D mean Tensor with size matching the last dimension of t.
               This is the first output from tf.nn.moments,
               or a saved moving average thereof.
            </param>
            <param name="v">
               A 1D variance Tensor with size matching the last dimension of t.
               This is the second output from tf.nn.moments,
               or a saved moving average thereof.
            </param>
            <param name="beta">
               A 1D beta Tensor with size matching the last dimension of t.
               An offset to be added to the normalized tensor.
            </param>
            <param name="gamma">
               A 1D gamma Tensor with size matching the last dimension of t.
               If "scale_after_normalization" is true, this tensor will be multiplied
               with the normalized tensor.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BatchNormWithGlobalNormalization'.
            </param>
            <param name="variance_epsilon">
               Optional argument
               A small float number to avoid dividing by 0.
            </param>
            <param name="scale_after_normalization">
               Optional argument
               A bool indicating whether the resulted tensor
               needs to be multiplied with gamma.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This op is deprecated. Prefer <c>tf.nn.batch_normalization</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.batch_norm_with_global_normalization_grad(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Single,System.Boolean,System.String)">
            <summary>
               Gradients for batch normalization.
            </summary>
            <param name="t">
               A 4D input Tensor.
            </param>
            <param name="m">
               A 1D mean Tensor with size matching the last dimension of t.
               This is the first output from tf.nn.moments,
               or a saved moving average thereof.
            </param>
            <param name="v">
               A 1D variance Tensor with size matching the last dimension of t.
               This is the second output from tf.nn.moments,
               or a saved moving average thereof.
            </param>
            <param name="gamma">
               A 1D gamma Tensor with size matching the last dimension of t.
               If "scale_after_normalization" is true, this Tensor will be multiplied
               with the normalized Tensor.
            </param>
            <param name="backprop">
               4D backprop Tensor.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BatchNormWithGlobalNormalizationGrad'.
            </param>
            <param name="variance_epsilon">
               Optional argument
               A small float number to avoid dividing by 0.
            </param>
            <param name="scale_after_normalization">
               Optional argument
               A bool indicating whether the resulted tensor
               needs to be multiplied with gamma.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               dx : 4D backprop tensor for input.
               dm : 1D backprop tensor for mean.
               dv : 1D backprop tensor for variance.
               db : 1D backprop tensor for beta.
               dg : 1D backprop tensor for gamma.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               This op is deprecated. See <c>tf.nn.batch_normalization</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.batch_to_space(Tensorflow.Tensor,Tensorflow.Tensor,System.Int32,System.String)">
            <summary>
               BatchToSpace for 4-D tensors of type T.
            </summary>
            <param name="input">
               4-D tensor with shape
               <c>[batch*block_size*block_size, height_pad/block_size, width_pad/block_size,
               depth]</c>. Note that the batch size of the input tensor must be divisible by
               <c>block_size * block_size</c>.
            </param>
            <param name="crops">
               2-D tensor of non-negative integers with shape <c>[2, 2]</c>. It specifies
               how many elements to crop from the intermediate result across the spatial
               dimensions as follows:
               
               crops = [[crop_top, crop_bottom], [crop_left, crop_right]]
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BatchToSpace'.
            </param>
            <param name="block_size">
               Optional argument
            </param>
            <returns>
               4-D with shape <c>[batch, height, width, depth]</c>, where:
               
               height = height_pad - crop_top - crop_bottom
               width = width_pad - crop_left - crop_right
               
               The attr <c>block_size</c> must be greater than one. It indicates the block size.
               
               Some examples:
               
               (1) For the following input of shape <c>[4, 1, 1, 1]</c> and block_size of 2:
               
              <code>
               [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]
              </code>
               
               The output tensor has shape <c>[1, 2, 2, 1]</c> and value:
               
              <code>
               x = [[[[1], [2]], [[3], [4]]]]
              </code>
               
               (2) For the following input of shape <c>[4, 1, 1, 3]</c> and block_size of 2:
               
              <code>
               [[[1, 2, 3]], [[4, 5, 6]], [[7, 8, 9]], [[10, 11, 12]]]
              </code>
               
               The output tensor has shape <c>[1, 2, 2, 3]</c> and value:
               
              <code>
               x = [[[[1, 2, 3], [4, 5, 6]],
               [[7, 8, 9], [10, 11, 12]]]]
              </code>
               
               (3) For the following input of shape <c>[4, 2, 2, 1]</c> and block_size of 2:
               
              <code>
               x = [[[[1], [3]], [[9], [11]]],
               [[[2], [4]], [[10], [12]]],
               [[[5], [7]], [[13], [15]]],
               [[[6], [8]], [[14], [16]]]]
              </code>
               
               The output tensor has shape <c>[1, 4, 4, 1]</c> and value:
               
              <code>
               x = [[[1],   [2],  [3],  [4]],
               [[5],   [6],  [7],  [8]],
               [[9],  [10], [11],  [12]],
               [[13], [14], [15],  [16]]]
              </code>
               
               (4) For the following input of shape <c>[8, 1, 2, 1]</c> and block_size of 2:
               
              <code>
               x = [[[[1], [3]]], [[[9], [11]]], [[[2], [4]]], [[[10], [12]]],
               [[[5], [7]]], [[[13], [15]]], [[[6], [8]]], [[[14], [16]]]]
              </code>
               
               The output tensor has shape <c>[2, 2, 4, 1]</c> and value:
               
              <code>
               x = [[[[1], [3]], [[5], [7]]],
               [[[2], [4]], [[10], [12]]],
               [[[5], [7]], [[13], [15]]],
               [[[6], [8]], [[14], [16]]]]
              </code>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This is a legacy version of the more general BatchToSpaceND.
               
               Rearranges (permutes) data from batch into blocks of spatial data, followed by
               cropping. This is the reverse transformation of SpaceToBatch. More specifically,
               this op outputs a copy of the input tensor where values from the <c>batch</c>
               dimension are moved in spatial blocks to the <c>height</c> and <c>width</c> dimensions,
               followed by cropping along the <c>height</c> and <c>width</c> dimensions.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.batch_to_space_n_d(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               BatchToSpace for N-D tensors of type T.
            </summary>
            <param name="input">
               N-D with shape <c>input_shape = [batch] + spatial_shape + remaining_shape</c>,
               where spatial_shape has M dimensions.
            </param>
            <param name="block_shape">
               1-D with shape <c>[M]</c>, all values must be &amp;gt;= 1.
            </param>
            <param name="crops">
               2-D with shape <c>[M, 2]</c>, all values must be &amp;gt;= 0.
               <c>crops[i] = [crop_start, crop_end]</c> specifies the amount to crop from input
               dimension <c>i + 1</c>, which corresponds to spatial dimension <c>i</c>.  It is
               required that
               <c>crop_start[i] + crop_end[i] &amp;lt;= block_shape[i] * input_shape[i + 1]</c>.
               
               This operation is equivalent to the following steps:
               
               1. Reshape <c>input</c> to <c>reshaped</c> of shape:
               [block_shape[0], ..., block_shape[M-1],
               batch / prod(block_shape),
               input_shape[1], ..., input_shape[N-1]]
               
               2. Permute dimensions of <c>reshaped</c> to produce <c>permuted</c> of shape
               [batch / prod(block_shape),
               
               input_shape[1], block_shape[0],
               ...,
               input_shape[M], block_shape[M-1],
               
               input_shape[M+1], ..., input_shape[N-1]]
               
               3. Reshape <c>permuted</c> to produce <c>reshaped_permuted</c> of shape
               [batch / prod(block_shape),
               
               input_shape[1] * block_shape[0],
               ...,
               input_shape[M] * block_shape[M-1],
               
               input_shape[M+1],
               ...,
               input_shape[N-1]]
               
               4. Crop the start and end of dimensions <c>[1, ..., M]</c> of
               <c>reshaped_permuted</c> according to <c>crops</c> to produce the output of shape:
               [batch / prod(block_shape),
               
               input_shape[1] * block_shape[0] - crops[0,0] - crops[0,1],
               ...,
               input_shape[M] * block_shape[M-1] - crops[M-1,0] - crops[M-1,1],
               
               input_shape[M+1], ..., input_shape[N-1]]
               
               Some examples:
               
               (1) For the following input of shape <c>[4, 1, 1, 1]</c>, <c>block_shape = [2, 2]</c>, and
               <c>crops = [[0, 0], [0, 0]]</c>:
               
              <code>
               [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]
              </code>
               
               The output tensor has shape <c>[1, 2, 2, 1]</c> and value:
               
              <code>
               x = [[[[1], [2]], [[3], [4]]]]
              </code>
               
               (2) For the following input of shape <c>[4, 1, 1, 3]</c>, <c>block_shape = [2, 2]</c>, and
               <c>crops = [[0, 0], [0, 0]]</c>:
               
              <code>
               [[[1, 2, 3]], [[4, 5, 6]], [[7, 8, 9]], [[10, 11, 12]]]
              </code>
               
               The output tensor has shape <c>[1, 2, 2, 3]</c> and value:
               
              <code>
               x = [[[[1, 2, 3], [4, 5, 6]],
               [[7, 8, 9], [10, 11, 12]]]]
              </code>
               
               (3) For the following input of shape <c>[4, 2, 2, 1]</c>, <c>block_shape = [2, 2]</c>, and
               <c>crops = [[0, 0], [0, 0]]</c>:
               
              <code>
               x = [[[[1], [3]], [[9], [11]]],
               [[[2], [4]], [[10], [12]]],
               [[[5], [7]], [[13], [15]]],
               [[[6], [8]], [[14], [16]]]]
              </code>
               
               The output tensor has shape <c>[1, 4, 4, 1]</c> and value:
               
              <code>
               x = [[[1],   [2],  [3],  [4]],
               [[5],   [6],  [7],  [8]],
               [[9],  [10], [11],  [12]],
               [[13], [14], [15],  [16]]]
              </code>
               
               (4) For the following input of shape <c>[8, 1, 3, 1]</c>, <c>block_shape = [2, 2]</c>, and
               <c>crops = [[0, 0], [2, 0]]</c>:
               
              <code>
               x = [[[[0], [1], [3]]], [[[0], [9], [11]]],
               [[[0], [2], [4]]], [[[0], [10], [12]]],
               [[[0], [5], [7]]], [[[0], [13], [15]]],
               [[[0], [6], [8]]], [[[0], [14], [16]]]]
              </code>
               
               The output tensor has shape <c>[2, 2, 4, 1]</c> and value:
               
              <code>
               x = [[[[1],   [2],  [3],  [4]],
               [[5],   [6],  [7],  [8]]],
               [[[9],  [10], [11],  [12]],
               [[13], [14], [15],  [16]]]]
              </code>
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BatchToSpaceND'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation reshapes the "batch" dimension 0 into <c>M + 1</c> dimensions of shape
               <c>block_shape + [batch]</c>, interleaves these blocks back into the grid defined by
               the spatial dimensions <c>[1, ..., M]</c>, to obtain a result with the same rank as
               the input.  The spatial dimensions of this intermediate result are then
               optionally cropped according to <c>crops</c> to produce the output.  This is the
               reverse of SpaceToBatch.  See below for a precise description.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.bessel_i0e(Tensorflow.Tensor,System.String)">
            <summary>
               Computes the Bessel i0e function of <c>x</c> element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BesselI0e'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Exponentially scaled modified Bessel function of order 0 defined as
               <c>bessel_i0e(x) = exp(-abs(x)) bessel_i0(x)</c>.
               
               This function is faster and numerically stabler than <c>bessel_i0(x)</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.bessel_i1e(Tensorflow.Tensor,System.String)">
            <summary>
               Computes the Bessel i1e function of <c>x</c> element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BesselI1e'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Exponentially scaled modified Bessel function of order 0 defined as
               <c>bessel_i1e(x) = exp(-abs(x)) bessel_i1(x)</c>.
               
               This function is faster and numerically stabler than <c>bessel_i1(x)</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.betainc(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Compute the regularized incomplete beta integral \\(I_x(a, b)\\).
            </summary>
            <param name="a">
            </param>
            <param name="b">
            </param>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Betainc'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The regularized incomplete beta integral is defined as:
               
               
               \\(I_x(a, b) = \frac{B(x; a, b)}{B(a, b)}\\)
               
               where
               
               
               \\(B(x; a, b) = \int_0^x t^{a-1} (1 - t)^{b-1} dt\\)
               
               
               is the incomplete beta function and \\(B(a, b)\\) is the *complete*
               beta function.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.bias_add(Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.String)">
            <summary>
               Adds <c>bias</c> to <c>value</c>.
            </summary>
            <param name="value">
               Any number of dimensions.
            </param>
            <param name="bias">
               1-D with size the last dimension of <c>value</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BiasAdd'.
            </param>
            <param name="data_format">
               Specify the data format of the input and output data. With the
               default format "NHWC", the bias tensor will be added to the last dimension
               of the value tensor.
               Alternatively, the format could be "NCHW", the data storage order of:
               [batch, in_channels, in_height, in_width].
               The tensor will be added to "in_channels", the third-to-the-last
               dimension.
            </param>
            <returns>
               Broadcasted sum of <c>value</c> and <c>bias</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This is a special case of <c>tf.add</c> where <c>bias</c> is restricted to be 1-D.
               Broadcasting is supported, so <c>value</c> may have any number of dimensions.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.bias_add_grad(Tensorflow.Tensor,System.String,System.String)">
            <summary>
               The backward operation for "BiasAdd" on the "bias" tensor.
            </summary>
            <param name="out_backprop">
               Any number of dimensions.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BiasAddGrad'.
            </param>
            <param name="data_format">
               Specify the data format of the input and output data. With the
               default format "NHWC", the bias tensor will be added to the last dimension
               of the value tensor.
               Alternatively, the format could be "NCHW", the data storage order of:
               [batch, in_channels, in_height, in_width].
               The tensor will be added to "in_channels", the third-to-the-last
               dimension.
            </param>
            <returns>
               1-D with size the feature dimension of <c>out_backprop</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               It accumulates all the values from out_backprop into the feature dimension.
               For NHWC data format, the feature dimension is the last. For NCHW data format,
               the feature dimension is the third-to-last.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.bias_add_v1(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Adds <c>bias</c> to <c>value</c>.
            </summary>
            <param name="value">
               Any number of dimensions.
            </param>
            <param name="bias">
               1-D with size the last dimension of <c>value</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BiasAddV1'.
            </param>
            <returns>
               Broadcasted sum of <c>value</c> and <c>bias</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This is a deprecated version of BiasAdd and will be soon removed.
               
               This is a special case of <c>tf.add</c> where <c>bias</c> is restricted to be 1-D.
               Broadcasting is supported, so <c>value</c> may have any number of dimensions.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.bincount(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Counts the number of occurrences of each value in an integer array.
            </summary>
            <param name="arr">
               int32 <c>Tensor</c>.
            </param>
            <param name="size">
               non-negative int32 scalar <c>Tensor</c>.
            </param>
            <param name="weights">
               is an int32, int64, float32, or float64 <c>Tensor</c> with the same
               shape as <c>arr</c>, or a length-0 <c>Tensor</c>, in which case it acts as all weights
               equal to 1.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Bincount'.
            </param>
            <returns>
               1D <c>Tensor</c> with length equal to <c>size</c>. The counts or summed weights for
               each value in the range [0, size).
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Outputs a vector with length <c>size</c> and the same dtype as <c>weights</c>. If
               <c>weights</c> are empty, then index <c>i</c> stores the number of times the value <c>i</c> is
               counted in <c>arr</c>. If <c>weights</c> are non-empty, then index <c>i</c> stores the sum of
               the value in <c>weights</c> at each index where the corresponding value in <c>arr</c> is
               <c>i</c>.
               
               Values in <c>arr</c> outside of the range [0, size) are ignored.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.bitcast(Tensorflow.Tensor,Tensorflow.TF_DataType,System.String)">
            <summary>
               Bitcasts a tensor from one type to another without copying data.
            </summary>
            <param name="input">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Bitcast'.
            </param>
            <param name="type">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Given a tensor <c>input</c>, this operation returns a tensor that has the same buffer
               data as <c>input</c> with datatype <c>type</c>.
               
               If the input datatype <c>T</c> is larger than the output datatype <c>type</c> then the
               shape changes from [...] to [..., sizeof(<c>T</c>)/sizeof(<c>type</c>)].
               
               If <c>T</c> is smaller than <c>type</c>, the operator requires that the rightmost
               dimension be equal to sizeof(<c>type</c>)/sizeof(<c>T</c>). The shape then goes from
               [..., sizeof(<c>type</c>)/sizeof(<c>T</c>)] to [...].
               
               *NOTE*: Bitcast is implemented as a low-level cast, so machines with different
               endian orderings will give different results.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.bitwise_and(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Elementwise computes the bitwise AND of <c>x</c> and <c>y</c>.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BitwiseAnd'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The result will have those bits set, that are set in both <c>x</c> and <c>y</c>. The
               computation is performed on the underlying representations of <c>x</c> and <c>y</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.bitwise_or(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Elementwise computes the bitwise OR of <c>x</c> and <c>y</c>.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BitwiseOr'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The result will have those bits set, that are set in <c>x</c>, <c>y</c> or both. The
               computation is performed on the underlying representations of <c>x</c> and <c>y</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.bitwise_xor(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Elementwise computes the bitwise XOR of <c>x</c> and <c>y</c>.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BitwiseXor'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The result will have those bits set, that are different in <c>x</c> and <c>y</c>. The
               computation is performed on the underlying representations of <c>x</c> and <c>y</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.boosted_trees_calculate_best_gains_per_feature(Tensorflow.Tensor,Tensorflow.Tensor[],Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32,System.String)">
            <summary>
               Calculates gains for each feature and returns the best possible split information for the feature.
            </summary>
            <param name="node_id_range">
               A Rank 1 tensor (shape=[2]) to specify the range [first, last) of node ids to process within <c>stats_summary_list</c>. The nodes are iterated between the two nodes specified by the tensor, as like <c>for node_id in range(node_id_range[0], node_id_range[1])</c> (Note that the last index node_id_range[1] is exclusive).
            </param>
            <param name="stats_summary_list">
               A list of Rank 3 tensor (#shape=[max_splits, bucket, 2]) for accumulated stats summary (gradient/hessian) per node per buckets for each feature. The first dimension of the tensor is the maximum number of splits, and thus not all elements of it will be used, but only the indexes specified by node_ids will be used.
            </param>
            <param name="l1">
               l1 regularization factor on leaf weights, per instance based.
            </param>
            <param name="l2">
               l2 regularization factor on leaf weights, per instance based.
            </param>
            <param name="tree_complexity">
               adjustment to the gain, per leaf based.
            </param>
            <param name="min_node_weight">
               mininum avg of hessians in a node before required for the node to be considered for splitting.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BoostedTreesCalculateBestGainsPerFeature'.
            </param>
            <param name="max_splits">
               Optional argument
               the number of nodes that can be split in the whole tree. Used as a dimension of output tensors.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               node_ids_list : An output list of Rank 1 tensors indicating possible split node ids for each feature. The length of the list is num_features, but each tensor has different size as each feature provides different possible nodes. See above for details like shapes and sizes.
               gains_list : An output list of Rank 1 tensors indicating the best gains for each feature to split for certain nodes. See above for details like shapes and sizes.
               thresholds_list : An output list of Rank 1 tensors indicating the bucket id to compare with (as a threshold) for split in each node. See above for details like shapes and sizes.
               left_node_contribs_list : A list of Rank 2 tensors indicating the contribution of the left nodes when branching from parent nodes (given by the tensor element in the output node_ids_list) to the left direction by the given threshold for each feature. This value will be used to make the left node value by adding to the parent node value. Second dimension size is 1 for 1-dimensional logits, but would be larger for multi-class problems. See above for details like shapes and sizes.
               right_node_contribs_list : A list of Rank 2 tensors, with the same shape/conditions as left_node_contribs_list, but just that the value is for the right node.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               The split information is the best threshold (bucket id), gains and left/right node contributions per node for each feature.
               
               It is possible that not all nodes can be split on each feature. Hence, the list of possible nodes can differ between the features. Therefore, we return <c>node_ids_list</c> for each feature, containing the list of nodes that this feature can be used to split.
               
               In this manner, the output is the best split per features and per node, so that it needs to be combined later to produce the best split for each node (among all possible features).
               
               The length of output lists are all of the same length, <c>num_features</c>.
               The output shapes are compatible in a way that the first dimension of all tensors of all lists are the same and equal to the number of possible split nodes for each feature.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.boosted_trees_center_bias(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Calculates the prior from the training data (the bias) and fills in the first node with the logits' prior. Returns a boolean indicating whether to continue centering.
            </summary>
            <param name="tree_ensemble_handle">
               Handle to the tree ensemble.
            </param>
            <param name="mean_gradients">
               A tensor with shape=[logits_dimension] with mean of gradients for a first node.
            </param>
            <param name="mean_hessians">
               A tensor with shape=[logits_dimension] mean of hessians for a first node.
            </param>
            <param name="l1">
               l1 regularization factor on leaf weights, per instance based.
            </param>
            <param name="l2">
               l2 regularization factor on leaf weights, per instance based.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BoostedTreesCenterBias'.
            </param>
            <returns>
               Bool, whether to continue bias centering.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.boosted_trees_create_ensemble(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Creates a tree ensemble model and returns a handle to it.
            </summary>
            <param name="tree_ensemble_handle">
               Handle to the tree ensemble resource to be created.
            </param>
            <param name="stamp_token">
               Token to use as the initial value of the resource stamp.
            </param>
            <param name="tree_ensemble_serialized">
               Serialized proto of the tree ensemble.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BoostedTreesCreateEnsemble'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.boosted_trees_deserialize_ensemble(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Deserializes a serialized tree ensemble config and replaces current tree
            </summary>
            <param name="tree_ensemble_handle">
               Handle to the tree ensemble.
            </param>
            <param name="stamp_token">
               Token to use as the new value of the resource stamp.
            </param>
            <param name="tree_ensemble_serialized">
               Serialized proto of the ensemble.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BoostedTreesDeserializeEnsemble'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               ensemble.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.boosted_trees_ensemble_resource_handle_op(System.String,System.String,System.String)">
            <summary>
               Creates a handle to a BoostedTreesEnsembleResource
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BoostedTreesEnsembleResourceHandleOp'.
            </param>
            <param name="container">
            </param>
            <param name="shared_name">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.boosted_trees_example_debug_outputs(Tensorflow.Tensor,Tensorflow.Tensor[],System.Int32,System.String)">
            <summary>
               Debugging/model interpretability outputs for each example.
            </summary>
            <param name="tree_ensemble_handle">
            </param>
            <param name="bucketized_features">
               A list of rank 1 Tensors containing bucket id for each
               feature.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BoostedTreesExampleDebugOutputs'.
            </param>
            <param name="logits_dimension">
               Optional argument
               scalar, dimension of the logits, to be used for constructing the protos in
               examples_debug_outputs_serialized.
            </param>
            <returns>
               Output rank 1 Tensor containing a proto serialized as a string for each example.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               It traverses all the trees and computes debug metrics for individual examples,
               such as getting split feature ids and logits after each split along the decision
               path used to compute directional feature contributions.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.boosted_trees_get_ensemble_states(Tensorflow.Tensor,System.String)">
            <summary>
               Retrieves the tree ensemble resource stamp token, number of trees and growing statistics.
            </summary>
            <param name="tree_ensemble_handle">
               Handle to the tree ensemble.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BoostedTreesGetEnsembleStates'.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               stamp_token : Stamp token of the tree ensemble resource.
               num_trees : The number of trees in the tree ensemble resource.
               num_finalized_trees : The number of trees that were finished successfully.
               num_attempted_layers : The number of layers we attempted to build (but not necessarily succeeded).
               last_layer_nodes_range : Rank size 2 tensor that contains start and end ids of the nodes in the latest
               layer.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.boosted_trees_make_stats_summary(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor[],System.Int32,System.Int32,System.String)">
            <summary>
               Makes the summary of accumulated stats for the batch.
            </summary>
            <param name="node_ids">
               int32 Rank 1 Tensor containing node ids, which each example falls into for the requested layer.
            </param>
            <param name="gradients">
               float32; Rank 2 Tensor (shape=[#examples, 1]) for gradients.
            </param>
            <param name="hessians">
               float32; Rank 2 Tensor (shape=[#examples, 1]) for hessians.
            </param>
            <param name="bucketized_features_list">
               int32 list of Rank 1 Tensors, each containing the bucketized feature (for each feature column).
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BoostedTreesMakeStatsSummary'.
            </param>
            <param name="max_splits">
               Optional argument
               int; the maximum number of splits possible in the whole tree.
            </param>
            <param name="num_buckets">
               Optional argument
               int; equals to the maximum possible value of bucketized feature.
            </param>
            <returns>
               output Rank 4 Tensor (shape=[#features, #splits, #buckets, 2]) containing accumulated stats put into the corresponding node and bucket. The first index of 4th dimension refers to gradients, and the second to hessians.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The summary stats contains gradients and hessians accumulated into the corresponding node and bucket for each example.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.boosted_trees_predict(Tensorflow.Tensor,Tensorflow.Tensor[],System.Int32,System.String)">
            <summary>
               Runs multiple additive regression ensemble predictors on input instances and
            </summary>
            <param name="tree_ensemble_handle">
            </param>
            <param name="bucketized_features">
               A list of rank 1 Tensors containing bucket id for each
               feature.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BoostedTreesPredict'.
            </param>
            <param name="logits_dimension">
               Optional argument
               scalar, dimension of the logits, to be used for partial logits
               shape.
            </param>
            <returns>
               Output rank 2 Tensor containing logits for each example.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               computes the logits. It is designed to be used during prediction.
               It traverses all the trees and calculates the final score for each instance.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.boosted_trees_serialize_ensemble(Tensorflow.Tensor,System.String)">
            <summary>
               Serializes the tree ensemble to a proto.
            </summary>
            <param name="tree_ensemble_handle">
               Handle to the tree ensemble.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BoostedTreesSerializeEnsemble'.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               stamp_token : Stamp token of the tree ensemble resource.
               tree_ensemble_serialized : Serialized proto of the ensemble.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.boosted_trees_training_predict(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor[],System.Int32,System.String)">
            <summary>
               Runs multiple additive regression ensemble predictors on input instances and
            </summary>
            <param name="tree_ensemble_handle">
            </param>
            <param name="cached_tree_ids">
               Rank 1 Tensor containing cached tree ids which is the starting
               tree of prediction.
            </param>
            <param name="cached_node_ids">
               Rank 1 Tensor containing cached node id which is the starting
               node of prediction.
            </param>
            <param name="bucketized_features">
               A list of rank 1 Tensors containing bucket id for each
               feature.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BoostedTreesTrainingPredict'.
            </param>
            <param name="logits_dimension">
               Optional argument
               scalar, dimension of the logits, to be used for partial logits
               shape.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               partial_logits : Rank 2 Tensor containing logits update (with respect to cached
               values stored) for each example.
               tree_ids : Rank 1 Tensor containing new tree ids for each example.
               node_ids : Rank 1 Tensor containing new node ids in the new tree_ids.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               computes the update to cached logits. It is designed to be used during training.
               It traverses the trees starting from cached tree id and cached node id and
               calculates the updates to be pushed to the cache.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.boosted_trees_update_ensemble(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor[],Tensorflow.Tensor[],Tensorflow.Tensor[],Tensorflow.Tensor[],Tensorflow.Tensor[],Tensorflow.Tensor,Tensorflow.Tensor,System.Int32,System.String)">
            <summary>
               Updates the tree ensemble by either adding a layer to the last tree being grown
            </summary>
            <param name="tree_ensemble_handle">
               Handle to the ensemble variable.
            </param>
            <param name="feature_ids">
               Rank 1 tensor with ids for each feature. This is the real id of
               the feature that will be used in the split.
            </param>
            <param name="node_ids">
               List of rank 1 tensors representing the nodes for which this feature
               has a split.
            </param>
            <param name="gains">
               List of rank 1 tensors representing the gains for each of the feature's
               split.
            </param>
            <param name="thresholds">
               List of rank 1 tensors representing the thesholds for each of the
               feature's split.
            </param>
            <param name="left_node_contribs">
               List of rank 2 tensors with left leaf contribs for each of
               the feature's splits. Will be added to the previous node values to constitute
               the values of the left nodes.
            </param>
            <param name="right_node_contribs">
               List of rank 2 tensors with right leaf contribs for each
               of the feature's splits. Will be added to the previous node values to constitute
               the values of the right nodes.
            </param>
            <param name="max_depth">
               Max depth of the tree to build.
            </param>
            <param name="learning_rate">
               shrinkage const for each new tree.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BoostedTreesUpdateEnsemble'.
            </param>
            <param name="pruning_mode">
               Optional argument
               0-No pruning, 1-Pre-pruning, 2-Post-pruning.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               or by starting a new tree.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.broadcast_args(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Return the shape of s0 op s1 with broadcast.
            </summary>
            <param name="s0">
            </param>
            <param name="s1">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BroadcastArgs'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Given <c>s0</c> and <c>s1</c>, tensors that represent shapes, compute <c>r0</c>, the
               broadcasted shape. <c>s0</c>, <c>s1</c> and <c>r0</c> are all integer vectors.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.broadcast_gradient_args(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Return the reduction indices for computing gradients of s0 op s1 with broadcast.
            </summary>
            <param name="s0">
            </param>
            <param name="s1">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BroadcastGradientArgs'.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               r0 :
               r1 :
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               This is typically used by gradient computations for a broadcasting operation.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.broadcast_to(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Broadcast an array for a compatible shape.
            </summary>
            <param name="input">
               A Tensor to broadcast.
            </param>
            <param name="shape">
               An 1-D <c>int</c> Tensor. The shape of the desired output.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BroadcastTo'.
            </param>
            <returns>
               A Tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Broadcasting is the process of making arrays to have compatible shapes
               for arithmetic operations. Two shapes are compatible if for each
               dimension pair they are either equal or one of them is one. When trying
               to broadcast a Tensor to a shape, it starts with the trailing dimensions,
               and works its way forward.
               
               For example,
              <code>
               &amp;gt;&amp;gt;&amp;gt; x = tf.constant([1, 2, 3])
               &amp;gt;&amp;gt;&amp;gt; y = tf.broadcast_to(x, [3, 3])
               &amp;gt;&amp;gt;&amp;gt; sess.run(y)
               array([[1, 2, 3],
               [1, 2, 3],
               [1, 2, 3]], dtype=int32)
              </code>
               In the above example, the input Tensor with the shape of <c>[1, 3]</c>
               is broadcasted to output Tensor with shape of <c>[3, 3]</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.bucketize(Tensorflow.Tensor,System.Single[],System.String)">
            <summary>
               Bucketizes 'input' based on 'boundaries'.
            </summary>
            <param name="input">
               Any shape of Tensor contains with int or float type.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Bucketize'.
            </param>
            <param name="boundaries">
               Optional argument
               A sorted list of floats gives the boundary of the buckets.
            </param>
            <returns>
               Same shape with 'input', each value of input replaced with bucket index.
               
               @compatibility(numpy)
               Equivalent to np.digitize.
               @end_compatibility
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               For example, if the inputs are
               boundaries = [0, 10, 100]
               input = [[-5, 10000]
               [150,   10]
               [5,    100]]
               
               then the output will be
               output = [[0, 3]
               [3, 2]
               [1, 3]]
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.bytes_produced_stats_dataset(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Records the bytes size of each element of <c>input_dataset</c> in a StatsAggregator.
            </summary>
            <param name="input_dataset">
            </param>
            <param name="tag">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'BytesProducedStatsDataset'.
            </param>
            <param name="output_types">
               Optional argument
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.c_t_c_beam_search_decoder(Tensorflow.Tensor,Tensorflow.Tensor,System.Int32,System.Int32,System.Nullable{System.Boolean},System.String)">
            <summary>
               Performs beam search decoding on the logits given in input.
            </summary>
            <param name="inputs">
               3-D, shape: <c>(max_time x batch_size x num_classes)</c>, the logits.
            </param>
            <param name="sequence_length">
               A vector containing sequence lengths, size <c>(batch)</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'CTCBeamSearchDecoder'.
            </param>
            <param name="beam_width">
               Optional argument
               A scalar &amp;gt;= 0 (beam search beam width).
            </param>
            <param name="top_paths">
               Optional argument
               A scalar &amp;gt;= 0, &amp;lt;= beam_width (controls output size).
            </param>
            <param name="merge_repeated">
               If true, merge repeated classes in output.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               decoded_indices : A list (length: top_paths) of indices matrices.  Matrix j,
               size <c>(total_decoded_outputs[j] x 2)</c>, has indices of a
               <c>SparseTensor&amp;lt;int64, 2&amp;gt;</c>.  The rows store: [batch, time].
               decoded_values : A list (length: top_paths) of values vectors.  Vector j,
               size <c>(length total_decoded_outputs[j])</c>, has the values of a
               <c>SparseTensor&amp;lt;int64, 2&amp;gt;</c>.  The vector stores the decoded classes for beam j.
               decoded_shape : A list (length: top_paths) of shape vector.  Vector j,
               size <c>(2)</c>, stores the shape of the decoded <c>SparseTensor[j]</c>.
               Its values are: <c>[batch_size, max_decoded_length[j]]</c>.
               log_probability : A matrix, shaped: <c>(batch_size x top_paths)</c>.  The
               sequence log-probabilities.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               A note about the attribute merge_repeated: For the beam search decoder,
               this means that if consecutive entries in a beam are the same, only
               the first of these is emitted.  That is, when the top path is "A B B B B",
               "A B" is returned if merge_repeated = True but "A B B B B" is
               returned if merge_repeated = False.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.c_t_c_greedy_decoder(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Performs greedy decoding on the logits given in inputs.
            </summary>
            <param name="inputs">
               3-D, shape: <c>(max_time x batch_size x num_classes)</c>, the logits.
            </param>
            <param name="sequence_length">
               A vector containing sequence lengths, size <c>(batch_size)</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'CTCGreedyDecoder'.
            </param>
            <param name="merge_repeated">
               If True, merge repeated classes in output.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               decoded_indices : Indices matrix, size <c>(total_decoded_outputs x 2)</c>,
               of a <c>SparseTensor&amp;lt;int64, 2&amp;gt;</c>.  The rows store: [batch, time].
               decoded_values : Values vector, size: <c>(total_decoded_outputs)</c>,
               of a <c>SparseTensor&amp;lt;int64, 2&amp;gt;</c>.  The vector stores the decoded classes.
               decoded_shape : Shape vector, size <c>(2)</c>, of the decoded SparseTensor.
               Values are: <c>[batch_size, max_decoded_length]</c>.
               log_probability : Matrix, size <c>(batch_size x 1)</c>, containing sequence
               log-probabilities.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               A note about the attribute merge_repeated: if enabled, when
               consecutive logits' maximum indices are the same, only the first of
               these is emitted.  Labeling the blank '*', the sequence "A B B * B B"
               becomes "A B B" if merge_repeated = True and "A B B B B" if
               merge_repeated = False.
               
               Regardless of the value of merge_repeated, if the maximum index of a given
               time and batch corresponds to the blank, index <c>(num_classes - 1)</c>, no new
               element is emitted.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.c_t_c_loss(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.String)">
            <summary>
               Calculates the CTC Loss (log probability) for each batch entry.  Also calculates
            </summary>
            <param name="inputs">
               3-D, shape: <c>(max_time x batch_size x num_classes)</c>, the logits.
            </param>
            <param name="labels_indices">
               The indices of a <c>SparseTensor&amp;lt;int32, 2&amp;gt;</c>.
               <c>labels_indices(i, :) == [b, t]</c> means <c>labels_values(i)</c> stores the id for
               <c>(batch b, time t)</c>.
            </param>
            <param name="labels_values">
               The values (labels) associated with the given batch and time.
            </param>
            <param name="sequence_length">
               A vector containing sequence lengths (batch).
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'CTCLoss'.
            </param>
            <param name="preprocess_collapse_repeated">
               Scalar, if true then repeated labels are
               collapsed prior to the CTC calculation.
            </param>
            <param name="ctc_merge_repeated">
               Scalar.  If set to false, *during* CTC calculation
               repeated non-blank labels will not be merged and are interpreted as
               individual labels.  This is a simplified version of CTC.
            </param>
            <param name="ignore_longer_outputs_than_inputs">
               Scalar. If set to true, during CTC
               calculation, items that have longer output sequences than input sequences
               are skipped: they don't contribute to the loss term and have zero-gradient.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               loss : A vector (batch) containing log-probabilities.
               gradient : The gradient of <c>loss</c>.  3-D, shape:
               <c>(max_time x batch_size x num_classes)</c>.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               the gradient.  This class performs the softmax operation for you, so inputs
               should be e.g. linear projections of outputs by an LSTM.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.cache_dataset(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Creates a dataset that caches elements from <c>input_dataset</c>.
            </summary>
            <param name="input_dataset">
            </param>
            <param name="filename">
               A path on the filesystem where we should cache the dataset. Note: this
               will be a directory.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'CacheDataset'.
            </param>
            <param name="output_types">
               Optional argument
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               A CacheDataset will iterate over the input_dataset, and store tensors. If the
               cache already exists, the cache will be used. If the cache is inappropriate
               (e.g. cannot be opened, contains tensors of the wrong shape / size), an error
               will the returned when used.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.cast(Tensorflow.Tensor,Tensorflow.TF_DataType,System.Nullable{System.Boolean},System.String)">
            <summary>
               Cast x of type SrcT to y of DstT.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Cast'.
            </param>
            <param name="DstT">
               Optional argument
            </param>
            <param name="Truncate">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.ceil(Tensorflow.Tensor,System.String)">
            <summary>
               Returns element-wise smallest integer not less than x.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Ceil'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.check_numerics(Tensorflow.Tensor,System.String,System.String)">
            <summary>
               Checks a tensor for NaN and Inf values.
            </summary>
            <param name="tensor">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'CheckNumerics'.
            </param>
            <param name="message">
               Optional argument
               Prefix of the error message.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               When run, reports an <c>InvalidArgument</c> error if <c>tensor</c> has any values
               that are not a number (NaN) or infinity (Inf). Otherwise, passes <c>tensor</c> as-is.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.cholesky(Tensorflow.Tensor,System.String)">
            <summary>
               Computes the Cholesky decomposition of one or more square matrices.
            </summary>
            <param name="input">
               Shape is <c>[..., M, M]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Cholesky'.
            </param>
            <returns>
               Shape is <c>[..., M, M]</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The input is a tensor of shape <c>[..., M, M]</c> whose inner-most 2 dimensions
               form square matrices.
               
               The input has to be symmetric and positive definite. Only the lower-triangular
               part of the input will be used for this operation. The upper-triangular part
               will not be read.
               
               The output is a tensor of the same shape as the input
               containing the Cholesky decompositions for all input submatrices <c>[..., :, :]</c>.
               
               **Note**: The gradient computation on GPU is faster for large matrices but
               not for large batch dimensions when the submatrices are small. In this
               case it might be faster to use the CPU.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.cholesky_grad(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes the reverse mode backpropagated gradient of the Cholesky algorithm.
            </summary>
            <param name="l">
               Output of batch Cholesky algorithm l = cholesky(A). Shape is <c>[..., M, M]</c>.
               Algorithm depends only on lower triangular part of the innermost matrices of
               this tensor.
            </param>
            <param name="grad">
               df/dl where f is some scalar function. Shape is <c>[..., M, M]</c>.
               Algorithm depends only on lower triangular part of the innermost matrices of
               this tensor.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'CholeskyGrad'.
            </param>
            <returns>
               Symmetrized version of df/dA . Shape is <c>[..., M, M]</c>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               For an explanation see "Differentiation of the Cholesky algorithm" by
               Iain Murray http://arxiv.org/abs/1602.07527.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.clip_by_value(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Clips tensor values to a specified min and max.
            </summary>
            <param name="t">
               A <c>Tensor</c>.
            </param>
            <param name="clip_value_min">
               A 0-D (scalar) <c>Tensor</c>, or a <c>Tensor</c> with the same shape
               as <c>t</c>. The minimum value to clip by.
            </param>
            <param name="clip_value_max">
               A 0-D (scalar) <c>Tensor</c>, or a <c>Tensor</c> with the same shape
               as <c>t</c>. The maximum value to clip by.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ClipByValue'.
            </param>
            <returns>
               A clipped <c>Tensor</c> with the same shape as input 't'.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Given a tensor <c>t</c>, this operation returns a tensor of the same type and
               shape as <c>t</c> with its values clipped to <c>clip_value_min</c> and <c>clip_value_max</c>.
               Any values less than <c>clip_value_min</c> are set to <c>clip_value_min</c>. Any values
               greater than <c>clip_value_max</c> are set to <c>clip_value_max</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.collective_bcast_recv(Tensorflow.TF_DataType,System.Int32,System.Int32,System.Int32,Tensorflow.TensorShape,System.String)">
            <summary>
               Receives a tensor value broadcast from another device.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'CollectiveBcastRecv'.
            </param>
            <param name="T">
               Optional argument
            </param>
            <param name="group_size">
               Optional argument
            </param>
            <param name="group_key">
               Optional argument
            </param>
            <param name="instance_key">
               Optional argument
            </param>
            <param name="shape">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.collective_bcast_send(Tensorflow.Tensor,System.Int32,System.Int32,System.Int32,Tensorflow.TensorShape,System.String)">
            <summary>
               Broadcasts a tensor value to one or more other devices.
            </summary>
            <param name="input">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'CollectiveBcastSend'.
            </param>
            <param name="group_size">
               Optional argument
            </param>
            <param name="group_key">
               Optional argument
            </param>
            <param name="instance_key">
               Optional argument
            </param>
            <param name="shape">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.collective_reduce(Tensorflow.Tensor,System.Int32,System.Int32,System.Int32,System.String,System.String,System.Int32[],System.String)">
            <summary>
               Mutually reduces multiple tensors of identical type and shape.
            </summary>
            <param name="input">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'CollectiveReduce'.
            </param>
            <param name="group_size">
               Optional argument
            </param>
            <param name="group_key">
               Optional argument
            </param>
            <param name="instance_key">
               Optional argument
            </param>
            <param name="merge_op">
               Optional argument
            </param>
            <param name="final_op">
               Optional argument
            </param>
            <param name="subdiv_offsets">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.compare_and_bitpack(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Compare values of <c>input</c> to <c>threshold</c> and pack resulting bits into a <c>uint8</c>.
            </summary>
            <param name="input">
               Values to compare against <c>threshold</c> and bitpack.
            </param>
            <param name="threshold">
               Threshold to compare against.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'CompareAndBitpack'.
            </param>
            <returns>
               The bitpacked comparisons.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Each comparison returns a boolean <c>true</c> (if <c>input_value &amp;gt; threshold</c>)
               or and <c>false</c> otherwise.
               
               This operation is useful for Locality-Sensitive-Hashing (LSH) and other
               algorithms that use hashing approximations of cosine and <c>L2</c> distances;
               codes can be generated from an input via:
               
              <code>
               codebook_size = 50
               codebook_bits = codebook_size * 32
               codebook = tf.get_variable('codebook', [x.shape[-1].value, codebook_bits],
               dtype=x.dtype,
               initializer=tf.orthogonal_initializer())
               codes = compare_and_threshold(tf.matmul(x, codebook), threshold=0.)
               codes = tf.bitcast(codes, tf.int32)  # go from uint8 to int32
               # now codes has shape x.shape[:-1] + [codebook_size]
              </code>
               
               **NOTE**: Currently, the innermost dimension of the tensor must be divisible
               by 8.
               
               Given an <c>input</c> shaped <c>[s0, s1, ..., s_n]</c>, the output is
               a <c>uint8</c> tensor shaped <c>[s0, s1, ..., s_n / 8]</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.complex(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Converts two real numbers to a complex number.
            </summary>
            <param name="real">
            </param>
            <param name="imag">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Complex'.
            </param>
            <param name="Tout">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Given a tensor <c>real</c> representing the real part of a complex number, and a
               tensor <c>imag</c> representing the imaginary part of a complex number, this
               operation returns complex numbers elementwise of the form \\(a + bj\\), where
               *a* represents the <c>real</c> part and *b* represents the <c>imag</c> part.
               
               The input tensors <c>real</c> and <c>imag</c> must have the same shape.
               
               For example:
               
              <code>
               # tensor 'real' is [2.25, 3.25]
               # tensor <c>imag</c> is [4.75, 5.75]
               tf.complex(real, imag) ==&amp;gt; [[2.25 + 4.75j], [3.25 + 5.75j]]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.complex_abs(Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Computes the complex absolute value of a tensor.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ComplexAbs'.
            </param>
            <param name="Tout">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Given a tensor <c>x</c> of complex numbers, this operation returns a tensor of type
               <c>float</c> or <c>double</c> that is the absolute value of each element in <c>x</c>. All
               elements in <c>x</c> must be complex numbers of the form \\(a + bj\\). The absolute
               value is computed as \\( \sqrt{a^2 + b^2}\\).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.compute_accidental_hits(Tensorflow.Tensor,Tensorflow.Tensor,System.Int32,System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Computes the ids of the positions in sampled_candidates that match true_labels.
            </summary>
            <param name="true_classes">
               The true_classes output of UnpackSparseLabels.
            </param>
            <param name="sampled_candidates">
               The sampled_candidates output of CandidateSampler.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ComputeAccidentalHits'.
            </param>
            <param name="num_true">
               Optional argument
               Number of true labels per context.
            </param>
            <param name="seed">
               If either seed or seed2 are set to be non-zero, the random number
               generator is seeded by the given seed.  Otherwise, it is seeded by a
               random seed.
            </param>
            <param name="seed2">
               An second seed to avoid seed collision.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               indices : A vector of indices corresponding to rows of true_candidates.
               ids : A vector of IDs of positions in sampled_candidates that match a true_label
               for the row with the corresponding index in indices.
               weights : A vector of the same length as indices and ids, in which each element
               is -FLOAT_MAX.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               When doing log-odds NCE, the result of this op should be passed through a
               SparseToDense op, then added to the logits of the sampled candidates. This has
               the effect of 'removing' the sampled labels that match the true labels by
               making the classifier sure that they are sampled labels.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.concat(Tensorflow.Tensor,Tensorflow.Tensor[],System.String)">
            <summary>
               Concatenates tensors along one dimension.
            </summary>
            <param name="concat_dim">
               0-D.  The dimension along which to concatenate.  Must be in the
               range [0, rank(values)).
            </param>
            <param name="values">
               The <c>N</c> Tensors to concatenate. Their ranks and types must match,
               and their sizes must match in all dimensions except <c>concat_dim</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Concat'.
            </param>
            <returns>
               A <c>Tensor</c> with the concatenation of values stacked along the
               <c>concat_dim</c> dimension.  This tensor's shape matches that of <c>values</c> except
               in <c>concat_dim</c> where it has the sum of the sizes.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.concat_offset(Tensorflow.Tensor,Tensorflow.Tensor[],System.String)">
            <summary>
               Computes offsets of concat inputs within its output.
            </summary>
            <param name="concat_dim">
               The dimension along which to concatenate.
            </param>
            <param name="shape">
               The <c>N</c> int32 vectors representing shape of tensors being concatenated.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ConcatOffset'.
            </param>
            <returns>
               The <c>N</c> int32 vectors representing the starting offset
               of input tensors within the concatenated output.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               For example:
               
              <code>
               # 'x' is [2, 2, 7]
               # 'y' is [2, 3, 7]
               # 'z' is [2, 5, 7]
               concat_offset(2, [x, y, z]) =&amp;gt; [0, 0, 0], [0, 2, 0], [0, 5, 0]
              </code>
               
               This is typically used by gradient computations for a concat operation.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.concat_v2(Tensorflow.Tensor[],Tensorflow.Tensor,System.String)">
            <summary>
               Concatenates tensors along one dimension.
            </summary>
            <param name="values">
               List of <c>N</c> Tensors to concatenate. Their ranks and types must match,
               and their sizes must match in all dimensions except <c>concat_dim</c>.
            </param>
            <param name="axis">
               0-D.  The dimension along which to concatenate.  Must be in the
               range [-rank(values), rank(values)).
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ConcatV2'.
            </param>
            <returns>
               A <c>Tensor</c> with the concatenation of values stacked along the
               <c>concat_dim</c> dimension.  This tensor's shape matches that of <c>values</c> except
               in <c>concat_dim</c> where it has the sum of the sizes.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.concatenate_dataset(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Creates a dataset that concatenates <c>input_dataset</c> with <c>another_dataset</c>.
            </summary>
            <param name="input_dataset">
            </param>
            <param name="another_dataset">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ConcatenateDataset'.
            </param>
            <param name="output_types">
               Optional argument
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.conditional_accumulator(Tensorflow.TF_DataType,Tensorflow.TensorShape,System.String,System.String,System.String)">
            <summary>
               A conditional accumulator for aggregating gradients.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ConditionalAccumulator'.
            </param>
            <param name="dtype">
               Optional argument
               The type of the value being accumulated.
            </param>
            <param name="shape">
               Optional argument
               The shape of the values, can be [], in which case shape is unknown.
            </param>
            <param name="container">
               If non-empty, this accumulator is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this accumulator will be shared under the
               given name across multiple sessions.
            </param>
            <returns>
               The handle to the accumulator.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The accumulator accepts gradients marked with local_step greater or
               equal to the most recent global_step known to the accumulator. The
               average can be extracted from the accumulator, provided sufficient
               gradients have been accumulated. Extracting the average automatically
               resets the aggregate to 0, and increments the global_step recorded by
               the accumulator.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.configure_distributed_t_p_u(System.String,System.String,System.Nullable{System.Boolean},System.String)">
            <summary>
               An op that sets up the centralized structures for a distributed TPU
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ConfigureDistributedTPU'.
            </param>
            <param name="embedding_config">
               Reserved. Do not use.
            </param>
            <param name="tpu_embedding_config">
               Serialized tensorflow.tpu.TPUEmbeddingConfiguration that
               describes the embedding lookups of the program.
            </param>
            <param name="is_global_init">
               Reserved. Do not use.
            </param>
            <returns>
               A serialized tensorflow.tpu.TopologyProto that describes the TPU
               topology.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               system.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.conj(Tensorflow.Tensor,System.String)">
            <summary>
               Returns the complex conjugate of a complex number.
            </summary>
            <param name="input">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Conj'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Given a tensor <c>input</c> of complex numbers, this operation returns a tensor of
               complex numbers that are the complex conjugate of each element in <c>input</c>. The
               complex numbers in <c>input</c> must be of the form \\(a + bj\\), where *a* is the
               real part and *b* is the imaginary part.
               
               The complex conjugate returned by this operation is of the form \\(a - bj\\).
               
               For example:
               
              <code>
               # tensor 'input' is [-2.25 + 4.75j, 3.25 + 5.75j]
               tf.conj(input) ==&amp;gt; [-2.25 - 4.75j, 3.25 - 5.75j]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.conjugate_transpose(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Shuffle dimensions of x according to a permutation and conjugate the result.
            </summary>
            <param name="x">
            </param>
            <param name="perm">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ConjugateTranspose'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The output <c>y</c> has the same rank as <c>x</c>. The shapes of <c>x</c> and <c>y</c> satisfy:
               <c>y.shape[i] == x.shape[perm[i]] for i in [0, 1, ..., rank(x) - 1]</c>
               <c>y[i,j,k,...,s,t,u] == conj(x[perm[i], perm[j], perm[k],...,perm[s], perm[t], perm[u]])</c>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.constant(Tensorflow.Tensor,Tensorflow.TF_DataType,System.String)">
            <summary>
               Returns a constant tensor.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Const'.
            </param>
            <param name="value">
               Optional argument
               Attr <c>value</c> is the tensor to return.
            </param>
            <param name="dtype">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.consume_mutex_lock(Tensorflow.Tensor,System.String)">
            <summary>
               This op consumes a lock created by <c>MutexLock</c>.
            </summary>
            <param name="mutex_lock">
               A tensor returned by <c>MutexLock</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ConsumeMutexLock'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               This op exists to consume a tensor created by <c>MutexLock</c> (other than
               direct control dependencies).  It should be the only that consumes the tensor,
               and will raise an error if it is not.  Its only purpose is to keep the
               mutex lock tensor alive until it is consumed by this op.
               
               **NOTE**: This operation must run on the same device as its input.  This may
               be enforced via the <c>colocate_with</c> mechanism.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.control_trigger(System.String)">
            <summary>
               Does nothing. Serves as a control trigger for scheduling.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ControlTrigger'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               Only useful as a placeholder for control edges.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.conv2d(Tensorflow.Tensor,Tensorflow.Tensor,System.Int32[],System.String,System.Nullable{System.Boolean},System.String,System.Int32[],System.String)">
            <summary>
               Computes a 2-D convolution given 4-D <c>input</c> and <c>filter</c> tensors.
            </summary>
            <param name="input">
               A 4-D tensor. The dimension order is interpreted according to the value
               of <c>data_format</c>, see below for details.
            </param>
            <param name="filter">
               A 4-D tensor of shape
               <c>[filter_height, filter_width, in_channels, out_channels]</c>
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Conv2D'.
            </param>
            <param name="strides">
               Optional argument
               1-D tensor of length 4.  The stride of the sliding window for each
               dimension of <c>input</c>. The dimension order is determined by the value of
               <c>data_format</c>, see below for details.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <param name="use_cudnn_on_gpu">
            </param>
            <param name="data_format">
               Specify the data format of the input and output data. With the
               default format "NHWC", the data is stored in the order of:
               [batch, height, width, channels].
               Alternatively, the format could be "NCHW", the data storage order of:
               [batch, channels, height, width].
            </param>
            <param name="dilations">
               1-D tensor of length 4.  The dilation factor for each dimension of
               <c>input</c>. If set to k &amp;gt; 1, there will be k-1 skipped cells between each
               filter element on that dimension. The dimension order is determined by the
               value of <c>data_format</c>, see above for details. Dilations in the batch and
               depth dimensions must be 1.
            </param>
            <returns>
               A 4-D tensor. The dimension order is determined by the value of
               <c>data_format</c>, see below for details.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Given an input tensor of shape <c>[batch, in_height, in_width, in_channels]</c>
               and a filter / kernel tensor of shape
               <c>[filter_height, filter_width, in_channels, out_channels]</c>, this op
               performs the following:
               
               1. Flattens the filter to a 2-D matrix with shape
               <c>[filter_height * filter_width * in_channels, output_channels]</c>.
               2. Extracts image patches from the input tensor to form a *virtual*
               tensor of shape <c>[batch, out_height, out_width,
               filter_height * filter_width * in_channels]</c>.
               3. For each patch, right-multiplies the filter matrix and the image patch
               vector.
               
               In detail, with the default NHWC format,
               
               output[b, i, j, k] =
               sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q] *
               filter[di, dj, q, k]
               
               Must have <c>strides[0] = strides[3] = 1</c>.  For the most common case of the same
               horizontal and vertices strides, <c>strides = [1, stride, stride, 1]</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.conv2d_backprop_filter(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32[],System.String,System.Nullable{System.Boolean},System.String,System.Int32[],System.String)">
            <summary>
               Computes the gradients of convolution with respect to the filter.
            </summary>
            <param name="input">
               4-D with shape <c>[batch, in_height, in_width, in_channels]</c>.
            </param>
            <param name="filter_sizes">
               An integer vector representing the tensor shape of <c>filter</c>,
               where <c>filter</c> is a 4-D
               <c>[filter_height, filter_width, in_channels, out_channels]</c> tensor.
            </param>
            <param name="out_backprop">
               4-D with shape <c>[batch, out_height, out_width, out_channels]</c>.
               Gradients w.r.t. the output of the convolution.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Conv2DBackpropFilter'.
            </param>
            <param name="strides">
               Optional argument
               The stride of the sliding window for each dimension of the input
               of the convolution. Must be in the same order as the dimension specified with
               format.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <param name="use_cudnn_on_gpu">
            </param>
            <param name="data_format">
               Specify the data format of the input and output data. With the
               default format "NHWC", the data is stored in the order of:
               [batch, in_height, in_width, in_channels].
               Alternatively, the format could be "NCHW", the data storage order of:
               [batch, in_channels, in_height, in_width].
            </param>
            <param name="dilations">
               1-D tensor of length 4.  The dilation factor for each dimension of
               <c>input</c>. If set to k &amp;gt; 1, there will be k-1 skipped cells between each filter
               element on that dimension. The dimension order is determined by the value of
               <c>data_format</c>, see above for details. Dilations in the batch and depth
               dimensions must be 1.
            </param>
            <returns>
               4-D with shape
               <c>[filter_height, filter_width, in_channels, out_channels]</c>.  Gradient w.r.t.
               the <c>filter</c> input of the convolution.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.conv2d_backprop_input(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32[],System.String,System.Nullable{System.Boolean},System.String,System.Int32[],System.String)">
            <summary>
               Computes the gradients of convolution with respect to the input.
            </summary>
            <param name="input_sizes">
               An integer vector representing the shape of <c>input</c>,
               where <c>input</c> is a 4-D <c>[batch, height, width, channels]</c> tensor.
            </param>
            <param name="filter">
               4-D with shape
               <c>[filter_height, filter_width, in_channels, out_channels]</c>.
            </param>
            <param name="out_backprop">
               4-D with shape <c>[batch, out_height, out_width, out_channels]</c>.
               Gradients w.r.t. the output of the convolution.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Conv2DBackpropInput'.
            </param>
            <param name="strides">
               Optional argument
               The stride of the sliding window for each dimension of the input
               of the convolution. Must be in the same order as the dimension specified with
               format.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <param name="use_cudnn_on_gpu">
            </param>
            <param name="data_format">
               Specify the data format of the input and output data. With the
               default format "NHWC", the data is stored in the order of:
               [batch, in_height, in_width, in_channels].
               Alternatively, the format could be "NCHW", the data storage order of:
               [batch, in_channels, in_height, in_width].
            </param>
            <param name="dilations">
               1-D tensor of length 4.  The dilation factor for each dimension of
               <c>input</c>. If set to k &amp;gt; 1, there will be k-1 skipped cells between each filter
               element on that dimension. The dimension order is determined by the value of
               <c>data_format</c>, see above for details. Dilations in the batch and depth
               dimensions must be 1.
            </param>
            <returns>
               4-D with shape <c>[batch, in_height, in_width, in_channels]</c>.  Gradient
               w.r.t. the input of the convolution.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.conv3d(Tensorflow.Tensor,Tensorflow.Tensor,System.Int32[],System.String,System.String,System.Int32[],System.String)">
            <summary>
               Computes a 3-D convolution given 5-D <c>input</c> and <c>filter</c> tensors.
            </summary>
            <param name="input">
               Shape <c>[batch, in_depth, in_height, in_width, in_channels]</c>.
            </param>
            <param name="filter">
               Shape <c>[filter_depth, filter_height, filter_width, in_channels,
               out_channels]</c>. <c>in_channels</c> must match between <c>input</c> and <c>filter</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Conv3D'.
            </param>
            <param name="strides">
               Optional argument
               1-D tensor of length 5. The stride of the sliding window for each
               dimension of <c>input</c>. Must have <c>strides[0] = strides[4] = 1</c>.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <param name="data_format">
               The data format of the input and output data. With the
               default format "NDHWC", the data is stored in the order of:
               [batch, in_depth, in_height, in_width, in_channels].
               Alternatively, the format could be "NCDHW", the data storage order is:
               [batch, in_channels, in_depth, in_height, in_width].
            </param>
            <param name="dilations">
               1-D tensor of length 5.  The dilation factor for each dimension of
               <c>input</c>. If set to k &amp;gt; 1, there will be k-1 skipped cells between each
               filter element on that dimension. The dimension order is determined by the
               value of <c>data_format</c>, see above for details. Dilations in the batch and
               depth dimensions must be 1.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               In signal processing, cross-correlation is a measure of similarity of
               two waveforms as a function of a time-lag applied to one of them. This
               is also known as a sliding dot product or sliding inner-product.
               
               Our Conv3D implements a form of cross-correlation.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.conv3d_backprop_filter(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32[],System.String,System.Int32[],System.String)">
            <summary>
               Computes the gradients of 3-D convolution with respect to the filter.
            </summary>
            <param name="input">
               Shape <c>[batch, depth, rows, cols, in_channels]</c>.
            </param>
            <param name="filter">
               Shape <c>[depth, rows, cols, in_channels, out_channels]</c>.
               <c>in_channels</c> must match between <c>input</c> and <c>filter</c>.
            </param>
            <param name="out_backprop">
               Backprop signal of shape <c>[batch, out_depth, out_rows, out_cols,
               out_channels]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Conv3DBackpropFilter'.
            </param>
            <param name="strides">
               Optional argument
               1-D tensor of length 5. The stride of the sliding window for each
               dimension of <c>input</c>. Must have <c>strides[0] = strides[4] = 1</c>.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <param name="dilations">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.conv3d_backprop_filter_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32[],System.String,System.String,System.Int32[],System.String)">
            <summary>
               Computes the gradients of 3-D convolution with respect to the filter.
            </summary>
            <param name="input">
               Shape <c>[batch, depth, rows, cols, in_channels]</c>.
            </param>
            <param name="filter_sizes">
               An integer vector representing the tensor shape of <c>filter</c>,
               where <c>filter</c> is a 5-D
               <c>[filter_depth, filter_height, filter_width, in_channels, out_channels]</c>
               tensor.
            </param>
            <param name="out_backprop">
               Backprop signal of shape <c>[batch, out_depth, out_rows, out_cols,
               out_channels]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Conv3DBackpropFilterV2'.
            </param>
            <param name="strides">
               Optional argument
               1-D tensor of length 5. The stride of the sliding window for each
               dimension of <c>input</c>. Must have <c>strides[0] = strides[4] = 1</c>.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <param name="data_format">
               The data format of the input and output data. With the
               default format "NDHWC", the data is stored in the order of:
               [batch, in_depth, in_height, in_width, in_channels].
               Alternatively, the format could be "NCDHW", the data storage order is:
               [batch, in_channels, in_depth, in_height, in_width].
            </param>
            <param name="dilations">
               1-D tensor of length 5.  The dilation factor for each dimension of
               <c>input</c>. If set to k &amp;gt; 1, there will be k-1 skipped cells between each
               filter element on that dimension. The dimension order is determined by the
               value of <c>data_format</c>, see above for details. Dilations in the batch and
               depth dimensions must be 1.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.conv3d_backprop_input(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32[],System.String,System.Int32[],System.String)">
            <summary>
               Computes the gradients of 3-D convolution with respect to the input.
            </summary>
            <param name="input">
               Shape <c>[batch, depth, rows, cols, in_channels]</c>.
            </param>
            <param name="filter">
               Shape <c>[depth, rows, cols, in_channels, out_channels]</c>.
               <c>in_channels</c> must match between <c>input</c> and <c>filter</c>.
            </param>
            <param name="out_backprop">
               Backprop signal of shape <c>[batch, out_depth, out_rows, out_cols,
               out_channels]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Conv3DBackpropInput'.
            </param>
            <param name="strides">
               Optional argument
               1-D tensor of length 5. The stride of the sliding window for each
               dimension of <c>input</c>. Must have <c>strides[0] = strides[4] = 1</c>.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <param name="dilations">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.conv3d_backprop_input_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32[],System.String,System.String,System.Int32[],System.String)">
            <summary>
               Computes the gradients of 3-D convolution with respect to the input.
            </summary>
            <param name="input_sizes">
               An integer vector representing the tensor shape of <c>input</c>,
               where <c>input</c> is a 5-D
               <c>[batch, depth, rows, cols, in_channels]</c> tensor.
            </param>
            <param name="filter">
               Shape <c>[depth, rows, cols, in_channels, out_channels]</c>.
               <c>in_channels</c> must match between <c>input</c> and <c>filter</c>.
            </param>
            <param name="out_backprop">
               Backprop signal of shape <c>[batch, out_depth, out_rows, out_cols,
               out_channels]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Conv3DBackpropInputV2'.
            </param>
            <param name="strides">
               Optional argument
               1-D tensor of length 5. The stride of the sliding window for each
               dimension of <c>input</c>. Must have <c>strides[0] = strides[4] = 1</c>.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <param name="data_format">
               The data format of the input and output data. With the
               default format "NDHWC", the data is stored in the order of:
               [batch, in_depth, in_height, in_width, in_channels].
               Alternatively, the format could be "NCDHW", the data storage order is:
               [batch, in_channels, in_depth, in_height, in_width].
            </param>
            <param name="dilations">
               1-D tensor of length 5.  The dilation factor for each dimension of
               <c>input</c>. If set to k &amp;gt; 1, there will be k-1 skipped cells between each
               filter element on that dimension. The dimension order is determined by the
               value of <c>data_format</c>, see above for details. Dilations in the batch and
               depth dimensions must be 1.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.copy(Tensorflow.Tensor,System.String,System.String[],System.String)">
            <summary>
               Copy Op.
            </summary>
            <param name="input">
               Input tensor.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Copy'.
            </param>
            <param name="tensor_name">
               The name of the input tensor.
            </param>
            <param name="debug_ops_spec">
               A list of debug op spec (op, url, gated_grpc) for attached debug
               ops. Each element of the list has the format
               &amp;lt;debug_op&amp;gt;;&amp;lt;grpc_url&amp;gt;;&amp;lt;gated_grpc&amp;gt;, wherein gated_grpc is boolean represented
               as 0/1. E.g., "DebugIdentity;grpc://foo:3333;1",
               "DebugIdentity;file:///tmp/tfdbg_1;0".
            </param>
            <returns>
               Output tensor, deep-copied from input.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Performs CPU-to-CPU or GPU-to-GPU deep-copying of tensor, depending on the
               device on which the tensor is allocated.
               N.B.: If the all downstream attached debug ops are disabled given the current
               gRPC gating status, the output will simply forward the input tensor without
               deep-copying. See the documentation of Debug* ops for more details.
               
               Unlike the CopyHost Op, this op does not have HostMemory constraint on its
               input or output.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.copy_host(Tensorflow.Tensor,System.String,System.String[],System.String)">
            <summary>
               Copy Host Op.
            </summary>
            <param name="input">
               Input tensor.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'CopyHost'.
            </param>
            <param name="tensor_name">
               The name of the input tensor.
            </param>
            <param name="debug_ops_spec">
               A list of debug op spec (op, url, gated_grpc) for attached debug
               ops. Each element of the list has the format
               &amp;lt;debug_op&amp;gt;;&amp;lt;grpc_url&amp;gt;;&amp;lt;gated_grpc&amp;gt;, wherein gated_grpc is boolean represented
               as 0/1. E.g., "DebugIdentity;grpc://foo:3333;1",
               "DebugIdentity;file:///tmp/tfdbg_1;0".
            </param>
            <returns>
               Output tensor, deep-copied from input.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Performs CPU-to-CPU deep-copying of tensor.
               N.B.: If the all downstream attached debug ops are disabled given the current
               gRPC gating status, the output will simply forward the input tensor without
               deep-copying. See the documentation of Debug* ops for more details.
               
               Unlike the Copy Op, this op has HostMemory constraint on its input or output.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.cos(Tensorflow.Tensor,System.String)">
            <summary>
               Computes cos of x element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Cos'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.cosh(Tensorflow.Tensor,System.String)">
            <summary>
               Computes hyperbolic cosine of x element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Cosh'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.count_up_to(Tensorflow.Tensor,System.Int32,System.String)">
            <summary>
               Increments 'ref' until it reaches 'limit'.
            </summary>
            <param name="referecne">
               Should be from a scalar <c>Variable</c> node.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'CountUpTo'.
            </param>
            <param name="limit">
               Optional argument
               If incrementing ref would bring it above limit, instead generates an
               'OutOfRange' error.
            </param>
            <returns>
               A copy of the input before increment. If nothing else modifies the
               input, the values produced will all be distinct.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.crop_and_resize(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.Nullable{System.Single},System.String)">
            <summary>
               Extracts crops from the input image tensor and resizes them.
            </summary>
            <param name="image">
               A 4-D tensor of shape <c>[batch, image_height, image_width, depth]</c>.
               Both <c>image_height</c> and <c>image_width</c> need to be positive.
            </param>
            <param name="boxes">
               A 2-D tensor of shape <c>[num_boxes, 4]</c>. The <c>i</c>-th row of the tensor
               specifies the coordinates of a box in the <c>box_ind[i]</c> image and is specified
               in normalized coordinates <c>[y1, x1, y2, x2]</c>. A normalized coordinate value of
               <c>y</c> is mapped to the image coordinate at <c>y * (image_height - 1)</c>, so as the
               <c>[0, 1]</c> interval of normalized image height is mapped to
               <c>[0, image_height - 1]</c> in image height coordinates. We do allow <c>y1</c> &amp;gt; <c>y2</c>, in
               which case the sampled crop is an up-down flipped version of the original
               image. The width dimension is treated similarly. Normalized coordinates
               outside the <c>[0, 1]</c> range are allowed, in which case we use
               <c>extrapolation_value</c> to extrapolate the input image values.
            </param>
            <param name="box_ind">
               A 1-D tensor of shape <c>[num_boxes]</c> with int32 values in <c>[0, batch)</c>.
               The value of <c>box_ind[i]</c> specifies the image that the <c>i</c>-th box refers to.
            </param>
            <param name="crop_size">
               A 1-D tensor of 2 elements, <c>size = [crop_height, crop_width]</c>. All
               cropped image patches are resized to this size. The aspect ratio of the image
               content is not preserved. Both <c>crop_height</c> and <c>crop_width</c> need to be
               positive.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'CropAndResize'.
            </param>
            <param name="method">
               A string specifying the sampling method for resizing. It can be either
               <c>"bilinear"</c> or <c>"nearest"</c> and default to <c>"bilinear"</c>. Currently two sampling
               methods are supported: Bilinear and Nearest Neighbor.
            </param>
            <param name="extrapolation_value">
               Value used for extrapolation, when applicable.
            </param>
            <returns>
               A 4-D tensor of shape <c>[num_boxes, crop_height, crop_width, depth]</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Extracts crops from the input image tensor and resizes them using bilinear
               sampling or nearest neighbor sampling (possibly with aspect ratio change) to a
               common output size specified by <c>crop_size</c>. This is more general than the
               <c>crop_to_bounding_box</c> op which extracts a fixed size slice from the input image
               and does not allow resizing or aspect ratio change.
               
               Returns a tensor with <c>crops</c> from the input <c>image</c> at positions defined at the
               bounding box locations in <c>boxes</c>. The cropped boxes are all resized (with
               bilinear or nearest neighbor interpolation) to a fixed
               <c>size = [crop_height, crop_width]</c>. The result is a 4-D tensor
               <c>[num_boxes, crop_height, crop_width, depth]</c>. The resizing is corner aligned.
               In particular, if <c>boxes = [[0, 0, 1, 1]]</c>, the method will give identical
               results to using <c>tf.image.resize_bilinear()</c> or
               <c>tf.image.resize_nearest_neighbor()</c>(depends on the <c>method</c> argument) with
               <c>align_corners=True</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.crop_and_resize_grad_boxes(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.String)">
            <summary>
               Computes the gradient of the crop_and_resize op wrt the input boxes tensor.
            </summary>
            <param name="grads">
               A 4-D tensor of shape <c>[num_boxes, crop_height, crop_width, depth]</c>.
            </param>
            <param name="image">
               A 4-D tensor of shape <c>[batch, image_height, image_width, depth]</c>.
               Both <c>image_height</c> and <c>image_width</c> need to be positive.
            </param>
            <param name="boxes">
               A 2-D tensor of shape <c>[num_boxes, 4]</c>. The <c>i</c>-th row of the tensor
               specifies the coordinates of a box in the <c>box_ind[i]</c> image and is specified
               in normalized coordinates <c>[y1, x1, y2, x2]</c>. A normalized coordinate value of
               <c>y</c> is mapped to the image coordinate at <c>y * (image_height - 1)</c>, so as the
               <c>[0, 1]</c> interval of normalized image height is mapped to
               <c>[0, image_height - 1]</c> in image height coordinates. We do allow y1 &amp;gt; y2, in
               which case the sampled crop is an up-down flipped version of the original
               image. The width dimension is treated similarly. Normalized coordinates
               outside the <c>[0, 1]</c> range are allowed, in which case we use
               <c>extrapolation_value</c> to extrapolate the input image values.
            </param>
            <param name="box_ind">
               A 1-D tensor of shape <c>[num_boxes]</c> with int32 values in <c>[0, batch)</c>.
               The value of <c>box_ind[i]</c> specifies the image that the <c>i</c>-th box refers to.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'CropAndResizeGradBoxes'.
            </param>
            <param name="method">
               A string specifying the interpolation method. Only 'bilinear' is
               supported for now.
            </param>
            <returns>
               A 2-D tensor of shape <c>[num_boxes, 4]</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.crop_and_resize_grad_image(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType,System.String,System.String)">
            <summary>
               Computes the gradient of the crop_and_resize op wrt the input image tensor.
            </summary>
            <param name="grads">
               A 4-D tensor of shape <c>[num_boxes, crop_height, crop_width, depth]</c>.
            </param>
            <param name="boxes">
               A 2-D tensor of shape <c>[num_boxes, 4]</c>. The <c>i</c>-th row of the tensor
               specifies the coordinates of a box in the <c>box_ind[i]</c> image and is specified
               in normalized coordinates <c>[y1, x1, y2, x2]</c>. A normalized coordinate value of
               <c>y</c> is mapped to the image coordinate at <c>y * (image_height - 1)</c>, so as the
               <c>[0, 1]</c> interval of normalized image height is mapped to
               <c>[0, image_height - 1]</c> in image height coordinates. We do allow y1 &amp;gt; y2, in
               which case the sampled crop is an up-down flipped version of the original
               image. The width dimension is treated similarly. Normalized coordinates
               outside the <c>[0, 1]</c> range are allowed, in which case we use
               <c>extrapolation_value</c> to extrapolate the input image values.
            </param>
            <param name="box_ind">
               A 1-D tensor of shape <c>[num_boxes]</c> with int32 values in <c>[0, batch)</c>.
               The value of <c>box_ind[i]</c> specifies the image that the <c>i</c>-th box refers to.
            </param>
            <param name="image_size">
               A 1-D tensor with value <c>[batch, image_height, image_width, depth]</c>
               containing the original image size. Both <c>image_height</c> and <c>image_width</c> need
               to be positive.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'CropAndResizeGradImage'.
            </param>
            <param name="T">
               Optional argument
            </param>
            <param name="method">
               A string specifying the interpolation method. Only 'bilinear' is
               supported for now.
            </param>
            <returns>
               A 4-D tensor of shape <c>[batch, image_height, image_width, depth]</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.cross(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Compute the pairwise cross product.
            </summary>
            <param name="a">
               A tensor containing 3-element vectors.
            </param>
            <param name="b">
               Another tensor, of same type and shape as <c>a</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Cross'.
            </param>
            <returns>
               Pairwise cross product of the vectors in <c>a</c> and <c>b</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               <c>a</c> and <c>b</c> must be the same shape; they can either be simple 3-element vectors,
               or any shape where the innermost dimension is 3. In the latter case, each pair
               of corresponding 3-element vectors is cross-multiplied independently.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.cross_replica_sum(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               An Op to sum inputs across replicated TPU instances. Each
            </summary>
            <param name="input">
               The local input to the sum.
            </param>
            <param name="group_assignment">
               An int32 tensor with shape
               [num_groups, num_replicas_per_group]. <c>group_assignment[i]</c> represents the
               replica ids in the ith subgroup.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'CrossReplicaSum'.
            </param>
            <returns>
               The sum of all the distributed inputs.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               instance supplies its own input. If group_assignment is empty, the output of
               each is the sum of all the inputs, otherwise the output of each is the sum of
               the inputs belonging to the same group.
               
               For example, suppose there are 8 TPU instances: <c>[A, B, C, D, E, F, G, H]</c>.
               Passing group_assignment=<c>[[0,2,4,6],[1,3,5,7]]</c> sets <c>A, C, E, G</c> as group 0,
               and <c>B, D, F, H</c> as group 1. Thus we get the outputs:
               <c>[A+C+E+G, B+D+F+H, A+C+E+G, B+D+F+H, A+C+E+G, B+D+F+H, A+C+E+G, B+D+F+H]</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.cudnn_r_n_n(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.String,System.String,System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Boolean},System.String)">
            <summary>
               A RNN backed by cuDNN.
            </summary>
            <param name="input">
            </param>
            <param name="input_h">
            </param>
            <param name="input_c">
            </param>
            <param name="parameters">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'CudnnRNN'.
            </param>
            <param name="rnn_mode">
            </param>
            <param name="input_mode">
            </param>
            <param name="direction">
            </param>
            <param name="dropout">
            </param>
            <param name="seed">
            </param>
            <param name="seed2">
            </param>
            <param name="is_training">
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output :
               output_h :
               output_c :
               reserve_space :
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Computes the RNN from the input and initial states, with respect to the params
               buffer.
               
               rnn_mode: Indicates the type of the RNN model.
               input_mode: Indicate whether there is a linear projection between the input and
               the actual computation before the first layer. 'skip_input' is only allowed
               when input_size == num_units; 'auto_select' implies 'skip_input' when
               input_size == num_units; otherwise, it implies 'linear_input'.
               direction: Indicates whether a bidirectional model will be used. Should be
               "unidirectional" or "bidirectional".
               dropout: Dropout probability. When set to 0., dropout is disabled.
               seed: The 1st part of a seed to initialize dropout.
               seed2: The 2nd part of a seed to initialize dropout.
               input: A 3-D tensor with the shape of [seq_length, batch_size, input_size].
               input_h: A 3-D tensor with the shape of [num_layer * dir, batch_size,
               num_units].
               input_c: For LSTM, a 3-D tensor with the shape of
               [num_layer * dir, batch, num_units]. For other models, it is ignored.
               params: A 1-D tensor that contains the weights and biases in an opaque layout.
               The size must be created through CudnnRNNParamsSize, and initialized
               separately. Note that they might not be compatible across different
               generations. So it is a good idea to save and restore
               output: A 3-D tensor with the shape of [seq_length, batch_size,
               dir * num_units].
               output_h: The same shape has input_h.
               output_c: The same shape as input_c for LSTM. An empty tensor for other models.
               is_training: Indicates whether this operation is used for inferenece or
               training.
               reserve_space: An opaque tensor that can be used in backprop calculation. It
               is only produced if is_training is false.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.cudnn_r_n_n_backprop(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.String,System.String,System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Backprop step of CudnnRNN.
            </summary>
            <param name="input">
            </param>
            <param name="input_h">
            </param>
            <param name="input_c">
            </param>
            <param name="parameters">
            </param>
            <param name="output">
            </param>
            <param name="output_h">
            </param>
            <param name="output_c">
            </param>
            <param name="output_backprop">
            </param>
            <param name="output_h_backprop">
            </param>
            <param name="output_c_backprop">
            </param>
            <param name="reserve_space">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'CudnnRNNBackprop'.
            </param>
            <param name="rnn_mode">
            </param>
            <param name="input_mode">
            </param>
            <param name="direction">
            </param>
            <param name="dropout">
            </param>
            <param name="seed">
            </param>
            <param name="seed2">
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               input_backprop :
               input_h_backprop :
               input_c_backprop :
               params_backprop :
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Compute the backprop of both data and weights in a RNN.
               
               rnn_mode: Indicates the type of the RNN model.
               input_mode: Indicate whether there is a linear projection between the input and
               the actual computation before the first layer. 'skip_input' is only allowed
               when input_size == num_units; 'auto_select' implies 'skip_input' when
               input_size == num_units; otherwise, it implies 'linear_input'.
               direction: Indicates whether a bidirectional model will be used. Should be
               "unidirectional" or "bidirectional".
               dropout: Dropout probability. When set to 0., dropout is disabled.
               seed: The 1st part of a seed to initialize dropout.
               seed2: The 2nd part of a seed to initialize dropout.
               input: A 3-D tensor with the shape of [seq_length, batch_size, input_size].
               input_h: A 3-D tensor with the shape of [num_layer * dir, batch_size,
               num_units].
               input_c: For LSTM, a 3-D tensor with the shape of
               [num_layer * dir, batch, num_units]. For other models, it is ignored.
               params: A 1-D tensor that contains the weights and biases in an opaque layout.
               The size must be created through CudnnRNNParamsSize, and initialized
               separately. Note that they might not be compatible across different
               generations. So it is a good idea to save and restore
               output: A 3-D tensor with the shape of [seq_length, batch_size,
               dir * num_units].
               output_h: The same shape has input_h.
               output_c: The same shape as input_c for LSTM. An empty tensor for other models.
               output_backprop: A 3-D tensor with the same shape as output in the forward pass.
               output_h_backprop: A 3-D tensor with the same shape as output_h in the forward
               pass.
               output_c_backprop: A 3-D tensor with the same shape as output_c in the forward
               pass.
               reserve_space: The same reserve_space produced in for forward operation.
               input_backprop: The backprop to input in the forward pass. Has the same shape
               as input.
               input_h_backprop: The backprop to input_h in the forward pass. Has the same
               shape as input_h.
               input_c_backprop: The backprop to input_c in the forward pass. Has the same
               shape as input_c.
               params_backprop: The backprop to the params buffer in the forward pass. Has the
               same shape as params.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.cudnn_r_n_n_backprop_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.String,System.String,System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Backprop step of CudnnRNN.
            </summary>
            <param name="input">
            </param>
            <param name="input_h">
            </param>
            <param name="input_c">
            </param>
            <param name="parameters">
            </param>
            <param name="output">
            </param>
            <param name="output_h">
            </param>
            <param name="output_c">
            </param>
            <param name="output_backprop">
            </param>
            <param name="output_h_backprop">
            </param>
            <param name="output_c_backprop">
            </param>
            <param name="reserve_space">
            </param>
            <param name="host_reserved">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'CudnnRNNBackpropV2'.
            </param>
            <param name="rnn_mode">
            </param>
            <param name="input_mode">
            </param>
            <param name="direction">
            </param>
            <param name="dropout">
            </param>
            <param name="seed">
            </param>
            <param name="seed2">
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               input_backprop :
               input_h_backprop :
               input_c_backprop :
               params_backprop :
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Compute the backprop of both data and weights in a RNN. Takes an extra
               "host_reserved" inupt than CudnnRNNBackprop, which is used to determine RNN
               cudnnRNNAlgo_t and cudnnMathType_t.
               
               rnn_mode: Indicates the type of the RNN model.
               input_mode: Indicates whether there is a linear projection between the input and
               the actual computation before the first layer. 'skip_input' is only allowed
               when input_size == num_units; 'auto_select' implies 'skip_input' when
               input_size == num_units; otherwise, it implies 'linear_input'.
               direction: Indicates whether a bidirectional model will be used. Should be
               "unidirectional" or "bidirectional".
               dropout: Dropout probability. When set to 0., dropout is disabled.
               seed: The 1st part of a seed to initialize dropout.
               seed2: The 2nd part of a seed to initialize dropout.
               input: A 3-D tensor with the shape of [seq_length, batch_size, input_size].
               input_h: A 3-D tensor with the shape of [num_layer * dir, batch_size,
               num_units].
               input_c: For LSTM, a 3-D tensor with the shape of
               [num_layer * dir, batch, num_units]. For other models, it is ignored.
               params: A 1-D tensor that contains the weights and biases in an opaque layout.
               The size must be created through CudnnRNNParamsSize, and initialized
               separately. Note that they might not be compatible across different
               generations. So it is a good idea to save and restore
               output: A 3-D tensor with the shape of [seq_length, batch_size,
               dir * num_units].
               output_h: The same shape has input_h.
               output_c: The same shape as input_c for LSTM. An empty tensor for other models.
               output_backprop: A 3-D tensor with the same shape as output in the forward pass.
               output_h_backprop: A 3-D tensor with the same shape as output_h in the forward
               pass.
               output_c_backprop: A 3-D tensor with the same shape as output_c in the forward
               pass.
               reserve_space: The same reserve_space produced in the forward operation.
               host_reserved: The same host_reserved produced in the forward operation.
               input_backprop: The backprop to input in the forward pass. Has the same shape
               as input.
               input_h_backprop: The backprop to input_h in the forward pass. Has the same
               shape as input_h.
               input_c_backprop: The backprop to input_c in the forward pass. Has the same
               shape as input_c.
               params_backprop: The backprop to the params buffer in the forward pass. Has the
               same shape as params.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.cudnn_r_n_n_canonical_to_params(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor[],Tensorflow.Tensor[],System.String,System.String,System.String,System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Converts CudnnRNN params from canonical form to usable form.
            </summary>
            <param name="num_layers">
            </param>
            <param name="num_units">
            </param>
            <param name="input_size">
            </param>
            <param name="weights">
            </param>
            <param name="biases">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'CudnnRNNCanonicalToParams'.
            </param>
            <param name="rnn_mode">
            </param>
            <param name="input_mode">
            </param>
            <param name="direction">
            </param>
            <param name="dropout">
            </param>
            <param name="seed">
            </param>
            <param name="seed2">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Writes a set of weights into the opaque params buffer so they can be used in
               upcoming training or inferences.
               
               Note that the params buffer may not be compatible across different GPUs. So any
               save and restoration should be converted to and from the canonical weights and
               biases.
               
               num_layers: Specifies the number of layers in the RNN model.
               num_units: Specifies the size of the hidden state.
               input_size: Specifies the size of the input state.
               weights: the canonical form of weights that can be used for saving
               and restoration. They are more likely to be compatible across different
               generations.
               biases: the canonical form of biases that can be used for saving
               and restoration. They are more likely to be compatible across different
               generations.
               num_params: number of parameter sets for all layers.
               Each layer may contain multiple parameter sets, with each set consisting of
               a weight matrix and a bias vector.
               rnn_mode: Indicates the type of the RNN model.
               input_mode: Indicate whether there is a linear projection between the input and
               The actual computation before the first layer. 'skip_input' is only allowed
               when input_size == num_units; 'auto_select' implies 'skip_input' when
               input_size == num_units; otherwise, it implies 'linear_input'.
               direction: Indicates whether a bidirectional model will be used.
               dir = (direction == bidirectional) ? 2 : 1
               dropout: dropout probability. When set to 0., dropout is disabled.
               seed: the 1st part of a seed to initialize dropout.
               seed2: the 2nd part of a seed to initialize dropout.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.cudnn_r_n_n_params_size(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType,Tensorflow.TF_DataType,System.String,System.String,System.String,System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Computes size of weights that can be used by a Cudnn RNN model.
            </summary>
            <param name="num_layers">
            </param>
            <param name="num_units">
            </param>
            <param name="input_size">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'CudnnRNNParamsSize'.
            </param>
            <param name="T">
               Optional argument
            </param>
            <param name="S">
               Optional argument
            </param>
            <param name="rnn_mode">
            </param>
            <param name="input_mode">
            </param>
            <param name="direction">
            </param>
            <param name="dropout">
            </param>
            <param name="seed">
            </param>
            <param name="seed2">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Return the params size that can be used by the Cudnn RNN model. Subsequent
               weight allocation and initialization should use this size.
               
               num_layers: Specifies the number of layers in the RNN model.
               num_units: Specifies the size of the hidden state.
               input_size: Specifies the size of the input state.
               rnn_mode: Indicates the type of the RNN model.
               input_mode: Indicate whether there is a linear projection between the input and
               The actual computation before the first layer. 'skip_input' is only allowed
               when input_size == num_units; 'auto_select' implies 'skip_input' when
               input_size == num_units; otherwise, it implies 'linear_input'.
               direction: Indicates whether a bidirectional model will be used.
               dir = (direction == bidirectional) ? 2 : 1
               dropout: dropout probability. When set to 0., dropout is disabled.
               seed: the 1st part of a seed to initialize dropout.
               seed2: the 2nd part of a seed to initialize dropout.
               params_size: The size of the params buffer that should be allocated and
               initialized for this RNN model. Note that this params buffer may not be
               compatible across GPUs. Please use CudnnRNNParamsWeights and
               CudnnRNNParamsBiases to save and restore them in a way that is compatible
               across different runs.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.cudnn_r_n_n_params_to_canonical(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32,System.String,System.String,System.String,System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Retrieves CudnnRNN params in canonical form.
            </summary>
            <param name="num_layers">
            </param>
            <param name="num_units">
            </param>
            <param name="input_size">
            </param>
            <param name="parameters">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'CudnnRNNParamsToCanonical'.
            </param>
            <param name="num_params">
               Optional argument
            </param>
            <param name="rnn_mode">
            </param>
            <param name="input_mode">
            </param>
            <param name="direction">
            </param>
            <param name="dropout">
            </param>
            <param name="seed">
            </param>
            <param name="seed2">
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               weights :
               biases :
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Retrieves a set of weights from the opaque params buffer that can be saved and
               restored in a way compatible with future runs.
               
               Note that the params buffer may not be compatible across different GPUs. So any
               save and restoration should be converted to and from the canonical weights and
               biases.
               
               num_layers: Specifies the number of layers in the RNN model.
               num_units: Specifies the size of the hidden state.
               input_size: Specifies the size of the input state.
               num_params: number of parameter sets for all layers.
               Each layer may contain multiple parameter sets, with each set consisting of
               a weight matrix and a bias vector.
               weights: the canonical form of weights that can be used for saving
               and restoration. They are more likely to be compatible across different
               generations.
               biases: the canonical form of biases that can be used for saving
               and restoration. They are more likely to be compatible across different
               generations.
               rnn_mode: Indicates the type of the RNN model.
               input_mode: Indicate whether there is a linear projection between the input and
               The actual computation before the first layer. 'skip_input' is only allowed
               when input_size == num_units; 'auto_select' implies 'skip_input' when
               input_size == num_units; otherwise, it implies 'linear_input'.
               direction: Indicates whether a bidirectional model will be used.
               dir = (direction == bidirectional) ? 2 : 1
               dropout: dropout probability. When set to 0., dropout is disabled.
               seed: the 1st part of a seed to initialize dropout.
               seed2: the 2nd part of a seed to initialize dropout.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.cudnn_r_n_n_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.String,System.String,System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Boolean},System.String)">
            <summary>
               A RNN backed by cuDNN.
            </summary>
            <param name="input">
            </param>
            <param name="input_h">
            </param>
            <param name="input_c">
            </param>
            <param name="parameters">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'CudnnRNNV2'.
            </param>
            <param name="rnn_mode">
            </param>
            <param name="input_mode">
            </param>
            <param name="direction">
            </param>
            <param name="dropout">
            </param>
            <param name="seed">
            </param>
            <param name="seed2">
            </param>
            <param name="is_training">
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output :
               output_h :
               output_c :
               reserve_space :
               host_reserved :
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Computes the RNN from the input and initial states, with respect to the params
               buffer. Produces one extra output "host_reserved" than CudnnRNN.
               
               rnn_mode: Indicates the type of the RNN model.
               input_mode: Indicates whether there is a linear projection between the input and
               the actual computation before the first layer. 'skip_input' is only allowed
               when input_size == num_units; 'auto_select' implies 'skip_input' when
               input_size == num_units; otherwise, it implies 'linear_input'.
               direction: Indicates whether a bidirectional model will be used. Should be
               "unidirectional" or "bidirectional".
               dropout: Dropout probability. When set to 0., dropout is disabled.
               seed: The 1st part of a seed to initialize dropout.
               seed2: The 2nd part of a seed to initialize dropout.
               input: A 3-D tensor with the shape of [seq_length, batch_size, input_size].
               input_h: A 3-D tensor with the shape of [num_layer * dir, batch_size,
               num_units].
               input_c: For LSTM, a 3-D tensor with the shape of
               [num_layer * dir, batch, num_units]. For other models, it is ignored.
               params: A 1-D tensor that contains the weights and biases in an opaque layout.
               The size must be created through CudnnRNNParamsSize, and initialized
               separately. Note that they might not be compatible across different
               generations. So it is a good idea to save and restore
               output: A 3-D tensor with the shape of [seq_length, batch_size,
               dir * num_units].
               output_h: The same shape has input_h.
               output_c: The same shape as input_c for LSTM. An empty tensor for other models.
               is_training: Indicates whether this operation is used for inferenece or
               training.
               reserve_space: An opaque tensor that can be used in backprop calculation. It
               is only produced if is_training is true.
               host_reserved: An opaque tensor that can be used in backprop calculation. It is
               only produced if is_training is true. It is output on host memory rather than
               device memory.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.cumprod(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.String)">
            <summary>
               Compute the cumulative product of the tensor <c>x</c> along <c>axis</c>.
            </summary>
            <param name="x">
               A <c>Tensor</c>. Must be one of the following types: <c>float32</c>, <c>float64</c>,
               <c>int64</c>, <c>int32</c>, <c>uint8</c>, <c>uint16</c>, <c>int16</c>, <c>int8</c>, <c>complex64</c>,
               <c>complex128</c>, <c>qint8</c>, <c>quint8</c>, <c>qint32</c>, <c>half</c>.
            </param>
            <param name="axis">
               A <c>Tensor</c> of type <c>int32</c> (default: 0). Must be in the range
               <c>[-rank(x), rank(x))</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Cumprod'.
            </param>
            <param name="exclusive">
               If <c>True</c>, perform exclusive cumprod.
            </param>
            <param name="reverse">
               A <c>bool</c> (default: False).
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               By default, this op performs an inclusive cumprod, which means that the first
               element of the input is identical to the first element of the output:
               
              <code>
               tf.cumprod([a, b, c])  # =&amp;gt; [a, a * b, a * b * c]
              </code>
               
               By setting the <c>exclusive</c> kwarg to <c>True</c>, an exclusive cumprod is
               performed instead:
               
              <code>
               tf.cumprod([a, b, c], exclusive=True)  # =&amp;gt; [1, a, a * b]
              </code>
               
               By setting the <c>reverse</c> kwarg to <c>True</c>, the cumprod is performed in the
               opposite direction:
               
              <code>
               tf.cumprod([a, b, c], reverse=True)  # =&amp;gt; [a * b * c, b * c, c]
              </code>
               
               This is more efficient than using separate <c>tf.reverse</c> ops.
               
               The <c>reverse</c> and <c>exclusive</c> kwargs can also be combined:
               
              <code>
               tf.cumprod([a, b, c], exclusive=True, reverse=True)  # =&amp;gt; [b * c, c, 1]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.cumsum(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.String)">
            <summary>
               Compute the cumulative sum of the tensor <c>x</c> along <c>axis</c>.
            </summary>
            <param name="x">
               A <c>Tensor</c>. Must be one of the following types: <c>float32</c>, <c>float64</c>,
               <c>int64</c>, <c>int32</c>, <c>uint8</c>, <c>uint16</c>, <c>int16</c>, <c>int8</c>, <c>complex64</c>,
               <c>complex128</c>, <c>qint8</c>, <c>quint8</c>, <c>qint32</c>, <c>half</c>.
            </param>
            <param name="axis">
               A <c>Tensor</c> of type <c>int32</c> (default: 0). Must be in the range
               <c>[-rank(x), rank(x))</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Cumsum'.
            </param>
            <param name="exclusive">
               If <c>True</c>, perform exclusive cumsum.
            </param>
            <param name="reverse">
               A <c>bool</c> (default: False).
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               By default, this op performs an inclusive cumsum, which means that the first
               element of the input is identical to the first element of the output:
               
              <code>
               tf.cumsum([a, b, c])  # =&amp;gt; [a, a + b, a + b + c]
              </code>
               
               By setting the <c>exclusive</c> kwarg to <c>True</c>, an exclusive cumsum is
               performed instead:
               
              <code>
               tf.cumsum([a, b, c], exclusive=True)  # =&amp;gt; [0, a, a + b]
              </code>
               
               By setting the <c>reverse</c> kwarg to <c>True</c>, the cumsum is performed in the
               opposite direction:
               
              <code>
               tf.cumsum([a, b, c], reverse=True)  # =&amp;gt; [a + b + c, b + c, c]
              </code>
               
               This is more efficient than using separate <c>tf.reverse</c> ops.
               
               The <c>reverse</c> and <c>exclusive</c> kwargs can also be combined:
               
              <code>
               tf.cumsum([a, b, c], exclusive=True, reverse=True)  # =&amp;gt; [b + c, c, 0]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.data_format_dim_map(Tensorflow.Tensor,System.String,System.String,System.String)">
            <summary>
               Returns the dimension index in the destination data format given the one in
            </summary>
            <param name="x">
               A Tensor with each element as a dimension index in source data format.
               Must be in the range [-4, 4).
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DataFormatDimMap'.
            </param>
            <param name="src_format">
               source data format.
            </param>
            <param name="dst_format">
               destination data format.
            </param>
            <returns>
               A Tensor with each element as a dimension index in destination data format.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               the source data format.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.data_format_vec_permute(Tensorflow.Tensor,System.String,System.String,System.String)">
            <summary>
               Returns the permuted vector/tensor in the destination data format given the
            </summary>
            <param name="x">
               Vector of size 4 or Tensor of shape (4, 2) in source data format.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DataFormatVecPermute'.
            </param>
            <param name="src_format">
               source data format.
            </param>
            <param name="dst_format">
               destination data format.
            </param>
            <returns>
               Vector of size 4 or Tensor of shape (4, 2) in destination data format.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               one in the source data format.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.dataset_to_graph(Tensorflow.Tensor,System.String)">
            <summary>
               Returns a serialized GraphDef representing <c>input_dataset</c>.
            </summary>
            <param name="input_dataset">
               A variant tensor representing the dataset to return the graph representation for.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DatasetToGraph'.
            </param>
            <returns>
               The graph representation of the dataset (as serialized GraphDef).
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Returns a graph representation for <c>input_dataset</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.dataset_to_single_element(Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Outputs the single element from the given dataset.
            </summary>
            <param name="dataset">
               A handle to a dataset that contains a single element.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DatasetToSingleElement'.
            </param>
            <param name="output_types">
               Optional argument
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               The components of the single element of <c>input</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.dataset_to_t_f_record(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Writes the given dataset to the given file using the TFRecord format.
            </summary>
            <param name="input_dataset">
               A variant tensor representing the dataset to write.
            </param>
            <param name="filename">
               A scalar string tensor representing the filename to use.
            </param>
            <param name="compression_type">
               A scalar string tensor containing either (i) the empty string (no
               compression), (ii) "ZLIB", or (iii) "GZIP".
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DatasetToTFRecord'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.debug_gradient_identity(Tensorflow.Tensor,System.String)">
            <summary>
               Identity op for gradient debugging.
            </summary>
            <param name="input">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DebugGradientIdentity'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This op is hidden from public in Python. It is used by TensorFlow Debugger to
               register gradient tensors for gradient debugging.
               This op operates on non-reference-type tensors.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.debug_gradient_ref_identity(Tensorflow.Tensor,System.String)">
            <summary>
               Identity op for gradient debugging.
            </summary>
            <param name="input">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DebugGradientRefIdentity'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This op is hidden from public in Python. It is used by TensorFlow Debugger to
               register gradient tensors for gradient debugging.
               This op operates on reference-type tensors.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.debug_identity(Tensorflow.Tensor,System.String,System.String,System.String[],System.Nullable{System.Boolean},System.String)">
            <summary>
               Debug Identity Op.
            </summary>
            <param name="input">
               Input tensor, non-Reference type.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DebugIdentity'.
            </param>
            <param name="device_name">
            </param>
            <param name="tensor_name">
               Name of the input tensor.
            </param>
            <param name="debug_urls">
               List of URLs to debug targets, e.g.,
               file:///foo/tfdbg_dump, grpc:://localhost:11011
            </param>
            <param name="gated_grpc">
               Whether this op will be gated. If any of the debug_urls of this
               debug node is of the grpc:// scheme, when the value of this attribute is set
               to True, the data will not actually be sent via the grpc stream unless this
               debug op has been enabled at the debug_url. If all of the debug_urls of this
               debug node are of the grpc:// scheme and the debug op is enabled at none of
               them, the output will be an empty Tensor.
            </param>
            <returns>
               Output tensor that equals the input tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Provides an identity mapping of the non-Ref type input tensor for debugging.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.debug_nan_count(Tensorflow.Tensor,System.String,System.String,System.String[],System.Nullable{System.Boolean},System.String)">
            <summary>
               Debug NaN Value Counter Op
            </summary>
            <param name="input">
               Input tensor, non-Reference type.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DebugNanCount'.
            </param>
            <param name="device_name">
            </param>
            <param name="tensor_name">
               Name of the input tensor.
            </param>
            <param name="debug_urls">
               List of URLs to debug targets, e.g.,
               file:///foo/tfdbg_dump, grpc:://localhost:11011.
            </param>
            <param name="gated_grpc">
               Whether this op will be gated. If any of the debug_urls of this
               debug node is of the grpc:// scheme, when the value of this attribute is set
               to True, the data will not actually be sent via the grpc stream unless this
               debug op has been enabled at the debug_url. If all of the debug_urls of this
               debug node are of the grpc:// scheme and the debug op is enabled at none of
               them, the output will be an empty Tensor.
            </param>
            <returns>
               An integer output tensor that is the number of NaNs in the input.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Counts number of NaNs in the input tensor, for debugging.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.debug_numeric_summary(Tensorflow.Tensor,System.String,System.String,System.String[],System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.String)">
            <summary>
               Debug Numeric Summary Op.
            </summary>
            <param name="input">
               Input tensor, non-Reference type, float or double.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DebugNumericSummary'.
            </param>
            <param name="device_name">
            </param>
            <param name="tensor_name">
               Name of the input tensor.
            </param>
            <param name="debug_urls">
               List of URLs to debug targets, e.g.,
               file:///foo/tfdbg_dump, grpc:://localhost:11011
            </param>
            <param name="lower_bound">
               (float) The lower bound &amp;lt;= which values will be included in the
               generalized -inf count. Default: -inf.
            </param>
            <param name="upper_bound">
               (float) The upper bound &amp;gt;= which values will be included in the
               generalized +inf count. Default: +inf.
            </param>
            <param name="mute_if_healthy">
               (bool) Do not send data to the debug URLs unless at least one
               of elements [2], [3] and [7] (i.e., the nan count and the generalized -inf and
               inf counts) is non-zero.
            </param>
            <param name="gated_grpc">
               Whether this op will be gated. If any of the debug_urls of this
               debug node is of the grpc:// scheme, when the value of this attribute is set
               to True, the data will not actually be sent via the grpc stream unless this
               debug op has been enabled at the debug_url. If all of the debug_urls of this
               debug node are of the grpc:// scheme and the debug op is enabled at none of
               them, the output will be an empty Tensor.
            </param>
            <returns>
               A double tensor of shape [14 + nDimensions], where nDimensions is the
               the number of dimensions of the tensor's shape. The elements of output are:
               [0]: is initialized (1.0) or not (0.0).
               [1]: total number of elements
               [2]: NaN element count
               [3]: generalized -inf count: elements &amp;lt;= lower_bound. lower_bound is -inf by
               default.
               [4]: negative element count (excluding -inf), if lower_bound is the default
               -inf. Otherwise, this is the count of elements &amp;gt; lower_bound and &amp;lt; 0.
               [5]: zero element count
               [6]: positive element count (excluding +inf), if upper_bound is the default
               -inf. Otherwise, this is the count of elements &amp;lt; upper_bound and &amp;gt; 0.
               [7]: generalized +inf count, elements &amp;gt;= upper_bound. upper_bound is +inf by
               default.
               Output elements [1:8] are all zero, if the tensor is uninitialized.
               [8]: minimum of all non-inf and non-NaN elements.
               If uninitialized or no such element exists: +inf.
               [9]: maximum of all non-inf and non-NaN elements.
               If uninitialized or no such element exists: -inf.
               [10]: mean of all non-inf and non-NaN elements.
               If uninitialized or no such element exists: NaN.
               [11]: variance of all non-inf and non-NaN elements.
               If uninitialized or no such element exists: NaN.
               [12]: Data type of the tensor encoded as an enum integer. See the DataType
               proto for more details.
               [13]: Number of dimensions of the tensor (ndims).
               [14+]: Sizes of the dimensions.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Provide a basic summary of numeric value types, range and distribution.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.decode_and_crop_jpeg(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Single},System.String,System.String)">
            <summary>
               Decode and Crop a JPEG-encoded image to a uint8 tensor.
            </summary>
            <param name="contents">
               0-D.  The JPEG-encoded image.
            </param>
            <param name="crop_window">
               1-D.  The crop window: [crop_y, crop_x, crop_height, crop_width].
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DecodeAndCropJpeg'.
            </param>
            <param name="channels">
               Number of color channels for the decoded image.
            </param>
            <param name="ratio">
               Downscaling ratio.
            </param>
            <param name="fancy_upscaling">
               If true use a slower but nicer upscaling of the
               chroma planes (yuv420/422 only).
            </param>
            <param name="try_recover_truncated">
               If true try to recover an image from truncated input.
            </param>
            <param name="acceptable_fraction">
               The minimum required fraction of lines before a truncated
               input is accepted.
            </param>
            <param name="dct_method">
               string specifying a hint about the algorithm used for
               decompression.  Defaults to "" which maps to a system-specific
               default.  Currently valid values are ["INTEGER_FAST",
               "INTEGER_ACCURATE"].  The hint may be ignored (e.g., the internal
               jpeg library changes to a version that does not have that specific
               option.)
            </param>
            <returns>
               3-D with shape <c>[height, width, channels]</c>..
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The attr <c>channels</c> indicates the desired number of color channels for the
               decoded image.
               
               Accepted values are:
               
               *   0: Use the number of channels in the JPEG-encoded image.
               *   1: output a grayscale image.
               *   3: output an RGB image.
               
               If needed, the JPEG-encoded image is transformed to match the requested number
               of color channels.
               
               The attr <c>ratio</c> allows downscaling the image by an integer factor during
               decoding.  Allowed values are: 1, 2, 4, and 8.  This is much faster than
               downscaling the image later.
               
               
               It is equivalent to a combination of decode and crop, but much faster by only
               decoding partial jpeg image.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.decode_base64(Tensorflow.Tensor,System.String)">
            <summary>
               Decode web-safe base64-encoded strings.
            </summary>
            <param name="input">
               Base64 strings to decode.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DecodeBase64'.
            </param>
            <returns>
               Decoded strings.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Input may or may not have padding at the end. See EncodeBase64 for padding.
               Web-safe means that input must use - and _ instead of + and /.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.decode_bmp(Tensorflow.Tensor,System.Nullable{System.Int32},System.String)">
            <summary>
               Decode the first frame of a BMP-encoded image to a uint8 tensor.
            </summary>
            <param name="contents">
               0-D.  The BMP-encoded image.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DecodeBmp'.
            </param>
            <param name="channels">
            </param>
            <returns>
               3-D with shape <c>[height, width, channels]</c>. RGB order
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The attr <c>channels</c> indicates the desired number of color channels for the
               decoded image.
               
               Accepted values are:
               
               *   0: Use the number of channels in the BMP-encoded image.
               *   3: output an RGB image.
               *   4: output an RGBA image.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.decode_c_s_v(Tensorflow.Tensor,Tensorflow.Tensor[],System.String,System.Nullable{System.Boolean},System.String,System.Int32[],System.String)">
            <summary>
               Convert CSV records to tensors. Each column maps to one tensor.
            </summary>
            <param name="records">
               Each string is a record/row in the csv and all records should have
               the same format.
            </param>
            <param name="record_defaults">
               One tensor per column of the input record, with either a
               scalar default value for that column or an empty vector if the column is
               required.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DecodeCSV'.
            </param>
            <param name="field_delim">
               char delimiter to separate fields in a record.
            </param>
            <param name="use_quote_delim">
               If false, treats double quotation marks as regular
               characters inside of the string fields (ignoring RFC 4180, Section 2,
               Bullet 5).
            </param>
            <param name="na_value">
               Additional string to recognize as NA/NaN.
            </param>
            <param name="select_cols">
            </param>
            <returns>
               Each tensor will have the same shape as records.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               RFC 4180 format is expected for the CSV records.
               (https://tools.ietensorflow.org/html/rfc4180)
               Note that we allow leading and trailing spaces with int or float field.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.decode_compressed(Tensorflow.Tensor,System.String,System.String)">
            <summary>
               Decompress strings.
            </summary>
            <param name="bytes">
               A Tensor of string which is compressed.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DecodeCompressed'.
            </param>
            <param name="compression_type">
               A scalar containing either (i) the empty string (no
               compression), (ii) "ZLIB", or (iii) "GZIP".
            </param>
            <returns>
               A Tensor with the same shape as input <c>bytes</c>, uncompressed
               from bytes.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This op decompresses each element of the <c>bytes</c> input <c>Tensor</c>, which
               is assumed to be compressed using the given <c>compression_type</c>.
               
               The <c>output</c> is a string <c>Tensor</c> of the same shape as <c>bytes</c>,
               each element containing the decompressed data from the corresponding
               element in <c>bytes</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.decode_gif(Tensorflow.Tensor,System.String)">
            <summary>
               Decode the first frame of a GIF-encoded image to a uint8 tensor.
            </summary>
            <param name="contents">
               0-D.  The GIF-encoded image.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DecodeGif'.
            </param>
            <returns>
               4-D with shape <c>[num_frames, height, width, 3]</c>. RGB order
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               GIF with frame or transparency compression are not supported
               convert animated GIF from compressed to uncompressed by:
               
               convert $src.gif -coalesce $dst.gif
               
               This op also supports decoding JPEGs and PNGs, though it is cleaner to use
               <c>tf.image.decode_image</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.decode_j_s_o_n_example(Tensorflow.Tensor,System.String)">
            <summary>
               Convert JSON-encoded Example records to binary protocol buffer strings.
            </summary>
            <param name="json_examples">
               Each string is a JSON object serialized according to the JSON
               mapping of the Example proto.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DecodeJSONExample'.
            </param>
            <returns>
               Each string is a binary Example protocol buffer corresponding
               to the respective element of <c>json_examples</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This op translates a tensor containing Example records, encoded using
               the [standard JSON
               mapping](https://developers.google.com/protocol-buffers/docs/proto3#json),
               into a tensor containing the same records encoded as binary protocol
               buffers. The resulting tensor can then be fed to any of the other
               Example-parsing ops.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.decode_jpeg(Tensorflow.Tensor,System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Single},System.String,System.String)">
            <summary>
               Decode a JPEG-encoded image to a uint8 tensor.
            </summary>
            <param name="contents">
               0-D.  The JPEG-encoded image.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DecodeJpeg'.
            </param>
            <param name="channels">
               Number of color channels for the decoded image.
            </param>
            <param name="ratio">
               Downscaling ratio.
            </param>
            <param name="fancy_upscaling">
               If true use a slower but nicer upscaling of the
               chroma planes (yuv420/422 only).
            </param>
            <param name="try_recover_truncated">
               If true try to recover an image from truncated input.
            </param>
            <param name="acceptable_fraction">
               The minimum required fraction of lines before a truncated
               input is accepted.
            </param>
            <param name="dct_method">
               string specifying a hint about the algorithm used for
               decompression.  Defaults to "" which maps to a system-specific
               default.  Currently valid values are ["INTEGER_FAST",
               "INTEGER_ACCURATE"].  The hint may be ignored (e.g., the internal
               jpeg library changes to a version that does not have that specific
               option.)
            </param>
            <returns>
               3-D with shape <c>[height, width, channels]</c>..
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The attr <c>channels</c> indicates the desired number of color channels for the
               decoded image.
               
               Accepted values are:
               
               *   0: Use the number of channels in the JPEG-encoded image.
               *   1: output a grayscale image.
               *   3: output an RGB image.
               
               If needed, the JPEG-encoded image is transformed to match the requested number
               of color channels.
               
               The attr <c>ratio</c> allows downscaling the image by an integer factor during
               decoding.  Allowed values are: 1, 2, 4, and 8.  This is much faster than
               downscaling the image later.
               
               
               This op also supports decoding PNGs and non-animated GIFs since the interface is
               the same, though it is cleaner to use <c>tf.image.decode_image</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.decode_png(Tensorflow.Tensor,System.Nullable{System.Int32},System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Decode a PNG-encoded image to a uint8 or uint16 tensor.
            </summary>
            <param name="contents">
               0-D.  The PNG-encoded image.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DecodePng'.
            </param>
            <param name="channels">
               Number of color channels for the decoded image.
            </param>
            <param name="dtype">
            </param>
            <returns>
               3-D with shape <c>[height, width, channels]</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The attr <c>channels</c> indicates the desired number of color channels for the
               decoded image.
               
               Accepted values are:
               
               *   0: Use the number of channels in the PNG-encoded image.
               *   1: output a grayscale image.
               *   3: output an RGB image.
               *   4: output an RGBA image.
               
               If needed, the PNG-encoded image is transformed to match the requested number
               of color channels.
               
               This op also supports decoding JPEGs and non-animated GIFs since the interface
               is the same, though it is cleaner to use <c>tf.image.decode_image</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.decode_proto_v2(Tensorflow.Tensor,System.String,System.String[],Tensorflow.TF_DataType[],System.String,System.String,System.Nullable{System.Boolean},System.String)">
            <summary>
               The op extracts fields from a serialized protocol buffers message into tensors.
            </summary>
            <param name="bytes">
               Tensor of serialized protos with shape <c>batch_shape</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DecodeProtoV2'.
            </param>
            <param name="message_type">
               Optional argument
               Name of the proto message type to decode.
            </param>
            <param name="field_names">
               Optional argument
               List of strings containing proto field names.
            </param>
            <param name="output_types">
               Optional argument
               List of TF types to use for the respective field in field_names.
            </param>
            <param name="descriptor_source">
               Either the special value <c>local://</c> or a path to a file containing
               a serialized <c>FileDescriptorSet</c>.
            </param>
            <param name="message_format">
               Either <c>binary</c> or <c>text</c>.
            </param>
            <param name="sanitize">
               Whether to sanitize the result or not.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               sizes : Tensor of int32 with shape <c>[batch_shape, len(field_names)]</c>.
               Each entry is the number of values found for the corresponding field.
               Optional fields may have 0 or 1 values.
               values : List of tensors containing values for the corresponding field.
               <c>values[i]</c> has datatype <c>output_types[i]</c>
               and shape <c>[batch_shape, max(sizes[...,i])]</c>.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               The <c>decode_proto</c> op extracts fields from a serialized protocol buffers
               message into tensors.  The fields in <c>field_names</c> are decoded and converted
               to the corresponding <c>output_types</c> if possible.
               
               A <c>message_type</c> name must be provided to give context for the field
               names. The actual message descriptor can be looked up either in the
               linked-in descriptor pool or a filename provided by the caller using
               the <c>descriptor_source</c> attribute.
               
               Each output tensor is a dense tensor. This means that it is padded to
               hold the largest number of repeated elements seen in the input
               minibatch. (The shape is also padded by one to prevent zero-sized
               dimensions). The actual repeat counts for each example in the
               minibatch can be found in the <c>sizes</c> output. In many cases the output
               of <c>decode_proto</c> is fed immediately into tf.squeeze if missing values
               are not a concern. When using tf.squeeze, always pass the squeeze
               dimension explicitly to avoid surprises.
               
               For the most part, the mapping between Proto field types and
               TensorFlow dtypes is straightforward. However, there are a few
               special cases:
               
               - A proto field that contains a submessage or group can only be converted
               to <c>DT_STRING</c> (the serialized submessage). This is to reduce the
               complexity of the API. The resulting string can be used as input
               to another instance of the decode_proto op.
               
               - TensorFlow lacks support for unsigned integers. The ops represent uint64
               types as a <c>DT_INT64</c> with the same twos-complement bit pattern
               (the obvious way). Unsigned int32 values can be represented exactly by
               specifying type <c>DT_INT64</c>, or using twos-complement if the caller
               specifies <c>DT_INT32</c> in the <c>output_types</c> attribute.
               
               The <c>descriptor_source</c> attribute selects a source of protocol
               descriptors to consult when looking up <c>message_type</c>. This may be a
               filename containing a serialized <c>FileDescriptorSet</c> message,
               or the special value <c>local://</c>, in which case only descriptors linked
               into the code will be searched; the filename can be on any filesystem
               accessible to TensorFlow.
               
               You can build a <c>descriptor_source</c> file using the <c>--descriptor_set_out</c>
               and <c>--include_imports</c> options to the protocol compiler <c>protoc</c>.
               
               The <c>local://</c> database only covers descriptors linked into the
               code via C++ libraries, not Python imports. You can link in a proto descriptor
               by creating a cc_library target with alwayslink=1.
               
               Both binary and text proto serializations are supported, and can be
               chosen using the <c>format</c> attribute.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.decode_raw(Tensorflow.Tensor,Tensorflow.TF_DataType,System.Nullable{System.Boolean},System.String)">
            <summary>
               Reinterpret the bytes of a string as a vector of numbers.
            </summary>
            <param name="bytes">
               All the elements must have the same length.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DecodeRaw'.
            </param>
            <param name="out_type">
               Optional argument
            </param>
            <param name="little_endian">
               Whether the input <c>bytes</c> are in little-endian order.
               Ignored for <c>out_type</c> values that are stored in a single byte like
               <c>uint8</c>.
            </param>
            <returns>
               A Tensor with one more dimension than the input <c>bytes</c>.  The
               added dimension will have size equal to the length of the elements
               of <c>bytes</c> divided by the number of bytes to represent <c>out_type</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.decode_wav(Tensorflow.Tensor,System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Decode a 16-bit PCM WAV file to a float tensor.
            </summary>
            <param name="contents">
               The WAV-encoded audio, usually from a file.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DecodeWav'.
            </param>
            <param name="desired_channels">
               Number of sample channels wanted.
            </param>
            <param name="desired_samples">
               Length of audio requested.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               audio : 2-D with shape <c>[length, channels]</c>.
               sample_rate : Scalar holding the sample rate found in the WAV header.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               The -32768 to 32767 signed 16-bit values will be scaled to -1.0 to 1.0 in float.
               
               When desired_channels is set, if the input contains fewer channels than this
               then the last channel will be duplicated to give the requested number, else if
               the input has more channels than requested then the additional channels will be
               ignored.
               
               If desired_samples is set, then the audio will be cropped or padded with zeroes
               to the requested length.
               
               The first output contains a Tensor with the content of the audio samples. The
               lowest dimension will be the number of channels, and the second will be the
               number of samples. For example, a ten-sample-long stereo WAV file should give an
               output shape of [10, 2].
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.deep_copy(Tensorflow.Tensor,System.String)">
            <summary>
               Makes a copy of <c>x</c>.
            </summary>
            <param name="x">
               The source tensor of type <c>T</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DeepCopy'.
            </param>
            <returns>
               y: A <c>Tensor</c> of type <c>T</c>. A copy of <c>x</c>. Guaranteed that <c>y</c>
               is not an alias of <c>x</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.delete_session_tensor(Tensorflow.Tensor,System.String)">
            <summary>
               Delete the tensor specified by its handle in the session.
            </summary>
            <param name="handle">
               The handle for a tensor stored in the session state.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DeleteSessionTensor'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.dense_to_dense_set_operation(Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.Nullable{System.Boolean},System.String)">
            <summary>
               Applies set operation along last dimension of 2 <c>Tensor</c> inputs.
            </summary>
            <param name="set1">
               <c>Tensor</c> with rank <c>n</c>. 1st <c>n-1</c> dimensions must be the same as <c>set2</c>.
               Dimension <c>n</c> contains values in a set, duplicates are allowed but ignored.
            </param>
            <param name="set2">
               <c>Tensor</c> with rank <c>n</c>. 1st <c>n-1</c> dimensions must be the same as <c>set1</c>.
               Dimension <c>n</c> contains values in a set, duplicates are allowed but ignored.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DenseToDenseSetOperation'.
            </param>
            <param name="set_operation">
               Optional argument
            </param>
            <param name="validate_indices">
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               result_indices : 2D indices of a <c>SparseTensor</c>.
               result_values : 1D values of a <c>SparseTensor</c>.
               result_shape : 1D <c>Tensor</c> shape of a <c>SparseTensor</c>. <c>result_shape[0...n-1]</c> is
               the same as the 1st <c>n-1</c> dimensions of <c>set1</c> and <c>set2</c>, <c>result_shape[n]</c>
               is the max result set size across all <c>0...n-1</c> dimensions.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               See SetOperationOp::SetOperationFromContext for values of <c>set_operation</c>.
               
               Output <c>result</c> is a <c>SparseTensor</c> represented by <c>result_indices</c>,
               <c>result_values</c>, and <c>result_shape</c>. For <c>set1</c> and <c>set2</c> ranked <c>n</c>, this
               has rank <c>n</c> and the same 1st <c>n-1</c> dimensions as <c>set1</c> and <c>set2</c>. The <c>nth</c>
               dimension contains the result of <c>set_operation</c> applied to the corresponding
               <c>[0...n-1]</c> dimension of <c>set</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.dense_to_sparse_batch_dataset(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Creates a dataset that batches input elements into a SparseTensor.
            </summary>
            <param name="input_dataset">
               A handle to an input dataset. Must have a single component.
            </param>
            <param name="batch_size">
               A scalar representing the number of elements to accumulate in a
               batch.
            </param>
            <param name="row_shape">
               A vector representing the dense shape of each row in the produced
               SparseTensor. The shape may be partially specified, using <c>-1</c> to indicate
               that a particular dimension should use the maximum size of all batch elements.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DenseToSparseBatchDataset'.
            </param>
            <param name="output_types">
               Optional argument
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.dense_to_sparse_set_operation(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.Nullable{System.Boolean},System.String)">
            <summary>
               Applies set operation along last dimension of <c>Tensor</c> and <c>SparseTensor</c>.
            </summary>
            <param name="set1">
               <c>Tensor</c> with rank <c>n</c>. 1st <c>n-1</c> dimensions must be the same as <c>set2</c>.
               Dimension <c>n</c> contains values in a set, duplicates are allowed but ignored.
            </param>
            <param name="set2_indices">
               2D <c>Tensor</c>, indices of a <c>SparseTensor</c>. Must be in row-major
               order.
            </param>
            <param name="set2_values">
               1D <c>Tensor</c>, values of a <c>SparseTensor</c>. Must be in row-major
               order.
            </param>
            <param name="set2_shape">
               1D <c>Tensor</c>, shape of a <c>SparseTensor</c>. <c>set2_shape[0...n-1]</c> must
               be the same as the 1st <c>n-1</c> dimensions of <c>set1</c>, <c>result_shape[n]</c> is the
               max set size across <c>n-1</c> dimensions.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DenseToSparseSetOperation'.
            </param>
            <param name="set_operation">
               Optional argument
            </param>
            <param name="validate_indices">
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               result_indices : 2D indices of a <c>SparseTensor</c>.
               result_values : 1D values of a <c>SparseTensor</c>.
               result_shape : 1D <c>Tensor</c> shape of a <c>SparseTensor</c>. <c>result_shape[0...n-1]</c> is
               the same as the 1st <c>n-1</c> dimensions of <c>set1</c> and <c>set2</c>, <c>result_shape[n]</c>
               is the max result set size across all <c>0...n-1</c> dimensions.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               See SetOperationOp::SetOperationFromContext for values of <c>set_operation</c>.
               
               Input <c>set2</c> is a <c>SparseTensor</c> represented by <c>set2_indices</c>, <c>set2_values</c>,
               and <c>set2_shape</c>. For <c>set2</c> ranked <c>n</c>, 1st <c>n-1</c> dimensions must be the same
               as <c>set1</c>. Dimension <c>n</c> contains values in a set, duplicates are allowed but
               ignored.
               
               If <c>validate_indices</c> is <c>True</c>, this op validates the order and range of <c>set2</c>
               indices.
               
               Output <c>result</c> is a <c>SparseTensor</c> represented by <c>result_indices</c>,
               <c>result_values</c>, and <c>result_shape</c>. For <c>set1</c> and <c>set2</c> ranked <c>n</c>, this
               has rank <c>n</c> and the same 1st <c>n-1</c> dimensions as <c>set1</c> and <c>set2</c>. The <c>nth</c>
               dimension contains the result of <c>set_operation</c> applied to the corresponding
               <c>[0...n-1]</c> dimension of <c>set</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.depth_to_space(Tensorflow.Tensor,System.Int32,System.String,System.String)">
            <summary>
               DepthToSpace for tensors of type T.
            </summary>
            <param name="input">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DepthToSpace'.
            </param>
            <param name="block_size">
               Optional argument
               The size of the spatial block, same as in Space2Depth.
            </param>
            <param name="data_format">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Rearranges data from depth into blocks of spatial data.
               This is the reverse transformation of SpaceToDepth. More specifically,
               this op outputs a copy of the input tensor where values from the <c>depth</c>
               dimension are moved in spatial blocks to the <c>height</c> and <c>width</c> dimensions.
               The attr <c>block_size</c> indicates the input block size and how the data is moved.
               
               * Chunks of data of size <c>block_size * block_size</c> from depth are rearranged
               into non-overlapping blocks of size <c>block_size x block_size</c>
               * The width the output tensor is <c>input_depth * block_size</c>, whereas the
               height is <c>input_height * block_size</c>.
               * The Y, X coordinates within each block of the output image are determined
               by the high order component of the input channel index.
               * The depth of the input tensor must be divisible by
               <c>block_size * block_size</c>.
               
               The <c>data_format</c> attr specifies the layout of the input and output tensors
               with the following options:
               "NHWC": <c>[ batch, height, width, channels ]</c>
               "NCHW": <c>[ batch, channels, height, width ]</c>
               "NCHW_VECT_C":
               <c>qint8 [ batch, channels / 4, height, width, 4 ]</c>
               
               It is useful to consider the operation as transforming a 6-D Tensor.
               e.g. for data_format = NHWC,
               Each element in the input tensor can be specified via 6 coordinates,
               ordered by decreasing memory layout significance as:
               n,iY,iX,bY,bX,oC  (where n=batch index, iX, iY means X or Y coordinates
               within the input image, bX, bY means coordinates
               within the output block, oC means output channels).
               The output would be the input transposed to the following layout:
               n,iY,bY,iX,bX,oC
               
               This operation is useful for resizing the activations between convolutions
               (but keeping all data), e.g. instead of pooling. It is also useful for training
               purely convolutional models.
               
               For example, given an input of shape <c>[1, 1, 1, 4]</c>, data_format = "NHWC" and
               block_size = 2:
               
              <code>
               x = [[[[1, 2, 3, 4]]]]
               
              </code>
               
               This operation will output a tensor of shape <c>[1, 2, 2, 1]</c>:
               
              <code>
               [[[[1], [2]],
               [[3], [4]]]]
              </code>
               
               Here, the input has a batch of 1 and each batch element has shape <c>[1, 1, 4]</c>,
               the corresponding output will have 2x2 elements and will have a depth of
               1 channel (1 = <c>4 / (block_size * block_size)</c>).
               The output element shape is <c>[2, 2, 1]</c>.
               
               For an input tensor with larger depth, here of shape <c>[1, 1, 1, 12]</c>, e.g.
               
              <code>
               x = [[[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]]]
              </code>
               
               This operation, for block size of 2, will return the following tensor of shape
               <c>[1, 2, 2, 3]</c>
               
              <code>
               [[[[1, 2, 3], [4, 5, 6]],
               [[7, 8, 9], [10, 11, 12]]]]
               
              </code>
               
               Similarly, for the following input of shape <c>[1 2 2 4]</c>, and a block size of 2:
               
              <code>
               x =  [[[[1, 2, 3, 4],
               [5, 6, 7, 8]],
               [[9, 10, 11, 12],
               [13, 14, 15, 16]]]]
              </code>
               
               the operator will return the following tensor of shape <c>[1 4 4 1]</c>:
               
              <code>
               x = [[[ [1],   [2],  [5],  [6]],
               [ [3],   [4],  [7],  [8]],
               [ [9],  [10], [13],  [14]],
               [ [11], [12], [15],  [16]]]]
               
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.depthwise_conv2d_native(Tensorflow.Tensor,Tensorflow.Tensor,System.Int32[],System.String,System.String,System.Int32[],System.String)">
            <summary>
               Computes a 2-D depthwise convolution given 4-D <c>input</c> and <c>filter</c> tensors.
            </summary>
            <param name="input">
            </param>
            <param name="filter">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DepthwiseConv2dNative'.
            </param>
            <param name="strides">
               Optional argument
               1-D of length 4.  The stride of the sliding window for each dimension
               of <c>input</c>.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <param name="data_format">
               Specify the data format of the input and output data. With the
               default format "NHWC", the data is stored in the order of:
               [batch, height, width, channels].
               Alternatively, the format could be "NCHW", the data storage order of:
               [batch, channels, height, width].
            </param>
            <param name="dilations">
               1-D tensor of length 4.  The dilation factor for each dimension of
               <c>input</c>. If set to k &amp;gt; 1, there will be k-1 skipped cells between each filter
               element on that dimension. The dimension order is determined by the value of
               <c>data_format</c>, see above for details. Dilations in the batch and depth
               dimensions must be 1.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Given an input tensor of shape <c>[batch, in_height, in_width, in_channels]</c>
               and a filter / kernel tensor of shape
               <c>[filter_height, filter_width, in_channels, channel_multiplier]</c>, containing
               <c>in_channels</c> convolutional filters of depth 1, <c>depthwise_conv2d</c> applies
               a different filter to each input channel (expanding from 1 channel to
               <c>channel_multiplier</c> channels for each), then concatenates the results
               together. Thus, the output has <c>in_channels * channel_multiplier</c> channels.
               
              <code>
               for k in 0..in_channels-1
               for q in 0..channel_multiplier-1
               output[b, i, j, k * channel_multiplier + q] =
               sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
               filter[di, dj, k, q]
              </code>
               
               Must have <c>strides[0] = strides[3] = 1</c>.  For the most common case of the same
               horizontal and vertices strides, <c>strides = [1, stride, stride, 1]</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.depthwise_conv2d_native_backprop_filter(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32[],System.String,System.String,System.Int32[],System.String)">
            <summary>
               Computes the gradients of depthwise convolution with respect to the filter.
            </summary>
            <param name="input">
               4-D with shape based on <c>data_format</c>.  For example, if
               <c>data_format</c> is 'NHWC' then <c>input</c> is a 4-D <c>[batch, in_height,
               in_width, in_channels]</c> tensor.
            </param>
            <param name="filter_sizes">
               An integer vector representing the tensor shape of <c>filter</c>,
               where <c>filter</c> is a 4-D
               <c>[filter_height, filter_width, in_channels, depthwise_multiplier]</c> tensor.
            </param>
            <param name="out_backprop">
               4-D with shape  based on <c>data_format</c>.
               For example, if <c>data_format</c> is 'NHWC' then
               out_backprop shape is <c>[batch, out_height, out_width, out_channels]</c>.
               Gradients w.r.t. the output of the convolution.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DepthwiseConv2dNativeBackpropFilter'.
            </param>
            <param name="strides">
               Optional argument
               The stride of the sliding window for each dimension of the input
               of the convolution.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <param name="data_format">
               Specify the data format of the input and output data. With the
               default format "NHWC", the data is stored in the order of:
               [batch, height, width, channels].
               Alternatively, the format could be "NCHW", the data storage order of:
               [batch, channels, height, width].
            </param>
            <param name="dilations">
               1-D tensor of length 4.  The dilation factor for each dimension of
               <c>input</c>. If set to k &amp;gt; 1, there will be k-1 skipped cells between each filter
               element on that dimension. The dimension order is determined by the value of
               <c>data_format</c>, see above for details. Dilations in the batch and depth
               dimensions must be 1.
            </param>
            <returns>
               4-D with shape
               <c>[filter_height, filter_width, in_channels, out_channels]</c>.  Gradient w.r.t.
               the <c>filter</c> input of the convolution.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.depthwise_conv2d_native_backprop_input(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32[],System.String,System.String,System.Int32[],System.String)">
            <summary>
               Computes the gradients of depthwise convolution with respect to the input.
            </summary>
            <param name="input_sizes">
               An integer vector representing the shape of <c>input</c>, based
               on <c>data_format</c>.  For example, if <c>data_format</c> is 'NHWC' then
               <c>input</c> is a 4-D <c>[batch, height, width, channels]</c> tensor.
            </param>
            <param name="filter">
               4-D with shape
               <c>[filter_height, filter_width, in_channels, depthwise_multiplier]</c>.
            </param>
            <param name="out_backprop">
               4-D with shape  based on <c>data_format</c>.
               For example, if <c>data_format</c> is 'NHWC' then
               out_backprop shape is <c>[batch, out_height, out_width, out_channels]</c>.
               Gradients w.r.t. the output of the convolution.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DepthwiseConv2dNativeBackpropInput'.
            </param>
            <param name="strides">
               Optional argument
               The stride of the sliding window for each dimension of the input
               of the convolution.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <param name="data_format">
               Specify the data format of the input and output data. With the
               default format "NHWC", the data is stored in the order of:
               [batch, height, width, channels].
               Alternatively, the format could be "NCHW", the data storage order of:
               [batch, channels, height, width].
            </param>
            <param name="dilations">
               1-D tensor of length 4.  The dilation factor for each dimension of
               <c>input</c>. If set to k &amp;gt; 1, there will be k-1 skipped cells between each filter
               element on that dimension. The dimension order is determined by the value of
               <c>data_format</c>, see above for details. Dilations in the batch and depth
               dimensions must be 1.
            </param>
            <returns>
               4-D with shape according to <c>data_format</c>.  For example, if
               <c>data_format</c> is 'NHWC', output shape is <c>[batch, in_height,
               in_width, in_channels]</c>.  Gradient w.r.t. the input of the
               convolution.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.dequantize(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.String)">
            <summary>
               Dequantize the 'input' tensor into a float Tensor.
            </summary>
            <param name="input">
            </param>
            <param name="min_range">
               The minimum scalar value possibly produced for the input.
            </param>
            <param name="max_range">
               The maximum scalar value possibly produced for the input.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Dequantize'.
            </param>
            <param name="mode">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               [min_range, max_range] are scalar floats that specify the range for
               the 'input' data. The 'mode' attribute controls exactly which calculations are
               used to convert the float values to their quantized equivalents.
               
               In 'MIN_COMBINED' mode, each value of the tensor will undergo the following:
               
              <code>
               if T == qint8, in[i] += (range(T) + 1)/ 2.0
               out[i] = min_range + (in[i]* (max_range - min_range) / range(T))
              </code>
               here <c>range(T) = numeric_limits&amp;lt;T&amp;gt;::max() - numeric_limits&amp;lt;T&amp;gt;::min()</c>
               
               *MIN_COMBINED Mode Example*
               
               If the input comes from a QuantizedRelu6, the output type is
               quint8 (range of 0-255) but the possible range of QuantizedRelu6 is
               0-6.  The min_range and max_range values are therefore 0.0 and 6.0.
               Dequantize on quint8 will take each value, cast to float, and multiply
               by 6 / 255.
               Note that if quantizedtype is qint8, the operation will additionally add
               each value by 128 prior to casting.
               
               If the mode is 'MIN_FIRST', then this approach is used:
               
              <code>
               num_discrete_values = 1 &amp;lt;&amp;lt; (# of bits in T)
               range_adjust = num_discrete_values / (num_discrete_values - 1)
               range = (range_max - range_min) * range_adjust
               range_scale = range / num_discrete_values
               const double offset_input = static_cast&amp;lt;double&amp;gt;(input) - lowest_quantized;
               result = range_min + ((input - numeric_limits&amp;lt;T&amp;gt;::min()) * range_scale)
              </code>
               
               *SCALED mode Example*
               
               <c>SCALED</c> mode matches the quantization approach used in
               <c>QuantizeAndDequantize{V2|V3}</c>.
               
               If the mode is <c>SCALED</c>, we do not use the full range of the output type,
               choosing to elide the lowest possible value for symmetry (e.g., output range is
               -127 to 127, not -128 to 127 for signed 8 bit quantization), so that 0.0 maps to
               0.
               
               We first find the range of values in our tensor. The
               range we use is always centered on 0, so we find m such that
              <code>
               m = max(abs(input_min), abs(input_max))
              </code>
               
               Our input tensor range is then <c>[-m, m]</c>.
               
               Next, we choose our fixed-point quantization buckets, <c>[min_fixed, max_fixed]</c>.
               If T is signed, this is
              <code>
               num_bits = sizeof(T) * 8
               [min_fixed, max_fixed] =
               [-(1 &amp;lt;&amp;lt; (num_bits - 1) - 1), (1 &amp;lt;&amp;lt; (num_bits - 1)) - 1]
              </code>
               
               Otherwise, if T is unsigned, the fixed-point range is
              <code>
               [min_fixed, max_fixed] = [0, (1 &amp;lt;&amp;lt; num_bits) - 1]
              </code>
               
               From this we compute our scaling factor, s:
              <code>
               s = (2 * m) / (max_fixed - min_fixed)
              </code>
               
               Now we can dequantize the elements of our tensor:
              <code>
               result = input * s
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.deserialize_iterator(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Converts the given variant tensor to an iterator and stores it in the given resource.
            </summary>
            <param name="resource_handle">
               A handle to an iterator resource.
            </param>
            <param name="serialized">
               A variant tensor storing the state of the iterator contained in the
               resource.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DeserializeIterator'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.deserialize_many_sparse(Tensorflow.Tensor,Tensorflow.TF_DataType,System.String)">
            <summary>
               Deserialize and concatenate <c>SparseTensors</c> from a serialized minibatch.
            </summary>
            <param name="serialized_sparse">
               2-D, The <c>N</c> serialized <c>SparseTensor</c> objects.
               Must have 3 columns.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DeserializeManySparse'.
            </param>
            <param name="dtype">
               Optional argument
               The <c>dtype</c> of the serialized <c>SparseTensor</c> objects.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               sparse_indices :
               sparse_values :
               sparse_shape :
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               The input <c>serialized_sparse</c> must be a string matrix of shape <c>[N x 3]</c> where
               <c>N</c> is the minibatch size and the rows correspond to packed outputs of
               <c>SerializeSparse</c>.  The ranks of the original <c>SparseTensor</c> objects
               must all match.  When the final <c>SparseTensor</c> is created, it has rank one
               higher than the ranks of the incoming <c>SparseTensor</c> objects
               (they have been concatenated along a new row dimension).
               
               The output <c>SparseTensor</c> object's shape values for all dimensions but the
               first are the max across the input <c>SparseTensor</c> objects' shape values
               for the corresponding dimensions.  Its first shape value is <c>N</c>, the minibatch
               size.
               
               The input <c>SparseTensor</c> objects' indices are assumed ordered in
               standard lexicographic order.  If this is not the case, after this
               step run <c>SparseReorder</c> to restore index ordering.
               
               For example, if the serialized input is a <c>[2 x 3]</c> matrix representing two
               original <c>SparseTensor</c> objects:
               
               index = [ 0]
               [10]
               [20]
               values = [1, 2, 3]
               shape = [50]
               
               and
               
               index = [ 2]
               [10]
               values = [4, 5]
               shape = [30]
               
               then the final deserialized <c>SparseTensor</c> will be:
               
               index = [0  0]
               [0 10]
               [0 20]
               [1  2]
               [1 10]
               values = [1, 2, 3, 4, 5]
               shape = [2 50]
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.deserialize_sparse(Tensorflow.Tensor,Tensorflow.TF_DataType,System.String)">
            <summary>
               Deserialize <c>SparseTensor</c> objects.
            </summary>
            <param name="serialized_sparse">
               The serialized <c>SparseTensor</c> objects. The last dimension
               must have 3 columns.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DeserializeSparse'.
            </param>
            <param name="dtype">
               Optional argument
               The <c>dtype</c> of the serialized <c>SparseTensor</c> objects.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               sparse_indices :
               sparse_values :
               sparse_shape :
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               The input <c>serialized_sparse</c> must have the shape <c>[?, ?, ..., ?, 3]</c> where
               the last dimension stores serialized <c>SparseTensor</c> objects and the other N
               dimensions (N &amp;gt;= 0) correspond to a batch. The ranks of the original
               <c>SparseTensor</c> objects must all match. When the final <c>SparseTensor</c> is
               created, its rank is the rank of the incoming <c>SparseTensor</c> objects plus N;
               the sparse tensors have been concatenated along new dimensions, one for each
               batch.
               
               The output <c>SparseTensor</c> object's shape values for the original dimensions
               are the max across the input <c>SparseTensor</c> objects' shape values for the
               corresponding dimensions. The new dimensions match the size of the batch.
               
               The input <c>SparseTensor</c> objects' indices are assumed ordered in
               standard lexicographic order.  If this is not the case, after this
               step run <c>SparseReorder</c> to restore index ordering.
               
               For example, if the serialized input is a <c>[2 x 3]</c> matrix representing two
               original <c>SparseTensor</c> objects:
               
               index = [ 0]
               [10]
               [20]
               values = [1, 2, 3]
               shape = [50]
               
               and
               
               index = [ 2]
               [10]
               values = [4, 5]
               shape = [30]
               
               then the final deserialized <c>SparseTensor</c> will be:
               
               index = [0  0]
               [0 10]
               [0 20]
               [1  2]
               [1 10]
               values = [1, 2, 3, 4, 5]
               shape = [2 50]
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.destroy_resource_op(Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Deletes the resource specified by the handle.
            </summary>
            <param name="resource">
               handle to the resource to delete.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DestroyResourceOp'.
            </param>
            <param name="ignore_lookup_error">
               whether to ignore the error when the resource
               doesn't exist.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               All subsequent operations using the resource will result in a NotFound
               error status.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.destroy_temporary_variable(Tensorflow.Tensor,System.String,System.String)">
            <summary>
               Destroys the temporary variable and returns its final value.
            </summary>
            <param name="referecne">
               A reference to the temporary variable tensor.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DestroyTemporaryVariable'.
            </param>
            <param name="var_name">
               Optional argument
               Name of the temporary variable, usually the name of the matching
               'TemporaryVariable' op.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Sets output to the value of the Tensor pointed to by 'ref', then destroys
               the temporary variable called 'var_name'.
               All other uses of 'ref' *must* have executed before this op.
               This is typically achieved by chaining the ref through each assign op, or by
               using control dependencies.
               
               Outputs the final value of the tensor pointed to by 'ref'.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.diag(Tensorflow.Tensor,System.String)">
            <summary>
               Returns a diagonal tensor with a given diagonal values.
            </summary>
            <param name="diagonal">
               Rank k tensor where k is at most 1.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Diag'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Given a <c>diagonal</c>, this operation returns a tensor with the <c>diagonal</c> and
               everything else padded with zeros. The diagonal is computed as follows:
               
               Assume <c>diagonal</c> has dimensions [D1,..., Dk], then the output is a tensor of
               rank 2k with dimensions [D1,..., Dk, D1,..., Dk] where:
               
               <c>output[i1,..., ik, i1,..., ik] = diagonal[i1, ..., ik]</c> and 0 everywhere else.
               
               For example:
               
              <code>
               # 'diagonal' is [1, 2, 3, 4]
               tf.diag(diagonal) ==&amp;gt; [[1, 0, 0, 0]
               [0, 2, 0, 0]
               [0, 0, 3, 0]
               [0, 0, 0, 4]]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.diag_part(Tensorflow.Tensor,System.String)">
            <summary>
               Returns the diagonal part of the tensor.
            </summary>
            <param name="input">
               Rank k tensor where k is even and not zero.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DiagPart'.
            </param>
            <returns>
               The extracted diagonal.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation returns a tensor with the <c>diagonal</c> part
               of the <c>input</c>. The <c>diagonal</c> part is computed as follows:
               
               Assume <c>input</c> has dimensions <c>[D1,..., Dk, D1,..., Dk]</c>, then the output is a
               tensor of rank <c>k</c> with dimensions <c>[D1,..., Dk]</c> where:
               
               <c>diagonal[i1,..., ik] = input[i1, ..., ik, i1,..., ik]</c>.
               
               For example:
               
              <code>
               # 'input' is [[1, 0, 0, 0]
               [0, 2, 0, 0]
               [0, 0, 3, 0]
               [0, 0, 0, 4]]
               
               tf.diag_part(input) ==&amp;gt; [1, 2, 3, 4]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.digamma(Tensorflow.Tensor,System.String)">
            <summary>
               Computes Psi, the derivative of Lgamma (the log of the absolute value of
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Digamma'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               <c>Gamma(x)</c>), element-wise.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.dilation2d(Tensorflow.Tensor,Tensorflow.Tensor,System.Int32[],System.Int32[],System.String,System.String)">
            <summary>
               Computes the grayscale dilation of 4-D <c>input</c> and 3-D <c>filter</c> tensors.
            </summary>
            <param name="input">
               4-D with shape <c>[batch, in_height, in_width, depth]</c>.
            </param>
            <param name="filter">
               3-D with shape <c>[filter_height, filter_width, depth]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Dilation2D'.
            </param>
            <param name="strides">
               Optional argument
               The stride of the sliding window for each dimension of the input
               tensor. Must be: <c>[1, stride_height, stride_width, 1]</c>.
            </param>
            <param name="rates">
               Optional argument
               The input stride for atrous morphological dilation. Must be:
               <c>[1, rate_height, rate_width, 1]</c>.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <returns>
               4-D with shape <c>[batch, out_height, out_width, depth]</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The <c>input</c> tensor has shape <c>[batch, in_height, in_width, depth]</c> and the
               <c>filter</c> tensor has shape <c>[filter_height, filter_width, depth]</c>, i.e., each
               input channel is processed independently of the others with its own structuring
               function. The <c>output</c> tensor has shape
               <c>[batch, out_height, out_width, depth]</c>. The spatial dimensions of the output
               tensor depend on the <c>padding</c> algorithm. We currently only support the default
               "NHWC" <c>data_format</c>.
               
               In detail, the grayscale morphological 2-D dilation is the max-sum correlation
               (for consistency with <c>conv2d</c>, we use unmirrored filters):
               
               output[b, y, x, c] =
               max_{dy, dx} input[b,
               strides[1] * y + rates[1] * dy,
               strides[2] * x + rates[2] * dx,
               c] +
               filter[dy, dx, c]
               
               Max-pooling is a special case when the filter has size equal to the pooling
               kernel size and contains all zeros.
               
               Note on duality: The dilation of <c>input</c> by the <c>filter</c> is equal to the
               negation of the erosion of <c>-input</c> by the reflected <c>filter</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.dilation2d_backprop_filter(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32[],System.Int32[],System.String,System.String)">
            <summary>
               Computes the gradient of morphological 2-D dilation with respect to the filter.
            </summary>
            <param name="input">
               4-D with shape <c>[batch, in_height, in_width, depth]</c>.
            </param>
            <param name="filter">
               3-D with shape <c>[filter_height, filter_width, depth]</c>.
            </param>
            <param name="out_backprop">
               4-D with shape <c>[batch, out_height, out_width, depth]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Dilation2DBackpropFilter'.
            </param>
            <param name="strides">
               Optional argument
               1-D of length 4. The stride of the sliding window for each dimension of
               the input tensor. Must be: <c>[1, stride_height, stride_width, 1]</c>.
            </param>
            <param name="rates">
               Optional argument
               1-D of length 4. The input stride for atrous morphological dilation.
               Must be: <c>[1, rate_height, rate_width, 1]</c>.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <returns>
               3-D with shape <c>[filter_height, filter_width, depth]</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.dilation2d_backprop_input(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32[],System.Int32[],System.String,System.String)">
            <summary>
               Computes the gradient of morphological 2-D dilation with respect to the input.
            </summary>
            <param name="input">
               4-D with shape <c>[batch, in_height, in_width, depth]</c>.
            </param>
            <param name="filter">
               3-D with shape <c>[filter_height, filter_width, depth]</c>.
            </param>
            <param name="out_backprop">
               4-D with shape <c>[batch, out_height, out_width, depth]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Dilation2DBackpropInput'.
            </param>
            <param name="strides">
               Optional argument
               1-D of length 4. The stride of the sliding window for each dimension of
               the input tensor. Must be: <c>[1, stride_height, stride_width, 1]</c>.
            </param>
            <param name="rates">
               Optional argument
               1-D of length 4. The input stride for atrous morphological dilation.
               Must be: <c>[1, rate_height, rate_width, 1]</c>.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <returns>
               4-D with shape <c>[batch, in_height, in_width, depth]</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.div(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns x / y element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Div'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               *NOTE*: <c>Div</c> supports broadcasting. More about broadcasting
               [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.div_no_nan(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns 0 if the denominator is zero.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DivNoNan'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               
               *NOTE*: <c>DivNoNan</c> supports broadcasting. More about broadcasting
               [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.draw_bounding_boxes(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Draw bounding boxes on a batch of images.
            </summary>
            <param name="images">
               4-D with shape <c>[batch, height, width, depth]</c>. A batch of images.
            </param>
            <param name="boxes">
               3-D with shape <c>[batch, num_bounding_boxes, 4]</c> containing bounding
               boxes.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DrawBoundingBoxes'.
            </param>
            <returns>
               4-D with the same shape as <c>images</c>. The batch of input images with
               bounding boxes drawn on the images.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Outputs a copy of <c>images</c> but draws on top of the pixels zero or more bounding
               boxes specified by the locations in <c>boxes</c>. The coordinates of the each
               bounding box in <c>boxes</c> are encoded as <c>[y_min, x_min, y_max, x_max]</c>. The
               bounding box coordinates are floats in <c>[0.0, 1.0]</c> relative to the width and
               height of the underlying image.
               
               For example, if an image is 100 x 200 pixels (height x width) and the bounding
               box is <c>[0.1, 0.2, 0.5, 0.9]</c>, the upper-left and bottom-right coordinates of
               the bounding box will be <c>(40, 10)</c> to <c>(180, 50)</c> (in (x,y) coordinates).
               
               Parts of the bounding box may fall outside the image.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.dynamic_partition(Tensorflow.Tensor,Tensorflow.Tensor,System.Int32,System.String)">
            <summary>
               Partitions <c>data</c> into <c>num_partitions</c> tensors using indices from <c>partitions</c>.
            </summary>
            <param name="data">
            </param>
            <param name="partitions">
               Any shape.  Indices in the range <c>[0, num_partitions)</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DynamicPartition'.
            </param>
            <param name="num_partitions">
               Optional argument
               The number of partitions to output.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               For each index tuple <c>js</c> of size <c>partitions.ndim</c>, the slice <c>data[js, ...]</c>
               becomes part of <c>outputs[partitions[js]]</c>.  The slices with <c>partitions[js] = i</c>
               are placed in <c>outputs[i]</c> in lexicographic order of <c>js</c>, and the first
               dimension of <c>outputs[i]</c> is the number of entries in <c>partitions</c> equal to <c>i</c>.
               In detail,
               
              <code>
               outputs[i].shape = [sum(partitions == i)] + data.shape[partitions.ndim:]
               
               outputs[i] = pack([data[js, ...] for js if partitions[js] == i])
              </code>
               
               <c>data.shape</c> must start with <c>partitions.shape</c>.
               
               For example:
               
              <code>
               # Scalar partitions.
               partitions = 1
               num_partitions = 2
               data = [10, 20]
               outputs[0] = []  # Empty with shape [0, 2]
               outputs[1] = [[10, 20]]
               
               # Vector partitions.
               partitions = [0, 0, 1, 1, 0]
               num_partitions = 2
               data = [10, 20, 30, 40, 50]
               outputs[0] = [10, 20, 50]
               outputs[1] = [30, 40]
              </code>
               
               See <c>dynamic_stitch</c> for an example on how to merge partitions back.
               
               &amp;lt;div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;"&amp;gt;
               &amp;lt;img style="width:100%" src="https://www.tensorflow.org/images/DynamicPartition.png" alt&amp;gt;
               &amp;lt;/div&amp;gt;
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.dynamic_stitch(Tensorflow.Tensor[],Tensorflow.Tensor[],System.String)">
            <summary>
               Interleave the values from the <c>data</c> tensors into a single tensor.
            </summary>
            <param name="indices">
            </param>
            <param name="data">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DynamicStitch'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Builds a merged tensor such that
               
              <code>
               merged[indices[m][i, ..., j], ...] = data[m][i, ..., j, ...]
              </code>
               
               For example, if each <c>indices[m]</c> is scalar or vector, we have
               
              <code>
               # Scalar indices:
               merged[indices[m], ...] = data[m][...]
               
               # Vector indices:
               merged[indices[m][i], ...] = data[m][i, ...]
              </code>
               
               Each <c>data[i].shape</c> must start with the corresponding <c>indices[i].shape</c>,
               and the rest of <c>data[i].shape</c> must be constant w.r.t. <c>i</c>.  That is, we
               must have <c>data[i].shape = indices[i].shape + constant</c>.  In terms of this
               <c>constant</c>, the output shape is
               
               merged.shape = [max(indices)] + constant
               
               Values are merged in order, so if an index appears in both <c>indices[m][i]</c> and
               <c>indices[n][j]</c> for <c>(m,i) &amp;lt; (n,j)</c> the slice <c>data[n][j]</c> will appear in the
               merged result. If you do not need this guarantee, ParallelDynamicStitch might
               perform better on some devices.
               
               For example:
               
              <code>
               indices[0] = 6
               indices[1] = [4, 1]
               indices[2] = [[5, 2], [0, 3]]
               data[0] = [61, 62]
               data[1] = [[41, 42], [11, 12]]
               data[2] = [[[51, 52], [21, 22]], [[1, 2], [31, 32]]]
               merged = [[1, 2], [11, 12], [21, 22], [31, 32], [41, 42],
               [51, 52], [61, 62]]
              </code>
               
               This method can be used to merge partitions created by <c>dynamic_partition</c>
               as illustrated on the following example:
               
              <code>
               # Apply function (increments x_i) on elements for which a certain condition
               # apply (x_i != -1 in this example).
               x=tf.constant([0.1, -1., 5.2, 4.3, -1., 7.4])
               condition_mask=tf.not_equal(x,tf.constant(-1.))
               partitioned_data = tf.dynamic_partition(
               x, tf.cast(condition_mask, tf.int32) , 2)
               partitioned_data[1] = partitioned_data[1] + 1.0
               condition_indices = tf.dynamic_partition(
               tf.range(tf.shape(x)[0]), tf.cast(condition_mask, tf.int32) , 2)
               x = tf.dynamic_stitch(condition_indices, partitioned_data)
               # Here x=[1.1, -1., 6.2, 5.3, -1, 8.4], the -1. values remain
               # unchanged.
              </code>
               
               &amp;lt;div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;"&amp;gt;
               &amp;lt;img style="width:100%" src="https://www.tensorflow.org/images/DynamicStitch.png" alt&amp;gt;
               &amp;lt;/div&amp;gt;
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.edit_distance(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Computes the (possibly normalized) Levenshtein Edit Distance.
            </summary>
            <param name="hypothesis_indices">
               The indices of the hypothesis list SparseTensor.
               This is an N x R int64 matrix.
            </param>
            <param name="hypothesis_values">
               The values of the hypothesis list SparseTensor.
               This is an N-length vector.
            </param>
            <param name="hypothesis_shape">
               The shape of the hypothesis list SparseTensor.
               This is an R-length vector.
            </param>
            <param name="truth_indices">
               The indices of the truth list SparseTensor.
               This is an M x R int64 matrix.
            </param>
            <param name="truth_values">
               The values of the truth list SparseTensor.
               This is an M-length vector.
            </param>
            <param name="truth_shape">
               truth indices, vector.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'EditDistance'.
            </param>
            <param name="normalize">
               boolean (if true, edit distances are normalized by length of truth).
               
               The output is:
            </param>
            <returns>
               A dense float tensor with rank R - 1.
               
               For the example input:
               
               // hypothesis represents a 2x1 matrix with variable-length values:
               //   (0,0) = ["a"]
               //   (1,0) = ["b"]
               hypothesis_indices = [[0, 0, 0],
               [1, 0, 0]]
               hypothesis_values = ["a", "b"]
               hypothesis_shape = [2, 1, 1]
               
               // truth represents a 2x2 matrix with variable-length values:
               //   (0,0) = []
               //   (0,1) = ["a"]
               //   (1,0) = ["b", "c"]
               //   (1,1) = ["a"]
               truth_indices = [[0, 1, 0],
               [1, 0, 0],
               [1, 0, 1],
               [1, 1, 0]]
               truth_values = ["a", "b", "c", "a"]
               truth_shape = [2, 2, 2]
               normalize = true
               
               The output will be:
               
               // output is a 2x2 matrix with edit distances normalized by truth lengths.
               output = [[inf, 1.0],  // (0,0): no truth, (0,1): no hypothesis
               [0.5, 1.0]]  // (1,0): addition, (1,1): no hypothesis
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The inputs are variable-length sequences provided by SparseTensors
               (hypothesis_indices, hypothesis_values, hypothesis_shape)
               and
               (truth_indices, truth_values, truth_shape).
               
               The inputs are:
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.elu(Tensorflow.Tensor,System.String)">
            <summary>
               Computes exponential linear: <c>exp(features) - 1</c> if &amp;lt; 0, <c>features</c> otherwise.
            </summary>
            <param name="features">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Elu'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               See [Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)
               ](http://arxiv.org/abs/1511.07289)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.elu_grad(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes gradients for the exponential linear (Elu) operation.
            </summary>
            <param name="gradients">
               The backpropagated gradients to the corresponding Elu operation.
            </param>
            <param name="outputs">
               The outputs of the corresponding Elu operation.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'EluGrad'.
            </param>
            <returns>
               The gradients: <c>gradients * (outputs + 1)</c> if outputs &amp;lt; 0,
               <c>gradients</c> otherwise.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.empty(Tensorflow.Tensor,Tensorflow.TF_DataType,System.Nullable{System.Boolean},System.String)">
            <summary>
               Creates a tensor with the given shape.
               
               This operation creates a tensor of <c>shape</c> and <c>dtype</c>.
            </summary>
            <param name="shape">
               1-D. Represents the shape of the output tensor.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Empty'.
            </param>
            <param name="dtype">
               Optional argument
            </param>
            <param name="init">
               If True, initialize the returned tensor with the default value of dtype.  Otherwise, the implementation is free not to initializethe tensor's content.
            </param>
            <returns>
               A <c>Tensor</c> of type <c>T</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.empty_tensor_list(Tensorflow.Tensor,Tensorflow.TF_DataType,System.String)">
            <summary>
               Creates and returns an empty tensor list.
            </summary>
            <param name="element_shape">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'EmptyTensorList'.
            </param>
            <param name="element_dtype">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               All list elements must be tensors of dtype element_dtype and shape compatible
               with element_shape.
               
               handle: an empty tensor list.
               element_dtype: the type of elements in the list.
               element_shape: a shape compatible with that of elements in the list.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.encode_base64(Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Encode strings into web-safe base64 format.
            </summary>
            <param name="input">
               Strings to be encoded.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'EncodeBase64'.
            </param>
            <param name="pad">
               Bool whether padding is applied at the ends.
            </param>
            <returns>
               Input strings encoded in base64.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Refer to the following article for more information on base64 format:
               en.wikipedia.org/wiki/Base64. Base64 strings may have padding with '=' at the
               end so that the encoded has length multiple of 4. See Padding section of the
               link above.
               
               Web-safe means that the encoder uses - and _ instead of + and /.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.encode_jpeg(Tensorflow.Tensor,System.String,System.Nullable{System.Int32},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.String,System.Nullable{System.Int32},System.Nullable{System.Int32},System.String,System.String)">
            <summary>
               JPEG-encode an image.
            </summary>
            <param name="image">
               3-D with shape <c>[height, width, channels]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'EncodeJpeg'.
            </param>
            <param name="format">
               Per pixel image format.
            </param>
            <param name="quality">
               Quality of the compression from 0 to 100 (higher is better and slower).
            </param>
            <param name="progressive">
               If True, create a JPEG that loads progressively (coarse to fine).
            </param>
            <param name="optimize_size">
               If True, spend CPU/RAM to reduce size with no quality change.
            </param>
            <param name="chroma_downsampling">
               See http://en.wikipedia.org/wiki/Chroma_subsampling.
            </param>
            <param name="density_unit">
               Unit used to specify <c>x_density</c> and <c>y_density</c>:
               pixels per inch (<c>'in'</c>) or centimeter (<c>'cm'</c>).
            </param>
            <param name="x_density">
               Horizontal pixels per density unit.
            </param>
            <param name="y_density">
               Vertical pixels per density unit.
            </param>
            <param name="xmp_metadata">
               If not empty, embed this XMP metadata in the image header.
            </param>
            <returns>
               0-D. JPEG-encoded image.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               <c>image</c> is a 3-D uint8 Tensor of shape <c>[height, width, channels]</c>.
               
               The attr <c>format</c> can be used to override the color format of the encoded
               output.  Values can be:
               
               *   <c>''</c>: Use a default format based on the number of channels in the image.
               *   <c>grayscale</c>: Output a grayscale JPEG image.  The <c>channels</c> dimension
               of <c>image</c> must be 1.
               *   <c>rgb</c>: Output an RGB JPEG image. The <c>channels</c> dimension
               of <c>image</c> must be 3.
               
               If <c>format</c> is not specified or is the empty string, a default format is picked
               in function of the number of channels in <c>image</c>:
               
               *   1: Output a grayscale image.
               *   3: Output an RGB image.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.encode_png(Tensorflow.Tensor,System.Nullable{System.Int32},System.String)">
            <summary>
               PNG-encode an image.
            </summary>
            <param name="image">
               3-D with shape <c>[height, width, channels]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'EncodePng'.
            </param>
            <param name="compression">
               Compression level.
            </param>
            <returns>
               0-D. PNG-encoded image.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               <c>image</c> is a 3-D uint8 or uint16 Tensor of shape <c>[height, width, channels]</c>
               where <c>channels</c> is:
               
               *   1: for grayscale.
               *   2: for grayscale + alpha.
               *   3: for RGB.
               *   4: for RGBA.
               
               The ZLIB compression level, <c>compression</c>, can be -1 for the PNG-encoder
               default or a value from 0 to 9.  9 is the highest compression level, generating
               the smallest output, but is slower.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.encode_proto(Tensorflow.Tensor,Tensorflow.Tensor[],System.String[],System.String,System.String,System.String)">
            <summary>
               The op serializes protobuf messages provided in the input tensors.
            </summary>
            <param name="sizes">
               Tensor of int32 with shape <c>[batch_shape, len(field_names)]</c>.
            </param>
            <param name="values">
               List of tensors containing values for the corresponding field.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'EncodeProto'.
            </param>
            <param name="field_names">
               Optional argument
               List of strings containing proto field names.
            </param>
            <param name="message_type">
               Optional argument
               Name of the proto message type to decode.
            </param>
            <param name="descriptor_source">
            </param>
            <returns>
               Tensor of serialized protos with shape <c>batch_shape</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The types of the tensors in <c>values</c> must match the schema for the
               fields specified in <c>field_names</c>. All the tensors in <c>values</c> must
               have a common shape prefix, *batch_shape*.
               
               The <c>sizes</c> tensor specifies repeat counts for each field.  The repeat
               count (last dimension) of a each tensor in <c>values</c> must be greater
               than or equal to corresponding repeat count in <c>sizes</c>.
               
               A <c>message_type</c> name must be provided to give context for the field
               names. The actual message descriptor can be looked up either in the
               linked-in descriptor pool or a filename provided by the caller using
               the <c>descriptor_source</c> attribute.
               
               The <c>descriptor_source</c> attribute selects a source of protocol
               descriptors to consult when looking up <c>message_type</c>. This may be a
               filename containing a serialized <c>FileDescriptorSet</c> message,
               or the special value <c>local://</c>, in which case only descriptors linked
               into the code will be searched; the filename can be on any filesystem
               accessible to TensorFlow.
               
               You can build a <c>descriptor_source</c> file using the <c>--descriptor_set_out</c>
               and <c>--include_imports</c> options to the protocol compiler <c>protoc</c>.
               
               The <c>local://</c> database only covers descriptors linked into the
               code via C++ libraries, not Python imports. You can link in a proto descriptor
               by creating a cc_library target with alwayslink=1.
               
               There are a few special cases in the value mapping:
               
               Submessage and group fields must be pre-serialized as TensorFlow strings.
               
               TensorFlow lacks support for unsigned int64s, so they must be
               represented as <c>tf.int64</c> with the same twos-complement bit pattern
               (the obvious way).
               
               Unsigned int32 values can be represented exactly with <c>tf.int64</c>, or
               with sign wrapping if the input is of type <c>tf.int32</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.encode_wav(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Encode audio data using the WAV file format.
            </summary>
            <param name="audio">
               2-D with shape <c>[length, channels]</c>.
            </param>
            <param name="sample_rate">
               Scalar containing the sample frequency.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'EncodeWav'.
            </param>
            <returns>
               0-D. WAV-encoded file contents.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation will generate a string suitable to be saved out to create a .wav
               audio file. It will be encoded in the 16-bit PCM format. It takes in float
               values in the range -1.0f to 1.0f, and any outside that value will be clamped to
               that range.
               
               <c>audio</c> is a 2-D float Tensor of shape <c>[length, channels]</c>.
               <c>sample_rate</c> is a scalar Tensor holding the rate to use (e.g. 44100).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.ensure_shape(Tensorflow.Tensor,Tensorflow.TensorShape,System.String)">
            <summary>
               Ensures that the tensor's shape matches the expected shape.
            </summary>
            <param name="input">
               A tensor, whose shape is to be validated.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'EnsureShape'.
            </param>
            <param name="shape">
               Optional argument
               The expected (possibly partially specified) shape of the input tensor.
            </param>
            <returns>
               A tensor with the same shape and contents as the input tensor or value.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Raises an error if the input tensor's shape does not match the specified shape.
               Returns the input tensor otherwise.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.enter(Tensorflow.Tensor,System.String,System.Nullable{System.Boolean},System.Nullable{System.Int32},System.String)">
            <summary>
               Creates or finds a child frame, and makes <c>data</c> available to the child frame.
            </summary>
            <param name="data">
               The tensor to be made available to the child frame.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Enter'.
            </param>
            <param name="frame_name">
               Optional argument
               The name of the child frame.
            </param>
            <param name="is_constant">
               If true, the output is constant within the child frame.
            </param>
            <param name="parallel_iterations">
               The number of iterations allowed to run in parallel.
            </param>
            <returns>
               The same tensor as <c>data</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This op is used together with <c>Exit</c> to create loops in the graph.
               The unique <c>frame_name</c> is used by the <c>Executor</c> to identify frames. If
               <c>is_constant</c> is true, <c>output</c> is a constant in the child frame; otherwise
               it may be changed in the child frame. At most <c>parallel_iterations</c> iterations
               are run in parallel in the child frame.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.equal(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns the truth value of (x == y) element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Equal'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               *NOTE*: <c>Equal</c> supports broadcasting. More about broadcasting
               [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.erf(Tensorflow.Tensor,System.String)">
            <summary>
               Computes the Gauss error function of <c>x</c> element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Erf'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.erfc(Tensorflow.Tensor,System.String)">
            <summary>
               Computes the complementary error function of <c>x</c> element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Erfc'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.exit(Tensorflow.Tensor,System.String)">
            <summary>
               Exits the current frame to its parent frame.
            </summary>
            <param name="data">
               The tensor to be made available to the parent frame.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Exit'.
            </param>
            <returns>
               The same tensor as <c>data</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Exit makes its input <c>data</c> available to the parent frame.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.exp(Tensorflow.Tensor,System.String)">
            <summary>
               Computes exponential of x element-wise.  \\(y = e^x\\).
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Exp'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.expand_dims(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Inserts a dimension of 1 into a tensor's shape.
            </summary>
            <param name="input">
            </param>
            <param name="dim">
               0-D (scalar). Specifies the dimension index at which to
               expand the shape of <c>input</c>. Must be in the range
               <c>[-rank(input) - 1, rank(input)]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ExpandDims'.
            </param>
            <returns>
               Contains the same data as <c>input</c>, but its shape has an additional
               dimension of size 1 added.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Given a tensor <c>input</c>, this operation inserts a dimension of 1 at the
               dimension index <c>axis</c> of <c>input</c>'s shape. The dimension index <c>axis</c> starts at
               zero; if you specify a negative number for <c>axis</c> it is counted backward from
               the end.
               
               This operation is useful if you want to add a batch dimension to a single
               element. For example, if you have a single image of shape <c>[height, width,
               channels]</c>, you can make it a batch of 1 image with <c>expand_dims(image, 0)</c>,
               which will make the shape <c>[1, height, width, channels]</c>.
               
               Other examples:
               
              <code>
               # 't' is a tensor of shape [2]
               shape(expand_dims(t, 0)) ==&amp;gt; [1, 2]
               shape(expand_dims(t, 1)) ==&amp;gt; [2, 1]
               shape(expand_dims(t, -1)) ==&amp;gt; [2, 1]
               
               # 't2' is a tensor of shape [2, 3, 5]
               shape(expand_dims(t2, 0)) ==&amp;gt; [1, 2, 3, 5]
               shape(expand_dims(t2, 2)) ==&amp;gt; [2, 3, 1, 5]
               shape(expand_dims(t2, 3)) ==&amp;gt; [2, 3, 5, 1]
              </code>
               
               This operation requires that:
               
               <c>-1-input.dims() &amp;lt;= dim &amp;lt;= input.dims()</c>
               
               This operation is related to <c>squeeze()</c>, which removes dimensions of
               size 1.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.expm1(Tensorflow.Tensor,System.String)">
            <summary>
               Computes exponential of x - 1 element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Expm1'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               I.e., \\(y = (\exp x) - 1\\).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.extract_glimpse(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.String)">
            <summary>
               Extracts a glimpse from the input tensor.
            </summary>
            <param name="input">
               A 4-D float tensor of shape <c>[batch_size, height, width, channels]</c>.
            </param>
            <param name="size">
               A 1-D tensor of 2 elements containing the size of the glimpses
               to extract.  The glimpse height must be specified first, following
               by the glimpse width.
            </param>
            <param name="offsets">
               A 2-D integer tensor of shape <c>[batch_size, 2]</c> containing
               the y, x locations of the center of each window.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ExtractGlimpse'.
            </param>
            <param name="centered">
               indicates if the offset coordinates are centered relative to
               the image, in which case the (0, 0) offset is relative to the center
               of the input images. If false, the (0,0) offset corresponds to the
               upper left corner of the input images.
            </param>
            <param name="normalized">
               indicates if the offset coordinates are normalized.
            </param>
            <param name="uniform_noise">
               indicates if the noise should be generated using a
               uniform distribution or a Gaussian distribution.
            </param>
            <returns>
               A tensor representing the glimpses <c>[batch_size,
               glimpse_height, glimpse_width, channels]</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Returns a set of windows called glimpses extracted at location
               <c>offsets</c> from the input tensor. If the windows only partially
               overlaps the inputs, the non overlapping areas will be filled with
               random noise.
               
               The result is a 4-D tensor of shape <c>[batch_size, glimpse_height,
               glimpse_width, channels]</c>. The channels and batch dimensions are the
               same as that of the input tensor. The height and width of the output
               windows are specified in the <c>size</c> parameter.
               
               The argument <c>normalized</c> and <c>centered</c> controls how the windows are built:
               
               * If the coordinates are normalized but not centered, 0.0 and 1.0
               correspond to the minimum and maximum of each height and width
               dimension.
               * If the coordinates are both normalized and centered, they range from
               -1.0 to 1.0. The coordinates (-1.0, -1.0) correspond to the upper
               left corner, the lower right corner is located at (1.0, 1.0) and the
               center is at (0, 0).
               * If the coordinates are not normalized they are interpreted as
               numbers of pixels.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.extract_image_patches(Tensorflow.Tensor,System.Int32[],System.Int32[],System.Int32[],System.String,System.String)">
            <summary>
               Extract <c>patches</c> from <c>images</c> and put them in the "depth" output dimension.
            </summary>
            <param name="images">
               4-D Tensor with shape <c>[batch, in_rows, in_cols, depth]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ExtractImagePatches'.
            </param>
            <param name="ksizes">
               Optional argument
               The size of the sliding window for each dimension of <c>images</c>.
            </param>
            <param name="strides">
               Optional argument
               1-D of length 4. How far the centers of two consecutive patches are in
               the images. Must be: <c>[1, stride_rows, stride_cols, 1]</c>.
            </param>
            <param name="rates">
               Optional argument
               1-D of length 4. Must be: <c>[1, rate_rows, rate_cols, 1]</c>. This is the
               input stride, specifying how far two consecutive patch samples are in the
               input. Equivalent to extracting patches with
               <c>patch_sizes_eff = patch_sizes + (patch_sizes - 1) * (rates - 1)</c>, followed by
               subsampling them spatially by a factor of <c>rates</c>. This is equivalent to
               <c>rate</c> in dilated (a.k.a. Atrous) convolutions.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
               
               We specify the size-related attributes as:
               
              <code>
               ksizes = [1, ksize_rows, ksize_cols, 1]
               strides = [1, strides_rows, strides_cols, 1]
               rates = [1, rates_rows, rates_cols, 1]
              </code>
            </param>
            <returns>
               4-D Tensor with shape <c>[batch, out_rows, out_cols, ksize_rows *
               ksize_cols * depth]</c> containing image patches with size
               <c>ksize_rows x ksize_cols x depth</c> vectorized in the "depth" dimension. Note
               <c>out_rows</c> and <c>out_cols</c> are the dimensions of the output patches.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.extract_jpeg_shape(Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Extract the shape information of a JPEG-encoded image.
            </summary>
            <param name="contents">
               0-D. The JPEG-encoded image.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ExtractJpegShape'.
            </param>
            <param name="output_type">
               (Optional) The output type of the operation (int32 or int64).
               Defaults to int32.
            </param>
            <returns>
               1-D. The image shape with format [height, width, channels].
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This op only parses the image header, so it is much faster than DecodeJpeg.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.f_f_t(Tensorflow.Tensor,System.String)">
            <summary>
               Fast Fourier transform.
            </summary>
            <param name="input">
               A complex64 tensor.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FFT'.
            </param>
            <returns>
               A complex64 tensor of the same shape as <c>input</c>. The inner-most
               dimension of <c>input</c> is replaced with its 1D Fourier transform.
               
               @compatibility(numpy)
               Equivalent to np.fft.fft
               @end_compatibility
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Computes the 1-dimensional discrete Fourier transform over the inner-most
               dimension of <c>input</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.f_f_t2d(Tensorflow.Tensor,System.String)">
            <summary>
               2D fast Fourier transform.
            </summary>
            <param name="input">
               A complex64 tensor.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FFT2D'.
            </param>
            <returns>
               A complex64 tensor of the same shape as <c>input</c>. The inner-most 2
               dimensions of <c>input</c> are replaced with their 2D Fourier transform.
               
               @compatibility(numpy)
               Equivalent to np.fft.fft2
               @end_compatibility
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Computes the 2-dimensional discrete Fourier transform over the inner-most
               2 dimensions of <c>input</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.f_f_t3d(Tensorflow.Tensor,System.String)">
            <summary>
               3D fast Fourier transform.
            </summary>
            <param name="input">
               A complex64 tensor.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FFT3D'.
            </param>
            <returns>
               A complex64 tensor of the same shape as <c>input</c>. The inner-most 3
               dimensions of <c>input</c> are replaced with their 3D Fourier transform.
               
               @compatibility(numpy)
               Equivalent to np.fft.fftn with 3 dimensions.
               @end_compatibility
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Computes the 3-dimensional discrete Fourier transform over the inner-most 3
               dimensions of <c>input</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.f_i_f_o_queue(Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               A queue that produces elements in first-in first-out order.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FIFOQueue'.
            </param>
            <param name="component_types">
               Optional argument
               The type of each component in a value.
            </param>
            <param name="shapes">
               The shape of each component in a value. The length of this attr must
               be either 0 or the same as the length of component_types. If the length of
               this attr is 0, the shapes of queue elements are not constrained, and
               only one element may be dequeued at a time.
            </param>
            <param name="capacity">
               The upper bound on the number of elements in this queue.
               Negative numbers mean no limit.
            </param>
            <param name="container">
               If non-empty, this queue is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this queue will be shared under the given name
               across multiple sessions.
            </param>
            <returns>
               The handle to the queue.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.f_i_f_o_queue_v2(Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               A queue that produces elements in first-in first-out order.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FIFOQueueV2'.
            </param>
            <param name="component_types">
               Optional argument
               The type of each component in a value.
            </param>
            <param name="shapes">
               The shape of each component in a value. The length of this attr must
               be either 0 or the same as the length of component_types. If the length of
               this attr is 0, the shapes of queue elements are not constrained, and
               only one element may be dequeued at a time.
            </param>
            <param name="capacity">
               The upper bound on the number of elements in this queue.
               Negative numbers mean no limit.
            </param>
            <param name="container">
               If non-empty, this queue is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this queue will be shared under the given name
               across multiple sessions.
            </param>
            <returns>
               The handle to the queue.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.fake_param(Tensorflow.TF_DataType,Tensorflow.TensorShape,System.String)">
            <summary>
               This op is used as a placeholder in If branch functions. It doesn't provide a
               valid output when run, so must either be removed (e.g. replaced with a
               function input) or guaranteed not to be used (e.g. if mirroring an
               intermediate output needed for the gradient computation of the other branch).
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FakeParam'.
            </param>
            <param name="dtype">
               Optional argument
               The type of the output.
            </param>
            <param name="shape">
               Optional argument
               The purported shape of the output. This is only used for shape inference;
               the output will not necessarily have this shape. Can be a partial shape.
            </param>
            <returns>
               \"Fake\" output value. This should not be consumed by another op.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.fake_quant_with_min_max_args(Tensorflow.Tensor,System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Boolean},System.String)">
            <summary>
               Fake-quantize the 'inputs' tensor, type float to 'outputs' tensor of same type.
            </summary>
            <param name="inputs">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FakeQuantWithMinMaxArgs'.
            </param>
            <param name="min">
            </param>
            <param name="max">
            </param>
            <param name="num_bits">
            </param>
            <param name="narrow_range">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Attributes <c>[min; max]</c> define the clamping range for the <c>inputs</c> data.
               <c>inputs</c> values are quantized into the quantization range (<c>[0; 2^num_bits - 1]</c>
               when <c>narrow_range</c> is false and <c>[1; 2^num_bits - 1]</c> when it is true) and
               then de-quantized and output as floats in <c>[min; max]</c> interval.
               <c>num_bits</c> is the bitwidth of the quantization; between 2 and 16, inclusive.
               
               Quantization is called fake since the output is still in floating point.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.fake_quant_with_min_max_args_gradient(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Boolean},System.String)">
            <summary>
               Compute gradients for a FakeQuantWithMinMaxArgs operation.
            </summary>
            <param name="gradients">
               Backpropagated gradients above the FakeQuantWithMinMaxArgs operation.
            </param>
            <param name="inputs">
               Values passed as inputs to the FakeQuantWithMinMaxArgs operation.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FakeQuantWithMinMaxArgsGradient'.
            </param>
            <param name="min">
            </param>
            <param name="max">
            </param>
            <param name="num_bits">
            </param>
            <param name="narrow_range">
            </param>
            <returns>
               Backpropagated gradients below the FakeQuantWithMinMaxArgs operation:
               <c>gradients * (inputs &amp;gt;= min &amp;&amp; inputs &amp;lt;= max)</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.fake_quant_with_min_max_vars(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Int32},System.Nullable{System.Boolean},System.String)">
            <summary>
               Fake-quantize the 'inputs' tensor of type float via global float scalars <c>min</c>
            </summary>
            <param name="inputs">
            </param>
            <param name="min">
            </param>
            <param name="max">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FakeQuantWithMinMaxVars'.
            </param>
            <param name="num_bits">
            </param>
            <param name="narrow_range">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               and <c>max</c> to 'outputs' tensor of same shape as <c>inputs</c>.
               
               <c>[min; max]</c> define the clamping range for the <c>inputs</c> data.
               <c>inputs</c> values are quantized into the quantization range (<c>[0; 2^num_bits - 1]</c>
               when <c>narrow_range</c> is false and <c>[1; 2^num_bits - 1]</c> when it is true) and
               then de-quantized and output as floats in <c>[min; max]</c> interval.
               <c>num_bits</c> is the bitwidth of the quantization; between 2 and 16, inclusive.
               
               This operation has a gradient and thus allows for training <c>min</c> and <c>max</c>
               values.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.fake_quant_with_min_max_vars_gradient(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Int32},System.Nullable{System.Boolean},System.String)">
            <summary>
               Compute gradients for a FakeQuantWithMinMaxVars operation.
            </summary>
            <param name="gradients">
               Backpropagated gradients above the FakeQuantWithMinMaxVars operation.
            </param>
            <param name="inputs">
               Values passed as inputs to the FakeQuantWithMinMaxVars operation.
               min, max: Quantization interval, scalar floats.
            </param>
            <param name="min">
            </param>
            <param name="max">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FakeQuantWithMinMaxVarsGradient'.
            </param>
            <param name="num_bits">
               The bitwidth of the quantization; between 2 and 8, inclusive.
            </param>
            <param name="narrow_range">
               Whether to quantize into 2^num_bits - 1 distinct values.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               backprops_wrt_input : Backpropagated gradients w.r.t. inputs:
               <c>gradients * (inputs &amp;gt;= min &amp;&amp; inputs &amp;lt;= max)</c>.
               backprop_wrt_min : Backpropagated gradients w.r.t. min parameter:
               <c>sum(gradients * (inputs &amp;lt; min))</c>.
               backprop_wrt_max : Backpropagated gradients w.r.t. max parameter:
               <c>sum(gradients * (inputs &amp;gt; max))</c>.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.fake_quant_with_min_max_vars_per_channel(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Int32},System.Nullable{System.Boolean},System.String)">
            <summary>
               Fake-quantize the 'inputs' tensor of type float and one of the shapes: <c>[d]</c>,
            </summary>
            <param name="inputs">
            </param>
            <param name="min">
            </param>
            <param name="max">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FakeQuantWithMinMaxVarsPerChannel'.
            </param>
            <param name="num_bits">
            </param>
            <param name="narrow_range">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               <c>[b, d]</c> <c>[b, h, w, d]</c> via per-channel floats <c>min</c> and <c>max</c> of shape <c>[d]</c>
               to 'outputs' tensor of same shape as <c>inputs</c>.
               
               <c>[min; max]</c> define the clamping range for the <c>inputs</c> data.
               <c>inputs</c> values are quantized into the quantization range (<c>[0; 2^num_bits - 1]</c>
               when <c>narrow_range</c> is false and <c>[1; 2^num_bits - 1]</c> when it is true) and
               then de-quantized and output as floats in <c>[min; max]</c> interval.
               <c>num_bits</c> is the bitwidth of the quantization; between 2 and 16, inclusive.
               
               This operation has a gradient and thus allows for training <c>min</c> and <c>max</c>
               values.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.fake_quant_with_min_max_vars_per_channel_gradient(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Int32},System.Nullable{System.Boolean},System.String)">
            <summary>
               Compute gradients for a FakeQuantWithMinMaxVarsPerChannel operation.
            </summary>
            <param name="gradients">
               Backpropagated gradients above the FakeQuantWithMinMaxVars operation,
               shape one of: <c>[d]</c>, <c>[b, d]</c>,  <c>[b, h, w, d]</c>.
            </param>
            <param name="inputs">
               Values passed as inputs to the FakeQuantWithMinMaxVars operation, shape
               same as <c>gradients</c>.
               min, max: Quantization interval, floats of shape <c>[d]</c>.
            </param>
            <param name="min">
            </param>
            <param name="max">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FakeQuantWithMinMaxVarsPerChannelGradient'.
            </param>
            <param name="num_bits">
               The bitwidth of the quantization; between 2 and 16, inclusive.
            </param>
            <param name="narrow_range">
               Whether to quantize into 2^num_bits - 1 distinct values.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               backprops_wrt_input : Backpropagated gradients w.r.t. inputs, shape same as
               <c>inputs</c>:
               <c>gradients * (inputs &amp;gt;= min &amp;&amp; inputs &amp;lt;= max)</c>.
               backprop_wrt_min : Backpropagated gradients w.r.t. min parameter, shape <c>[d]</c>:
               <c>sum_per_d(gradients * (inputs &amp;lt; min))</c>.
               backprop_wrt_max : Backpropagated gradients w.r.t. max parameter, shape <c>[d]</c>:
               <c>sum_per_d(gradients * (inputs &amp;gt; max))</c>.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.fake_queue(Tensorflow.Tensor,System.String)">
            <summary>
               Deprecated. Do not use.
            </summary>
            <param name="resource">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FakeQueue'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.fill(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Creates a tensor filled with a scalar value.
            </summary>
            <param name="dims">
               1-D. Represents the shape of the output tensor.
            </param>
            <param name="value">
               0-D (scalar). Value to fill the returned tensor.
               
               @compatibility(numpy)
               Equivalent to np.full
               @end_compatibility
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Fill'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation creates a tensor of shape <c>dims</c> and fills it with <c>value</c>.
               
               For example:
               
              <code>
               # Output tensor has shape [2, 3].
               fill([2, 3], 9) ==&amp;gt; [[9, 9, 9]
               [9, 9, 9]]
              </code>
               
               <c>tf.fill</c> differs from <c>tf.constant</c> in a few ways:
               
               *   <c>tf.fill</c> only supports scalar contents, whereas <c>tf.constant</c> supports
               Tensor values.
               *   <c>tf.fill</c> creates an Op in the computation graph that constructs the actual
               Tensor value at runtime. This is in contrast to <c>tf.constant</c> which embeds
               the entire Tensor into the graph with a <c>Const</c> node.
               *   Because <c>tf.fill</c> evaluates at graph runtime, it supports dynamic shapes
               based on other runtime Tensors, unlike <c>tf.constant</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.filter_by_last_component_dataset(Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Creates a dataset containing elements of first component of <c>input_dataset</c> having true in the last component.
            </summary>
            <param name="input_dataset">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FilterByLastComponentDataset'.
            </param>
            <param name="output_types">
               Optional argument
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.fixed_length_record_dataset(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Creates a dataset that emits the records from one or more binary files.
            </summary>
            <param name="filenames">
               A scalar or a vector containing the name(s) of the file(s) to be
               read.
            </param>
            <param name="header_bytes">
               A scalar representing the number of bytes to skip at the
               beginning of a file.
            </param>
            <param name="record_bytes">
               A scalar representing the number of bytes in each record.
            </param>
            <param name="footer_bytes">
               A scalar representing the number of bytes to skip at the end
               of a file.
            </param>
            <param name="buffer_size">
               A scalar representing the number of bytes to buffer. Must be &amp;gt; 0.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FixedLengthRecordDataset'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.fixed_length_record_reader(System.Int32,System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               A Reader that outputs fixed-length records from a file.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FixedLengthRecordReader'.
            </param>
            <param name="record_bytes">
               Optional argument
               Number of bytes in the record.
            </param>
            <param name="header_bytes">
               Number of bytes in the header, defaults to 0.
            </param>
            <param name="footer_bytes">
               Number of bytes in the footer, defaults to 0.
            </param>
            <param name="hop_bytes">
               Number of bytes to hop before each read. Default of 0 means using
               record_bytes.
            </param>
            <param name="container">
               If non-empty, this reader is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this reader is named in the given bucket
               with this shared_name. Otherwise, the node name is used instead.
            </param>
            <returns>
               The handle to reference the Reader.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.fixed_length_record_reader_v2(System.Int32,System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.String,System.String,System.String,System.String)">
            <summary>
               A Reader that outputs fixed-length records from a file.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FixedLengthRecordReaderV2'.
            </param>
            <param name="record_bytes">
               Optional argument
               Number of bytes in the record.
            </param>
            <param name="header_bytes">
               Number of bytes in the header, defaults to 0.
            </param>
            <param name="footer_bytes">
               Number of bytes in the footer, defaults to 0.
            </param>
            <param name="hop_bytes">
               Number of bytes to hop before each read. Default of 0 means using
               record_bytes.
            </param>
            <param name="container">
               If non-empty, this reader is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this reader is named in the given bucket
               with this shared_name. Otherwise, the node name is used instead.
            </param>
            <param name="encoding">
               The type of encoding for the file. Currently ZLIB and GZIP
               are supported. Defaults to none.
            </param>
            <returns>
               The handle to reference the Reader.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.fixed_unigram_candidate_sampler(Tensorflow.Tensor,System.Int32,System.Int32,System.Boolean,System.Int32,System.String,System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Single[],System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Generates labels for candidate sampling with a learned unigram distribution.
            </summary>
            <param name="true_classes">
               A batch_size * num_true matrix, in which each row contains the
               IDs of the num_true target_classes in the corresponding original label.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FixedUnigramCandidateSampler'.
            </param>
            <param name="num_true">
               Optional argument
               Number of true labels per context.
            </param>
            <param name="num_sampled">
               Optional argument
               Number of candidates to randomly sample.
            </param>
            <param name="unique">
               Optional argument
               If unique is true, we sample with rejection, so that all sampled
               candidates in a batch are unique. This requires some approximation to
               estimate the post-rejection sampling probabilities.
            </param>
            <param name="range_max">
               Optional argument
               The sampler will sample integers from the interval [0, range_max).
            </param>
            <param name="vocab_file">
               Each valid line in this file (which should have a CSV-like format)
               corresponds to a valid word ID. IDs are in sequential order, starting from
               num_reserved_ids. The last entry in each line is expected to be a value
               corresponding to the count or relative probability. Exactly one of vocab_file
               and unigrams needs to be passed to this op.
            </param>
            <param name="distortion">
               The distortion is used to skew the unigram probability distribution.
               Each weight is first raised to the distortion's power before adding to the
               internal unigram distribution. As a result, distortion = 1.0 gives regular
               unigram sampling (as defined by the vocab file), and distortion = 0.0 gives
               a uniform distribution.
            </param>
            <param name="num_reserved_ids">
               Optionally some reserved IDs can be added in the range [0,
               ..., num_reserved_ids) by the users. One use case is that a special unknown
               word token is used as ID 0. These IDs will have a sampling probability of 0.
            </param>
            <param name="num_shards">
               A sampler can be used to sample from a subset of the original range
               in order to speed up the whole computation through parallelism. This parameter
               (together with 'shard') indicates the number of partitions that are being
               used in the overall computation.
            </param>
            <param name="shard">
               A sampler can be used to sample from a subset of the original range
               in order to speed up the whole computation through parallelism. This parameter
               (together with 'num_shards') indicates the particular partition number of a
               sampler op, when partitioning is being used.
            </param>
            <param name="unigrams">
               A list of unigram counts or probabilities, one per ID in sequential
               order. Exactly one of vocab_file and unigrams should be passed to this op.
            </param>
            <param name="seed">
               If either seed or seed2 are set to be non-zero, the random number
               generator is seeded by the given seed.  Otherwise, it is seeded by a
               random seed.
            </param>
            <param name="seed2">
               An second seed to avoid seed collision.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               sampled_candidates : A vector of length num_sampled, in which each element is
               the ID of a sampled candidate.
               true_expected_count : A batch_size * num_true matrix, representing
               the number of times each candidate is expected to occur in a batch
               of sampled candidates. If unique=true, then this is a probability.
               sampled_expected_count : A vector of length num_sampled, for each sampled
               candidate representing the number of times the candidate is expected
               to occur in a batch of sampled candidates.  If unique=true, then this is a
               probability.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               A unigram sampler could use a fixed unigram distribution read from a
               file or passed in as an in-memory array instead of building up the distribution
               from data on the fly. There is also an option to skew the distribution by
               applying a distortion power to the weights.
               
               The vocabulary file should be in CSV-like format, with the last field
               being the weight associated with the word.
               
               For each batch, this op picks a single set of sampled candidate labels.
               
               The advantages of sampling candidates per-batch are simplicity and the
               possibility of efficient dense matrix multiplication. The disadvantage is that
               the sampled candidates must be chosen independently of the context and of the
               true labels.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.floor(Tensorflow.Tensor,System.String)">
            <summary>
               Returns element-wise largest integer not greater than x.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Floor'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.floor_div(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns x // y element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FloorDiv'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               *NOTE*: <c>FloorDiv</c> supports broadcasting. More about broadcasting
               [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.floor_mod(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns element-wise remainder of division. When <c>x &amp;lt; 0</c> xor <c>y &amp;lt; 0</c> is
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FloorMod'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               true, this follows Python semantics in that the result here is consistent
               with a flooring divide. E.g. <c>floor(x / y) * y + mod(x, y) = x</c>.
               
               *NOTE*: <c>FloorMod</c> supports broadcasting. More about broadcasting
               [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.fractional_avg_pool(Tensorflow.Tensor,System.Single[],System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Performs fractional average pooling on the input.
            </summary>
            <param name="value">
               4-D with shape <c>[batch, height, width, channels]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FractionalAvgPool'.
            </param>
            <param name="pooling_ratio">
               Optional argument
               Pooling ratio for each dimension of <c>value</c>, currently only
               supports row and col dimension and should be &amp;gt;= 1.0. For example, a valid
               pooling ratio looks like [1.0, 1.44, 1.73, 1.0]. The first and last elements
               must be 1.0 because we don't allow pooling on batch and channels
               dimensions. 1.44 and 1.73 are pooling ratio on height and width dimensions
               respectively.
            </param>
            <param name="pseudo_random">
               When set to True, generates the pooling sequence in a
               pseudorandom fashion, otherwise, in a random fashion. Check paper [Benjamin
               Graham, Fractional Max-Pooling](http://arxiv.org/abs/1412.6071) for
               difference between pseudorandom and random.
            </param>
            <param name="overlapping">
               When set to True, it means when pooling, the values at the boundary
               of adjacent pooling cells are used by both cells. For example:
               
               <c>index  0  1  2  3  4</c>
               
               <c>value  20 5  16 3  7</c>
               
               If the pooling sequence is [0, 2, 4], then 16, at index 2 will be used twice.
               The result would be [41/3, 26/3] for fractional avg pooling.
            </param>
            <param name="deterministic">
               When set to True, a fixed pooling region will be used when
               iterating over a FractionalAvgPool node in the computation graph. Mainly used
               in unit test to make FractionalAvgPool deterministic.
            </param>
            <param name="seed">
               If either seed or seed2 are set to be non-zero, the random number
               generator is seeded by the given seed.  Otherwise, it is seeded by a
               random seed.
            </param>
            <param name="seed2">
               An second seed to avoid seed collision.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output : output tensor after fractional avg pooling.
               row_pooling_sequence : row pooling sequence, needed to calculate gradient.
               col_pooling_sequence : column pooling sequence, needed to calculate gradient.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Fractional average pooling is similar to Fractional max pooling in the pooling
               region generation step. The only difference is that after pooling regions are
               generated, a mean operation is performed instead of a max operation in each
               pooling region.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.fractional_avg_pool_grad(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Computes gradient of the FractionalAvgPool function.
            </summary>
            <param name="orig_input_tensor_shape">
               Original input tensor shape for <c>fractional_avg_pool</c>
            </param>
            <param name="out_backprop">
               4-D with shape <c>[batch, height, width, channels]</c>.  Gradients
               w.r.t. the output of <c>fractional_avg_pool</c>.
            </param>
            <param name="row_pooling_sequence">
               row pooling sequence, form pooling region with
               col_pooling_sequence.
            </param>
            <param name="col_pooling_sequence">
               column pooling sequence, form pooling region with
               row_pooling sequence.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FractionalAvgPoolGrad'.
            </param>
            <param name="overlapping">
               When set to True, it means when pooling, the values at the boundary
               of adjacent pooling cells are used by both cells. For example:
               
               <c>index  0  1  2  3  4</c>
               
               <c>value  20 5  16 3  7</c>
               
               If the pooling sequence is [0, 2, 4], then 16, at index 2 will be used twice.
               The result would be [41/3, 26/3] for fractional avg pooling.
            </param>
            <returns>
               4-D.  Gradients w.r.t. the input of <c>fractional_avg_pool</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Unlike FractionalMaxPoolGrad, we don't need to find arg_max for
               FractionalAvgPoolGrad, we just need to evenly back-propagate each element of
               out_backprop to those indices that form the same pooling cell. Therefore, we
               just need to know the shape of original input tensor, instead of the whole
               tensor.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.fractional_max_pool(Tensorflow.Tensor,System.Single[],System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Performs fractional max pooling on the input.
            </summary>
            <param name="value">
               4-D with shape <c>[batch, height, width, channels]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FractionalMaxPool'.
            </param>
            <param name="pooling_ratio">
               Optional argument
               Pooling ratio for each dimension of <c>value</c>, currently only
               supports row and col dimension and should be &amp;gt;= 1.0. For example, a valid
               pooling ratio looks like [1.0, 1.44, 1.73, 1.0]. The first and last elements
               must be 1.0 because we don't allow pooling on batch and channels
               dimensions. 1.44 and 1.73 are pooling ratio on height and width dimensions
               respectively.
            </param>
            <param name="pseudo_random">
               When set to True, generates the pooling sequence in a
               pseudorandom fashion, otherwise, in a random fashion. Check paper [Benjamin
               Graham, Fractional Max-Pooling](http://arxiv.org/abs/1412.6071) for
               difference between pseudorandom and random.
            </param>
            <param name="overlapping">
               When set to True, it means when pooling, the values at the boundary
               of adjacent pooling cells are used by both cells. For example:
               
               <c>index  0  1  2  3  4</c>
               
               <c>value  20 5  16 3  7</c>
               
               If the pooling sequence is [0, 2, 4], then 16, at index 2 will be used twice.
               The result would be [20, 16] for fractional max pooling.
            </param>
            <param name="deterministic">
               When set to True, a fixed pooling region will be used when
               iterating over a FractionalMaxPool node in the computation graph. Mainly used
               in unit test to make FractionalMaxPool deterministic.
            </param>
            <param name="seed">
               If either seed or seed2 are set to be non-zero, the random number
               generator is seeded by the given seed.  Otherwise, it is seeded by a
               random seed.
            </param>
            <param name="seed2">
               An second seed to avoid seed collision.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output : output tensor after fractional max pooling.
               row_pooling_sequence : row pooling sequence, needed to calculate gradient.
               col_pooling_sequence : column pooling sequence, needed to calculate gradient.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Fractional max pooling is slightly different than regular max pooling.  In
               regular max pooling, you downsize an input set by taking the maximum value of
               smaller N x N subsections of the set (often 2x2), and try to reduce the set by
               a factor of N, where N is an integer.  Fractional max pooling, as you might
               expect from the word "fractional", means that the overall reduction ratio N
               does not have to be an integer.
               
               The sizes of the pooling regions are generated randomly but are fairly uniform.
               For example, let's look at the height dimension, and the constraints on the
               list of rows that will be pool boundaries.
               
               First we define the following:
               
               1.  input_row_length : the number of rows from the input set
               2.  output_row_length : which will be smaller than the input
               3.  alpha = input_row_length / output_row_length : our reduction ratio
               4.  K = floor(alpha)
               5.  row_pooling_sequence : this is the result list of pool boundary rows
               
               Then, row_pooling_sequence should satisfy:
               
               1.  a[0] = 0 : the first value of the sequence is 0
               2.  a[end] = input_row_length : the last value of the sequence is the size
               3.  K &amp;lt;= (a[i+1] - a[i]) &amp;lt;= K+1 : all intervals are K or K+1 size
               4.  length(row_pooling_sequence) = output_row_length+1
               
               For more details on fractional max pooling, see this paper:
               [Benjamin Graham, Fractional Max-Pooling](http://arxiv.org/abs/1412.6071)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.fractional_max_pool_grad(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Computes gradient of the FractionalMaxPool function.
            </summary>
            <param name="orig_input">
               Original input for <c>fractional_max_pool</c>
            </param>
            <param name="orig_output">
               Original output for <c>fractional_max_pool</c>
            </param>
            <param name="out_backprop">
               4-D with shape <c>[batch, height, width, channels]</c>.  Gradients
               w.r.t. the output of <c>fractional_max_pool</c>.
            </param>
            <param name="row_pooling_sequence">
               row pooling sequence, form pooling region with
               col_pooling_sequence.
            </param>
            <param name="col_pooling_sequence">
               column pooling sequence, form pooling region with
               row_pooling sequence.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FractionalMaxPoolGrad'.
            </param>
            <param name="overlapping">
               When set to True, it means when pooling, the values at the boundary
               of adjacent pooling cells are used by both cells. For example:
               
               <c>index  0  1  2  3  4</c>
               
               <c>value  20 5  16 3  7</c>
               
               If the pooling sequence is [0, 2, 4], then 16, at index 2 will be used twice.
               The result would be [20, 16] for fractional max pooling.
            </param>
            <returns>
               4-D.  Gradients w.r.t. the input of <c>fractional_max_pool</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.fused_batch_norm(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Single},System.String,System.Nullable{System.Boolean},System.String)">
            <summary>
               Batch normalization.
            </summary>
            <param name="x">
               A 4D Tensor for input data.
            </param>
            <param name="scale">
               A 1D Tensor for scaling factor, to scale the normalized x.
            </param>
            <param name="offset">
               A 1D Tensor for offset, to shift to the normalized x.
            </param>
            <param name="mean">
               A 1D Tensor for population mean. Used for inference only;
               must be empty for training.
            </param>
            <param name="variance">
               A 1D Tensor for population variance. Used for inference only;
               must be empty for training.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FusedBatchNorm'.
            </param>
            <param name="epsilon">
               A small float number added to the variance of x.
            </param>
            <param name="data_format">
               The data format for x and y. Either "NHWC" (default) or "NCHW".
            </param>
            <param name="is_training">
               A bool value to indicate the operation is for training (default)
               or inference.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               y : A 4D Tensor for output data.
               batch_mean : A 1D Tensor for the computed batch mean, to be used by TensorFlow
               to compute the running mean.
               batch_variance : A 1D Tensor for the computed batch variance, to be used by
               TensorFlow to compute the running variance.
               reserve_space_1 : A 1D Tensor for the computed batch mean, to be reused
               in the gradient computation.
               reserve_space_2 : A 1D Tensor for the computed batch variance (inverted variance
               in the cuDNN case), to be reused in the gradient computation.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Note that the size of 4D Tensors are defined by either "NHWC" or "NCHW".
               The size of 1D Tensors matches the dimension C of the 4D Tensors.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.fused_batch_norm_grad(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Single},System.String,System.Nullable{System.Boolean},System.String)">
            <summary>
               Gradient for batch normalization.
            </summary>
            <param name="y_backprop">
               A 4D Tensor for the gradient with respect to y.
            </param>
            <param name="x">
               A 4D Tensor for input data.
            </param>
            <param name="scale">
               A 1D Tensor for scaling factor, to scale the normalized x.
            </param>
            <param name="reserve_space_1">
               When is_training is True, a 1D Tensor for the computed batch
               mean to be reused in gradient computation. When is_training is
               False, a 1D Tensor for the population mean to be reused in both
               1st and 2nd order gradient computation.
            </param>
            <param name="reserve_space_2">
               When is_training is True, a 1D Tensor for the computed batch
               variance (inverted variance in the cuDNN case) to be reused in
               gradient computation. When is_training is False, a 1D Tensor
               for the population variance to be reused in both 1st and 2nd
               order gradient computation.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FusedBatchNormGrad'.
            </param>
            <param name="epsilon">
               A small float number added to the variance of x.
            </param>
            <param name="data_format">
               The data format for y_backprop, x, x_backprop.
               Either "NHWC" (default) or "NCHW".
            </param>
            <param name="is_training">
               A bool value to indicate the operation is for training (default)
               or inference.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               x_backprop : A 4D Tensor for the gradient with respect to x.
               scale_backprop : A 1D Tensor for the gradient with respect to scale.
               offset_backprop : A 1D Tensor for the gradient with respect to offset.
               reserve_space_3 : Unused placeholder to match the mean input in FusedBatchNorm.
               reserve_space_4 : Unused placeholder to match the variance input
               in FusedBatchNorm.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Note that the size of 4D Tensors are defined by either "NHWC" or "NCHW".
               The size of 1D Tensors matches the dimension C of the 4D Tensors.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.fused_batch_norm_grad_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Single},System.String,System.Nullable{System.Boolean},System.String)">
            <summary>
               Gradient for batch normalization.
            </summary>
            <param name="y_backprop">
               A 4D Tensor for the gradient with respect to y.
            </param>
            <param name="x">
               A 4D Tensor for input data.
            </param>
            <param name="scale">
               A 1D Tensor for scaling factor, to scale the normalized x.
            </param>
            <param name="reserve_space_1">
               When is_training is True, a 1D Tensor for the computed batch
               mean to be reused in gradient computation. When is_training is
               False, a 1D Tensor for the population mean to be reused in both
               1st and 2nd order gradient computation.
            </param>
            <param name="reserve_space_2">
               When is_training is True, a 1D Tensor for the computed batch
               variance (inverted variance in the cuDNN case) to be reused in
               gradient computation. When is_training is False, a 1D Tensor
               for the population variance to be reused in both 1st and 2nd
               order gradient computation.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FusedBatchNormGradV2'.
            </param>
            <param name="epsilon">
               A small float number added to the variance of x.
            </param>
            <param name="data_format">
               The data format for y_backprop, x, x_backprop.
               Either "NHWC" (default) or "NCHW".
            </param>
            <param name="is_training">
               A bool value to indicate the operation is for training (default)
               or inference.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               x_backprop : A 4D Tensor for the gradient with respect to x.
               scale_backprop : A 1D Tensor for the gradient with respect to scale.
               offset_backprop : A 1D Tensor for the gradient with respect to offset.
               reserve_space_3 : Unused placeholder to match the mean input in FusedBatchNorm.
               reserve_space_4 : Unused placeholder to match the variance input
               in FusedBatchNorm.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Note that the size of 4D Tensors are defined by either "NHWC" or "NCHW".
               The size of 1D Tensors matches the dimension C of the 4D Tensors.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.fused_batch_norm_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Single},System.String,System.Nullable{System.Boolean},System.String)">
            <summary>
               Batch normalization.
            </summary>
            <param name="x">
               A 4D Tensor for input data.
            </param>
            <param name="scale">
               A 1D Tensor for scaling factor, to scale the normalized x.
            </param>
            <param name="offset">
               A 1D Tensor for offset, to shift to the normalized x.
            </param>
            <param name="mean">
               A 1D Tensor for population mean. Used for inference only;
               must be empty for training.
            </param>
            <param name="variance">
               A 1D Tensor for population variance. Used for inference only;
               must be empty for training.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FusedBatchNormV2'.
            </param>
            <param name="epsilon">
               A small float number added to the variance of x.
            </param>
            <param name="data_format">
               The data format for x and y. Either "NHWC" (default) or "NCHW".
            </param>
            <param name="is_training">
               A bool value to indicate the operation is for training (default)
               or inference.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               y : A 4D Tensor for output data.
               batch_mean : A 1D Tensor for the computed batch mean, to be used by TensorFlow
               to compute the running mean.
               batch_variance : A 1D Tensor for the computed batch variance, to be used by
               TensorFlow to compute the running variance.
               reserve_space_1 : A 1D Tensor for the computed batch mean, to be reused
               in the gradient computation.
               reserve_space_2 : A 1D Tensor for the computed batch variance (inverted variance
               in the cuDNN case), to be reused in the gradient computation.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Note that the size of 4D Tensors are defined by either "NHWC" or "NCHW".
               The size of 1D Tensors matches the dimension C of the 4D Tensors.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.fused_pad_conv2d(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.Int32[],System.String,System.String)">
            <summary>
               Performs a padding as a preprocess during a convolution.
            </summary>
            <param name="input">
               4-D with shape <c>[batch, in_height, in_width, in_channels]</c>.
            </param>
            <param name="paddings">
               A two-column matrix specifying the padding sizes. The number of
               rows must be the same as the rank of <c>input</c>.
            </param>
            <param name="filter">
               4-D with shape
               <c>[filter_height, filter_width, in_channels, out_channels]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FusedPadConv2D'.
            </param>
            <param name="mode">
               Optional argument
            </param>
            <param name="strides">
               Optional argument
               1-D of length 4.  The stride of the sliding window for each dimension
               of <c>input</c>. Must be in the same order as the dimension specified with format.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Similar to FusedResizeAndPadConv2d, this op allows for an optimized
               implementation where the spatial padding transformation stage is fused with the
               im2col lookup, but in this case without the bilinear filtering required for
               resizing. Fusing the padding prevents the need to write out the intermediate
               results as whole tensors, reducing memory pressure, and we can get some latency
               gains by merging the transformation calculations.
               The data_format attribute for Conv2D isn't supported by this op, and 'NHWC'
               order is used instead.
               Internally this op uses a single per-graph scratch buffer, which means that it
               will block if multiple versions are being run in parallel. This is because this
               operator is primarily an optimization to minimize memory usage.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.fused_resize_and_pad_conv2d(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.Int32[],System.String,System.Nullable{System.Boolean},System.String)">
            <summary>
               Performs a resize and padding as a preprocess during a convolution.
            </summary>
            <param name="input">
               4-D with shape <c>[batch, in_height, in_width, in_channels]</c>.
            </param>
            <param name="size">
               A 1-D int32 Tensor of 2 elements: <c>new_height, new_width</c>.  The
               new size for the images.
            </param>
            <param name="paddings">
               A two-column matrix specifying the padding sizes. The number of
               rows must be the same as the rank of <c>input</c>.
            </param>
            <param name="filter">
               4-D with shape
               <c>[filter_height, filter_width, in_channels, out_channels]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'FusedResizeAndPadConv2D'.
            </param>
            <param name="mode">
               Optional argument
            </param>
            <param name="strides">
               Optional argument
               1-D of length 4.  The stride of the sliding window for each dimension
               of <c>input</c>. Must be in the same order as the dimension specified with format.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <param name="resize_align_corners">
               If true, the centers of the 4 corner pixels of the input and output tensors are
               aligned, preserving the values at the corner pixels. Defaults to false.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               It's often possible to do spatial transformations more efficiently as part of
               the packing stage of a convolution, so this op allows for an optimized
               implementation where these stages are fused together. This prevents the need to
               write out the intermediate results as whole tensors, reducing memory pressure,
               and we can get some latency gains by merging the transformation calculations.
               The data_format attribute for Conv2D isn't supported by this op, and defaults to
               'NHWC' order.
               Internally this op uses a single per-graph scratch buffer, which means that it
               will block if multiple versions are being run in parallel. This is because this
               operator is primarily an optimization to minimize memory usage.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.gather(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Gather slices from <c>params</c> according to <c>indices</c>.
            </summary>
            <param name="parameters">
            </param>
            <param name="indices">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Gather'.
            </param>
            <param name="validate_indices">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               <c>indices</c> must be an integer tensor of any dimension (usually 0-D or 1-D).
               Produces an output tensor with shape <c>indices.shape + params.shape[1:]</c> where:
               
              <code>
               # Scalar indices
               output[:, ..., :] = params[indices, :, ... :]
               
               # Vector indices
               output[i, :, ..., :] = params[indices[i], :, ... :]
               
               # Higher rank indices
               output[i, ..., j, :, ... :] = params[indices[i, ..., j], :, ..., :]
              </code>
               
               If <c>indices</c> is a permutation and <c>len(indices) == params.shape[0]</c> then
               this operation will permute <c>params</c> accordingly.
               
               <c>validate_indices</c>: DEPRECATED. If this operation is assigned to CPU, values in
               <c>indices</c> are always validated to be within range. If assigned to GPU,
               out-of-bound indices result in safe but unspecified behavior, which may include
               raising an error.
               
               &amp;lt;div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;"&amp;gt;
               &amp;lt;img style="width:100%" src="https://www.tensorflow.org/images/Gather.png" alt&amp;gt;
               &amp;lt;/div&amp;gt;
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.gather_nd(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Gather slices from <c>params</c> into a Tensor with shape specified by <c>indices</c>.
            </summary>
            <param name="parameters">
               The tensor from which to gather values.
            </param>
            <param name="indices">
               Index tensor.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'GatherNd'.
            </param>
            <returns>
               Values from <c>params</c> gathered from indices given by <c>indices</c>, with
               shape <c>indices.shape[:-1] + params.shape[indices.shape[-1]:]</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               <c>indices</c> is an K-dimensional integer tensor, best thought of as a
               (K-1)-dimensional tensor of indices into <c>params</c>, where each element defines a
               slice of <c>params</c>:
               
               output[\\(i_0, ..., i_{K-2}\\)] = params[indices[\\(i_0, ..., i_{K-2}\\)]]
               
               Whereas in <c>tf.gather</c> <c>indices</c> defines slices into the first
               dimension of <c>params</c>, in <c>tf.gather_nd</c>, <c>indices</c> defines slices into the
               first <c>N</c> dimensions of <c>params</c>, where <c>N = indices.shape[-1]</c>.
               
               The last dimension of <c>indices</c> can be at most the rank of
               <c>params</c>:
               
               indices.shape[-1] &amp;lt;= params.rank
               
               The last dimension of <c>indices</c> corresponds to elements
               (if <c>indices.shape[-1] == params.rank</c>) or slices
               (if <c>indices.shape[-1] &amp;lt; params.rank</c>) along dimension <c>indices.shape[-1]</c>
               of <c>params</c>.  The output tensor has shape
               
               indices.shape[:-1] + params.shape[indices.shape[-1]:]
               
               Note that on CPU, if an out of bound index is found, an error is returned.
               On GPU, if an out of bound index is found, a 0 is stored in the
               corresponding output value.
               
               Some examples below.
               
               Simple indexing into a matrix:
               
              <code>
               indices = [[0, 0], [1, 1]]
               params = [['a', 'b'], ['c', 'd']]
               output = ['a', 'd']
              </code>
               
               Slice indexing into a matrix:
               
              <code>
               indices = [[1], [0]]
               params = [['a', 'b'], ['c', 'd']]
               output = [['c', 'd'], ['a', 'b']]
              </code>
               
               Indexing into a 3-tensor:
               
              <code>
               indices = [[1]]
               params = [[['a0', 'b0'], ['c0', 'd0']],
               [['a1', 'b1'], ['c1', 'd1']]]
               output = [[['a1', 'b1'], ['c1', 'd1']]]
               
               
               indices = [[0, 1], [1, 0]]
               params = [[['a0', 'b0'], ['c0', 'd0']],
               [['a1', 'b1'], ['c1', 'd1']]]
               output = [['c0', 'd0'], ['a1', 'b1']]
               
               
               indices = [[0, 0, 1], [1, 0, 1]]
               params = [[['a0', 'b0'], ['c0', 'd0']],
               [['a1', 'b1'], ['c1', 'd1']]]
               output = ['b0', 'b1']
              </code>
               
               Batched indexing into a matrix:
               
              <code>
               indices = [[[0, 0]], [[0, 1]]]
               params = [['a', 'b'], ['c', 'd']]
               output = [['a'], ['b']]
              </code>
               
               Batched slice indexing into a matrix:
               
              <code>
               indices = [[[1]], [[0]]]
               params = [['a', 'b'], ['c', 'd']]
               output = [[['c', 'd']], [['a', 'b']]]
              </code>
               
               Batched indexing into a 3-tensor:
               
              <code>
               indices = [[[1]], [[0]]]
               params = [[['a0', 'b0'], ['c0', 'd0']],
               [['a1', 'b1'], ['c1', 'd1']]]
               output = [[[['a1', 'b1'], ['c1', 'd1']]],
               [[['a0', 'b0'], ['c0', 'd0']]]]
               
               indices = [[[0, 1], [1, 0]], [[0, 0], [1, 1]]]
               params = [[['a0', 'b0'], ['c0', 'd0']],
               [['a1', 'b1'], ['c1', 'd1']]]
               output = [[['c0', 'd0'], ['a1', 'b1']],
               [['a0', 'b0'], ['c1', 'd1']]]
               
               
               indices = [[[0, 0, 1], [1, 0, 1]], [[0, 1, 1], [1, 1, 0]]]
               params = [[['a0', 'b0'], ['c0', 'd0']],
               [['a1', 'b1'], ['c1', 'd1']]]
               output = [['b0', 'b1'], ['d0', 'c1']]
              </code>
               
               See also <c>tf.gather</c> and <c>tf.batch_gather</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.gather_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Gather slices from <c>params</c> axis <c>axis</c> according to <c>indices</c>.
            </summary>
            <param name="parameters">
               The tensor from which to gather values. Must be at least rank
               <c>axis + 1</c>.
            </param>
            <param name="indices">
               Index tensor. Must be in range <c>[0, params.shape[axis])</c>.
            </param>
            <param name="axis">
               The axis in <c>params</c> to gather <c>indices</c> from. Defaults to the first
               dimension. Supports negative indexes.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'GatherV2'.
            </param>
            <returns>
               Values from <c>params</c> gathered from indices given by <c>indices</c>, with
               shape <c>params.shape[:axis] + indices.shape + params.shape[axis + 1:]</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               <c>indices</c> must be an integer tensor of any dimension (usually 0-D or 1-D).
               Produces an output tensor with shape <c>params.shape[:axis] + indices.shape +
               params.shape[axis + 1:]</c> where:
               
              <code>
               # Scalar indices (output is rank(params) - 1).
               output[a_0, ..., a_n, b_0, ..., b_n] =
               params[a_0, ..., a_n, indices, b_0, ..., b_n]
               
               # Vector indices (output is rank(params)).
               output[a_0, ..., a_n, i, b_0, ..., b_n] =
               params[a_0, ..., a_n, indices[i], b_0, ..., b_n]
               
               # Higher rank indices (output is rank(params) + rank(indices) - 1).
               output[a_0, ..., a_n, i, ..., j, b_0, ... b_n] =
               params[a_0, ..., a_n, indices[i, ..., j], b_0, ..., b_n]
              </code>
               
               &amp;lt;div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;"&amp;gt;
               &amp;lt;img style="width:100%" src="https://www.tensorflow.org/images/Gather.png" alt&amp;gt;
               &amp;lt;/div&amp;gt;
               
               Note that on CPU, if an out of bound index is found, an error is returned.
               On GPU, if an out of bound index is found, a 0 is stored in the
               corresponding output value.
               
               See also <c>tf.batch_gather</c> and <c>tf.gather_nd</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.generate_vocab_remapping(Tensorflow.Tensor,Tensorflow.Tensor,System.Int32,System.Int32,System.Nullable{System.Int32},System.String)">
            <summary>
               Given a path to new and old vocabulary files, returns a remapping Tensor of
            </summary>
            <param name="new_vocab_file">
               Path to the new vocab file.
            </param>
            <param name="old_vocab_file">
               Path to the old vocab file.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'GenerateVocabRemapping'.
            </param>
            <param name="new_vocab_offset">
               Optional argument
               How many entries into the new vocab file to start reading.
            </param>
            <param name="num_new_vocab">
               Optional argument
               Number of entries in the new vocab file to remap.
            </param>
            <param name="old_vocab_size">
               Number of entries in the old vocab file to consider.  If -1,
               use the entire old vocabulary.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               remapping : A Tensor of length num_new_vocab where the element at index i
               is equal to the old ID that maps to the new ID i.  This element is -1 for any
               new ID that is not found in the old vocabulary.
               num_present : Number of new vocab entries found in old vocab.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               length <c>num_new_vocab</c>, where <c>remapping[i]</c> contains the row number in the old
               vocabulary that corresponds to row <c>i</c> in the new vocabulary (starting at line
               <c>new_vocab_offset</c> and up to <c>num_new_vocab</c> entities), or <c>-1</c> if entry <c>i</c>
               in the new vocabulary is not in the old vocabulary.  The old vocabulary is
               constrained to the first <c>old_vocab_size</c> entries if <c>old_vocab_size</c> is not the
               default value of -1.
               
               <c>num_vocab_offset</c> enables
               use in the partitioned variable case, and should generally be set through
               examining partitioning info.  The format of the files should be a text file,
               with each line containing a single entity within the vocabulary.
               
               For example, with <c>new_vocab_file</c> a text file containing each of the following
               elements on a single line: <c>[f0, f1, f2, f3]</c>, old_vocab_file = [f1, f0, f3],
               <c>num_new_vocab = 3, new_vocab_offset = 1</c>, the returned remapping would be
               <c>[0, -1, 2]</c>.
               
               The op also returns a count of how many entries in the new vocabulary
               were present in the old vocabulary, which is used to calculate the number of
               values to initialize in a weight matrix remapping
               
               This functionality can be used to remap both row vocabularies (typically,
               features) and column vocabularies (typically, classes) from TensorFlow
               checkpoints.  Note that the partitioning logic relies on contiguous vocabularies
               corresponding to div-partitioned variables.  Moreover, the underlying remapping
               uses an IndexTable (as opposed to an inexact CuckooTable), so client code should
               use the corresponding index_table_from_file() as the FeatureColumn framework
               does (as opposed to tf.feature_to_id(), which uses a CuckooTable).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.get_session_handle(Tensorflow.Tensor,System.String)">
            <summary>
               Store the input tensor in the state of the current session.
            </summary>
            <param name="value">
               The tensor to be stored.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'GetSessionHandle'.
            </param>
            <returns>
               The handle for the tensor stored in the session state, represented
               as a string.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.get_session_handle_v2(Tensorflow.Tensor,System.String)">
            <summary>
               Store the input tensor in the state of the current session.
            </summary>
            <param name="value">
               The tensor to be stored.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'GetSessionHandleV2'.
            </param>
            <returns>
               The handle for the tensor stored in the session state, represented
               as a ResourceHandle object.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.get_session_tensor(Tensorflow.Tensor,Tensorflow.TF_DataType,System.String)">
            <summary>
               Get the value of the tensor specified by its handle.
            </summary>
            <param name="handle">
               The handle for a tensor stored in the session state.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'GetSessionTensor'.
            </param>
            <param name="dtype">
               Optional argument
               The type of the output value.
            </param>
            <returns>
               The tensor for the given handle.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.greater(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns the truth value of (x &amp;gt; y) element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Greater'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               *NOTE*: <c>Greater</c> supports broadcasting. More about broadcasting
               [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.greater_equal(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns the truth value of (x &amp;gt;= y) element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'GreaterEqual'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               *NOTE*: <c>GreaterEqual</c> supports broadcasting. More about broadcasting
               [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.guarantee_const(Tensorflow.Tensor,System.String)">
            <summary>
               Gives a guarantee to the TF runtime that the input tensor is a constant.
            </summary>
            <param name="input">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'GuaranteeConst'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The runtime is then free to make optimizations based on this.
               
               Only accepts value typed tensors as inputs and rejects resource variable handles
               as input.
               
               Returns the input tensor without modification.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.h_s_v_to_r_g_b(Tensorflow.Tensor,System.String)">
            <summary>
               Convert one or more images from HSV to RGB.
            </summary>
            <param name="images">
               1-D or higher rank. HSV data to convert. Last dimension must be size 3.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'HSVToRGB'.
            </param>
            <returns>
               <c>images</c> converted to RGB.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Outputs a tensor of the same shape as the <c>images</c> tensor, containing the RGB
               value of the pixels. The output is only well defined if the value in <c>images</c>
               are in <c>[0,1]</c>.
               
               See <c>rgb_to_hsv</c> for a description of the HSV encoding.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.hash_table(Tensorflow.TF_DataType,Tensorflow.TF_DataType,System.String,System.String,System.Nullable{System.Boolean},System.String)">
            <summary>
               Creates a non-initialized hash table.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'HashTable'.
            </param>
            <param name="key_dtype">
               Optional argument
               Type of the table keys.
            </param>
            <param name="value_dtype">
               Optional argument
               Type of the table values.
            </param>
            <param name="container">
               If non-empty, this table is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this table is shared under the given name across
               multiple sessions.
            </param>
            <param name="use_node_name_sharing">
               If true and shared_name is empty, the table is shared
               using the node name.
            </param>
            <returns>
               Handle to a table.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This op creates a hash table, specifying the type of its keys and values.
               Before using the table you will have to initialize it.  After initialization the
               table will be immutable.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.hash_table_v2(Tensorflow.TF_DataType,Tensorflow.TF_DataType,System.String,System.String,System.Nullable{System.Boolean},System.String)">
            <summary>
               Creates a non-initialized hash table.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'HashTableV2'.
            </param>
            <param name="key_dtype">
               Optional argument
               Type of the table keys.
            </param>
            <param name="value_dtype">
               Optional argument
               Type of the table values.
            </param>
            <param name="container">
               If non-empty, this table is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this table is shared under the given name across
               multiple sessions.
            </param>
            <param name="use_node_name_sharing">
               If true and shared_name is empty, the table is shared
               using the node name.
            </param>
            <returns>
               Handle to a table.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This op creates a hash table, specifying the type of its keys and values.
               Before using the table you will have to initialize it.  After initialization the
               table will be immutable.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.histogram_fixed_width(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Return histogram of values.
            </summary>
            <param name="values">
               Numeric <c>Tensor</c>.
            </param>
            <param name="value_range">
               Shape [2] <c>Tensor</c> of same <c>dtype</c> as <c>values</c>.
               values &amp;lt;= value_range[0] will be mapped to hist[0],
               values &amp;gt;= value_range[1] will be mapped to hist[-1].
            </param>
            <param name="nbins">
               Scalar <c>int32 Tensor</c>.  Number of histogram bins.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'HistogramFixedWidth'.
            </param>
            <param name="dtype">
            </param>
            <returns>
               A 1-D <c>Tensor</c> holding histogram of values.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Given the tensor <c>values</c>, this operation returns a rank 1 histogram counting
               the number of entries in <c>values</c> that fall into every bin.  The bins are
               equal width and determined by the arguments <c>value_range</c> and <c>nbins</c>.
               
              <code>
               # Bins will be:  (-inf, 1), [1, 2), [2, 3), [3, 4), [4, inf)
               nbins = 5
               value_range = [0.0, 5.0]
               new_values = [-1.0, 0.0, 1.5, 2.0, 5.0, 15]
               
               with tf.get_default_session() as sess:
               hist = tf.histogram_fixed_width(new_values, value_range, nbins=5)
               variables.global_variables_initializer().run()
               sess.run(hist) =&amp;gt; [2, 1, 1, 0, 2]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.histogram_summary(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Outputs a <c>Summary</c> protocol buffer with a histogram.
            </summary>
            <param name="tag">
               Scalar.  Tag to use for the <c>Summary.Value</c>.
            </param>
            <param name="values">
               Any shape. Values to use to build the histogram.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'HistogramSummary'.
            </param>
            <returns>
               Scalar. Serialized <c>Summary</c> protocol buffer.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The generated
               [<c>Summary</c>](https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto)
               has one summary value containing a histogram for <c>values</c>.
               
               This op reports an <c>InvalidArgument</c> error if any value is not finite.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.host_const(Tensorflow.Tensor,Tensorflow.TF_DataType,System.String)">
            <summary>
               Returns a constant tensor on the host. Only for writing C++ tests.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'HostConst'.
            </param>
            <param name="value">
               Optional argument
               Attr <c>value</c> is the tensor to return.
            </param>
            <param name="dtype">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.i_f_f_t(Tensorflow.Tensor,System.String)">
            <summary>
               Inverse fast Fourier transform.
            </summary>
            <param name="input">
               A complex64 tensor.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'IFFT'.
            </param>
            <returns>
               A complex64 tensor of the same shape as <c>input</c>. The inner-most
               dimension of <c>input</c> is replaced with its inverse 1D Fourier transform.
               
               @compatibility(numpy)
               Equivalent to np.fft.ifft
               @end_compatibility
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Computes the inverse 1-dimensional discrete Fourier transform over the
               inner-most dimension of <c>input</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.i_f_f_t2d(Tensorflow.Tensor,System.String)">
            <summary>
               Inverse 2D fast Fourier transform.
            </summary>
            <param name="input">
               A complex64 tensor.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'IFFT2D'.
            </param>
            <returns>
               A complex64 tensor of the same shape as <c>input</c>. The inner-most 2
               dimensions of <c>input</c> are replaced with their inverse 2D Fourier transform.
               
               @compatibility(numpy)
               Equivalent to np.fft.ifft2
               @end_compatibility
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Computes the inverse 2-dimensional discrete Fourier transform over the
               inner-most 2 dimensions of <c>input</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.i_f_f_t3d(Tensorflow.Tensor,System.String)">
            <summary>
               Inverse 3D fast Fourier transform.
            </summary>
            <param name="input">
               A complex64 tensor.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'IFFT3D'.
            </param>
            <returns>
               A complex64 tensor of the same shape as <c>input</c>. The inner-most 3
               dimensions of <c>input</c> are replaced with their inverse 3D Fourier transform.
               
               @compatibility(numpy)
               Equivalent to np.fft.ifftn with 3 dimensions.
               @end_compatibility
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Computes the inverse 3-dimensional discrete Fourier transform over the
               inner-most 3 dimensions of <c>input</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.i_r_f_f_t(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Inverse real-valued fast Fourier transform.
            </summary>
            <param name="input">
               A complex64 tensor.
            </param>
            <param name="fft_length">
               An int32 tensor of shape [1]. The FFT length.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'IRFFT'.
            </param>
            <returns>
               A float32 tensor of the same rank as <c>input</c>. The inner-most
               dimension of <c>input</c> is replaced with the <c>fft_length</c> samples of its inverse
               1D Fourier transform.
               
               @compatibility(numpy)
               Equivalent to np.fft.irfft
               @end_compatibility
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Computes the inverse 1-dimensional discrete Fourier transform of a real-valued
               signal over the inner-most dimension of <c>input</c>.
               
               The inner-most dimension of <c>input</c> is assumed to be the result of <c>RFFT</c>: the
               <c>fft_length / 2 + 1</c> unique components of the DFT of a real-valued signal. If
               <c>fft_length</c> is not provided, it is computed from the size of the inner-most
               dimension of <c>input</c> (<c>fft_length = 2 * (inner - 1)</c>). If the FFT length used to
               compute <c>input</c> is odd, it should be provided since it cannot be inferred
               properly.
               
               Along the axis <c>IRFFT</c> is computed on, if <c>fft_length / 2 + 1</c> is smaller
               than the corresponding dimension of <c>input</c>, the dimension is cropped. If it is
               larger, the dimension is padded with zeros.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.i_r_f_f_t2d(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Inverse 2D real-valued fast Fourier transform.
            </summary>
            <param name="input">
               A complex64 tensor.
            </param>
            <param name="fft_length">
               An int32 tensor of shape [2]. The FFT length for each dimension.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'IRFFT2D'.
            </param>
            <returns>
               A float32 tensor of the same rank as <c>input</c>. The inner-most 2
               dimensions of <c>input</c> are replaced with the <c>fft_length</c> samples of their
               inverse 2D Fourier transform.
               
               @compatibility(numpy)
               Equivalent to np.fft.irfft2
               @end_compatibility
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Computes the inverse 2-dimensional discrete Fourier transform of a real-valued
               signal over the inner-most 2 dimensions of <c>input</c>.
               
               The inner-most 2 dimensions of <c>input</c> are assumed to be the result of <c>RFFT2D</c>:
               The inner-most dimension contains the <c>fft_length / 2 + 1</c> unique components of
               the DFT of a real-valued signal. If <c>fft_length</c> is not provided, it is computed
               from the size of the inner-most 2 dimensions of <c>input</c>. If the FFT length used
               to compute <c>input</c> is odd, it should be provided since it cannot be inferred
               properly.
               
               Along each axis <c>IRFFT2D</c> is computed on, if <c>fft_length</c> (or
               <c>fft_length / 2 + 1</c> for the inner-most dimension) is smaller than the
               corresponding dimension of <c>input</c>, the dimension is cropped. If it is larger,
               the dimension is padded with zeros.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.i_r_f_f_t3d(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Inverse 3D real-valued fast Fourier transform.
            </summary>
            <param name="input">
               A complex64 tensor.
            </param>
            <param name="fft_length">
               An int32 tensor of shape [3]. The FFT length for each dimension.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'IRFFT3D'.
            </param>
            <returns>
               A float32 tensor of the same rank as <c>input</c>. The inner-most 3
               dimensions of <c>input</c> are replaced with the <c>fft_length</c> samples of their
               inverse 3D real Fourier transform.
               
               @compatibility(numpy)
               Equivalent to np.irfftn with 3 dimensions.
               @end_compatibility
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Computes the inverse 3-dimensional discrete Fourier transform of a real-valued
               signal over the inner-most 3 dimensions of <c>input</c>.
               
               The inner-most 3 dimensions of <c>input</c> are assumed to be the result of <c>RFFT3D</c>:
               The inner-most dimension contains the <c>fft_length / 2 + 1</c> unique components of
               the DFT of a real-valued signal. If <c>fft_length</c> is not provided, it is computed
               from the size of the inner-most 3 dimensions of <c>input</c>. If the FFT length used
               to compute <c>input</c> is odd, it should be provided since it cannot be inferred
               properly.
               
               Along each axis <c>IRFFT3D</c> is computed on, if <c>fft_length</c> (or
               <c>fft_length / 2 + 1</c> for the inner-most dimension) is smaller than the
               corresponding dimension of <c>input</c>, the dimension is cropped. If it is larger,
               the dimension is padded with zeros.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.identity(Tensorflow.Tensor,System.String)">
            <summary>
               Return a tensor with the same shape and contents as the input tensor or value.
            </summary>
            <param name="input">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Identity'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.identity_n(Tensorflow.Tensor[],System.String)">
            <summary>
               Returns a list of tensors with the same shapes and contents as the input
            </summary>
            <param name="input">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'IdentityN'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               tensors.
               
               This op can be used to override the gradient for complicated functions. For
               example, suppose y = f(x) and we wish to apply a custom function g for backprop
               such that dx = g(dy). In Python,
               
              <code>
               with tf.get_default_graph().gradient_override_map(
               {'IdentityN': 'OverrideGradientWithG'}):
               y, _ = identity_n([f(x), x])
               
               @tf.RegisterGradient('OverrideGradientWithG')
               def ApplyG(op, dy, _):
               return [None, g(dy)]  # Do not backprop to f(x).
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.identity_reader(System.String,System.String,System.String)">
            <summary>
               A Reader that outputs the queued work as both the key and value.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'IdentityReader'.
            </param>
            <param name="container">
               If non-empty, this reader is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this reader is named in the given bucket
               with this shared_name. Otherwise, the node name is used instead.
            </param>
            <returns>
               The handle to reference the Reader.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               To use, enqueue strings in a Queue.  ReaderRead will take the front
               work string and output (work, work).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.identity_reader_v2(System.String,System.String,System.String)">
            <summary>
               A Reader that outputs the queued work as both the key and value.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'IdentityReaderV2'.
            </param>
            <param name="container">
               If non-empty, this reader is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this reader is named in the given bucket
               with this shared_name. Otherwise, the node name is used instead.
            </param>
            <returns>
               The handle to reference the Reader.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               To use, enqueue strings in a Queue.  ReaderRead will take the front
               work string and output (work, work).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.igamma(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Compute the lower regularized incomplete Gamma function <c>P(a, x)</c>.
            </summary>
            <param name="a">
            </param>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Igamma'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The lower regularized incomplete Gamma function is defined as:
               
               
               \\(P(a, x) = gamma(a, x) / Gamma(a) = 1 - Q(a, x)\\)
               
               where
               
               \\(gamma(a, x) = \\int_{0}^{x} t^{a-1} exp(-t) dt\\)
               
               is the lower incomplete Gamma function.
               
               Note, above <c>Q(a, x)</c> (<c>Igammac</c>) is the upper regularized complete
               Gamma function.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.igamma_grad_a(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes the gradient of <c>igamma(a, x)</c> wrt <c>a</c>.
            </summary>
            <param name="a">
            </param>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'IgammaGradA'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.igammac(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Compute the upper regularized incomplete Gamma function <c>Q(a, x)</c>.
            </summary>
            <param name="a">
            </param>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Igammac'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The upper regularized incomplete Gamma function is defined as:
               
               \\(Q(a, x) = Gamma(a, x) / Gamma(a) = 1 - P(a, x)\\)
               
               where
               
               \\(Gamma(a, x) = int_{x}^{\infty} t^{a-1} exp(-t) dt\\)
               
               is the upper incomplete Gama function.
               
               Note, above <c>P(a, x)</c> (<c>Igamma</c>) is the lower regularized complete
               Gamma function.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.imag(Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Returns the imaginary part of a complex number.
            </summary>
            <param name="input">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Imag'.
            </param>
            <param name="Tout">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Given a tensor <c>input</c> of complex numbers, this operation returns a tensor of
               type <c>float</c> that is the imaginary part of each element in <c>input</c>. All
               elements in <c>input</c> must be complex numbers of the form \\(a + bj\\), where *a*
               is the real part and *b* is the imaginary part returned by this operation.
               
               For example:
               
              <code>
               # tensor 'input' is [-2.25 + 4.75j, 3.25 + 5.75j]
               tf.imag(input) ==&amp;gt; [4.75, 5.75]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.image_summary(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Int32},Tensorflow.Tensor,System.String)">
            <summary>
               Outputs a <c>Summary</c> protocol buffer with images.
            </summary>
            <param name="tag">
               Scalar. Used to build the <c>tag</c> attribute of the summary values.
            </param>
            <param name="tensor">
               4-D of shape <c>[batch_size, height, width, channels]</c> where
               <c>channels</c> is 1, 3, or 4.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ImageSummary'.
            </param>
            <param name="max_images">
               Max number of batch elements to generate images for.
            </param>
            <param name="bad_color">
               Color to use for pixels with non-finite values.
            </param>
            <returns>
               Scalar. Serialized <c>Summary</c> protocol buffer.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The summary has up to <c>max_images</c> summary values containing images. The
               images are built from <c>tensor</c> which must be 4-D with shape <c>[batch_size,
               height, width, channels]</c> and where <c>channels</c> can be:
               
               *  1: <c>tensor</c> is interpreted as Grayscale.
               *  3: <c>tensor</c> is interpreted as RGB.
               *  4: <c>tensor</c> is interpreted as RGBA.
               
               The images have the same number of channels as the input tensor. For float
               input, the values are normalized one image at a time to fit in the range
               <c>[0, 255]</c>.  <c>uint8</c> values are unchanged.  The op uses two different
               normalization algorithms:
               
               *  If the input values are all positive, they are rescaled so the largest one
               is 255.
               
               *  If any input value is negative, the values are shifted so input value 0.0
               is at 127.  They are then rescaled so that either the smallest value is 0,
               or the largest one is 255.
               
               The <c>tag</c> argument is a scalar <c>Tensor</c> of type <c>string</c>.  It is used to
               build the <c>tag</c> of the summary values:
               
               *  If <c>max_images</c> is 1, the summary value tag is '*tag*/image'.
               *  If <c>max_images</c> is greater than 1, the summary value tags are
               generated sequentially as '*tag*/image/0', '*tag*/image/1', etc.
               
               The <c>bad_color</c> argument is the color to use in the generated images for
               non-finite input values.  It is a <c>uint8</c> 1-D tensor of length <c>channels</c>.
               Each element must be in the range <c>[0, 255]</c> (It represents the value of a
               pixel in the output image).  Non-finite values in the input tensor are
               replaced by this tensor in the output image.  The default value is the color
               red.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.immutable_const(Tensorflow.TF_DataType,Tensorflow.TensorShape,System.String,System.String)">
            <summary>
               Returns immutable tensor from memory region.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ImmutableConst'.
            </param>
            <param name="dtype">
               Optional argument
               Type of the returned tensor.
            </param>
            <param name="shape">
               Optional argument
               Shape of the returned tensor.
            </param>
            <param name="memory_region_name">
               Optional argument
               Name of readonly memory region used by the tensor, see
               NewReadOnlyMemoryRegionFromFile in tensorflow::Env.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The current implementation memmaps the tensor from a file.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.in_top_k(Tensorflow.Tensor,Tensorflow.Tensor,System.Int32,System.String)">
            <summary>
               Says whether the targets are in the top <c>K</c> predictions.
            </summary>
            <param name="predictions">
               A <c>batch_size</c> x <c>classes</c> tensor.
            </param>
            <param name="targets">
               A <c>batch_size</c> vector of class ids.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'InTopK'.
            </param>
            <param name="k">
               Optional argument
               Number of top elements to look at for computing precision.
            </param>
            <returns>
               Computed Precision at <c>k</c> as a <c>bool Tensor</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This outputs a <c>batch_size</c> bool array, an entry <c>out[i]</c> is <c>true</c> if the
               prediction for the target class is among the top <c>k</c> predictions among
               all predictions for example <c>i</c>. Note that the behavior of <c>InTopK</c> differs
               from the <c>TopK</c> op in its handling of ties; if multiple classes have the
               same prediction value and straddle the top-<c>k</c> boundary, all of those
               classes are considered to be in the top <c>k</c>.
               
               More formally, let
               
               \\(predictions_i\\) be the predictions for all classes for example <c>i</c>,
               \\(targets_i\\) be the target class for example <c>i</c>,
               \\(out_i\\) be the output for example <c>i</c>,
               
               $$out_i = predictions_{i, targets_i} \in TopKIncludingTies(predictions_i)$$
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.in_top_k_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Says whether the targets are in the top <c>K</c> predictions.
            </summary>
            <param name="predictions">
               A <c>batch_size</c> x <c>classes</c> tensor.
            </param>
            <param name="targets">
               A <c>batch_size</c> vector of class ids.
            </param>
            <param name="k">
               Number of top elements to look at for computing precision.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'InTopKV2'.
            </param>
            <returns>
               Computed precision at <c>k</c> as a <c>bool Tensor</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This outputs a <c>batch_size</c> bool array, an entry <c>out[i]</c> is <c>true</c> if the
               prediction for the target class is among the top <c>k</c> predictions among
               all predictions for example <c>i</c>. Note that the behavior of <c>InTopK</c> differs
               from the <c>TopK</c> op in its handling of ties; if multiple classes have the
               same prediction value and straddle the top-<c>k</c> boundary, all of those
               classes are considered to be in the top <c>k</c>.
               
               More formally, let
               
               \\(predictions_i\\) be the predictions for all classes for example <c>i</c>,
               \\(targets_i\\) be the target class for example <c>i</c>,
               \\(out_i\\) be the output for example <c>i</c>,
               
               $$out_i = predictions_{i, targets_i} \in TopKIncludingTies(predictions_i)$$
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.infeed_dequeue(Tensorflow.TF_DataType,Tensorflow.TensorShape,System.String)">
            <summary>
               A placeholder op for a value that will be fed into the computation.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'InfeedDequeue'.
            </param>
            <param name="dtype">
               Optional argument
               The type of elements in the tensor.
            </param>
            <param name="shape">
               Optional argument
               The shape of the tensor.
            </param>
            <returns>
               A tensor that will be provided using the infeed mechanism.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.infeed_dequeue_tuple(Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               A placeholder op for multiple values that will be fed into the computation
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'InfeedDequeueTuple'.
            </param>
            <param name="dtypes">
               Optional argument
               The element types of each element in <c>outputs</c>.
            </param>
            <param name="shapes">
               Optional argument
               The shapes of each tensor in <c>outputs</c>.
            </param>
            <returns>
               A list of tensors that will be provided using the infeed mechanism.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               simultaneously as an XLA tuple.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.infeed_enqueue(Tensorflow.Tensor,Tensorflow.TensorShape,System.Nullable{System.Int32},System.String)">
            <summary>
               An op which feeds a single Tensor value into the computation.
            </summary>
            <param name="input">
               A tensor that will be provided using the infeed mechanism.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'InfeedEnqueue'.
            </param>
            <param name="shape">
               The shape of the tensor.
            </param>
            <param name="device_ordinal">
               The TPU device to use. This should be -1 when the Op
               is running on a TPU device, and &amp;gt;= 0 when the Op is running on the CPU
               device.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.infeed_enqueue_tuple(Tensorflow.Tensor[],Tensorflow.TensorShape[],System.Nullable{System.Int32},System.String)">
            <summary>
               An op which feeds multiple Tensor values into the computation as an XLA tuple.
            </summary>
            <param name="inputs">
               A list of tensors that will be provided using the infeed mechanism.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'InfeedEnqueueTuple'.
            </param>
            <param name="shapes">
               Optional argument
               The shapes of each tensor in <c>inputs</c>.
            </param>
            <param name="device_ordinal">
               The TPU device to use. This should be -1 when the Op
               is running on a TPU device, and &amp;gt;= 0 when the Op is running on the CPU
               device.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.initialize_table(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Table initializer that takes two tensors for keys and values respectively.
            </summary>
            <param name="table_handle">
               Handle to a table which will be initialized.
            </param>
            <param name="keys">
               Keys of type Tkey.
            </param>
            <param name="values">
               Values of type Tval.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'InitializeTable'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.initialize_table_from_text_file(Tensorflow.Tensor,Tensorflow.Tensor,System.Int32,System.Int32,System.Nullable{System.Int32},System.String,System.String)">
            <summary>
               Initializes a table from a text file.
            </summary>
            <param name="table_handle">
               Handle to a table which will be initialized.
            </param>
            <param name="filename">
               Filename of a vocabulary text file.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'InitializeTableFromTextFile'.
            </param>
            <param name="key_index">
               Optional argument
               Column index in a line to get the table <c>key</c> values from.
            </param>
            <param name="value_index">
               Optional argument
               Column index that represents information of a line to get the table
               <c>value</c> values from.
            </param>
            <param name="vocab_size">
               Number of elements of the file, use -1 if unknown.
            </param>
            <param name="delimiter">
               Delimiter to separate fields in a line.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               It inserts one key-value pair into the table for each line of the file.
               The key and value is extracted from the whole line content, elements from the
               split line based on <c>delimiter</c> or the line number (starting from zero).
               Where to extract the key and value from a line is specified by <c>key_index</c> and
               <c>value_index</c>.
               
               - A value of -1 means use the line number(starting from zero), expects <c>int64</c>.
               - A value of -2 means use the whole line content, expects <c>string</c>.
               - A value &amp;gt;= 0 means use the index (starting at zero) of the split line based
               on <c>delimiter</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.initialize_table_from_text_file_v2(Tensorflow.Tensor,Tensorflow.Tensor,System.Int32,System.Int32,System.Nullable{System.Int32},System.String,System.String)">
            <summary>
               Initializes a table from a text file.
            </summary>
            <param name="table_handle">
               Handle to a table which will be initialized.
            </param>
            <param name="filename">
               Filename of a vocabulary text file.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'InitializeTableFromTextFileV2'.
            </param>
            <param name="key_index">
               Optional argument
               Column index in a line to get the table <c>key</c> values from.
            </param>
            <param name="value_index">
               Optional argument
               Column index that represents information of a line to get the table
               <c>value</c> values from.
            </param>
            <param name="vocab_size">
               Number of elements of the file, use -1 if unknown.
            </param>
            <param name="delimiter">
               Delimiter to separate fields in a line.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               It inserts one key-value pair into the table for each line of the file.
               The key and value is extracted from the whole line content, elements from the
               split line based on <c>delimiter</c> or the line number (starting from zero).
               Where to extract the key and value from a line is specified by <c>key_index</c> and
               <c>value_index</c>.
               
               - A value of -1 means use the line number(starting from zero), expects <c>int64</c>.
               - A value of -2 means use the whole line content, expects <c>string</c>.
               - A value &amp;gt;= 0 means use the index (starting at zero) of the split line based
               on <c>delimiter</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.initialize_table_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Table initializer that takes two tensors for keys and values respectively.
            </summary>
            <param name="table_handle">
               Handle to a table which will be initialized.
            </param>
            <param name="keys">
               Keys of type Tkey.
            </param>
            <param name="values">
               Values of type Tval.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'InitializeTableV2'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.inplace_add(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Adds v into specified rows of x.
               
               Computes y = x; y[i, :] += v; return y.
            </summary>
            <param name="x">
               A <c>Tensor</c> of type T.
            </param>
            <param name="i">
               A vector. Indices into the left-most dimension of <c>x</c>.
            </param>
            <param name="v">
               A <c>Tensor</c> of type T. Same dimension sizes as x except the first dimension, which must be the same as i's size.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'InplaceAdd'.
            </param>
            <returns>
               A <c>Tensor</c> of type T. An alias of <c>x</c>. The content of <c>y</c> is undefined if there are duplicates in <c>i</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.inplace_sub(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Subtracts <c>v</c> into specified rows of <c>x</c>.
               
               Computes y = x; y[i, :] -= v; return y.
            </summary>
            <param name="x">
               A <c>Tensor</c> of type T.
            </param>
            <param name="i">
               A vector. Indices into the left-most dimension of <c>x</c>.
            </param>
            <param name="v">
               A <c>Tensor</c> of type T. Same dimension sizes as x except the first dimension, which must be the same as i's size.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'InplaceSub'.
            </param>
            <returns>
               A <c>Tensor</c> of type T. An alias of <c>x</c>. The content of <c>y</c> is undefined if there are duplicates in <c>i</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.inplace_update(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Updates specified rows with values in <c>v</c>.
               
               Computes <c>x[i, :] = v; return x</c>.
            </summary>
            <param name="x">
               A tensor of type <c>T</c>.
            </param>
            <param name="i">
               A vector. Indices into the left-most dimension of <c>x</c>.
            </param>
            <param name="v">
               A <c>Tensor</c> of type T. Same dimension sizes as x except the first dimension, which must be the same as i's size.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'InplaceUpdate'.
            </param>
            <returns>
               A <c>Tensor</c> of type T. An alias of <c>x</c>. The content of <c>y</c> is undefined if there are duplicates in <c>i</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.inv(Tensorflow.Tensor,System.String)">
            <summary>
               Computes the reciprocal of x element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Inv'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               I.e., \\(y = 1 / x\\).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.inv_grad(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes the gradient for the inverse of <c>x</c> wrt its input.
            </summary>
            <param name="y">
            </param>
            <param name="dy">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'InvGrad'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Specifically, <c>grad = -dy * y*y</c>, where <c>y = 1/x</c>, and <c>dy</c>
               is the corresponding input gradient.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.invert(Tensorflow.Tensor,System.String)">
            <summary>
               Flips all bits elementwise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Invert'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The result will have exactly those bits set, that are not set in <c>x</c>. The
               computation is performed on the underlying representation of x.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.invert_permutation(Tensorflow.Tensor,System.String)">
            <summary>
               Computes the inverse permutation of a tensor.
            </summary>
            <param name="x">
               1-D.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'InvertPermutation'.
            </param>
            <returns>
               1-D.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation computes the inverse of an index permutation. It takes a 1-D
               integer tensor <c>x</c>, which represents the indices of a zero-based array, and
               swaps each value with its index position. In other words, for an output tensor
               <c>y</c> and an input tensor <c>x</c>, this operation computes the following:
               
               <c>y[x[i]] = i for i in [0, 1, ..., len(x) - 1]</c>
               
               The values must include 0. There can be no duplicate values or negative values.
               
               For example:
               
              <code>
               # tensor <c>x</c> is [3, 4, 0, 2, 1]
               invert_permutation(x) ==&amp;gt; [2, 4, 3, 0, 1]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.is_boosted_trees_ensemble_initialized(Tensorflow.Tensor,System.String)">
            <summary>
               Checks whether a tree ensemble has been initialized.
            </summary>
            <param name="tree_ensemble_handle">
               Handle to the tree ensemble resouce.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'IsBoostedTreesEnsembleInitialized'.
            </param>
            <returns>
               output boolean on whether it is initialized or not.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.is_finite(Tensorflow.Tensor,System.String)">
            <summary>
               Returns which elements of x are finite.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'IsFinite'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               @compatibility(numpy)
               Equivalent to np.isfinite
               @end_compatibility
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.is_inf(Tensorflow.Tensor,System.String)">
            <summary>
               Returns which elements of x are Inf.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'IsInf'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               @compatibility(numpy)
               Equivalent to np.isinf
               @end_compatibility
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.is_nan(Tensorflow.Tensor,System.String)">
            <summary>
               Returns which elements of x are NaN.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'IsNan'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               @compatibility(numpy)
               Equivalent to np.isnan
               @end_compatibility
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.is_variable_initialized(Tensorflow.Tensor,System.String)">
            <summary>
               Checks whether a tensor has been initialized.
            </summary>
            <param name="referecne">
               Should be from a <c>Variable</c> node. May be uninitialized.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'IsVariableInitialized'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Outputs boolean scalar indicating whether the tensor has been initialized.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.iterator(System.String,System.String,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               A container for an iterator resource.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Iterator'.
            </param>
            <param name="shared_name">
               Optional argument
            </param>
            <param name="container">
               Optional argument
            </param>
            <param name="output_types">
               Optional argument
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               A handle to the iterator that can be passed to a "MakeIterator"
               or "IteratorGetNext" op.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.iterator_from_string_handle(Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Converts the given string representing a handle to an iterator to a resource.
            </summary>
            <param name="string_handle">
               A string representation of the given handle.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'IteratorFromStringHandle'.
            </param>
            <param name="output_types">
               If specified, defines the type of each tuple component in an
               element produced by the resulting iterator.
            </param>
            <param name="output_shapes">
               If specified, defines the shape of each tuple component in an
               element produced by the resulting iterator.
            </param>
            <returns>
               A handle to an iterator resource.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.iterator_get_next(Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Gets the next output from the given iterator .
            </summary>
            <param name="iterator">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'IteratorGetNext'.
            </param>
            <param name="output_types">
               Optional argument
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.iterator_get_next_as_optional(Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Gets the next output from the given iterator as an Optional variant.
            </summary>
            <param name="iterator">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'IteratorGetNextAsOptional'.
            </param>
            <param name="output_types">
               Optional argument
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.iterator_get_next_sync(Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Gets the next output from the given iterator.
            </summary>
            <param name="iterator">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'IteratorGetNextSync'.
            </param>
            <param name="output_types">
               Optional argument
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation is a synchronous version IteratorGetNext. It should only be used
               in situations where the iterator does not block the calling thread, or where
               the calling thread is not a member of the thread pool used to execute parallel
               operations (e.g. in eager mode).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.iterator_to_string_handle(Tensorflow.Tensor,System.String)">
            <summary>
               Converts the given <c>resource_handle</c> representing an iterator to a string.
            </summary>
            <param name="resource_handle">
               A handle to an iterator resource.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'IteratorToStringHandle'.
            </param>
            <returns>
               A string representation of the given handle.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.l2loss(Tensorflow.Tensor,System.String)">
            <summary>
               L2 Loss.
            </summary>
            <param name="t">
               Typically 2-D, but may have any dimensions.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'L2Loss'.
            </param>
            <returns>
               0-D.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Computes half the L2 norm of a tensor without the <c>sqrt</c>:
               
               output = sum(t ** 2) / 2
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.l_m_d_b_reader(System.String,System.String,System.String)">
            <summary>
               A Reader that outputs the records from a LMDB file.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'LMDBReader'.
            </param>
            <param name="container">
               If non-empty, this reader is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this reader is named in the given bucket
               with this shared_name. Otherwise, the node name is used instead.
            </param>
            <returns>
               The handle to reference the Reader.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.l_r_n(Tensorflow.Tensor,System.Nullable{System.Int32},System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Single},System.String)">
            <summary>
               Local Response Normalization.
            </summary>
            <param name="input">
               4-D.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'LRN'.
            </param>
            <param name="depth_radius">
               0-D.  Half-width of the 1-D normalization window.
            </param>
            <param name="bias">
               An offset (usually positive to avoid dividing by 0).
            </param>
            <param name="alpha">
               A scale factor, usually positive.
            </param>
            <param name="beta">
               An exponent.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The 4-D <c>input</c> tensor is treated as a 3-D array of 1-D vectors (along the last
               dimension), and each vector is normalized independently.  Within a given vector,
               each component is divided by the weighted, squared sum of inputs within
               <c>depth_radius</c>.  In detail,
               
               sqr_sum[a, b, c, d] =
               sum(input[a, b, c, d - depth_radius : d + depth_radius + 1] ** 2)
               output = input / (bias + alpha * sqr_sum) ** beta
               
               For details, see [Krizhevsky et al., ImageNet classification with deep
               convolutional neural networks (NIPS 2012)](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.l_r_n_grad(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Int32},System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Single},System.String)">
            <summary>
               Gradients for Local Response Normalization.
            </summary>
            <param name="input_grads">
               4-D with shape <c>[batch, height, width, channels]</c>.
            </param>
            <param name="input_image">
               4-D with shape <c>[batch, height, width, channels]</c>.
            </param>
            <param name="output_image">
               4-D with shape <c>[batch, height, width, channels]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'LRNGrad'.
            </param>
            <param name="depth_radius">
               A depth radius.
            </param>
            <param name="bias">
               An offset (usually &amp;gt; 0 to avoid dividing by 0).
            </param>
            <param name="alpha">
               A scale factor, usually positive.
            </param>
            <param name="beta">
               An exponent.
            </param>
            <returns>
               The gradients for LRN.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.latency_stats_dataset(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Records the latency of producing <c>input_dataset</c> elements in a StatsAggregator.
            </summary>
            <param name="input_dataset">
            </param>
            <param name="tag">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'LatencyStatsDataset'.
            </param>
            <param name="output_types">
               Optional argument
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.learned_unigram_candidate_sampler(Tensorflow.Tensor,System.Int32,System.Int32,System.Boolean,System.Int32,System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Generates labels for candidate sampling with a learned unigram distribution.
            </summary>
            <param name="true_classes">
               A batch_size * num_true matrix, in which each row contains the
               IDs of the num_true target_classes in the corresponding original label.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'LearnedUnigramCandidateSampler'.
            </param>
            <param name="num_true">
               Optional argument
               Number of true labels per context.
            </param>
            <param name="num_sampled">
               Optional argument
               Number of candidates to randomly sample.
            </param>
            <param name="unique">
               Optional argument
               If unique is true, we sample with rejection, so that all sampled
               candidates in a batch are unique. This requires some approximation to
               estimate the post-rejection sampling probabilities.
            </param>
            <param name="range_max">
               Optional argument
               The sampler will sample integers from the interval [0, range_max).
            </param>
            <param name="seed">
               If either seed or seed2 are set to be non-zero, the random number
               generator is seeded by the given seed.  Otherwise, it is seeded by a
               random seed.
            </param>
            <param name="seed2">
               An second seed to avoid seed collision.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               sampled_candidates : A vector of length num_sampled, in which each element is
               the ID of a sampled candidate.
               true_expected_count : A batch_size * num_true matrix, representing
               the number of times each candidate is expected to occur in a batch
               of sampled candidates. If unique=true, then this is a probability.
               sampled_expected_count : A vector of length num_sampled, for each sampled
               candidate representing the number of times the candidate is expected
               to occur in a batch of sampled candidates.  If unique=true, then this is a
               probability.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               See explanations of candidate sampling and the data formats at
               go/candidate-sampling.
               
               For each batch, this op picks a single set of sampled candidate labels.
               
               The advantages of sampling candidates per-batch are simplicity and the
               possibility of efficient dense matrix multiplication. The disadvantage is that
               the sampled candidates must be chosen independently of the context and of the
               true labels.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.left_shift(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Elementwise computes the bitwise left-shift of <c>x</c> and <c>y</c>.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'LeftShift'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               If <c>y</c> is negative, or greater than or equal to the width of <c>x</c> in bits the
               result is implementation defined.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.less(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns the truth value of (x &amp;lt; y) element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Less'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               *NOTE*: <c>Less</c> supports broadcasting. More about broadcasting
               [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.less_equal(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns the truth value of (x &amp;lt;= y) element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'LessEqual'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               *NOTE*: <c>LessEqual</c> supports broadcasting. More about broadcasting
               [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.lgamma(Tensorflow.Tensor,System.String)">
            <summary>
               Computes the log of the absolute value of <c>Gamma(x)</c> element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Lgamma'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.lin_space(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Generates values in an interval.
            </summary>
            <param name="start">
               0-D tensor. First entry in the range.
            </param>
            <param name="stop">
               0-D tensor. Last entry in the range.
            </param>
            <param name="num">
               0-D tensor. Number of values to generate.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'LinSpace'.
            </param>
            <returns>
               1-D. The generated values.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               A sequence of <c>num</c> evenly-spaced values are generated beginning at <c>start</c>.
               If <c>num &amp;gt; 1</c>, the values in the sequence increase by <c>stop - start / num - 1</c>,
               so that the last one is exactly <c>stop</c>.
               
               For example:
               
              <code>
               tf.linspace(10.0, 12.0, 3, name="linspace") =&amp;gt; [ 10.0  11.0  12.0]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.list_diff(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Computes the difference between two lists of numbers or strings.
            </summary>
            <param name="x">
               1-D. Values to keep.
            </param>
            <param name="y">
               1-D. Values to remove.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ListDiff'.
            </param>
            <param name="out_idx">
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output : 1-D. Values present in <c>x</c> but not in <c>y</c>.
               idx : 1-D. Positions of <c>x</c> values preserved in <c>out</c>.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Given a list <c>x</c> and a list <c>y</c>, this operation returns a list <c>out</c> that
               represents all values that are in <c>x</c> but not in <c>y</c>. The returned list <c>out</c>
               is sorted in the same order that the numbers appear in <c>x</c> (duplicates are
               preserved). This operation also returns a list <c>idx</c> that represents the
               position of each <c>out</c> element in <c>x</c>. In other words:
               
               <c>out[i] = x[idx[i]] for i in [0, 1, ..., len(out) - 1]</c>
               
               For example, given this input:
               
              <code>
               x = [1, 2, 3, 4, 5, 6]
               y = [1, 3, 5]
              </code>
               
               This operation would return:
               
              <code>
               out ==&amp;gt; [2, 4, 6]
               idx ==&amp;gt; [1, 3, 5]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.load_and_remap_matrix(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32,System.Int32,System.Nullable{System.Int32},System.String)">
            <summary>
               Loads a 2-D (matrix) <c>Tensor</c> with name <c>old_tensor_name</c> from the checkpoint
            </summary>
            <param name="ckpt_path">
               Path to the TensorFlow checkpoint (version 2, <c>TensorBundle</c>) from
               which the old matrix <c>Tensor</c> will be loaded.
            </param>
            <param name="old_tensor_name">
               Name of the 2-D <c>Tensor</c> to load from checkpoint.
            </param>
            <param name="row_remapping">
               An int <c>Tensor</c> of row remappings (generally created by
               <c>generate_vocab_remapping</c>).  Even if no row remapping is needed, this must
               still be an index-valued Tensor (e.g. [0, 1, 2, ...]), or a shifted
               index-valued <c>Tensor</c> (e.g. [8, 9, 10, ...], for partitioned <c>Variables</c>).
            </param>
            <param name="col_remapping">
               An int <c>Tensor</c> of column remappings (generally created by
               <c>generate_vocab_remapping</c>).  May be a size-0 <c>Tensor</c> if only row remapping
               is to be done (e.g. column ordering is the same).
            </param>
            <param name="initializing_values">
               A float <c>Tensor</c> containing  values to fill in for cells
               in the output matrix that are not loaded from the checkpoint. Length must be
               exactly the same as the number of missing / new cells.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'LoadAndRemapMatrix'.
            </param>
            <param name="num_rows">
               Optional argument
               Number of rows (length of the 1st dimension) in the output matrix.
            </param>
            <param name="num_cols">
               Optional argument
               Number of columns (length of the 2nd dimension) in the output matrix.
            </param>
            <param name="max_rows_in_memory">
               The maximum number of rows to load from the checkpoint at
               once. If less than or equal to 0, the entire matrix will be loaded into
               memory. Setting this arg trades increased disk reads for lower memory usage.
            </param>
            <returns>
               Output matrix containing existing values loaded from the
               checkpoint, and with any missing values filled in from initializing_values.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               at <c>ckpt_path</c> and potentially reorders its rows and columns using the
               specified remappings.
               
               Most users should use one of the wrapper initializers (such as
               <c>tf.contrib.framework.load_and_remap_matrix_initializer</c>) instead of this
               function directly.
               
               The remappings are 1-D tensors with the following properties:
               
               * <c>row_remapping</c> must have exactly <c>num_rows</c> entries. Row <c>i</c> of the output
               matrix will be initialized from the row corresponding to index
               <c>row_remapping[i]</c> in the old <c>Tensor</c> from the checkpoint.
               * <c>col_remapping</c> must have either 0 entries (indicating that no column
               reordering is needed) or <c>num_cols</c> entries. If specified, column <c>j</c> of the
               output matrix will be initialized from the column corresponding to index
               <c>col_remapping[j]</c> in the old <c>Tensor</c> from the checkpoint.
               * A value of -1 in either of the remappings signifies a "missing" entry. In that
               case, values from the <c>initializing_values</c> tensor will be used to fill that
               missing row or column. If <c>row_remapping</c> has <c>r</c> missing entries and
               <c>col_remapping</c> has <c>c</c> missing entries, then the following condition must be
               true:
               
               <c>(r * num_cols) + (c * num_rows) - (r * c) == len(initializing_values)</c>
               
               The remapping tensors can be generated using the GenerateVocabRemapping op.
               
               As an example, with row_remapping = [1, 0, -1], col_remapping = [0, 2, -1],
               initializing_values = [0.5, -0.5, 0.25, -0.25, 42], and w(i, j) representing
               the value from row i, column j of the old tensor in the checkpoint, the output
               matrix will look like the following:
               
               [[w(1, 0),  w(1, 2),  0.5],
               [w(0, 0),  w(0, 2), -0.5],
               [0.25,    -0.25,      42]]
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.log(Tensorflow.Tensor,System.String)">
            <summary>
               Computes natural logarithm of x element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Log'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               I.e., \\(y = \log_e x\\).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.log1p(Tensorflow.Tensor,System.String)">
            <summary>
               Computes natural logarithm of (1 + x) element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Log1p'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               I.e., \\(y = \log_e (1 + x)\\).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.log_matrix_determinant(Tensorflow.Tensor,System.String)">
            <summary>
               Computes the sign and the log of the absolute value of the determinant of
            </summary>
            <param name="input">
               Shape is <c>[N, M, M]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'LogMatrixDeterminant'.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               sign : The signs of the log determinants of the inputs. Shape is <c>[N]</c>.
               log_abs_determinant : The logs of the absolute values of the determinants
               of the N input matrices.  Shape is <c>[N]</c>.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               one or more square matrices.
               
               The input is a tensor of shape <c>[N, M, M]</c> whose inner-most 2 dimensions
               form square matrices. The outputs are two tensors containing the signs and
               absolute values of the log determinants for all N input submatrices
               <c>[..., :, :]</c> such that the determinant = sign*exp(log_abs_determinant).
               The log_abs_determinant is computed as det(P)*sum(log(diag(LU))) where LU
               is the LU decomposition of the input and P is the corresponding
               permutation matrix.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.log_softmax(Tensorflow.Tensor,System.String)">
            <summary>
               Computes log softmax activations.
            </summary>
            <param name="logits">
               2-D with shape <c>[batch_size, num_classes]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'LogSoftmax'.
            </param>
            <returns>
               Same shape as <c>logits</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               For each batch <c>i</c> and class <c>j</c> we have
               
               logsoftmax[i, j] = logits[i, j] - log(sum(exp(logits[i])))
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.log_uniform_candidate_sampler(Tensorflow.Tensor,System.Int32,System.Int32,System.Boolean,System.Int32,System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Generates labels for candidate sampling with a log-uniform distribution.
            </summary>
            <param name="true_classes">
               A batch_size * num_true matrix, in which each row contains the
               IDs of the num_true target_classes in the corresponding original label.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'LogUniformCandidateSampler'.
            </param>
            <param name="num_true">
               Optional argument
               Number of true labels per context.
            </param>
            <param name="num_sampled">
               Optional argument
               Number of candidates to randomly sample.
            </param>
            <param name="unique">
               Optional argument
               If unique is true, we sample with rejection, so that all sampled
               candidates in a batch are unique. This requires some approximation to
               estimate the post-rejection sampling probabilities.
            </param>
            <param name="range_max">
               Optional argument
               The sampler will sample integers from the interval [0, range_max).
            </param>
            <param name="seed">
               If either seed or seed2 are set to be non-zero, the random number
               generator is seeded by the given seed.  Otherwise, it is seeded by a
               random seed.
            </param>
            <param name="seed2">
               An second seed to avoid seed collision.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               sampled_candidates : A vector of length num_sampled, in which each element is
               the ID of a sampled candidate.
               true_expected_count : A batch_size * num_true matrix, representing
               the number of times each candidate is expected to occur in a batch
               of sampled candidates. If unique=true, then this is a probability.
               sampled_expected_count : A vector of length num_sampled, for each sampled
               candidate representing the number of times the candidate is expected
               to occur in a batch of sampled candidates.  If unique=true, then this is a
               probability.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               See explanations of candidate sampling and the data formats at
               go/candidate-sampling.
               
               For each batch, this op picks a single set of sampled candidate labels.
               
               The advantages of sampling candidates per-batch are simplicity and the
               possibility of efficient dense matrix multiplication. The disadvantage is that
               the sampled candidates must be chosen independently of the context and of the
               true labels.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.logical_and(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns the truth value of x AND y element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'LogicalAnd'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               *NOTE*: <c>LogicalAnd</c> supports broadcasting. More about broadcasting
               [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.logical_not(Tensorflow.Tensor,System.String)">
            <summary>
               Returns the truth value of NOT x element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'LogicalNot'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.logical_or(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns the truth value of x OR y element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'LogicalOr'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               *NOTE*: <c>LogicalOr</c> supports broadcasting. More about broadcasting
               [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.lookup_table_export(Tensorflow.Tensor,Tensorflow.TF_DataType,Tensorflow.TF_DataType,System.String)">
            <summary>
               Outputs all keys and values in the table.
            </summary>
            <param name="table_handle">
               Handle to the table.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'LookupTableExport'.
            </param>
            <param name="Tkeys">
               Optional argument
            </param>
            <param name="Tvalues">
               Optional argument
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               keys : Vector of all keys present in the table.
               values : Tensor of all values in the table. Indexed in parallel with <c>keys</c>.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.lookup_table_export_v2(Tensorflow.Tensor,Tensorflow.TF_DataType,Tensorflow.TF_DataType,System.String)">
            <summary>
               Outputs all keys and values in the table.
            </summary>
            <param name="table_handle">
               Handle to the table.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'LookupTableExportV2'.
            </param>
            <param name="Tkeys">
               Optional argument
            </param>
            <param name="Tvalues">
               Optional argument
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               keys : Vector of all keys present in the table.
               values : Tensor of all values in the table. Indexed in parallel with <c>keys</c>.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.lookup_table_find(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Looks up keys in a table, outputs the corresponding values.
            </summary>
            <param name="table_handle">
               Handle to the table.
            </param>
            <param name="keys">
               Any shape.  Keys to look up.
            </param>
            <param name="default_value">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'LookupTableFind'.
            </param>
            <returns>
               Same shape as <c>keys</c>.  Values found in the table, or <c>default_values</c>
               for missing keys.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The tensor <c>keys</c> must of the same type as the keys of the table.
               The output <c>values</c> is of the type of the table values.
               
               The scalar <c>default_value</c> is the value output for keys not present in the
               table. It must also be of the same type as the table values.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.lookup_table_find_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Looks up keys in a table, outputs the corresponding values.
            </summary>
            <param name="table_handle">
               Handle to the table.
            </param>
            <param name="keys">
               Any shape.  Keys to look up.
            </param>
            <param name="default_value">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'LookupTableFindV2'.
            </param>
            <returns>
               Same shape as <c>keys</c>.  Values found in the table, or <c>default_values</c>
               for missing keys.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The tensor <c>keys</c> must of the same type as the keys of the table.
               The output <c>values</c> is of the type of the table values.
               
               The scalar <c>default_value</c> is the value output for keys not present in the
               table. It must also be of the same type as the table values.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.lookup_table_import(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Replaces the contents of the table with the specified keys and values.
            </summary>
            <param name="table_handle">
               Handle to the table.
            </param>
            <param name="keys">
               Any shape.  Keys to look up.
            </param>
            <param name="values">
               Values to associate with keys.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'LookupTableImport'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               The tensor <c>keys</c> must be of the same type as the keys of the table.
               The tensor <c>values</c> must be of the type of the table values.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.lookup_table_import_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Replaces the contents of the table with the specified keys and values.
            </summary>
            <param name="table_handle">
               Handle to the table.
            </param>
            <param name="keys">
               Any shape.  Keys to look up.
            </param>
            <param name="values">
               Values to associate with keys.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'LookupTableImportV2'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               The tensor <c>keys</c> must be of the same type as the keys of the table.
               The tensor <c>values</c> must be of the type of the table values.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.lookup_table_insert(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Updates the table to associates keys with values.
            </summary>
            <param name="table_handle">
               Handle to the table.
            </param>
            <param name="keys">
               Any shape.  Keys to look up.
            </param>
            <param name="values">
               Values to associate with keys.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'LookupTableInsert'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               The tensor <c>keys</c> must be of the same type as the keys of the table.
               The tensor <c>values</c> must be of the type of the table values.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.lookup_table_insert_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Updates the table to associates keys with values.
            </summary>
            <param name="table_handle">
               Handle to the table.
            </param>
            <param name="keys">
               Any shape.  Keys to look up.
            </param>
            <param name="values">
               Values to associate with keys.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'LookupTableInsertV2'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               The tensor <c>keys</c> must be of the same type as the keys of the table.
               The tensor <c>values</c> must be of the type of the table values.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.lookup_table_size(Tensorflow.Tensor,System.String)">
            <summary>
               Computes the number of elements in the given table.
            </summary>
            <param name="table_handle">
               Handle to the table.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'LookupTableSize'.
            </param>
            <returns>
               Scalar that contains number of elements in the table.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.lookup_table_size_v2(Tensorflow.Tensor,System.String)">
            <summary>
               Computes the number of elements in the given table.
            </summary>
            <param name="table_handle">
               Handle to the table.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'LookupTableSizeV2'.
            </param>
            <returns>
               Scalar that contains number of elements in the table.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.loop_cond(Tensorflow.Tensor,System.String)">
            <summary>
               Forwards the input to the output.
            </summary>
            <param name="input">
               A boolean scalar, representing the branch predicate of the Switch op.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'LoopCond'.
            </param>
            <returns>
               The same tensor as <c>input</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operator represents the loop termination condition used by the
               "pivot" switches of a loop.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.make_iterator(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Makes a new iterator from the given <c>dataset</c> and stores it in <c>iterator</c>.
            </summary>
            <param name="dataset">
            </param>
            <param name="iterator">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MakeIterator'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               This operation may be executed multiple times. Each execution will reset the
               iterator in <c>iterator</c> to the first element of <c>dataset</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.map_clear(Tensorflow.TF_DataType[],System.Nullable{System.Int32},System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               Op removes all elements in the underlying container.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MapClear'.
            </param>
            <param name="dtypes">
               Optional argument
            </param>
            <param name="capacity">
            </param>
            <param name="memory_limit">
            </param>
            <param name="container">
            </param>
            <param name="shared_name">
            </param>
            <returns>
               Returns the description of the operation
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.map_incomplete_size(Tensorflow.TF_DataType[],System.Nullable{System.Int32},System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               Op returns the number of incomplete elements in the underlying container.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MapIncompleteSize'.
            </param>
            <param name="dtypes">
               Optional argument
            </param>
            <param name="capacity">
            </param>
            <param name="memory_limit">
            </param>
            <param name="container">
            </param>
            <param name="shared_name">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.map_peek(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],System.Nullable{System.Int32},System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               Op peeks at the values at the specified key.  If the
            </summary>
            <param name="key">
            </param>
            <param name="indices">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MapPeek'.
            </param>
            <param name="dtypes">
               Optional argument
            </param>
            <param name="capacity">
            </param>
            <param name="memory_limit">
            </param>
            <param name="container">
            </param>
            <param name="shared_name">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               underlying container does not contain this key
               this op will block until it does.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.map_size(Tensorflow.TF_DataType[],System.Nullable{System.Int32},System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               Op returns the number of elements in the underlying container.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MapSize'.
            </param>
            <param name="dtypes">
               Optional argument
            </param>
            <param name="capacity">
            </param>
            <param name="memory_limit">
            </param>
            <param name="container">
            </param>
            <param name="shared_name">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.map_stage(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor[],Tensorflow.TF_DataType[],System.Nullable{System.Int32},System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               Stage (key, values) in the underlying container which behaves like a hashtable.
            </summary>
            <param name="key">
               int64
            </param>
            <param name="indices">
            </param>
            <param name="values">
               a list of tensors
               dtypes A list of data types that inserted values should adhere to.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MapStage'.
            </param>
            <param name="dtypes">
               Optional argument
            </param>
            <param name="capacity">
               Maximum number of elements in the Staging Area. If &amp;gt; 0, inserts
               on the container will block when the capacity is reached.
            </param>
            <param name="memory_limit">
            </param>
            <param name="container">
               If non-empty, this queue is placed in the given container. Otherwise,
               a default container is used.
            </param>
            <param name="shared_name">
               It is necessary to match this name to the matching Unstage Op.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.map_unstage(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],System.Nullable{System.Int32},System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               Op removes and returns the values associated with the key
            </summary>
            <param name="key">
            </param>
            <param name="indices">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MapUnstage'.
            </param>
            <param name="dtypes">
               Optional argument
            </param>
            <param name="capacity">
            </param>
            <param name="memory_limit">
            </param>
            <param name="container">
            </param>
            <param name="shared_name">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               from the underlying container.   If the underlying container
               does not contain this key, the op will block until it does.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.map_unstage_no_key(Tensorflow.Tensor,Tensorflow.TF_DataType[],System.Nullable{System.Int32},System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               Op removes and returns a random (key, value)
            </summary>
            <param name="indices">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MapUnstageNoKey'.
            </param>
            <param name="dtypes">
               Optional argument
            </param>
            <param name="capacity">
            </param>
            <param name="memory_limit">
            </param>
            <param name="container">
            </param>
            <param name="shared_name">
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               key :
               values :
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               from the underlying container.   If the underlying container
               does not contain elements, the op will block until it does.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.mat_mul(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.String)">
            <summary>
               Multiply the matrix "a" by the matrix "b".
            </summary>
            <param name="a">
            </param>
            <param name="b">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MatMul'.
            </param>
            <param name="transpose_a">
               If true, "a" is transposed before multiplication.
            </param>
            <param name="transpose_b">
               If true, "b" is transposed before multiplication.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The inputs must be two-dimensional matrices and the inner dimension of
               "a" (after being transposed if transpose_a is true) must match the
               outer dimension of "b" (after being transposed if transposed_b is
               true).
               
               *Note*: The default kernel implementation for MatMul on GPUs uses
               cublas.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.matching_files(Tensorflow.Tensor,System.String)">
            <summary>
               Returns the set of files matching one or more glob patterns.
            </summary>
            <param name="pattern">
               Shell wildcard pattern(s). Scalar or vector of type string.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MatchingFiles'.
            </param>
            <returns>
               A vector of matching filenames.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Note that this routine only supports wildcard characters in the
               basename portion of the pattern, not in the directory portion.
               Note also that the order of filenames returned can be non-deterministic.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.matrix_band_part(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Copy a tensor setting everything outside a central band in each innermost matrix
            </summary>
            <param name="input">
               Rank <c>k</c> tensor.
            </param>
            <param name="num_lower">
               0-D tensor. Number of subdiagonals to keep. If negative, keep entire
               lower triangle.
            </param>
            <param name="num_upper">
               0-D tensor. Number of superdiagonals to keep. If negative, keep
               entire upper triangle.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MatrixBandPart'.
            </param>
            <returns>
               Rank <c>k</c> tensor of the same shape as input. The extracted banded tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               to zero.
               
               The <c>band</c> part is computed as follows:
               Assume <c>input</c> has <c>k</c> dimensions <c>[I, J, K, ..., M, N]</c>, then the output is a
               tensor with the same shape where
               
               <c>band[i, j, k, ..., m, n] = in_band(m, n) * input[i, j, k, ..., m, n]</c>.
               
               The indicator function
               
               <c>in_band(m, n) = (num_lower &amp;lt; 0 || (m-n) &amp;lt;= num_lower)) &amp;&amp;
               (num_upper &amp;lt; 0 || (n-m) &amp;lt;= num_upper)</c>.
               
               For example:
               
              <code>
               # if 'input' is [[ 0,  1,  2, 3]
               [-1,  0,  1, 2]
               [-2, -1,  0, 1]
               [-3, -2, -1, 0]],
               
               tf.matrix_band_part(input, 1, -1) ==&amp;gt; [[ 0,  1,  2, 3]
               [-1,  0,  1, 2]
               [ 0, -1,  0, 1]
               [ 0,  0, -1, 0]],
               
               tf.matrix_band_part(input, 2, 1) ==&amp;gt; [[ 0,  1,  0, 0]
               [-1,  0,  1, 0]
               [-2, -1,  0, 1]
               [ 0, -2, -1, 0]]
              </code>
               
               Useful special cases:
               
              <code>
               tf.matrix_band_part(input, 0, -1) ==&amp;gt; Upper triangular part.
               tf.matrix_band_part(input, -1, 0) ==&amp;gt; Lower triangular part.
               tf.matrix_band_part(input, 0, 0) ==&amp;gt; Diagonal.
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.matrix_determinant(Tensorflow.Tensor,System.String)">
            <summary>
               Computes the determinant of one or more square matrices.
            </summary>
            <param name="input">
               Shape is <c>[..., M, M]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MatrixDeterminant'.
            </param>
            <returns>
               Shape is <c>[...]</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The input is a tensor of shape <c>[..., M, M]</c> whose inner-most 2 dimensions
               form square matrices. The output is a tensor containing the determinants
               for all input submatrices <c>[..., :, :]</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.matrix_diag(Tensorflow.Tensor,System.String)">
            <summary>
               Returns a batched diagonal tensor with a given batched diagonal values.
            </summary>
            <param name="diagonal">
               Rank <c>k</c>, where <c>k &amp;gt;= 1</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MatrixDiag'.
            </param>
            <returns>
               Rank <c>k+1</c>, with <c>output.shape = diagonal.shape + [diagonal.shape[-1]]</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Given a <c>diagonal</c>, this operation returns a tensor with the <c>diagonal</c> and
               everything else padded with zeros. The diagonal is computed as follows:
               
               Assume <c>diagonal</c> has <c>k</c> dimensions <c>[I, J, K, ..., N]</c>, then the output is a
               tensor of rank <c>k+1</c> with dimensions <c>[I, J, K, ..., N, N]</c> where:
               
               <c>output[i, j, k, ..., m, n] = 1{m=n} * diagonal[i, j, k, ..., n]</c>.
               
               For example:
               
              <code>
               # 'diagonal' is [[1, 2, 3, 4], [5, 6, 7, 8]]
               
               and diagonal.shape = (2, 4)
               
               tf.matrix_diag(diagonal) ==&amp;gt; [[[1, 0, 0, 0]
               [0, 2, 0, 0]
               [0, 0, 3, 0]
               [0, 0, 0, 4]],
               [[5, 0, 0, 0]
               [0, 6, 0, 0]
               [0, 0, 7, 0]
               [0, 0, 0, 8]]]
               
               which has shape (2, 4, 4)
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.matrix_diag_part(Tensorflow.Tensor,System.String)">
            <summary>
               Returns the batched diagonal part of a batched tensor.
            </summary>
            <param name="input">
               Rank <c>k</c> tensor where <c>k &amp;gt;= 2</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MatrixDiagPart'.
            </param>
            <returns>
               The extracted diagonal(s) having shape
               <c>diagonal.shape = input.shape[:-2] + [min(input.shape[-2:])]</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation returns a tensor with the <c>diagonal</c> part
               of the batched <c>input</c>. The <c>diagonal</c> part is computed as follows:
               
               Assume <c>input</c> has <c>k</c> dimensions <c>[I, J, K, ..., M, N]</c>, then the output is a
               tensor of rank <c>k - 1</c> with dimensions <c>[I, J, K, ..., min(M, N)]</c> where:
               
               <c>diagonal[i, j, k, ..., n] = input[i, j, k, ..., n, n]</c>.
               
               The input must be at least a matrix.
               
               For example:
               
              <code>
               # 'input' is [[[1, 0, 0, 0]
               [0, 2, 0, 0]
               [0, 0, 3, 0]
               [0, 0, 0, 4]],
               [[5, 0, 0, 0]
               [0, 6, 0, 0]
               [0, 0, 7, 0]
               [0, 0, 0, 8]]]
               
               and input.shape = (2, 4, 4)
               
               tf.matrix_diag_part(input) ==&amp;gt; [[1, 2, 3, 4], [5, 6, 7, 8]]
               
               which has shape (2, 4)
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.matrix_exponential(Tensorflow.Tensor,System.String)">
            <summary>
               Deprecated, use python implementation tf.linalg.matrix_exponential.
            </summary>
            <param name="input">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MatrixExponential'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.matrix_inverse(Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Computes the inverse of one or more square invertible matrices or their
            </summary>
            <param name="input">
               Shape is <c>[..., M, M]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MatrixInverse'.
            </param>
            <param name="adjoint">
            </param>
            <returns>
               Shape is <c>[..., M, M]</c>.
               
               @compatibility(numpy)
               Equivalent to np.linalg.inv
               @end_compatibility
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               adjoints (conjugate transposes).
               
               The input is a tensor of shape <c>[..., M, M]</c> whose inner-most 2 dimensions
               form square matrices. The output is a tensor of the same shape as the input
               containing the inverse for all input submatrices <c>[..., :, :]</c>.
               
               The op uses LU decomposition with partial pivoting to compute the inverses.
               
               If a matrix is not invertible there is no guarantee what the op does. It
               may detect the condition and raise an exception or it may simply return a
               garbage result.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.matrix_logarithm(Tensorflow.Tensor,System.String)">
            <summary>
               Computes the matrix logarithm of one or more square matrices:
            </summary>
            <param name="input">
               Shape is <c>[..., M, M]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MatrixLogarithm'.
            </param>
            <returns>
               Shape is <c>[..., M, M]</c>.
               
               @compatibility(scipy)
               Equivalent to scipy.linalg.logm
               @end_compatibility
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               
               \\(log(exp(A)) = A\\)
               
               This op is only defined for complex matrices. If A is positive-definite and
               real, then casting to a complex matrix, taking the logarithm and casting back
               to a real matrix will give the correct result.
               
               This function computes the matrix logarithm using the Schur-Parlett algorithm.
               Details of the algorithm can be found in Section 11.6.2 of:
               Nicholas J. Higham, Functions of Matrices: Theory and Computation, SIAM 2008.
               ISBN 978-0-898716-46-7.
               
               The input is a tensor of shape <c>[..., M, M]</c> whose inner-most 2 dimensions
               form square matrices. The output is a tensor of the same shape as the input
               containing the exponential for all input submatrices <c>[..., :, :]</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.matrix_set_diag(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns a batched matrix tensor with new batched diagonal values.
            </summary>
            <param name="input">
               Rank <c>k+1</c>, where <c>k &amp;gt;= 1</c>.
            </param>
            <param name="diagonal">
               Rank <c>k</c>, where <c>k &amp;gt;= 1</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MatrixSetDiag'.
            </param>
            <returns>
               Rank <c>k+1</c>, with <c>output.shape = input.shape</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Given <c>input</c> and <c>diagonal</c>, this operation returns a tensor with the
               same shape and values as <c>input</c>, except for the main diagonal of the
               innermost matrices.  These will be overwritten by the values in <c>diagonal</c>.
               
               The output is computed as follows:
               
               Assume <c>input</c> has <c>k+1</c> dimensions <c>[I, J, K, ..., M, N]</c> and <c>diagonal</c> has
               <c>k</c> dimensions <c>[I, J, K, ..., min(M, N)]</c>.  Then the output is a
               tensor of rank <c>k+1</c> with dimensions <c>[I, J, K, ..., M, N]</c> where:
               
               * <c>output[i, j, k, ..., m, n] = diagonal[i, j, k, ..., n]</c> for <c>m == n</c>.
               * <c>output[i, j, k, ..., m, n] = input[i, j, k, ..., m, n]</c> for <c>m != n</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.matrix_solve(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Solves systems of linear equations.
            </summary>
            <param name="matrix">
               Shape is <c>[..., M, M]</c>.
            </param>
            <param name="rhs">
               Shape is <c>[..., M, K]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MatrixSolve'.
            </param>
            <param name="adjoint">
               Boolean indicating whether to solve with <c>matrix</c> or its (block-wise)
               adjoint.
            </param>
            <returns>
               Shape is <c>[..., M, K]</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               <c>Matrix</c> is a tensor of shape <c>[..., M, M]</c> whose inner-most 2 dimensions
               form square matrices. <c>Rhs</c> is a tensor of shape <c>[..., M, K]</c>. The <c>output</c> is
               a tensor shape <c>[..., M, K]</c>.  If <c>adjoint</c> is <c>False</c> then each output matrix
               satisfies <c>matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]</c>.
               If <c>adjoint</c> is <c>True</c> then each output matrix satisfies
               <c>adjoint(matrix[..., :, :]) * output[..., :, :] = rhs[..., :, :]</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.matrix_solve_ls(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Solves one or more linear least-squares problems.
            </summary>
            <param name="matrix">
               Shape is <c>[..., M, N]</c>.
            </param>
            <param name="rhs">
               Shape is <c>[..., M, K]</c>.
            </param>
            <param name="l2_regularizer">
               Scalar tensor.
               
               @compatibility(numpy)
               Equivalent to np.linalg.lstsq
               @end_compatibility
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MatrixSolveLs'.
            </param>
            <param name="fast">
            </param>
            <returns>
               Shape is <c>[..., N, K]</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               <c>matrix</c> is a tensor of shape <c>[..., M, N]</c> whose inner-most 2 dimensions
               form real or complex matrices of size <c>[M, N]</c>. <c>Rhs</c> is a tensor of the same
               type as <c>matrix</c> and shape <c>[..., M, K]</c>.
               The output is a tensor shape <c>[..., N, K]</c> where each output matrix solves
               each of the equations
               <c>matrix[..., :, :]</c> * <c>output[..., :, :]</c> = <c>rhs[..., :, :]</c>
               in the least squares sense.
               
               We use the following notation for (complex) matrix and right-hand sides
               in the batch:
               
               <c>matrix</c>=\\(A \in \mathbb{C}^{m \times n}\\),
               <c>rhs</c>=\\(B  \in \mathbb{C}^{m \times k}\\),
               <c>output</c>=\\(X  \in \mathbb{C}^{n \times k}\\),
               <c>l2_regularizer</c>=\\(\lambda \in \mathbb{R}\\).
               
               If <c>fast</c> is <c>True</c>, then the solution is computed by solving the normal
               equations using Cholesky decomposition. Specifically, if \\(m \ge n\\) then
               \\(X = (A^H A + \lambda I)^{-1} A^H B\\), which solves the least-squares
               problem \\(X = \mathrm{argmin}_{Z \in \Re^{n \times k} } ||A Z - B||_F^2 + \lambda ||Z||_F^2\\).
               If \\(m \lt n\\) then <c>output</c> is computed as
               \\(X = A^H (A A^H + \lambda I)^{-1} B\\), which (for \\(\lambda = 0\\)) is the
               minimum-norm solution to the under-determined linear system, i.e.
               \\(X = \mathrm{argmin}_{Z \in \mathbb{C}^{n \times k} } ||Z||_F^2 \\),
               subject to \\(A Z = B\\). Notice that the fast path is only numerically stable
               when \\(A\\) is numerically full rank and has a condition number
               \\(\mathrm{cond}(A) \lt \frac{1}{\sqrt{\epsilon_{mach} } }\\) or \\(\lambda\\) is
               sufficiently large.
               
               If <c>fast</c> is <c>False</c> an algorithm based on the numerically robust complete
               orthogonal decomposition is used. This computes the minimum-norm
               least-squares solution, even when \\(A\\) is rank deficient. This path is
               typically 6-7 times slower than the fast path. If <c>fast</c> is <c>False</c> then
               <c>l2_regularizer</c> is ignored.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.matrix_triangular_solve(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.String)">
            <summary>
               Solves systems of linear equations with upper or lower triangular matrices by
            </summary>
            <param name="matrix">
               Shape is <c>[..., M, M]</c>.
            </param>
            <param name="rhs">
               Shape is <c>[..., M, K]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MatrixTriangularSolve'.
            </param>
            <param name="lower">
               Boolean indicating whether the innermost matrices in <c>matrix</c> are
               lower or upper triangular.
            </param>
            <param name="adjoint">
               Boolean indicating whether to solve with <c>matrix</c> or its (block-wise)
               adjoint.
               
               @compatibility(numpy)
               Equivalent to scipy.linalg.solve_triangular
               @end_compatibility
            </param>
            <returns>
               Shape is <c>[..., M, K]</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               backsubstitution.
               
               <c>matrix</c> is a tensor of shape <c>[..., M, M]</c> whose inner-most 2 dimensions form
               square matrices. If <c>lower</c> is <c>True</c> then the strictly upper triangular part
               of each inner-most matrix is assumed to be zero and not accessed.
               If <c>lower</c> is False then the strictly lower triangular part of each inner-most
               matrix is assumed to be zero and not accessed.
               <c>rhs</c> is a tensor of shape <c>[..., M, K]</c>.
               
               The output is a tensor of shape <c>[..., M, K]</c>. If <c>adjoint</c> is
               <c>True</c> then the innermost matrices in <c>output</c> satisfy matrix equations
               <c>matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]</c>.
               If <c>adjoint</c> is <c>False</c> then the strictly then the  innermost matrices in
               <c>output</c> satisfy matrix equations
               <c>adjoint(matrix[..., i, k]) * output[..., k, j] = rhs[..., i, j]</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.max(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Computes the maximum of elements across dimensions of a tensor.
            </summary>
            <param name="input">
               The tensor to reduce.
            </param>
            <param name="reduction_indices">
               The dimensions to reduce. Must be in the range
               <c>[-rank(input), rank(input))</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Max'.
            </param>
            <param name="keep_dims">
               If true, retain reduced dimensions with length 1.
            </param>
            <returns>
               The reduced tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Reduces <c>input</c> along the dimensions given in <c>axis</c>. Unless
               <c>keep_dims</c> is true, the rank of the tensor is reduced by 1 for each entry in
               <c>axis</c>. If <c>keep_dims</c> is true, the reduced dimensions are
               retained with length 1.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.max_pool(Tensorflow.Tensor,System.Int32[],System.Int32[],System.String,System.String,System.String)">
            <summary>
               Performs max pooling on the input.
            </summary>
            <param name="input">
               4-D input to pool over.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MaxPool'.
            </param>
            <param name="ksize">
               Optional argument
               The size of the window for each dimension of the input tensor.
            </param>
            <param name="strides">
               Optional argument
               The stride of the sliding window for each dimension of the
               input tensor.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <param name="data_format">
               Specify the data format of the input and output data. With the
               default format "NHWC", the data is stored in the order of:
               [batch, in_height, in_width, in_channels].
               Alternatively, the format could be "NCHW", the data storage order of:
               [batch, in_channels, in_height, in_width].
            </param>
            <returns>
               The max pooled output tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.max_pool3d(Tensorflow.Tensor,System.Int32[],System.Int32[],System.String,System.String,System.String)">
            <summary>
               Performs 3D max pooling on the input.
            </summary>
            <param name="input">
               Shape <c>[batch, depth, rows, cols, channels]</c> tensor to pool over.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MaxPool3D'.
            </param>
            <param name="ksize">
               Optional argument
               1-D tensor of length 5. The size of the window for each dimension of
               the input tensor. Must have <c>ksize[0] = ksize[4] = 1</c>.
            </param>
            <param name="strides">
               Optional argument
               1-D tensor of length 5. The stride of the sliding window for each
               dimension of <c>input</c>. Must have <c>strides[0] = strides[4] = 1</c>.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <param name="data_format">
               The data format of the input and output data. With the
               default format "NDHWC", the data is stored in the order of:
               [batch, in_depth, in_height, in_width, in_channels].
               Alternatively, the format could be "NCDHW", the data storage order is:
               [batch, in_channels, in_depth, in_height, in_width].
            </param>
            <returns>
               The max pooled output tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.max_pool3d_grad(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32[],System.Int32[],System.String,System.String,System.String)">
            <summary>
               Computes gradients of max pooling function.
            </summary>
            <param name="orig_input">
               The original input tensor.
            </param>
            <param name="orig_output">
               The original output tensor.
            </param>
            <param name="grad">
               Output backprop of shape <c>[batch, depth, rows, cols, channels]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MaxPool3DGrad'.
            </param>
            <param name="ksize">
               Optional argument
               1-D tensor of length 5. The size of the window for each dimension of
               the input tensor. Must have <c>ksize[0] = ksize[4] = 1</c>.
            </param>
            <param name="strides">
               Optional argument
               1-D tensor of length 5. The stride of the sliding window for each
               dimension of <c>input</c>. Must have <c>strides[0] = strides[4] = 1</c>.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <param name="data_format">
               The data format of the input and output data. With the
               default format "NDHWC", the data is stored in the order of:
               [batch, in_depth, in_height, in_width, in_channels].
               Alternatively, the format could be "NCDHW", the data storage order is:
               [batch, in_channels, in_depth, in_height, in_width].
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.max_pool3d_grad_grad(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32[],System.Int32[],System.String,System.String,System.String)">
            <summary>
               Computes second-order gradients of the maxpooling function.
            </summary>
            <param name="orig_input">
               The original input tensor.
            </param>
            <param name="orig_output">
               The original output tensor.
            </param>
            <param name="grad">
               Output backprop of shape <c>[batch, depth, rows, cols, channels]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MaxPool3DGradGrad'.
            </param>
            <param name="ksize">
               Optional argument
               1-D tensor of length 5. The size of the window for each dimension of
               the input tensor. Must have <c>ksize[0] = ksize[4] = 1</c>.
            </param>
            <param name="strides">
               Optional argument
               1-D tensor of length 5. The stride of the sliding window for each
               dimension of <c>input</c>. Must have <c>strides[0] = strides[4] = 1</c>.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <param name="data_format">
               The data format of the input and output data. With the
               default format "NDHWC", the data is stored in the order of:
               [batch, in_depth, in_height, in_width, in_channels].
               Alternatively, the format could be "NCDHW", the data storage order is:
               [batch, in_channels, in_depth, in_height, in_width].
            </param>
            <returns>
               Gradients of gradients w.r.t. the input to <c>max_pool</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.max_pool_grad(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32[],System.Int32[],System.String,System.String,System.String)">
            <summary>
               Computes gradients of the maxpooling function.
            </summary>
            <param name="orig_input">
               The original input tensor.
            </param>
            <param name="orig_output">
               The original output tensor.
            </param>
            <param name="grad">
               4-D.  Gradients w.r.t. the output of <c>max_pool</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MaxPoolGrad'.
            </param>
            <param name="ksize">
               Optional argument
               The size of the window for each dimension of the input tensor.
            </param>
            <param name="strides">
               Optional argument
               The stride of the sliding window for each dimension of the
               input tensor.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <param name="data_format">
               Specify the data format of the input and output data. With the
               default format "NHWC", the data is stored in the order of:
               [batch, in_height, in_width, in_channels].
               Alternatively, the format could be "NCHW", the data storage order of:
               [batch, in_channels, in_height, in_width].
            </param>
            <returns>
               Gradients w.r.t. the input to <c>max_pool</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.max_pool_grad_grad(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32[],System.Int32[],System.String,System.String,System.String)">
            <summary>
               Computes second-order gradients of the maxpooling function.
            </summary>
            <param name="orig_input">
               The original input tensor.
            </param>
            <param name="orig_output">
               The original output tensor.
            </param>
            <param name="grad">
               4-D.  Gradients of gradients w.r.t. the input of <c>max_pool</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MaxPoolGradGrad'.
            </param>
            <param name="ksize">
               Optional argument
               The size of the window for each dimension of the input tensor.
            </param>
            <param name="strides">
               Optional argument
               The stride of the sliding window for each dimension of the
               input tensor.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <param name="data_format">
               Specify the data format of the input and output data. With the
               default format "NHWC", the data is stored in the order of:
               [batch, in_height, in_width, in_channels].
               Alternatively, the format could be "NCHW", the data storage order of:
               [batch, in_channels, in_height, in_width].
            </param>
            <returns>
               Gradients of gradients w.r.t. the input to <c>max_pool</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.max_pool_grad_grad_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.String,System.String)">
            <summary>
               Computes second-order gradients of the maxpooling function.
            </summary>
            <param name="orig_input">
               The original input tensor.
            </param>
            <param name="orig_output">
               The original output tensor.
            </param>
            <param name="grad">
               4-D.  Gradients of gradients w.r.t. the input of <c>max_pool</c>.
            </param>
            <param name="ksize">
               The size of the window for each dimension of the input tensor.
            </param>
            <param name="strides">
               The stride of the sliding window for each dimension of the
               input tensor.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MaxPoolGradGradV2'.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <param name="data_format">
               Specify the data format of the input and output data. With the
               default format "NHWC", the data is stored in the order of:
               [batch, in_height, in_width, in_channels].
               Alternatively, the format could be "NCHW", the data storage order of:
               [batch, in_channels, in_height, in_width].
            </param>
            <returns>
               Gradients of gradients w.r.t. the input to <c>max_pool</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.max_pool_grad_grad_with_argmax(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32[],System.Int32[],System.String,System.String)">
            <summary>
               Computes second-order gradients of the maxpooling function.
            </summary>
            <param name="input">
               The original input.
            </param>
            <param name="grad">
               4-D with shape <c>[batch, height, width, channels]</c>.  Gradients w.r.t. the
               input of <c>max_pool</c>.
            </param>
            <param name="argmax">
               The indices of the maximum values chosen for each output of <c>max_pool</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MaxPoolGradGradWithArgmax'.
            </param>
            <param name="ksize">
               Optional argument
               The size of the window for each dimension of the input tensor.
            </param>
            <param name="strides">
               Optional argument
               The stride of the sliding window for each dimension of the
               input tensor.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <returns>
               Gradients of gradients w.r.t. the input of <c>max_pool</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.max_pool_grad_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.String,System.String)">
            <summary>
               Computes gradients of the maxpooling function.
            </summary>
            <param name="orig_input">
               The original input tensor.
            </param>
            <param name="orig_output">
               The original output tensor.
            </param>
            <param name="grad">
               4-D.  Gradients w.r.t. the output of <c>max_pool</c>.
            </param>
            <param name="ksize">
               The size of the window for each dimension of the input tensor.
            </param>
            <param name="strides">
               The stride of the sliding window for each dimension of the
               input tensor.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MaxPoolGradV2'.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <param name="data_format">
               Specify the data format of the input and output data. With the
               default format "NHWC", the data is stored in the order of:
               [batch, in_height, in_width, in_channels].
               Alternatively, the format could be "NCHW", the data storage order of:
               [batch, in_channels, in_height, in_width].
            </param>
            <returns>
               Gradients w.r.t. the input to <c>max_pool</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.max_pool_grad_with_argmax(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32[],System.Int32[],System.String,System.String)">
            <summary>
               Computes gradients of the maxpooling function.
            </summary>
            <param name="input">
               The original input.
            </param>
            <param name="grad">
               4-D with shape <c>[batch, height, width, channels]</c>.  Gradients w.r.t. the
               output of <c>max_pool</c>.
            </param>
            <param name="argmax">
               The indices of the maximum values chosen for each output of <c>max_pool</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MaxPoolGradWithArgmax'.
            </param>
            <param name="ksize">
               Optional argument
               The size of the window for each dimension of the input tensor.
            </param>
            <param name="strides">
               Optional argument
               The stride of the sliding window for each dimension of the
               input tensor.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <returns>
               Gradients w.r.t. the input of <c>max_pool</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.max_pool_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.String,System.String)">
            <summary>
               Performs max pooling on the input.
            </summary>
            <param name="input">
               4-D input to pool over.
            </param>
            <param name="ksize">
               The size of the window for each dimension of the input tensor.
            </param>
            <param name="strides">
               The stride of the sliding window for each dimension of the
               input tensor.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MaxPoolV2'.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <param name="data_format">
               Specify the data format of the input and output data. With the
               default format "NHWC", the data is stored in the order of:
               [batch, in_height, in_width, in_channels].
               Alternatively, the format could be "NCHW", the data storage order of:
               [batch, in_channels, in_height, in_width].
            </param>
            <returns>
               The max pooled output tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.max_pool_with_argmax(Tensorflow.Tensor,System.Int32[],System.Int32[],System.String,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Performs max pooling on the input and outputs both max values and indices.
            </summary>
            <param name="input">
               4-D with shape <c>[batch, height, width, channels]</c>.  Input to pool over.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MaxPoolWithArgmax'.
            </param>
            <param name="ksize">
               Optional argument
               The size of the window for each dimension of the input tensor.
            </param>
            <param name="strides">
               Optional argument
               The stride of the sliding window for each dimension of the
               input tensor.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <param name="Targmax">
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output : The max pooled output tensor.
               argmax : 4-D.  The flattened indices of the max values chosen for each output.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               The indices in <c>argmax</c> are flattened, so that a maximum value at position
               <c>[b, y, x, c]</c> becomes flattened index
               <c>((b * height + y) * width + x) * channels + c</c>.
               
               The indices returned are always in <c>[0, height) x [0, width)</c> before flattening,
               even if padding is involved and the mathematically correct answer is outside
               (either negative or too large).  This is a bug, but fixing it is difficult to do
               in a safe backwards compatible way, especially due to flattening.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.maximum(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns the max of x and y (i.e. x &amp;gt; y ? x : y) element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Maximum'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               *NOTE*: <c>Maximum</c> supports broadcasting. More about broadcasting
               [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.mean(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Computes the mean of elements across dimensions of a tensor.
            </summary>
            <param name="input">
               The tensor to reduce.
            </param>
            <param name="reduction_indices">
               The dimensions to reduce. Must be in the range
               <c>[-rank(input), rank(input))</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Mean'.
            </param>
            <param name="keep_dims">
               If true, retain reduced dimensions with length 1.
            </param>
            <returns>
               The reduced tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Reduces <c>input</c> along the dimensions given in <c>axis</c>. Unless
               <c>keep_dims</c> is true, the rank of the tensor is reduced by 1 for each entry in
               <c>axis</c>. If <c>keep_dims</c> is true, the reduced dimensions are
               retained with length 1.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.merge(Tensorflow.Tensor[],System.String)">
            <summary>
               Forwards the value of an available tensor from <c>inputs</c> to <c>output</c>.
            </summary>
            <param name="inputs">
               The input tensors, exactly one of which will become available.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Merge'.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output : Will be set to the available input tensor.
               value_index : The index of the chosen input tensor in <c>inputs</c>.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               <c>Merge</c> waits for at least one of the tensors in <c>inputs</c> to become available.
               It is usually combined with <c>Switch</c> to implement branching.
               
               <c>Merge</c> forwards the first tensor to become available to <c>output</c>, and sets
               <c>value_index</c> to its index in <c>inputs</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.merge_summary(Tensorflow.Tensor[],System.String)">
            <summary>
               Merges summaries.
            </summary>
            <param name="inputs">
               Can be of any shape.  Each must contain serialized <c>Summary</c> protocol
               buffers.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MergeSummary'.
            </param>
            <returns>
               Scalar. Serialized <c>Summary</c> protocol buffer.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This op creates a
               [<c>Summary</c>](https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto)
               protocol buffer that contains the union of all the values in the input
               summaries.
               
               When the Op is run, it reports an <c>InvalidArgument</c> error if multiple values
               in the summaries to merge use the same tag.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.merge_v2checkpoints(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               V2 format specific: merges the metadata files of sharded checkpoints.  The
            </summary>
            <param name="checkpoint_prefixes">
               prefixes of V2 checkpoints to merge.
            </param>
            <param name="destination_prefix">
               scalar.  The desired final prefix.  Allowed to be the same
               as one of the checkpoint_prefixes.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MergeV2Checkpoints'.
            </param>
            <param name="delete_old_dirs">
               see above.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               result is one logical checkpoint, with one physical metadata file and renamed
               data files.
               
               Intended for "grouping" multiple checkpoints in a sharded checkpoint setup.
               
               If delete_old_dirs is true, attempts to delete recursively the dirname of each
               path in the input checkpoint_prefixes.  This is useful when those paths are non
               user-facing temporary locations.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.mfcc(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Transforms a spectrogram into a form that's useful for speech recognition.
            </summary>
            <param name="spectrogram">
               Typically produced by the Spectrogram op, with magnitude_squared
               set to true.
            </param>
            <param name="sample_rate">
               How many samples per second the source audio used.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Mfcc'.
            </param>
            <param name="upper_frequency_limit">
               The highest frequency to use when calculating the
               ceptstrum.
            </param>
            <param name="lower_frequency_limit">
               The lowest frequency to use when calculating the
               ceptstrum.
            </param>
            <param name="filterbank_channel_count">
               Resolution of the Mel bank used internally.
            </param>
            <param name="dct_coefficient_count">
               How many output channels to produce per time slice.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Mel Frequency Cepstral Coefficients are a way of representing audio data that's
               been effective as an input feature for machine learning. They are created by
               taking the spectrum of a spectrogram (a 'cepstrum'), and discarding some of the
               higher frequencies that are less significant to the human ear. They have a long
               history in the speech recognition world, and https://en.wikipedia.org/wiki/Mel-frequency_cepstrum
               is a good resource to learn more.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.min(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Computes the minimum of elements across dimensions of a tensor.
            </summary>
            <param name="input">
               The tensor to reduce.
            </param>
            <param name="reduction_indices">
               The dimensions to reduce. Must be in the range
               <c>[-rank(input), rank(input))</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Min'.
            </param>
            <param name="keep_dims">
               If true, retain reduced dimensions with length 1.
            </param>
            <returns>
               The reduced tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Reduces <c>input</c> along the dimensions given in <c>axis</c>. Unless
               <c>keep_dims</c> is true, the rank of the tensor is reduced by 1 for each entry in
               <c>axis</c>. If <c>keep_dims</c> is true, the reduced dimensions are
               retained with length 1.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.minimum(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns the min of x and y (i.e. x &amp;lt; y ? x : y) element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Minimum'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               *NOTE*: <c>Minimum</c> supports broadcasting. More about broadcasting
               [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.mirror_pad(Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.String)">
            <summary>
               Pads a tensor with mirrored values.
            </summary>
            <param name="input">
               The input tensor to be padded.
            </param>
            <param name="paddings">
               A two-column matrix specifying the padding sizes. The number of
               rows must be the same as the rank of <c>input</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MirrorPad'.
            </param>
            <param name="mode">
               Optional argument
               Either <c>REFLECT</c> or <c>SYMMETRIC</c>. In reflect mode the padded regions
               do not include the borders, while in symmetric mode the padded regions
               do include the borders. For example, if <c>input</c> is <c>[1, 2, 3]</c> and <c>paddings</c>
               is <c>[0, 2]</c>, then the output is <c>[1, 2, 3, 2, 1]</c> in reflect mode, and
               it is <c>[1, 2, 3, 3, 2]</c> in symmetric mode.
            </param>
            <returns>
               The padded tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation pads a <c>input</c> with mirrored values according to the <c>paddings</c>
               you specify. <c>paddings</c> is an integer tensor with shape <c>[n, 2]</c>, where n is
               the rank of <c>input</c>. For each dimension D of <c>input</c>, <c>paddings[D, 0]</c> indicates
               how many values to add before the contents of <c>input</c> in that dimension, and
               <c>paddings[D, 1]</c> indicates how many values to add after the contents of <c>input</c>
               in that dimension. Both <c>paddings[D, 0]</c> and <c>paddings[D, 1]</c> must be no greater
               than <c>input.dim_size(D)</c> (or <c>input.dim_size(D) - 1</c>) if <c>copy_border</c> is true
               (if false, respectively).
               
               The padded size of each dimension D of the output is:
               
               <c>paddings(D, 0) + input.dim_size(D) + paddings(D, 1)</c>
               
               For example:
               
              <code>
               # 't' is [[1, 2, 3], [4, 5, 6]].
               # 'paddings' is [[1, 1]], [2, 2]].
               # 'mode' is SYMMETRIC.
               # rank of 't' is 2.
               pad(t, paddings) ==&amp;gt; [[2, 1, 1, 2, 3, 3, 2]
               [2, 1, 1, 2, 3, 3, 2]
               [5, 4, 4, 5, 6, 6, 5]
               [5, 4, 4, 5, 6, 6, 5]]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.mirror_pad_grad(Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.String)">
            <summary>
               Gradient op for <c>MirrorPad</c> op. This op folds a mirror-padded tensor.
            </summary>
            <param name="input">
               The input tensor to be folded.
            </param>
            <param name="paddings">
               A two-column matrix specifying the padding sizes. The number of
               rows must be the same as the rank of <c>input</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MirrorPadGrad'.
            </param>
            <param name="mode">
               Optional argument
               The mode used in the <c>MirrorPad</c> op.
            </param>
            <returns>
               The folded tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation folds the padded areas of <c>input</c> by <c>MirrorPad</c> according to the
               <c>paddings</c> you specify. <c>paddings</c> must be the same as <c>paddings</c> argument
               given to the corresponding <c>MirrorPad</c> op.
               
               The folded size of each dimension D of the output is:
               
               <c>input.dim_size(D) - paddings(D, 0) - paddings(D, 1)</c>
               
               For example:
               
              <code>
               # 't' is [[1, 2, 3], [4, 5, 6], [7, 8, 9]].
               # 'paddings' is [[0, 1]], [0, 1]].
               # 'mode' is SYMMETRIC.
               # rank of 't' is 2.
               pad(t, paddings) ==&amp;gt; [[ 1,  5]
               [11, 28]]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.mod(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns element-wise remainder of division. This emulates C semantics in that
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Mod'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               the result here is consistent with a truncating divide. E.g.
               <c>tf.truncatediv(x, y) * y + truncate_mod(x, y) = x</c>.
               
               *NOTE*: <c>Mod</c> supports broadcasting. More about broadcasting
               [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.mul(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns x * y element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Mul'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               *NOTE*: <c>Multiply</c> supports broadcasting. More about broadcasting
               [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.multinomial(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Draws samples from a multinomial distribution.
            </summary>
            <param name="logits">
               2-D Tensor with shape <c>[batch_size, num_classes]</c>.  Each slice <c>[i, :]</c>
               represents the unnormalized log probabilities for all classes.
            </param>
            <param name="num_samples">
               0-D.  Number of independent samples to draw for each row slice.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Multinomial'.
            </param>
            <param name="seed">
               If either seed or seed2 is set to be non-zero, the internal random number
               generator is seeded by the given seed.  Otherwise, a random seed is used.
            </param>
            <param name="seed2">
               A second seed to avoid seed collision.
            </param>
            <param name="output_dtype">
            </param>
            <returns>
               2-D Tensor with shape <c>[batch_size, num_samples]</c>.  Each slice <c>[i, :]</c>
               contains the drawn class labels with range <c>[0, num_classes)</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.mutable_dense_hash_table(Tensorflow.Tensor,Tensorflow.TF_DataType,System.String,System.String,System.Nullable{System.Boolean},Tensorflow.TensorShape,System.Nullable{System.Int32},System.Nullable{System.Single},System.String)">
            <summary>
               Creates an empty hash table that uses tensors as the backing store.
            </summary>
            <param name="empty_key">
               The key used to represent empty key buckets internally. Must not
               be used in insert or lookup operations.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MutableDenseHashTable'.
            </param>
            <param name="value_dtype">
               Optional argument
               Type of the table values.
            </param>
            <param name="container">
               If non-empty, this table is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this table is shared under the given name across
               multiple sessions.
            </param>
            <param name="use_node_name_sharing">
            </param>
            <param name="value_shape">
               The shape of each value.
            </param>
            <param name="initial_num_buckets">
               The initial number of hash table buckets. Must be a power
               to 2.
            </param>
            <param name="max_load_factor">
               The maximum ratio between number of entries and number of
               buckets before growing the table. Must be between 0 and 1.
            </param>
            <returns>
               Handle to a table.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               It uses "open addressing" with quadratic reprobing to resolve
               collisions.
               
               This op creates a mutable hash table, specifying the type of its keys and
               values. Each value must be a scalar. Data can be inserted into the table using
               the insert operations. It does not support the initialization operation.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.mutable_dense_hash_table_v2(Tensorflow.Tensor,Tensorflow.TF_DataType,System.String,System.String,System.Nullable{System.Boolean},Tensorflow.TensorShape,System.Nullable{System.Int32},System.Nullable{System.Single},System.String)">
            <summary>
               Creates an empty hash table that uses tensors as the backing store.
            </summary>
            <param name="empty_key">
               The key used to represent empty key buckets internally. Must not
               be used in insert or lookup operations.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MutableDenseHashTableV2'.
            </param>
            <param name="value_dtype">
               Optional argument
               Type of the table values.
            </param>
            <param name="container">
               If non-empty, this table is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this table is shared under the given name across
               multiple sessions.
            </param>
            <param name="use_node_name_sharing">
            </param>
            <param name="value_shape">
               The shape of each value.
            </param>
            <param name="initial_num_buckets">
               The initial number of hash table buckets. Must be a power
               to 2.
            </param>
            <param name="max_load_factor">
               The maximum ratio between number of entries and number of
               buckets before growing the table. Must be between 0 and 1.
            </param>
            <returns>
               Handle to a table.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               It uses "open addressing" with quadratic reprobing to resolve
               collisions.
               
               This op creates a mutable hash table, specifying the type of its keys and
               values. Each value must be a scalar. Data can be inserted into the table using
               the insert operations. It does not support the initialization operation.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.mutable_hash_table(Tensorflow.TF_DataType,Tensorflow.TF_DataType,System.String,System.String,System.Nullable{System.Boolean},System.String)">
            <summary>
               Creates an empty hash table.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MutableHashTable'.
            </param>
            <param name="key_dtype">
               Optional argument
               Type of the table keys.
            </param>
            <param name="value_dtype">
               Optional argument
               Type of the table values.
            </param>
            <param name="container">
               If non-empty, this table is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this table is shared under the given name across
               multiple sessions.
            </param>
            <param name="use_node_name_sharing">
               If true and shared_name is empty, the table is shared
               using the node name.
            </param>
            <returns>
               Handle to a table.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This op creates a mutable hash table, specifying the type of its keys and
               values. Each value must be a scalar. Data can be inserted into the table using
               the insert operations. It does not support the initialization operation.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.mutable_hash_table_of_tensors(Tensorflow.TF_DataType,Tensorflow.TF_DataType,System.String,System.String,System.Nullable{System.Boolean},Tensorflow.TensorShape,System.String)">
            <summary>
               Creates an empty hash table.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MutableHashTableOfTensors'.
            </param>
            <param name="key_dtype">
               Optional argument
               Type of the table keys.
            </param>
            <param name="value_dtype">
               Optional argument
               Type of the table values.
            </param>
            <param name="container">
               If non-empty, this table is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this table is shared under the given name across
               multiple sessions.
            </param>
            <param name="use_node_name_sharing">
            </param>
            <param name="value_shape">
            </param>
            <returns>
               Handle to a table.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This op creates a mutable hash table, specifying the type of its keys and
               values. Each value must be a vector. Data can be inserted into the table using
               the insert operations. It does not support the initialization operation.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.mutable_hash_table_of_tensors_v2(Tensorflow.TF_DataType,Tensorflow.TF_DataType,System.String,System.String,System.Nullable{System.Boolean},Tensorflow.TensorShape,System.String)">
            <summary>
               Creates an empty hash table.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MutableHashTableOfTensorsV2'.
            </param>
            <param name="key_dtype">
               Optional argument
               Type of the table keys.
            </param>
            <param name="value_dtype">
               Optional argument
               Type of the table values.
            </param>
            <param name="container">
               If non-empty, this table is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this table is shared under the given name across
               multiple sessions.
            </param>
            <param name="use_node_name_sharing">
            </param>
            <param name="value_shape">
            </param>
            <returns>
               Handle to a table.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This op creates a mutable hash table, specifying the type of its keys and
               values. Each value must be a vector. Data can be inserted into the table using
               the insert operations. It does not support the initialization operation.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.mutable_hash_table_v2(Tensorflow.TF_DataType,Tensorflow.TF_DataType,System.String,System.String,System.Nullable{System.Boolean},System.String)">
            <summary>
               Creates an empty hash table.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MutableHashTableV2'.
            </param>
            <param name="key_dtype">
               Optional argument
               Type of the table keys.
            </param>
            <param name="value_dtype">
               Optional argument
               Type of the table values.
            </param>
            <param name="container">
               If non-empty, this table is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this table is shared under the given name across
               multiple sessions.
            </param>
            <param name="use_node_name_sharing">
               If true and shared_name is empty, the table is shared
               using the node name.
            </param>
            <returns>
               Handle to a table.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This op creates a mutable hash table, specifying the type of its keys and
               values. Each value must be a scalar. Data can be inserted into the table using
               the insert operations. It does not support the initialization operation.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.mutex_lock(Tensorflow.Tensor,System.String)">
            <summary>
               Locks a mutex resource.  The output is the lock.  So long as the lock tensor
            </summary>
            <param name="mutex">
               The mutex resource to lock.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MutexLock'.
            </param>
            <returns>
               A tensor that keeps a shared pointer to a lock on the mutex;
               when the Tensor is destroyed, the use count on the shared pointer is decreased
               by 1.  When it reaches 0, the lock is released.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               is alive, any other request to use <c>MutexLock</c> with this mutex will wait.
               
               This is particularly useful for creating a critical section when used in
               conjunction with <c>MutexLockIdentity</c>:
               
              <code>
               
               mutex = mutex_v2(
               shared_name=handle_name, container=container, name=name)
               
               def execute_in_critical_section(fn, *args, **kwargs):
               lock = gen_resource_variable_ops.mutex_lock(mutex)
               
               with ops.control_dependencies([lock]):
               r = fn(*args, **kwargs)
               
               with ops.control_dependencies(nest.flatten(r)):
               with ops.colocate_with(mutex):
               ensure_lock_exists = mutex_lock_identity(lock)
               
               # Make sure that if any element of r is accessed, all of
               # them are executed together.
               r = nest.map_structure(tf.identity, r)
               
               with ops.control_dependencies([ensure_lock_exists]):
               return nest.map_structure(tf.identity, r)
              </code>
               
               While <c>fn</c> is running in the critical section, no other functions which wish to
               use this critical section may run.
               
               Often the use case is that two executions of the same graph, in parallel,
               wish to run <c>fn</c>; and we wish to ensure that only one of them executes
               at a time.  This is especially important if <c>fn</c> modifies one or more
               variables at a time.
               
               It is also useful if two separate functions must share a resource, but we
               wish to ensure the usage is exclusive.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.mutex_v2(System.String,System.String,System.String)">
            <summary>
               Creates a Mutex resource that can be locked by <c>MutexLock</c>.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MutexV2'.
            </param>
            <param name="container">
               If non-empty, this variable is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this variable is named in the given bucket
               with this shared_name. Otherwise, the node name is used instead.
            </param>
            <returns>
               The mutex resource.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.neg(Tensorflow.Tensor,System.String)">
            <summary>
               Computes numerical negative value element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Neg'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               I.e., \\(y = -x\\).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.neg_train(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32[],System.Int32,System.String)">
            <summary>
               Training via negative sampling.
            </summary>
            <param name="w_in">
               input word embedding.
            </param>
            <param name="w_out">
               output word embedding.
            </param>
            <param name="examples">
               A vector of word ids.
            </param>
            <param name="labels">
               A vector of word ids.
            </param>
            <param name="lr">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'NegTrain'.
            </param>
            <param name="vocab_count">
               Optional argument
               Count of words in the vocabulary.
            </param>
            <param name="num_negative_samples">
               Optional argument
               Number of negative samples per example.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.next_iteration(Tensorflow.Tensor,System.String)">
            <summary>
               Makes its input available to the next iteration.
            </summary>
            <param name="data">
               The tensor to be made available to the next iteration.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'NextIteration'.
            </param>
            <returns>
               The same tensor as <c>data</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.no_op(System.String)">
            <summary>
               Does nothing. Only useful as a placeholder for control edges.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'NoOp'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.non_max_suppression(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Single},System.String)">
            <summary>
               Greedily selects a subset of bounding boxes in descending order of score,
            </summary>
            <param name="boxes">
               A 2-D float tensor of shape <c>[num_boxes, 4]</c>.
            </param>
            <param name="scores">
               A 1-D float tensor of shape <c>[num_boxes]</c> representing a single
               score corresponding to each box (each row of boxes).
            </param>
            <param name="max_output_size">
               A scalar integer tensor representing the maximum number of
               boxes to be selected by non max suppression.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'NonMaxSuppression'.
            </param>
            <param name="iou_threshold">
               A float representing the threshold for deciding whether boxes
               overlap too much with respect to IOU.
            </param>
            <returns>
               A 1-D integer tensor of shape <c>[M]</c> representing the selected
               indices from the boxes tensor, where <c>M &amp;lt;= max_output_size</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               pruning away boxes that have high intersection-over-union (IOU) overlap
               with previously selected boxes.  Bounding boxes are supplied as
               [y1, x1, y2, x2], where (y1, x1) and (y2, x2) are the coordinates of any
               diagonal pair of box corners and the coordinates can be provided as normalized
               (i.e., lying in the interval [0, 1]) or absolute.  Note that this algorithm
               is agnostic to where the origin is in the coordinate system.  Note that this
               algorithm is invariant to orthogonal transformations and translations
               of the coordinate system; thus translating or reflections of the coordinate
               system result in the same boxes being selected by the algorithm.
               The output of this operation is a set of integers indexing into the input
               collection of bounding boxes representing the selected boxes.  The bounding
               box coordinates corresponding to the selected indices can then be obtained
               using the <c>tf.gather operation</c>.  For example:
               selected_indices = tf.image.non_max_suppression(
               boxes, scores, max_output_size, iou_threshold)
               selected_boxes = tf.gather(boxes, selected_indices)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.non_max_suppression_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Greedily selects a subset of bounding boxes in descending order of score,
            </summary>
            <param name="boxes">
               A 2-D float tensor of shape <c>[num_boxes, 4]</c>.
            </param>
            <param name="scores">
               A 1-D float tensor of shape <c>[num_boxes]</c> representing a single
               score corresponding to each box (each row of boxes).
            </param>
            <param name="max_output_size">
               A scalar integer tensor representing the maximum number of
               boxes to be selected by non max suppression.
            </param>
            <param name="iou_threshold">
               A 0-D float tensor representing the threshold for deciding whether
               boxes overlap too much with respect to IOU.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'NonMaxSuppressionV2'.
            </param>
            <returns>
               A 1-D integer tensor of shape <c>[M]</c> representing the selected
               indices from the boxes tensor, where <c>M &amp;lt;= max_output_size</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               pruning away boxes that have high intersection-over-union (IOU) overlap
               with previously selected boxes.  Bounding boxes are supplied as
               [y1, x1, y2, x2], where (y1, x1) and (y2, x2) are the coordinates of any
               diagonal pair of box corners and the coordinates can be provided as normalized
               (i.e., lying in the interval [0, 1]) or absolute.  Note that this algorithm
               is agnostic to where the origin is in the coordinate system.  Note that this
               algorithm is invariant to orthogonal transformations and translations
               of the coordinate system; thus translating or reflections of the coordinate
               system result in the same boxes being selected by the algorithm.
               
               The output of this operation is a set of integers indexing into the input
               collection of bounding boxes representing the selected boxes.  The bounding
               box coordinates corresponding to the selected indices can then be obtained
               using the <c>tf.gather operation</c>.  For example:
               
               selected_indices = tf.image.non_max_suppression_v2(
               boxes, scores, max_output_size, iou_threshold)
               selected_boxes = tf.gather(boxes, selected_indices)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.non_max_suppression_v3(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Greedily selects a subset of bounding boxes in descending order of score,
            </summary>
            <param name="boxes">
               A 2-D float tensor of shape <c>[num_boxes, 4]</c>.
            </param>
            <param name="scores">
               A 1-D float tensor of shape <c>[num_boxes]</c> representing a single
               score corresponding to each box (each row of boxes).
            </param>
            <param name="max_output_size">
               A scalar integer tensor representing the maximum number of
               boxes to be selected by non max suppression.
            </param>
            <param name="iou_threshold">
               A 0-D float tensor representing the threshold for deciding whether
               boxes overlap too much with respect to IOU.
            </param>
            <param name="score_threshold">
               A 0-D float tensor representing the threshold for deciding when to remove
               boxes based on score.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'NonMaxSuppressionV3'.
            </param>
            <returns>
               A 1-D integer tensor of shape <c>[M]</c> representing the selected
               indices from the boxes tensor, where <c>M &amp;lt;= max_output_size</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               pruning away boxes that have high intersection-over-union (IOU) overlap
               with previously selected boxes.  Bounding boxes with score less than
               <c>score_threshold</c> are removed.  Bounding boxes are supplied as
               [y1, x1, y2, x2], where (y1, x1) and (y2, x2) are the coordinates of any
               diagonal pair of box corners and the coordinates can be provided as normalized
               (i.e., lying in the interval [0, 1]) or absolute.  Note that this algorithm
               is agnostic to where the origin is in the coordinate system and more
               generally is invariant to orthogonal transformations and translations
               of the coordinate system; thus translating or reflections of the coordinate
               system result in the same boxes being selected by the algorithm.
               The output of this operation is a set of integers indexing into the input
               collection of bounding boxes representing the selected boxes.  The bounding
               box coordinates corresponding to the selected indices can then be obtained
               using the <c>tf.gather operation</c>.  For example:
               selected_indices = tf.image.non_max_suppression_v2(
               boxes, scores, max_output_size, iou_threshold, score_threshold)
               selected_boxes = tf.gather(boxes, selected_indices)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.non_max_suppression_v4(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Greedily selects a subset of bounding boxes in descending order of score,
            </summary>
            <param name="boxes">
               A 2-D float tensor of shape <c>[num_boxes, 4]</c>.
            </param>
            <param name="scores">
               A 1-D float tensor of shape <c>[num_boxes]</c> representing a single
               score corresponding to each box (each row of boxes).
            </param>
            <param name="max_output_size">
               A scalar integer tensor representing the maximum number of
               boxes to be selected by non max suppression.
            </param>
            <param name="iou_threshold">
               A 0-D float tensor representing the threshold for deciding whether
               boxes overlap too much with respect to IOU.
            </param>
            <param name="score_threshold">
               A 0-D float tensor representing the threshold for deciding when to remove
               boxes based on score.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'NonMaxSuppressionV4'.
            </param>
            <param name="pad_to_max_output_size">
               If true, the output <c>selected_indices</c> is padded to be of length
               <c>max_output_size</c>. Defaults to false.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               selected_indices : A 1-D integer tensor of shape <c>[M]</c> representing the selected
               indices from the boxes tensor, where <c>M &amp;lt;= max_output_size</c>.
               valid_outputs : A 0-D integer tensor representing the number of valid elements in
               <c>selected_indices</c>, with the valid elements appearing first.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               pruning away boxes that have high intersection-over-union (IOU) overlap
               with previously selected boxes.  Bounding boxes with score less than
               <c>score_threshold</c> are removed.  Bounding boxes are supplied as
               [y1, x1, y2, x2], where (y1, x1) and (y2, x2) are the coordinates of any
               diagonal pair of box corners and the coordinates can be provided as normalized
               (i.e., lying in the interval [0, 1]) or absolute.  Note that this algorithm
               is agnostic to where the origin is in the coordinate system and more
               generally is invariant to orthogonal transformations and translations
               of the coordinate system; thus translating or reflections of the coordinate
               system result in the same boxes being selected by the algorithm.
               The output of this operation is a set of integers indexing into the input
               collection of bounding boxes representing the selected boxes.  The bounding
               box coordinates corresponding to the selected indices can then be obtained
               using the <c>tf.gather operation</c>.  For example:
               selected_indices = tf.image.non_max_suppression_v2(
               boxes, scores, max_output_size, iou_threshold, score_threshold)
               selected_boxes = tf.gather(boxes, selected_indices)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.non_max_suppression_with_overlaps(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Greedily selects a subset of bounding boxes in descending order of score,
            </summary>
            <param name="overlaps">
               A 2-D float tensor of shape <c>[num_boxes, num_boxes]</c> representing
               the n-by-n box overlap values.
            </param>
            <param name="scores">
               A 1-D float tensor of shape <c>[num_boxes]</c> representing a single
               score corresponding to each box (each row of boxes).
            </param>
            <param name="max_output_size">
               A scalar integer tensor representing the maximum number of
               boxes to be selected by non max suppression.
            </param>
            <param name="overlap_threshold">
               A 0-D float tensor representing the threshold for deciding whether
               boxes overlap too.
            </param>
            <param name="score_threshold">
               A 0-D float tensor representing the threshold for deciding when to remove
               boxes based on score.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'NonMaxSuppressionWithOverlaps'.
            </param>
            <returns>
               A 1-D integer tensor of shape <c>[M]</c> representing the selected
               indices from the boxes tensor, where <c>M &amp;lt;= max_output_size</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               pruning away boxes that have high overlaps
               with previously selected boxes.  Bounding boxes with score less than
               <c>score_threshold</c> are removed. N-by-n overlap values are supplied as square matrix,
               which allows for defining a custom overlap criterium (eg. intersection over union,
               intersection over area, etc.).
               
               The output of this operation is a set of integers indexing into the input
               collection of bounding boxes representing the selected boxes.  The bounding
               box coordinates corresponding to the selected indices can then be obtained
               using the <c>tf.gather operation</c>.  For example:
               
               selected_indices = tf.image.non_max_suppression_with_overlaps(
               overlaps, scores, max_output_size, overlap_threshold, score_threshold)
               selected_boxes = tf.gather(boxes, selected_indices)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.not_equal(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns the truth value of (x != y) element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'NotEqual'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               *NOTE*: <c>NotEqual</c> supports broadcasting. More about broadcasting
               [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.nth_element(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Finds values of the <c>n</c>-th order statistic for the last dimension.
            </summary>
            <param name="input">
               1-D or higher with last dimension at least <c>n+1</c>.
            </param>
            <param name="n">
               0-D. Position of sorted vector to select along the last dimension (along
               each row for matrices). Valid range of n is <c>[0, input.shape[:-1])</c>
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'NthElement'.
            </param>
            <param name="reverse">
               When set to True, find the nth-largest value in the vector and vice
               versa.
            </param>
            <returns>
               The <c>n</c>-th order statistic along each last dimensional slice.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               If the input is a vector (rank-1), finds the entries which is the nth-smallest
               value in the vector and outputs their values as scalar tensor.
               
               For matrices (resp. higher rank input), computes the entries which is the
               nth-smallest value in each row (resp. vector along the last dimension). Thus,
               
               values.shape = input.shape[:-1]
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.one_hot(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Int32},System.String)">
            <summary>
               Returns a one-hot tensor.
            </summary>
            <param name="indices">
               A tensor of indices.
            </param>
            <param name="depth">
               A scalar defining the depth of the one hot dimension.
            </param>
            <param name="on_value">
               A scalar defining the value to fill in output when <c>indices[j] = i</c>.
            </param>
            <param name="off_value">
               A scalar defining the value to fill in output when <c>indices[j] != i</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'OneHot'.
            </param>
            <param name="axis">
               The axis to fill (default: -1, a new inner-most axis).
            </param>
            <returns>
               The one-hot tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The locations represented by indices in <c>indices</c> take value <c>on_value</c>,
               while all other locations take value <c>off_value</c>.
               
               If the input <c>indices</c> is rank <c>N</c>, the output will have rank <c>N+1</c>,
               The new axis is created at dimension <c>axis</c> (default: the new axis is
               appended at the end).
               
               If <c>indices</c> is a scalar the output shape will be a vector of length <c>depth</c>.
               
               If <c>indices</c> is a vector of length <c>features</c>, the output shape will be:
              <code>
               features x depth if axis == -1
               depth x features if axis == 0
              </code>
               
               If <c>indices</c> is a matrix (batch) with shape <c>[batch, features]</c>,
               the output shape will be:
              <code>
               batch x features x depth if axis == -1
               batch x depth x features if axis == 1
               depth x batch x features if axis == 0
              </code>
               
               
               Examples
               =========
               
               Suppose that
               
              <code>
               indices = [0, 2, -1, 1]
               depth = 3
               on_value = 5.0
               off_value = 0.0
               axis = -1
              </code>
               
               Then output is <c>[4 x 3]</c>:
               
              <code>
               output =
               [5.0 0.0 0.0]  // one_hot(0)
               [0.0 0.0 5.0]  // one_hot(2)
               [0.0 0.0 0.0]  // one_hot(-1)
               [0.0 5.0 0.0]  // one_hot(1)
              </code>
               
               Suppose that
               
              <code>
               indices = [0, 2, -1, 1]
               depth = 3
               on_value = 0.0
               off_value = 3.0
               axis = 0
              </code>
               
               Then output is <c>[3 x 4]</c>:
               
              <code>
               output =
               [0.0 3.0 3.0 3.0]
               [3.0 3.0 3.0 0.0]
               [3.0 3.0 3.0 3.0]
               [3.0 0.0 3.0 3.0]
               //  ^                one_hot(0)
               //      ^            one_hot(2)
               //          ^        one_hot(-1)
               //              ^    one_hot(1)
              </code>
               Suppose that
               
              <code>
               indices = [[0, 2], [1, -1]]
               depth = 3
               on_value = 1.0
               off_value = 0.0
               axis = -1
              </code>
               
               Then output is <c>[2 x 2 x 3]</c>:
               
              <code>
               output =
               [
               [1.0, 0.0, 0.0]  // one_hot(0)
               [0.0, 0.0, 1.0]  // one_hot(2)
               ][
               [0.0, 1.0, 0.0]  // one_hot(1)
               [0.0, 0.0, 0.0]  // one_hot(-1)
               ]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.ones_like(Tensorflow.Tensor,System.String)">
            <summary>
               Returns a tensor of ones with the same shape and type as x.
            </summary>
            <param name="x">
               a tensor of type T.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'OnesLike'.
            </param>
            <returns>
               a tensor of the same shape and type as x but filled with ones.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.optimize_dataset(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Creates a dataset by applying optimizations to <c>input_dataset</c>.
            </summary>
            <param name="input_dataset">
               A variant tensor representing the input dataset.
            </param>
            <param name="optimizations">
               A <c>tf.string</c> vector <c>tf.Tensor</c> identifying optimizations to use.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'OptimizeDataset'.
            </param>
            <param name="output_types">
               Optional argument
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Creates a dataset by applying optimizations to <c>input_dataset</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.optional_from_value(Tensorflow.Tensor[],System.String)">
            <summary>
               Constructs an Optional variant from a tuple of tensors.
            </summary>
            <param name="components">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'OptionalFromValue'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.optional_get_value(Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Returns the value stored in an Optional variant or raises an error if none exists.
            </summary>
            <param name="optional">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'OptionalGetValue'.
            </param>
            <param name="output_types">
               Optional argument
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.optional_has_value(Tensorflow.Tensor,System.String)">
            <summary>
               Returns true if and only if the given Optional variant has a value.
            </summary>
            <param name="optional">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'OptionalHasValue'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.optional_none(System.String)">
            <summary>
               Creates an Optional variant with no value.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'OptionalNone'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.ordered_map_clear(Tensorflow.TF_DataType[],System.Nullable{System.Int32},System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               Op removes all elements in the underlying container.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'OrderedMapClear'.
            </param>
            <param name="dtypes">
               Optional argument
            </param>
            <param name="capacity">
            </param>
            <param name="memory_limit">
            </param>
            <param name="container">
            </param>
            <param name="shared_name">
            </param>
            <returns>
               Returns the description of the operation
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.ordered_map_incomplete_size(Tensorflow.TF_DataType[],System.Nullable{System.Int32},System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               Op returns the number of incomplete elements in the underlying container.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'OrderedMapIncompleteSize'.
            </param>
            <param name="dtypes">
               Optional argument
            </param>
            <param name="capacity">
            </param>
            <param name="memory_limit">
            </param>
            <param name="container">
            </param>
            <param name="shared_name">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.ordered_map_peek(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],System.Nullable{System.Int32},System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               Op peeks at the values at the specified key.  If the
            </summary>
            <param name="key">
            </param>
            <param name="indices">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'OrderedMapPeek'.
            </param>
            <param name="dtypes">
               Optional argument
            </param>
            <param name="capacity">
            </param>
            <param name="memory_limit">
            </param>
            <param name="container">
            </param>
            <param name="shared_name">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               underlying container does not contain this key
               this op will block until it does.   This Op is optimized for
               performance.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.ordered_map_size(Tensorflow.TF_DataType[],System.Nullable{System.Int32},System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               Op returns the number of elements in the underlying container.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'OrderedMapSize'.
            </param>
            <param name="dtypes">
               Optional argument
            </param>
            <param name="capacity">
            </param>
            <param name="memory_limit">
            </param>
            <param name="container">
            </param>
            <param name="shared_name">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.ordered_map_stage(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor[],Tensorflow.TF_DataType[],System.Nullable{System.Int32},System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               Stage (key, values) in the underlying container which behaves like a ordered
            </summary>
            <param name="key">
               int64
            </param>
            <param name="indices">
            </param>
            <param name="values">
               a list of tensors
               dtypes A list of data types that inserted values should adhere to.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'OrderedMapStage'.
            </param>
            <param name="dtypes">
               Optional argument
            </param>
            <param name="capacity">
               Maximum number of elements in the Staging Area. If &amp;gt; 0, inserts
               on the container will block when the capacity is reached.
            </param>
            <param name="memory_limit">
            </param>
            <param name="container">
               If non-empty, this queue is placed in the given container. Otherwise,
               a default container is used.
            </param>
            <param name="shared_name">
               It is necessary to match this name to the matching Unstage Op.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               associative container.   Elements are ordered by key.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.ordered_map_unstage(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],System.Nullable{System.Int32},System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               Op removes and returns the values associated with the key
            </summary>
            <param name="key">
            </param>
            <param name="indices">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'OrderedMapUnstage'.
            </param>
            <param name="dtypes">
               Optional argument
            </param>
            <param name="capacity">
            </param>
            <param name="memory_limit">
            </param>
            <param name="container">
            </param>
            <param name="shared_name">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               from the underlying container.   If the underlying container
               does not contain this key, the op will block until it does.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.ordered_map_unstage_no_key(Tensorflow.Tensor,Tensorflow.TF_DataType[],System.Nullable{System.Int32},System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               Op removes and returns the (key, value) element with the smallest
            </summary>
            <param name="indices">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'OrderedMapUnstageNoKey'.
            </param>
            <param name="dtypes">
               Optional argument
            </param>
            <param name="capacity">
            </param>
            <param name="memory_limit">
            </param>
            <param name="container">
            </param>
            <param name="shared_name">
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               key :
               values :
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               key from the underlying container.   If the underlying container
               does not contain elements, the op will block until it does.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.outfeed_dequeue(Tensorflow.TF_DataType,Tensorflow.TensorShape,System.Nullable{System.Int32},System.String)">
            <summary>
               Retrieves a single tensor from the computation outfeed.  This operation will
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'OutfeedDequeue'.
            </param>
            <param name="dtype">
               Optional argument
               The type of elements in the tensor.
            </param>
            <param name="shape">
               Optional argument
               The shape of the tensor.
            </param>
            <param name="device_ordinal">
               The TPU device to use. This should be -1 when the Op
               is running on a TPU device, and &amp;gt;= 0 when the Op is running on the CPU
               device.
            </param>
            <returns>
               A tensor that will be read from the device outfeed.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               block indefinitely until data is available.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.outfeed_dequeue_tuple(Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.Nullable{System.Int32},System.String)">
            <summary>
               Retrieve multiple values that will be emitted by the computation as an XLA
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'OutfeedDequeueTuple'.
            </param>
            <param name="dtypes">
               Optional argument
               The element types of each element in <c>outputs</c>.
            </param>
            <param name="shapes">
               Optional argument
               The shapes of each tensor in <c>outputs</c>.
            </param>
            <param name="device_ordinal">
               The TPU device to use. This should be -1 when the Op
               is running on a TPU device, and &amp;gt;= 0 when the Op is running on the CPU
               device.
            </param>
            <returns>
               A list of tensors that will be read from the outfeed.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               tuple.  This operations will block indefinitely until data is available.
               Output <c>i</c> corresponds to XLA tuple element <c>i</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.outfeed_enqueue(Tensorflow.Tensor,System.String)">
            <summary>
               An op which emits a single Tensor value from an XLA computation.
            </summary>
            <param name="input">
               A tensor that will be inserted into the outfeed queue.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'OutfeedEnqueue'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.outfeed_enqueue_tuple(Tensorflow.Tensor[],System.String)">
            <summary>
               An op which emits multiple Tensor values from an XLA computation.
            </summary>
            <param name="inputs">
               A list of tensors that will be inserted into the outfeed queue as an
               XLA tuple.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'OutfeedEnqueueTuple'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.pack(Tensorflow.Tensor[],System.Nullable{System.Int32},System.String)">
            <summary>
               Packs a list of <c>N</c> rank-<c>R</c> tensors into one rank-<c>(R+1)</c> tensor.
            </summary>
            <param name="values">
               Must be of same shape and type.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Pack'.
            </param>
            <param name="axis">
               Dimension along which to pack.  Negative values wrap around, so the
               valid range is <c>[-(R+1), R+1)</c>.
            </param>
            <returns>
               The packed tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Packs the <c>N</c> tensors in <c>values</c> into a tensor with rank one higher than each
               tensor in <c>values</c>, by packing them along the <c>axis</c> dimension.
               Given a list of tensors of shape <c>(A, B, C)</c>;
               
               if <c>axis == 0</c> then the <c>output</c> tensor will have the shape <c>(N, A, B, C)</c>.
               if <c>axis == 1</c> then the <c>output</c> tensor will have the shape <c>(A, N, B, C)</c>.
               Etc.
               
               For example:
               
              <code>
               # 'x' is [1, 4]
               # 'y' is [2, 5]
               # 'z' is [3, 6]
               pack([x, y, z]) =&amp;gt; [[1, 4], [2, 5], [3, 6]]  # Pack along first dim.
               pack([x, y, z], axis=1) =&amp;gt; [[1, 2, 3], [4, 5, 6]]
              </code>
               
               This is the opposite of <c>unpack</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.pad(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Pads a tensor with zeros.
            </summary>
            <param name="input">
            </param>
            <param name="paddings">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Pad'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation pads a <c>input</c> with zeros according to the <c>paddings</c> you
               specify. <c>paddings</c> is an integer tensor with shape <c>[Dn, 2]</c>, where n is the
               rank of <c>input</c>. For each dimension D of <c>input</c>, <c>paddings[D, 0]</c> indicates
               how many zeros to add before the contents of <c>input</c> in that dimension, and
               <c>paddings[D, 1]</c> indicates how many zeros to add after the contents of <c>input</c>
               in that dimension.
               
               The padded size of each dimension D of the output is:
               
               <c>paddings(D, 0) + input.dim_size(D) + paddings(D, 1)</c>
               
               For example:
               
              <code>
               # 't' is [[1, 1], [2, 2]]
               # 'paddings' is [[1, 1], [2, 2]]
               # rank of 't' is 2
               pad(t, paddings) ==&amp;gt; [[0, 0, 0, 0, 0, 0]
               [0, 0, 1, 1, 0, 0]
               [0, 0, 2, 2, 0, 0]
               [0, 0, 0, 0, 0, 0]]
              </code>
               
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.pad_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Pads a tensor.
            </summary>
            <param name="input">
            </param>
            <param name="paddings">
            </param>
            <param name="constant_values">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'PadV2'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation pads <c>input</c> according to the <c>paddings</c> and <c>constant_values</c>
               you specify. <c>paddings</c> is an integer tensor with shape <c>[Dn, 2]</c>, where n is
               the rank of <c>input</c>. For each dimension D of <c>input</c>, <c>paddings[D, 0]</c> indicates
               how many padding values to add before the contents of <c>input</c> in that dimension,
               and <c>paddings[D, 1]</c> indicates how many padding values to add after the contents
               of <c>input</c> in that dimension. <c>constant_values</c> is a scalar tensor of the same
               type as <c>input</c> that indicates the value to use for padding <c>input</c>.
               
               The padded size of each dimension D of the output is:
               
               <c>paddings(D, 0) + input.dim_size(D) + paddings(D, 1)</c>
               
               For example:
               
              <code>
               # 't' is [[1, 1], [2, 2]]
               # 'paddings' is [[1, 1], [2, 2]]
               # 'constant_values' is 0
               # rank of 't' is 2
               pad(t, paddings) ==&amp;gt; [[0, 0, 0, 0, 0, 0]
               [0, 0, 1, 1, 0, 0]
               [0, 0, 2, 2, 0, 0]
               [0, 0, 0, 0, 0, 0]]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.padded_batch_dataset(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor[],Tensorflow.Tensor[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Creates a dataset that batches and pads <c>batch_size</c> elements from the input.
            </summary>
            <param name="input_dataset">
            </param>
            <param name="batch_size">
               A scalar representing the number of elements to accumulate in a
               batch.
            </param>
            <param name="padded_shapes">
               A list of int64 tensors representing the desired padded shapes
               of the corresponding output components. These shapes may be partially
               specified, using <c>-1</c> to indicate that a particular dimension should be
               padded to the maximum size of all batch elements.
            </param>
            <param name="padding_values">
               A list of scalars containing the padding value to use for
               each of the outputs.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'PaddedBatchDataset'.
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.padded_batch_dataset_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor[],Tensorflow.Tensor[],Tensorflow.Tensor,Tensorflow.TensorShape[],System.String)">
            <summary>
               Creates a dataset that batches and pads <c>batch_size</c> elements from the input.
            </summary>
            <param name="input_dataset">
            </param>
            <param name="batch_size">
               A scalar representing the number of elements to accumulate in a
               batch.
            </param>
            <param name="padded_shapes">
               A list of int64 tensors representing the desired padded shapes
               of the corresponding output components. These shapes may be partially
               specified, using <c>-1</c> to indicate that a particular dimension should be
               padded to the maximum size of all batch elements.
            </param>
            <param name="padding_values">
               A list of scalars containing the padding value to use for
               each of the outputs.
            </param>
            <param name="drop_remainder">
               A scalar representing whether the last batch should be dropped in case its size
               is smaller than desired.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'PaddedBatchDatasetV2'.
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.padding_f_i_f_o_queue(Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               A queue that produces elements in first-in first-out order.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'PaddingFIFOQueue'.
            </param>
            <param name="component_types">
               Optional argument
               The type of each component in a value.
            </param>
            <param name="shapes">
               The shape of each component in a value. The length of this attr must
               be either 0 or the same as the length of component_types.
               Shapes of fixed rank but variable size are allowed by setting
               any shape dimension to -1.  In this case, the inputs' shape may vary along
               the given dimension, and DequeueMany will pad the given dimension with
               zeros up to the maximum shape of all elements in the given batch.
               If the length of this attr is 0, different queue elements may have
               different ranks and shapes, but only one element may be dequeued at a time.
            </param>
            <param name="capacity">
               The upper bound on the number of elements in this queue.
               Negative numbers mean no limit.
            </param>
            <param name="container">
               If non-empty, this queue is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this queue will be shared under the given name
               across multiple sessions.
            </param>
            <returns>
               The handle to the queue.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Variable-size shapes are allowed by setting the corresponding shape dimensions
               to 0 in the shape attr.  In this case DequeueMany will pad up to the maximum
               size of any given element in the minibatch.  See below for details.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.padding_f_i_f_o_queue_v2(Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               A queue that produces elements in first-in first-out order.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'PaddingFIFOQueueV2'.
            </param>
            <param name="component_types">
               Optional argument
               The type of each component in a value.
            </param>
            <param name="shapes">
               The shape of each component in a value. The length of this attr must
               be either 0 or the same as the length of component_types.
               Shapes of fixed rank but variable size are allowed by setting
               any shape dimension to -1.  In this case, the inputs' shape may vary along
               the given dimension, and DequeueMany will pad the given dimension with
               zeros up to the maximum shape of all elements in the given batch.
               If the length of this attr is 0, different queue elements may have
               different ranks and shapes, but only one element may be dequeued at a time.
            </param>
            <param name="capacity">
               The upper bound on the number of elements in this queue.
               Negative numbers mean no limit.
            </param>
            <param name="container">
               If non-empty, this queue is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this queue will be shared under the given name
               across multiple sessions.
            </param>
            <returns>
               The handle to the queue.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Variable-size shapes are allowed by setting the corresponding shape dimensions
               to 0 in the shape attr.  In this case DequeueMany will pad up to the maximum
               size of any given element in the minibatch.  See below for details.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.parallel_concat(Tensorflow.Tensor[],Tensorflow.TensorShape,System.String)">
            <summary>
               Concatenates a list of <c>N</c> tensors along the first dimension.
            </summary>
            <param name="values">
               Tensors to be concatenated. All must have size 1 in the first dimension
               and same shape.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ParallelConcat'.
            </param>
            <param name="shape">
               Optional argument
               the final shape of the result; should be equal to the shapes of any input
               but with the number of input values in the first dimension.
            </param>
            <returns>
               The concatenated tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The input tensors are all required to have size 1 in the first dimension.
               
               For example:
               
              <code>
               # 'x' is [[1, 4]]
               # 'y' is [[2, 5]]
               # 'z' is [[3, 6]]
               parallel_concat([x, y, z]) =&amp;gt; [[1, 4], [2, 5], [3, 6]]  # Pack along first dim.
              </code>
               
               The difference between concat and parallel_concat is that concat requires all
               of the inputs be computed before the operation will begin but doesn't require
               that the input shapes be known during graph construction.  Parallel concat
               will copy pieces of the input into the output as they become available, in
               some situations this can provide a performance benefit.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.parallel_dynamic_stitch(Tensorflow.Tensor[],Tensorflow.Tensor[],System.String)">
            <summary>
               Interleave the values from the <c>data</c> tensors into a single tensor.
            </summary>
            <param name="indices">
            </param>
            <param name="data">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ParallelDynamicStitch'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Builds a merged tensor such that
               
              <code>
               merged[indices[m][i, ..., j], ...] = data[m][i, ..., j, ...]
              </code>
               
               For example, if each <c>indices[m]</c> is scalar or vector, we have
               
              <code>
               # Scalar indices:
               merged[indices[m], ...] = data[m][...]
               
               # Vector indices:
               merged[indices[m][i], ...] = data[m][i, ...]
              </code>
               
               Each <c>data[i].shape</c> must start with the corresponding <c>indices[i].shape</c>,
               and the rest of <c>data[i].shape</c> must be constant w.r.t. <c>i</c>.  That is, we
               must have <c>data[i].shape = indices[i].shape + constant</c>.  In terms of this
               <c>constant</c>, the output shape is
               
               merged.shape = [max(indices)] + constant
               
               Values may be merged in parallel, so if an index appears in both <c>indices[m][i]</c>
               and <c>indices[n][j]</c>, the result may be invalid. This differs from the normal
               DynamicStitch operator that defines the behavior in that case.
               
               For example:
               
              <code>
               indices[0] = 6
               indices[1] = [4, 1]
               indices[2] = [[5, 2], [0, 3]]
               data[0] = [61, 62]
               data[1] = [[41, 42], [11, 12]]
               data[2] = [[[51, 52], [21, 22]], [[1, 2], [31, 32]]]
               merged = [[1, 2], [11, 12], [21, 22], [31, 32], [41, 42],
               [51, 52], [61, 62]]
              </code>
               
               This method can be used to merge partitions created by <c>dynamic_partition</c>
               as illustrated on the following example:
               
              <code>
               # Apply function (increments x_i) on elements for which a certain condition
               # apply (x_i != -1 in this example).
               x=tf.constant([0.1, -1., 5.2, 4.3, -1., 7.4])
               condition_mask=tf.not_equal(x,tf.constant(-1.))
               partitioned_data = tf.dynamic_partition(
               x, tf.cast(condition_mask, tf.int32) , 2)
               partitioned_data[1] = partitioned_data[1] + 1.0
               condition_indices = tf.dynamic_partition(
               tf.range(tf.shape(x)[0]), tf.cast(condition_mask, tf.int32) , 2)
               x = tf.dynamic_stitch(condition_indices, partitioned_data)
               # Here x=[1.1, -1., 6.2, 5.3, -1, 8.4], the -1. values remain
               # unchanged.
              </code>
               
               &amp;lt;div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;"&amp;gt;
               &amp;lt;img style="width:100%" src="https://www.tensorflow.org/images/DynamicStitch.png" alt&amp;gt;
               &amp;lt;/div&amp;gt;
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.parameterized_truncated_normal(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Outputs random values from a normal distribution. The parameters may each be a
            </summary>
            <param name="shape">
               The shape of the output tensor. Batches are indexed by the 0th dimension.
            </param>
            <param name="means">
               The mean parameter of each batch.
            </param>
            <param name="stdevs">
               The standard deviation parameter of each batch. Must be greater than 0.
            </param>
            <param name="minvals">
               The minimum cutoff. May be -infinity.
            </param>
            <param name="maxvals">
               The maximum cutoff. May be +infinity, and must be more than the minval
               for each batch.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ParameterizedTruncatedNormal'.
            </param>
            <param name="seed">
               If either <c>seed</c> or <c>seed2</c> are set to be non-zero, the random number
               generator is seeded by the given seed.  Otherwise, it is seeded by a
               random seed.
            </param>
            <param name="seed2">
               A second seed to avoid seed collision.
            </param>
            <returns>
               A matrix of shape num_batches x samples_per_batch, filled with random
               truncated normal values using the parameters for each row.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               scalar which applies to the entire output, or a vector of length shape[0] which
               stores the parameters for each batch.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.parse_example(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor[],Tensorflow.Tensor[],Tensorflow.Tensor[],Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Transforms a vector of brain.Example protos (as strings) into typed tensors.
            </summary>
            <param name="serialized">
               A vector containing a batch of binary serialized Example protos.
            </param>
            <param name="names">
               A vector containing the names of the serialized protos.
               May contain, for example, table key (descriptive) names for the
               corresponding serialized protos.  These are purely useful for debugging
               purposes, and the presence of values here has no effect on the output.
               May also be an empty vector if no names are available.
               If non-empty, this vector must be the same length as "serialized".
            </param>
            <param name="sparse_keys">
               A list of Nsparse string Tensors (scalars).
               The keys expected in the Examples' features associated with sparse values.
            </param>
            <param name="dense_keys">
               A list of Ndense string Tensors (scalars).
               The keys expected in the Examples' features associated with dense values.
            </param>
            <param name="dense_defaults">
               A list of Ndense Tensors (some may be empty).
               dense_defaults[j] provides default values
               when the example's feature_map lacks dense_key[j].  If an empty Tensor is
               provided for dense_defaults[j], then the Feature dense_keys[j] is required.
               The input type is inferred from dense_defaults[j], even when it's empty.
               If dense_defaults[j] is not empty, and dense_shapes[j] is fully defined,
               then the shape of dense_defaults[j] must match that of dense_shapes[j].
               If dense_shapes[j] has an undefined major dimension (variable strides dense
               feature), dense_defaults[j] must contain a single element:
               the padding element.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ParseExample'.
            </param>
            <param name="sparse_types">
               Optional argument
               A list of Nsparse types; the data types of data in each Feature
               given in sparse_keys.
               Currently the ParseExample supports DT_FLOAT (FloatList),
               DT_INT64 (Int64List), and DT_STRING (BytesList).
            </param>
            <param name="dense_shapes">
               Optional argument
               A list of Ndense shapes; the shapes of data in each Feature
               given in dense_keys.
               The number of elements in the Feature corresponding to dense_key[j]
               must always equal dense_shapes[j].NumEntries().
               If dense_shapes[j] == (D0, D1, ..., DN) then the shape of output
               Tensor dense_values[j] will be (|serialized|, D0, D1, ..., DN):
               The dense outputs are just the inputs row-stacked by batch.
               This works for dense_shapes[j] = (-1, D1, ..., DN).  In this case
               the shape of the output Tensor dense_values[j] will be
               (|serialized|, M, D1, .., DN), where M is the maximum number of blocks
               of elements of length D1 * .... * DN, across all minibatch entries
               in the input.  Any minibatch entry with less than M blocks of elements of
               length D1 * ... * DN will be padded with the corresponding default_value
               scalar element along the second dimension.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               sparse_indices :
               sparse_values :
               sparse_shapes :
               dense_values :
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.parse_example_dataset(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor[],System.String[],System.String[],Tensorflow.TF_DataType[],Tensorflow.TensorShape[],Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Transforms <c>input_dataset</c> containing <c>Example</c> protos as vectors of DT_STRING into a dataset of <c>Tensor</c> or <c>SparseTensor</c> objects representing the parsed features.
            </summary>
            <param name="input_dataset">
            </param>
            <param name="num_parallel_calls">
            </param>
            <param name="dense_defaults">
               A dict mapping string keys to <c>Tensor</c>s.
               The keys of the dict must match the dense_keys of the feature.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ParseExampleDataset'.
            </param>
            <param name="sparse_keys">
               Optional argument
               A list of string keys in the examples features.
               The results for these keys will be returned as <c>SparseTensor</c> objects.
            </param>
            <param name="dense_keys">
               Optional argument
               A list of Ndense string Tensors (scalars).
               The keys expected in the Examples features associated with dense values.
            </param>
            <param name="sparse_types">
               Optional argument
               A list of <c>DTypes</c> of the same length as <c>sparse_keys</c>.
               Only <c>tf.float32</c> (<c>FloatList</c>), <c>tf.int64</c> (<c>Int64List</c>),
               and <c>tf.string</c> (<c>BytesList</c>) are supported.
            </param>
            <param name="dense_shapes">
               Optional argument
               List of tuples with the same length as <c>dense_keys</c>.
               The shape of the data for each dense feature referenced by <c>dense_keys</c>.
               Required for any input tensors identified by <c>dense_keys</c>.  Must be
               either fully defined, or may contain an unknown first dimension.
               An unknown first dimension means the feature is treated as having
               a variable number of blocks, and the output shape along this dimension
               is considered unknown at graph build time.  Padding is applied for
               minibatch elements smaller than the maximum number of blocks for the
               given feature along this dimension.
            </param>
            <param name="output_types">
               Optional argument
               The type list for the return values.
            </param>
            <param name="output_shapes">
               Optional argument
               The list of shapes being produced.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.parse_sequence_example(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor[],System.String[],System.String[],System.String[],System.String[],System.String[],System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},Tensorflow.TF_DataType[],Tensorflow.TF_DataType[],Tensorflow.TensorShape[],Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Transforms a vector of brain.SequenceExample protos (as strings) into typed tensors.
            </summary>
            <param name="serialized">
               A vector containing binary serialized SequenceExample protos.
            </param>
            <param name="debug_name">
               A vector containing the names of the serialized protos.
               May contain, for example, table key (descriptive) name for the
               corresponding serialized proto.  This is purely useful for debugging
               purposes, and the presence of values here has no effect on the output.
               May also be an empty vector if no name is available.
            </param>
            <param name="context_dense_defaults">
               A list of Ncontext_dense Tensors (some may be empty).
               context_dense_defaults[j] provides default values
               when the SequenceExample's context map lacks context_dense_key[j].
               If an empty Tensor is provided for context_dense_defaults[j],
               then the Feature context_dense_keys[j] is required.
               The input type is inferred from context_dense_defaults[j], even when it's
               empty.  If context_dense_defaults[j] is not empty, its shape must match
               context_dense_shapes[j].
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ParseSequenceExample'.
            </param>
            <param name="feature_list_dense_missing_assumed_empty">
               Optional argument
               A vector listing the
               FeatureList keys which may be missing from the SequenceExamples.  If the
               associated FeatureList is missing, it is treated as empty.  By default,
               any FeatureList not listed in this vector must exist in the SequenceExamples.
            </param>
            <param name="context_sparse_keys">
               Optional argument
               A list of Ncontext_sparse string Tensors (scalars).
               The keys expected in the Examples' features associated with context_sparse
               values.
            </param>
            <param name="context_dense_keys">
               Optional argument
               A list of Ncontext_dense string Tensors (scalars).
               The keys expected in the SequenceExamples' context features associated with
               dense values.
            </param>
            <param name="feature_list_sparse_keys">
               Optional argument
               A list of Nfeature_list_sparse string Tensors
               (scalars).  The keys expected in the FeatureLists associated with sparse
               values.
            </param>
            <param name="feature_list_dense_keys">
               Optional argument
               A list of Nfeature_list_dense string Tensors (scalars).
               The keys expected in the SequenceExamples' feature_lists associated
               with lists of dense values.
            </param>
            <param name="Ncontext_sparse">
            </param>
            <param name="Ncontext_dense">
            </param>
            <param name="Nfeature_list_sparse">
            </param>
            <param name="Nfeature_list_dense">
            </param>
            <param name="context_sparse_types">
               A list of Ncontext_sparse types; the data types of data in
               each context Feature given in context_sparse_keys.
               Currently the ParseSingleSequenceExample supports DT_FLOAT (FloatList),
               DT_INT64 (Int64List), and DT_STRING (BytesList).
            </param>
            <param name="feature_list_dense_types">
            </param>
            <param name="context_dense_shapes">
               A list of Ncontext_dense shapes; the shapes of data in
               each context Feature given in context_dense_keys.
               The number of elements in the Feature corresponding to context_dense_key[j]
               must always equal context_dense_shapes[j].NumEntries().
               The shape of context_dense_values[j] will match context_dense_shapes[j].
            </param>
            <param name="feature_list_sparse_types">
               A list of Nfeature_list_sparse types; the data types
               of data in each FeatureList given in feature_list_sparse_keys.
               Currently the ParseSingleSequenceExample supports DT_FLOAT (FloatList),
               DT_INT64 (Int64List), and DT_STRING (BytesList).
            </param>
            <param name="feature_list_dense_shapes">
               A list of Nfeature_list_dense shapes; the shapes of
               data in each FeatureList given in feature_list_dense_keys.
               The shape of each Feature in the FeatureList corresponding to
               feature_list_dense_key[j] must always equal
               feature_list_dense_shapes[j].NumEntries().
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               context_sparse_indices :
               context_sparse_values :
               context_sparse_shapes :
               context_dense_values :
               feature_list_sparse_indices :
               feature_list_sparse_values :
               feature_list_sparse_shapes :
               feature_list_dense_values :
               feature_list_dense_lengths :
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.parse_single_example(Tensorflow.Tensor,Tensorflow.Tensor[],System.Int32,System.String[],System.String[],Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Transforms a tf.Example proto (as a string) into typed tensors.
            </summary>
            <param name="serialized">
               A vector containing a batch of binary serialized Example protos.
            </param>
            <param name="dense_defaults">
               A list of Tensors (some may be empty), whose length matches
               the length of <c>dense_keys</c>. dense_defaults[j] provides default values
               when the example's feature_map lacks dense_key[j].  If an empty Tensor is
               provided for dense_defaults[j], then the Feature dense_keys[j] is required.
               The input type is inferred from dense_defaults[j], even when it's empty.
               If dense_defaults[j] is not empty, and dense_shapes[j] is fully defined,
               then the shape of dense_defaults[j] must match that of dense_shapes[j].
               If dense_shapes[j] has an undefined major dimension (variable strides dense
               feature), dense_defaults[j] must contain a single element:
               the padding element.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ParseSingleExample'.
            </param>
            <param name="num_sparse">
               Optional argument
               The number of sparse features to be parsed from the example. This
               must match the lengths of <c>sparse_keys</c> and <c>sparse_types</c>.
            </param>
            <param name="sparse_keys">
               Optional argument
               A list of <c>num_sparse</c> strings.
               The keys expected in the Examples' features associated with sparse values.
            </param>
            <param name="dense_keys">
               Optional argument
               The keys expected in the Examples' features associated with dense
               values.
            </param>
            <param name="sparse_types">
               Optional argument
               A list of <c>num_sparse</c> types; the data types of data in each
               Feature given in sparse_keys.
               Currently the ParseSingleExample op supports DT_FLOAT (FloatList),
               DT_INT64 (Int64List), and DT_STRING (BytesList).
            </param>
            <param name="dense_shapes">
               Optional argument
               The shapes of data in each Feature given in dense_keys.
               The length of this list must match the length of <c>dense_keys</c>.  The
               number of elements in the Feature corresponding to dense_key[j] must
               always equal dense_shapes[j].NumEntries().  If dense_shapes[j] ==
               (D0, D1, ..., DN) then the shape of output Tensor dense_values[j]
               will be (D0, D1, ..., DN): In the case dense_shapes[j] = (-1, D1,
               ..., DN), the shape of the output Tensor dense_values[j] will be (M,
               D1, .., DN), where M is the number of blocks of elements of length
               D1 * .... * DN, in the input.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               sparse_indices :
               sparse_values :
               sparse_shapes :
               dense_values :
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.parse_single_sequence_example(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor[],Tensorflow.Tensor[],Tensorflow.Tensor[],Tensorflow.Tensor[],Tensorflow.Tensor[],Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TF_DataType[],Tensorflow.TensorShape[],Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Transforms a scalar brain.SequenceExample proto (as strings) into typed tensors.
            </summary>
            <param name="serialized">
               A scalar containing a binary serialized SequenceExample proto.
            </param>
            <param name="feature_list_dense_missing_assumed_empty">
               A vector listing the
               FeatureList keys which may be missing from the SequenceExample.  If the
               associated FeatureList is missing, it is treated as empty.  By default,
               any FeatureList not listed in this vector must exist in the SequenceExample.
            </param>
            <param name="context_sparse_keys">
               A list of Ncontext_sparse string Tensors (scalars).
               The keys expected in the Examples' features associated with context_sparse
               values.
            </param>
            <param name="context_dense_keys">
               A list of Ncontext_dense string Tensors (scalars).
               The keys expected in the SequenceExamples' context features associated with
               dense values.
            </param>
            <param name="feature_list_sparse_keys">
               A list of Nfeature_list_sparse string Tensors
               (scalars).  The keys expected in the FeatureLists associated with sparse
               values.
            </param>
            <param name="feature_list_dense_keys">
               A list of Nfeature_list_dense string Tensors (scalars).
               The keys expected in the SequenceExamples' feature_lists associated
               with lists of dense values.
            </param>
            <param name="context_dense_defaults">
               A list of Ncontext_dense Tensors (some may be empty).
               context_dense_defaults[j] provides default values
               when the SequenceExample's context map lacks context_dense_key[j].
               If an empty Tensor is provided for context_dense_defaults[j],
               then the Feature context_dense_keys[j] is required.
               The input type is inferred from context_dense_defaults[j], even when it's
               empty.  If context_dense_defaults[j] is not empty, its shape must match
               context_dense_shapes[j].
            </param>
            <param name="debug_name">
               A scalar containing the name of the serialized proto.
               May contain, for example, table key (descriptive) name for the
               corresponding serialized proto.  This is purely useful for debugging
               purposes, and the presence of values here has no effect on the output.
               May also be an empty scalar if no name is available.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ParseSingleSequenceExample'.
            </param>
            <param name="context_sparse_types">
               A list of Ncontext_sparse types; the data types of data in
               each context Feature given in context_sparse_keys.
               Currently the ParseSingleSequenceExample supports DT_FLOAT (FloatList),
               DT_INT64 (Int64List), and DT_STRING (BytesList).
            </param>
            <param name="feature_list_dense_types">
            </param>
            <param name="context_dense_shapes">
               A list of Ncontext_dense shapes; the shapes of data in
               each context Feature given in context_dense_keys.
               The number of elements in the Feature corresponding to context_dense_key[j]
               must always equal context_dense_shapes[j].NumEntries().
               The shape of context_dense_values[j] will match context_dense_shapes[j].
            </param>
            <param name="feature_list_sparse_types">
               A list of Nfeature_list_sparse types; the data types
               of data in each FeatureList given in feature_list_sparse_keys.
               Currently the ParseSingleSequenceExample supports DT_FLOAT (FloatList),
               DT_INT64 (Int64List), and DT_STRING (BytesList).
            </param>
            <param name="feature_list_dense_shapes">
               A list of Nfeature_list_dense shapes; the shapes of
               data in each FeatureList given in feature_list_dense_keys.
               The shape of each Feature in the FeatureList corresponding to
               feature_list_dense_key[j] must always equal
               feature_list_dense_shapes[j].NumEntries().
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               context_sparse_indices :
               context_sparse_values :
               context_sparse_shapes :
               context_dense_values :
               feature_list_sparse_indices :
               feature_list_sparse_values :
               feature_list_sparse_shapes :
               feature_list_dense_values :
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.parse_tensor(Tensorflow.Tensor,Tensorflow.TF_DataType,System.String)">
            <summary>
               Transforms a serialized tensorflow.TensorProto proto into a Tensor.
            </summary>
            <param name="serialized">
               A scalar string containing a serialized TensorProto proto.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ParseTensor'.
            </param>
            <param name="out_type">
               Optional argument
               The type of the serialized tensor.  The provided type must match the
               type of the serialized tensor and no implicit conversion will take place.
            </param>
            <returns>
               A Tensor of type <c>out_type</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.placeholder(Tensorflow.TF_DataType,Tensorflow.TensorShape,System.String)">
            <summary>
               A placeholder op for a value that will be fed into the computation.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Placeholder'.
            </param>
            <param name="dtype">
               Optional argument
               The type of elements in the tensor.
            </param>
            <param name="shape">
               (Optional) The shape of the tensor. If the shape has 0 dimensions, the
               shape is unconstrained.
            </param>
            <returns>
               A placeholder tensor that must be replaced using the feed mechanism.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               N.B. This operation will fail with an error if it is executed. It is
               intended as a way to represent a value that will always be fed, and to
               provide attrs that enable the fed value to be checked at runtime.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.placeholder_v2(Tensorflow.TF_DataType,Tensorflow.TensorShape,System.String)">
            <summary>
               A placeholder op for a value that will be fed into the computation.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'PlaceholderV2'.
            </param>
            <param name="dtype">
               Optional argument
               The type of elements in the tensor.
            </param>
            <param name="shape">
               Optional argument
               The shape of the tensor. The shape can be any partially-specified
               shape.  To be unconstrained, pass in a shape with unknown rank.
            </param>
            <returns>
               A placeholder tensor that must be replaced using the feed mechanism.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               N.B. This operation will fail with an error if it is executed. It is
               intended as a way to represent a value that will always be fed, and to
               provide attrs that enable the fed value to be checked at runtime.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.placeholder_with_default(Tensorflow.Tensor,Tensorflow.TensorShape,System.String)">
            <summary>
               A placeholder op that passes through <c>input</c> when its output is not fed.
            </summary>
            <param name="input">
               The default value to produce when <c>output</c> is not fed.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'PlaceholderWithDefault'.
            </param>
            <param name="shape">
               Optional argument
               The (possibly partial) shape of the tensor.
            </param>
            <returns>
               A placeholder tensor that defaults to <c>input</c> if it is not fed.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.polygamma(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Compute the polygamma function \\(\psi^{(n)}(x)\\).
            </summary>
            <param name="a">
            </param>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Polygamma'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The polygamma function is defined as:
               
               
               \\(\psi^{(n)}(x) = \frac{d^n}{dx^n} \psi(x)\\)
               
               where \\(\psi(x)\\) is the digamma function.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.population_count(Tensorflow.Tensor,System.String)">
            <summary>
               Computes element-wise population count (a.k.a. popcount, bitsum, bitcount).
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'PopulationCount'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               For each entry in <c>x</c>, calculates the number of <c>1</c> (on) bits in the binary
               representation of that entry.
               
               **NOTE**: It is more efficient to first <c>tf.bitcast</c> your tensors into
               <c>int32</c> or <c>int64</c> and perform the bitcount on the result, than to feed in
               8- or 16-bit inputs and then aggregate the resulting counts.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.pow(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes the power of one value to another.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Pow'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Given a tensor <c>x</c> and a tensor <c>y</c>, this operation computes \\(x^y\\) for
               corresponding elements in <c>x</c> and <c>y</c>. For example:
               
              <code>
               # tensor 'x' is [[2, 2]], [3, 3]]
               # tensor 'y' is [[8, 16], [2, 3]]
               tf.pow(x, y) ==&amp;gt; [[256, 65536], [9, 27]]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.prefetch_dataset(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Creates a dataset that asynchronously prefetches elements from <c>input_dataset</c>.
            </summary>
            <param name="input_dataset">
            </param>
            <param name="buffer_size">
               The maximum number of elements to buffer in an iterator over
               this dataset.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'PrefetchDataset'.
            </param>
            <param name="output_types">
               Optional argument
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.prevent_gradient(Tensorflow.Tensor,System.String,System.String)">
            <summary>
               An identity op that triggers an error if a gradient is requested.
            </summary>
            <param name="input">
               any tensor.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'PreventGradient'.
            </param>
            <param name="message">
               Will be printed in the error when anyone tries to differentiate
               this operation.
            </param>
            <returns>
               the same input tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               When executed in a graph, this op outputs its input tensor as-is.
               
               When building ops to compute gradients, the TensorFlow gradient system
               will return an error when trying to lookup the gradient of this op,
               because no gradient must ever be registered for this function.  This
               op exists to prevent subtle bugs from silently returning unimplemented
               gradients in some corner cases.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.print(Tensorflow.Tensor,Tensorflow.Tensor[],System.String,System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Prints a list of tensors.
            </summary>
            <param name="input">
               The tensor passed to <c>output</c>
            </param>
            <param name="data">
               A list of tensors to print out when op is evaluated.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Print'.
            </param>
            <param name="message">
               A string, prefix of the error message.
            </param>
            <param name="first_n">
               Only log <c>first_n</c> number of times. -1 disables logging.
            </param>
            <param name="summarize">
               Only print this many entries of each tensor.
            </param>
            <returns>
               = The unmodified <c>input</c> tensor
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Passes <c>input</c> through to <c>output</c> and prints <c>data</c> when evaluating.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.priority_queue(Tensorflow.TensorShape[],Tensorflow.TF_DataType[],System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               A queue that produces elements sorted by the first component value.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'PriorityQueue'.
            </param>
            <param name="shapes">
               Optional argument
               The shape of each component in a value. The length of this attr must
               be either 0 or the same as the length of component_types. If the length of
               this attr is 0, the shapes of queue elements are not constrained, and
               only one element may be dequeued at a time.
            </param>
            <param name="component_types">
               The type of each component in a value.
            </param>
            <param name="capacity">
               The upper bound on the number of elements in this queue.
               Negative numbers mean no limit.
            </param>
            <param name="container">
               If non-empty, this queue is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this queue will be shared under the given name
               across multiple sessions.
            </param>
            <returns>
               The handle to the queue.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Note that the PriorityQueue requires the first component of any element
               to be a scalar int64, in addition to the other elements declared by
               component_types.  Therefore calls to Enqueue and EnqueueMany (resp. Dequeue
               and DequeueMany) on a PriorityQueue will all require (resp. output) one extra
               entry in their input (resp. output) lists.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.priority_queue_v2(Tensorflow.TensorShape[],Tensorflow.TF_DataType[],System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               A queue that produces elements sorted by the first component value.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'PriorityQueueV2'.
            </param>
            <param name="shapes">
               Optional argument
               The shape of each component in a value. The length of this attr must
               be either 0 or the same as the length of component_types. If the length of
               this attr is 0, the shapes of queue elements are not constrained, and
               only one element may be dequeued at a time.
            </param>
            <param name="component_types">
               The type of each component in a value.
            </param>
            <param name="capacity">
               The upper bound on the number of elements in this queue.
               Negative numbers mean no limit.
            </param>
            <param name="container">
               If non-empty, this queue is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this queue will be shared under the given name
               across multiple sessions.
            </param>
            <returns>
               The handle to the queue.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Note that the PriorityQueue requires the first component of any element
               to be a scalar int64, in addition to the other elements declared by
               component_types.  Therefore calls to Enqueue and EnqueueMany (resp. Dequeue
               and DequeueMany) on a PriorityQueue will all require (resp. output) one extra
               entry in their input (resp. output) lists.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.prod(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Computes the product of elements across dimensions of a tensor.
            </summary>
            <param name="input">
               The tensor to reduce.
            </param>
            <param name="reduction_indices">
               The dimensions to reduce. Must be in the range
               <c>[-rank(input), rank(input))</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Prod'.
            </param>
            <param name="keep_dims">
               If true, retain reduced dimensions with length 1.
            </param>
            <returns>
               The reduced tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Reduces <c>input</c> along the dimensions given in <c>axis</c>. Unless
               <c>keep_dims</c> is true, the rank of the tensor is reduced by 1 for each entry in
               <c>axis</c>. If <c>keep_dims</c> is true, the reduced dimensions are
               retained with length 1.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.qr(Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Computes the QR decompositions of one or more matrices.
            </summary>
            <param name="input">
               A tensor of shape <c>[..., M, N]</c> whose inner-most 2 dimensions
               form matrices of size <c>[M, N]</c>. Let <c>P</c> be the minimum of <c>M</c> and <c>N</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Qr'.
            </param>
            <param name="full_matrices">
               If true, compute full-sized <c>q</c> and <c>r</c>. If false
               (the default), compute only the leading <c>P</c> columns of <c>q</c>.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               q : Orthonormal basis for range of <c>a</c>. If <c>full_matrices</c> is <c>False</c> then
               shape is <c>[..., M, P]</c>; if <c>full_matrices</c> is <c>True</c> then shape is
               <c>[..., M, M]</c>.
               r : Triangular factor. If <c>full_matrices</c> is <c>False</c> then shape is
               <c>[..., P, N]</c>. If <c>full_matrices</c> is <c>True</c> then shape is <c>[..., M, N]</c>.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Computes the QR decomposition of each inner matrix in <c>tensor</c> such that
               <c>tensor[..., :, :] = q[..., :, :] * r[..., :,:])</c>
               
              <code>
               # a is a tensor.
               # q is a tensor of orthonormal matrices.
               # r is a tensor of upper triangular matrices.
               q, r = qr(a)
               q_full, r_full = qr(a, full_matrices=True)
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.quantize_and_dequantize(Tensorflow.Tensor,System.Nullable{System.Boolean},System.Nullable{System.Int32},System.Nullable{System.Boolean},System.Nullable{System.Single},System.Nullable{System.Single},System.String)">
            <summary>
               Use QuantizeAndDequantizeV2 instead.
            </summary>
            <param name="input">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QuantizeAndDequantize'.
            </param>
            <param name="signed_input">
            </param>
            <param name="num_bits">
            </param>
            <param name="range_given">
            </param>
            <param name="input_min">
            </param>
            <param name="input_max">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.quantize_and_dequantize_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.Nullable{System.Int32},System.Nullable{System.Boolean},System.String)">
            <summary>
               Quantizes then dequantizes a tensor.
            </summary>
            <param name="input">
               Tensor to quantize and then dequantize.
            </param>
            <param name="input_min">
               If <c>range_given == True</c>, this specifies the minimum input value that needs to
               be represented, otherwise it is determined from the min value of the <c>input</c>
               tensor.
            </param>
            <param name="input_max">
               If <c>range_given == True</c>, this specifies the maximum input value that needs to
               be represented, otherwise it is determined from the max value of the <c>input</c>
               tensor.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QuantizeAndDequantizeV2'.
            </param>
            <param name="signed_input">
               Whether the quantization is signed or unsigned. (actually this parameter should
               have been called &amp;lt;b&amp;gt;<c>signed_output</c>&amp;lt;/b&amp;gt;)
            </param>
            <param name="num_bits">
               The bitwidth of the quantization.
            </param>
            <param name="range_given">
               Whether the range is given or should be determined from the <c>input</c> tensor.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This op simulates the precision loss from the quantized forward pass by:
               
               1. Quantizing the tensor to fixed point numbers, which should match the target
               quantization method when it is used in inference.
               2. Dequantizing it back to floating point numbers for the following ops, most
               likely matmul.
               
               There are different ways to quantize. This version uses only scaling, so 0.0
               maps to 0.
               
               From the specified 'num_bits' in the quantized output type, it determines
               minimum and maximum representable quantized values.
               
               e.g.
               
               *   [-128, 127] for signed, num_bits = 8, or
               *   [0, 255] for unsigned, num_bits = 8.
               
               If range_given == False, the initial input_min, input_max will be determined
               automatically as the minimum and maximum values in the input tensor, otherwise
               the specified values of input_min, input_max are used.
               
               Note: If the input_min, input_max are specified, they do not need to equal the
               actual minimum and maximum values in the tensor. e.g. in some cases it may be
               beneficial to specify these values such that the low probability extremes of the
               input distribution are clipped.
               
               This op determines the maximum scale_factor that would map the initial
               [input_min, input_max] range to a range that lies within the representable
               quantized range.
               
               It determines the scale from one of input_min and input_max, then updates the
               other one to maximize the respresentable range.
               
               e.g.
               
               *   if the output is signed, num_bits = 8, [input_min, input_max] = [-10.0,
               5.0]: it would use a scale_factor of -128 / -10.0 = 12.8 In this case, it
               would update input_max to be 127 / 12.8 = 9.921875
               *   if the output is signed, num_bits = 8, [input_min, input_max] = [-10.0,
               10.0]: it would use a scale_factor of 127 / 10.0 = 12.7 In this case, it
               would update input_min to be 128.0 / 12.7 = -10.07874
               *   if the output is unsigned, input_min is forced to be 0, and only the
               specified input_max is used.
               
               After determining the scale_factor and updating the input range, it applies the
               following to each value in the 'input' tensor.
               
               output = round(clamp(value, input_min, input_max) * scale_factor) / scale_factor.
               
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.quantize_and_dequantize_v3(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.String)">
            <summary>
               Quantizes then dequantizes a tensor.
            </summary>
            <param name="input">
            </param>
            <param name="input_min">
            </param>
            <param name="input_max">
            </param>
            <param name="num_bits">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QuantizeAndDequantizeV3'.
            </param>
            <param name="signed_input">
            </param>
            <param name="range_given">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This is almost identical to QuantizeAndDequantizeV2, except that num_bits is a
               tensor, so its value can change during training.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.quantize_down_and_shrink_range(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType,System.String)">
            <summary>
               Convert the quantized 'input' tensor into a lower-precision 'output', using the
            </summary>
            <param name="input">
            </param>
            <param name="input_min">
               The float value that the minimum quantized input value represents.
            </param>
            <param name="input_max">
               The float value that the maximum quantized input value represents.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QuantizeDownAndShrinkRange'.
            </param>
            <param name="out_type">
               Optional argument
               The type of the output. Should be a lower bit depth than Tinput.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output :
               output_min : The float value that the minimum quantized output value represents.
               output_max : The float value that the maximum quantized output value represents.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               actual distribution of the values to maximize the usage of the lower bit depth
               and adjusting the output min and max ranges accordingly.
               
               [input_min, input_max] are scalar floats that specify the range for the float
               interpretation of the 'input' data. For example, if input_min is -1.0f and
               input_max is 1.0f, and we are dealing with quint16 quantized data, then a 0
               value in the 16-bit data should be interpreted as -1.0f, and a 65535 means 1.0f.
               
               This operator tries to squeeze as much precision as possible into an output with
               a lower bit depth by calculating the actual min and max values found in the
               data. For example, maybe that quint16 input has no values lower than 16,384 and
               none higher than 49,152. That means only half the range is actually needed, all
               the float interpretations are between -0.5f and 0.5f, so if we want to compress
               the data into a quint8 output, we can use that range rather than the theoretical
               -1.0f to 1.0f that is suggested by the input min and max.
               
               In practice, this is most useful for taking output from operations like
               QuantizedMatMul that can produce higher bit-depth outputs than their inputs and
               may have large potential output ranges, but in practice have a distribution of
               input values that only uses a small fraction of the possible range. By feeding
               that output into this operator, we can reduce it from 32 bits down to 8 with
               minimal loss of accuracy.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.quantize_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType,System.String,System.String,System.String)">
            <summary>
               Quantize the 'input' tensor of type float to 'output' tensor of type 'T'.
            </summary>
            <param name="input">
            </param>
            <param name="min_range">
               The minimum scalar value possibly produced for the input.
            </param>
            <param name="max_range">
               The maximum scalar value possibly produced for the input.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QuantizeV2'.
            </param>
            <param name="T">
               Optional argument
            </param>
            <param name="mode">
            </param>
            <param name="round_mode">
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output : The quantized data produced from the float input.
               output_min : The actual minimum scalar value used for the output.
               output_max : The actual maximum scalar value used for the output.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               [min_range, max_range] are scalar floats that specify the range for
               the 'input' data. The 'mode' attribute controls exactly which calculations are
               used to convert the float values to their quantized equivalents.  The
               'round_mode' attribute controls which rounding tie-breaking algorithm is used
               when rounding float values to their quantized equivalents.
               
               In 'MIN_COMBINED' mode, each value of the tensor will undergo the following:
               
              <code>
               out[i] = (in[i] - min_range) * range(T) / (max_range - min_range)
               if T == qint8, out[i] -= (range(T) + 1) / 2.0
              </code>
               
               here <c>range(T) = numeric_limits&amp;lt;T&amp;gt;::max() - numeric_limits&amp;lt;T&amp;gt;::min()</c>
               
               *MIN_COMBINED Mode Example*
               
               Assume the input is type float and has a possible range of [0.0, 6.0] and the
               output type is quint8 ([0, 255]). The min_range and max_range values should be
               specified as 0.0 and 6.0. Quantizing from float to quint8 will multiply each
               value of the input by 255/6 and cast to quint8.
               
               If the output type was qint8 ([-128, 127]), the operation will additionally
               subtract each value by 128 prior to casting, so that the range of values aligns
               with the range of qint8.
               
               If the mode is 'MIN_FIRST', then this approach is used:
               
              <code>
               num_discrete_values = 1 &amp;lt;&amp;lt; (# of bits in T)
               range_adjust = num_discrete_values / (num_discrete_values - 1)
               range = (range_max - range_min) * range_adjust
               range_scale = num_discrete_values / range
               quantized = round(input * range_scale) - round(range_min * range_scale) +
               numeric_limits&amp;lt;T&amp;gt;::min()
               quantized = max(quantized, numeric_limits&amp;lt;T&amp;gt;::min())
               quantized = min(quantized, numeric_limits&amp;lt;T&amp;gt;::max())
              </code>
               
               The biggest difference between this and MIN_COMBINED is that the minimum range
               is rounded first, before it's subtracted from the rounded value. With
               MIN_COMBINED, a small bias is introduced where repeated iterations of quantizing
               and dequantizing will introduce a larger and larger error.
               
               *SCALED mode Example*
               
               <c>SCALED</c> mode matches the quantization approach used in
               <c>QuantizeAndDequantize{V2|V3}</c>.
               
               If the mode is <c>SCALED</c>, we do not use the full range of the output type,
               choosing to elide the lowest possible value for symmetry (e.g., output range is
               -127 to 127, not -128 to 127 for signed 8 bit quantization), so that 0.0 maps to
               0.
               
               We first find the range of values in our tensor. The
               range we use is always centered on 0, so we find m such that
               
              <code>
               m = max(abs(input_min), abs(input_max))
              </code>
               
               Our input tensor range is then <c>[-m, m]</c>.
               
               Next, we choose our fixed-point quantization buckets, <c>[min_fixed, max_fixed]</c>.
               If T is signed, this is
               
              <code>
               num_bits = sizeof(T) * 8
               [min_fixed, max_fixed] =
               [-(1 &amp;lt;&amp;lt; (num_bits - 1) - 1), (1 &amp;lt;&amp;lt; (num_bits - 1)) - 1]
              </code>
               
               Otherwise, if T is unsigned, the fixed-point range is
               
              <code>
               [min_fixed, max_fixed] = [0, (1 &amp;lt;&amp;lt; num_bits) - 1]
              </code>
               
               From this we compute our scaling factor, s:
               
              <code>
               s = (max_fixed - min_fixed) / (2 * m)
              </code>
               
               Now we can quantize the elements of our tensor:
               
              <code>
               result = round(input * s)
              </code>
               
               One thing to watch out for is that the operator may choose to adjust the
               requested minimum and maximum values slightly during the quantization process,
               so you should always use the output ports as the range for further calculations.
               For example, if the requested minimum and maximum values are close to equal,
               they will be separated by a small epsilon value to prevent ill-formed quantized
               buffers from being created. Otherwise, you can end up with buffers where all the
               quantized values map to the same float value, which causes problems for
               operations that have to perform further calculations on them.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.quantized_add(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Returns x + y element-wise, working on quantized buffers.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="min_x">
               The float value that the lowest quantized <c>x</c> value represents.
            </param>
            <param name="max_x">
               The float value that the highest quantized <c>x</c> value represents.
            </param>
            <param name="min_y">
               The float value that the lowest quantized <c>y</c> value represents.
            </param>
            <param name="max_y">
               The float value that the highest quantized <c>y</c> value represents.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QuantizedAdd'.
            </param>
            <param name="Toutput">
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               z :
               min_z : The float value that the lowest quantized output value represents.
               max_z : The float value that the highest quantized output value represents.
               
               *NOTE*: <c>QuantizedAdd</c> supports limited forms of broadcasting. More about
               broadcasting [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.quantized_avg_pool(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32[],System.Int32[],System.String,System.String)">
            <summary>
               Produces the average pool of the input tensor for quantized types.
            </summary>
            <param name="input">
               4-D with shape <c>[batch, height, width, channels]</c>.
            </param>
            <param name="min_input">
               The float value that the lowest quantized input value represents.
            </param>
            <param name="max_input">
               The float value that the highest quantized input value represents.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QuantizedAvgPool'.
            </param>
            <param name="ksize">
               Optional argument
               The size of the window for each dimension of the input tensor.
               The length must be 4 to match the number of dimensions of the input.
            </param>
            <param name="strides">
               Optional argument
               The stride of the sliding window for each dimension of the input
               tensor.  The length must be 4 to match the number of dimensions of the input.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output :
               min_output : The float value that the lowest quantized output value represents.
               max_output : The float value that the highest quantized output value represents.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.quantized_batch_norm_with_global_normalization(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType,System.Single,System.Boolean,System.String)">
            <summary>
               Quantized Batch normalization.
            </summary>
            <param name="t">
               A 4D input Tensor.
            </param>
            <param name="t_min">
               The value represented by the lowest quantized input.
            </param>
            <param name="t_max">
               The value represented by the highest quantized input.
            </param>
            <param name="m">
               A 1D mean Tensor with size matching the last dimension of t.
               This is the first output from tf.nn.moments,
               or a saved moving average thereof.
            </param>
            <param name="m_min">
               The value represented by the lowest quantized mean.
            </param>
            <param name="m_max">
               The value represented by the highest quantized mean.
            </param>
            <param name="v">
               A 1D variance Tensor with size matching the last dimension of t.
               This is the second output from tf.nn.moments,
               or a saved moving average thereof.
            </param>
            <param name="v_min">
               The value represented by the lowest quantized variance.
            </param>
            <param name="v_max">
               The value represented by the highest quantized variance.
            </param>
            <param name="beta">
               A 1D beta Tensor with size matching the last dimension of t.
               An offset to be added to the normalized tensor.
            </param>
            <param name="beta_min">
               The value represented by the lowest quantized offset.
            </param>
            <param name="beta_max">
               The value represented by the highest quantized offset.
            </param>
            <param name="gamma">
               A 1D gamma Tensor with size matching the last dimension of t.
               If "scale_after_normalization" is true, this tensor will be multiplied
               with the normalized tensor.
            </param>
            <param name="gamma_min">
               The value represented by the lowest quantized gamma.
            </param>
            <param name="gamma_max">
               The value represented by the highest quantized gamma.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QuantizedBatchNormWithGlobalNormalization'.
            </param>
            <param name="out_type">
               Optional argument
            </param>
            <param name="variance_epsilon">
               Optional argument
               A small float number to avoid dividing by 0.
            </param>
            <param name="scale_after_normalization">
               Optional argument
               A bool indicating whether the resulted tensor
               needs to be multiplied with gamma.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               result :
               result_min :
               result_max :
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               This op is deprecated and will be removed in the future. Prefer
               <c>tf.nn.batch_normalization</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.quantized_bias_add(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType,System.String)">
            <summary>
               Adds Tensor 'bias' to Tensor 'input' for Quantized types.
            </summary>
            <param name="input">
            </param>
            <param name="bias">
               A 1D bias Tensor with size matching the last dimension of 'input'.
            </param>
            <param name="min_input">
               The float value that the lowest quantized input value represents.
            </param>
            <param name="max_input">
               The float value that the highest quantized input value represents.
            </param>
            <param name="min_bias">
               The float value that the lowest quantized bias value represents.
            </param>
            <param name="max_bias">
               The float value that the highest quantized bias value represents.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QuantizedBiasAdd'.
            </param>
            <param name="out_type">
               Optional argument
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output :
               min_out : The float value that the lowest quantized output value represents.
               max_out : The float value that the highest quantized output value represents.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Broadcasts the values of bias on dimensions 0..N-2 of 'input'.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.quantized_concat(Tensorflow.Tensor,Tensorflow.Tensor[],Tensorflow.Tensor[],Tensorflow.Tensor[],System.String)">
            <summary>
               Concatenates quantized tensors along one dimension.
            </summary>
            <param name="concat_dim">
               0-D.  The dimension along which to concatenate.  Must be in the
               range [0, rank(values)).
            </param>
            <param name="values">
               The <c>N</c> Tensors to concatenate. Their ranks and types must match,
               and their sizes must match in all dimensions except <c>concat_dim</c>.
            </param>
            <param name="input_mins">
               The minimum scalar values for each of the input tensors.
            </param>
            <param name="input_maxes">
               The maximum scalar values for each of the input tensors.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QuantizedConcat'.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output : A <c>Tensor</c> with the concatenation of values stacked along the
               <c>concat_dim</c> dimension.  This tensor's shape matches that of <c>values</c> except
               in <c>concat_dim</c> where it has the sum of the sizes.
               output_min : The float value that the minimum quantized output value represents.
               output_max : The float value that the maximum quantized output value represents.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.quantized_conv2d(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32[],System.String,System.Nullable{Tensorflow.TF_DataType},System.Int32[],System.String)">
            <summary>
               Computes a 2D convolution given quantized 4D input and filter tensors.
            </summary>
            <param name="input">
            </param>
            <param name="filter">
               filter's input_depth dimension must match input's depth dimensions.
            </param>
            <param name="min_input">
               The float value that the lowest quantized input value represents.
            </param>
            <param name="max_input">
               The float value that the highest quantized input value represents.
            </param>
            <param name="min_filter">
               The float value that the lowest quantized filter value represents.
            </param>
            <param name="max_filter">
               The float value that the highest quantized filter value represents.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QuantizedConv2D'.
            </param>
            <param name="strides">
               Optional argument
               The stride of the sliding window for each dimension of the input
               tensor.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <param name="out_type">
            </param>
            <param name="dilations">
               1-D tensor of length 4.  The dilation factor for each dimension of
               <c>input</c>. If set to k &amp;gt; 1, there will be k-1 skipped cells between each
               filter element on that dimension. The dimension order is determined by the
               value of <c>data_format</c>, see above for details. Dilations in the batch and
               depth dimensions must be 1.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output :
               min_output : The float value that the lowest quantized output value represents.
               max_output : The float value that the highest quantized output value represents.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               The inputs are quantized tensors where the lowest value represents the real
               number of the associated minimum, and the highest represents the maximum.
               This means that you can only interpret the quantized output in the same way, by
               taking the returned minimum and maximum values into account.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.quantized_instance_norm(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Single},System.String)">
            <summary>
               Quantized Instance normalization.
            </summary>
            <param name="x">
               A 4D input Tensor.
            </param>
            <param name="x_min">
               The value represented by the lowest quantized input.
            </param>
            <param name="x_max">
               The value represented by the highest quantized input.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QuantizedInstanceNorm'.
            </param>
            <param name="output_range_given">
               If True, <c>given_y_min</c> and <c>given_y_min</c>
               and <c>given_y_max</c> are used as the output range. Otherwise,
               the implementation computes the output range.
            </param>
            <param name="given_y_min">
               Output in <c>y_min</c> if <c>output_range_given</c> is True.
            </param>
            <param name="given_y_max">
               Output in <c>y_max</c> if <c>output_range_given</c> is True.
            </param>
            <param name="variance_epsilon">
               A small float number to avoid dividing by 0.
            </param>
            <param name="min_separation">
               Minimum value of <c>y_max - y_min</c>
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               y : A 4D Tensor.
               y_min : The value represented by the lowest quantized output.
               y_max : The value represented by the highest quantized output.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.quantized_mat_mul(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Perform a quantized matrix multiplication of  <c>a</c> by the matrix <c>b</c>.
            </summary>
            <param name="a">
               Must be a two-dimensional tensor.
            </param>
            <param name="b">
               Must be a two-dimensional tensor.
            </param>
            <param name="min_a">
               The float value that the lowest quantized <c>a</c> value represents.
            </param>
            <param name="max_a">
               The float value that the highest quantized <c>a</c> value represents.
            </param>
            <param name="min_b">
               The float value that the lowest quantized <c>b</c> value represents.
            </param>
            <param name="max_b">
               The float value that the highest quantized <c>b</c> value represents.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QuantizedMatMul'.
            </param>
            <param name="Toutput">
            </param>
            <param name="transpose_a">
               If true, <c>a</c> is transposed before multiplication.
            </param>
            <param name="transpose_b">
               If true, <c>b</c> is transposed before multiplication.
            </param>
            <param name="Tactivation">
               The type of output produced by activation function
               following this operation.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output :
               min_out : The float value that the lowest quantized output value represents.
               max_out : The float value that the highest quantized output value represents.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               The inputs must be two-dimensional matrices and the inner dimension of
               <c>a</c> (after being transposed if <c>transpose_a</c> is non-zero) must match the
               outer dimension of <c>b</c> (after being transposed if <c>transposed_b</c> is
               non-zero).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.quantized_max_pool(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32[],System.Int32[],System.String,System.String)">
            <summary>
               Produces the max pool of the input tensor for quantized types.
            </summary>
            <param name="input">
               The 4D (batch x rows x cols x depth) Tensor to MaxReduce over.
            </param>
            <param name="min_input">
               The float value that the lowest quantized input value represents.
            </param>
            <param name="max_input">
               The float value that the highest quantized input value represents.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QuantizedMaxPool'.
            </param>
            <param name="ksize">
               Optional argument
               The size of the window for each dimension of the input tensor.
               The length must be 4 to match the number of dimensions of the input.
            </param>
            <param name="strides">
               Optional argument
               The stride of the sliding window for each dimension of the input
               tensor. The length must be 4 to match the number of dimensions of the input.
            </param>
            <param name="padding">
               Optional argument
               The type of padding algorithm to use.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output :
               min_output : The float value that the lowest quantized output value represents.
               max_output : The float value that the highest quantized output value represents.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.quantized_mul(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Returns x * y element-wise, working on quantized buffers.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="min_x">
               The float value that the lowest quantized <c>x</c> value represents.
            </param>
            <param name="max_x">
               The float value that the highest quantized <c>x</c> value represents.
            </param>
            <param name="min_y">
               The float value that the lowest quantized <c>y</c> value represents.
            </param>
            <param name="max_y">
               The float value that the highest quantized <c>y</c> value represents.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QuantizedMul'.
            </param>
            <param name="Toutput">
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               z :
               min_z : The float value that the lowest quantized output value represents.
               max_z : The float value that the highest quantized output value represents.
               
               *NOTE*: <c>QuantizedMul</c> supports limited forms of broadcasting. More about
               broadcasting [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.quantized_relu(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Computes Quantized Rectified Linear: <c>max(features, 0)</c>
            </summary>
            <param name="features">
            </param>
            <param name="min_features">
               The float value that the lowest quantized value represents.
            </param>
            <param name="max_features">
               The float value that the highest quantized value represents.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QuantizedRelu'.
            </param>
            <param name="out_type">
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               activations : Has the same output shape as "features".
               min_activations : The float value that the lowest quantized value represents.
               max_activations : The float value that the highest quantized value represents.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.quantized_relu6(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Computes Quantized Rectified Linear 6: <c>min(max(features, 0), 6)</c>
            </summary>
            <param name="features">
            </param>
            <param name="min_features">
               The float value that the lowest quantized value represents.
            </param>
            <param name="max_features">
               The float value that the highest quantized value represents.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QuantizedRelu6'.
            </param>
            <param name="out_type">
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               activations : Has the same output shape as "features".
               min_activations : The float value that the lowest quantized value represents.
               max_activations : The float value that the highest quantized value represents.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.quantized_relu_x(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Computes Quantized Rectified Linear X: <c>min(max(features, 0), max_value)</c>
            </summary>
            <param name="features">
            </param>
            <param name="max_value">
            </param>
            <param name="min_features">
               The float value that the lowest quantized value represents.
            </param>
            <param name="max_features">
               The float value that the highest quantized value represents.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QuantizedReluX'.
            </param>
            <param name="out_type">
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               activations : Has the same output shape as "features".
               min_activations : The float value that the lowest quantized value represents.
               max_activations : The float value that the highest quantized value represents.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.quantized_reshape(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Reshapes a quantized tensor as per the Reshape op.
            </summary>
            <param name="tensor">
            </param>
            <param name="shape">
               Defines the shape of the output tensor.
            </param>
            <param name="input_min">
               The minimum value of the input.
            </param>
            <param name="input_max">
               The maximum value of the input.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QuantizedReshape'.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output :
               output_min : This value is copied from input_min.
               output_max : This value is copied from input_max.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.quantized_resize_bilinear(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Resize quantized <c>images</c> to <c>size</c> using quantized bilinear interpolation.
            </summary>
            <param name="images">
               4-D with shape <c>[batch, height, width, channels]</c>.
            </param>
            <param name="size">
               = A 1-D int32 Tensor of 2 elements: <c>new_height, new_width</c>.  The
               new size for the images.
            </param>
            <param name="min">
            </param>
            <param name="max">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QuantizedResizeBilinear'.
            </param>
            <param name="align_corners">
               If true, the centers of the 4 corner pixels of the input and output tensors are
               aligned, preserving the values at the corner pixels. Defaults to false.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               resized_images : 4-D with shape
               <c>[batch, new_height, new_width, channels]</c>.
               out_min :
               out_max :
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Input images and output images must be quantized types.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.queue_close(Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Closes the given queue.
            </summary>
            <param name="handle">
               The handle to a queue.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QueueClose'.
            </param>
            <param name="cancel_pending_enqueues">
               If true, all pending enqueue requests that are
               blocked on the given queue will be canceled.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               This operation signals that no more elements will be enqueued in the
               given queue. Subsequent Enqueue(Many) operations will fail.
               Subsequent Dequeue(Many) operations will continue to succeed if
               sufficient elements remain in the queue. Subsequent Dequeue(Many)
               operations that would block will fail immediately.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.queue_close_v2(Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Closes the given queue.
            </summary>
            <param name="handle">
               The handle to a queue.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QueueCloseV2'.
            </param>
            <param name="cancel_pending_enqueues">
               If true, all pending enqueue requests that are
               blocked on the given queue will be canceled.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               This operation signals that no more elements will be enqueued in the
               given queue. Subsequent Enqueue(Many) operations will fail.
               Subsequent Dequeue(Many) operations will continue to succeed if
               sufficient elements remain in the queue. Subsequent Dequeue(Many)
               operations that would block will fail immediately.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.queue_dequeue(Tensorflow.Tensor,Tensorflow.TF_DataType[],System.Nullable{System.Int32},System.String)">
            <summary>
               Dequeues a tuple of one or more tensors from the given queue.
            </summary>
            <param name="handle">
               The handle to a queue.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QueueDequeue'.
            </param>
            <param name="component_types">
               Optional argument
               The type of each component in a tuple.
            </param>
            <param name="timeout_ms">
               If the queue is empty, this operation will block for up to
               timeout_ms milliseconds.
               Note: This option is not supported yet.
            </param>
            <returns>
               One or more tensors that were dequeued as a tuple.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation has k outputs, where k is the number of components
               in the tuples stored in the given queue, and output i is the ith
               component of the dequeued tuple.
               
               N.B. If the queue is empty, this operation will block until an element
               has been dequeued (or 'timeout_ms' elapses, if specified).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.queue_dequeue_many(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],System.Nullable{System.Int32},System.String)">
            <summary>
               Dequeues <c>n</c> tuples of one or more tensors from the given queue.
            </summary>
            <param name="handle">
               The handle to a queue.
            </param>
            <param name="n">
               The number of tuples to dequeue.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QueueDequeueMany'.
            </param>
            <param name="component_types">
               Optional argument
               The type of each component in a tuple.
            </param>
            <param name="timeout_ms">
               If the queue has fewer than n elements, this operation
               will block for up to timeout_ms milliseconds.
               Note: This option is not supported yet.
            </param>
            <returns>
               One or more tensors that were dequeued as a tuple.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               If the queue is closed and there are fewer than <c>n</c> elements, then an
               OutOfRange error is returned.
               
               This operation concatenates queue-element component tensors along the
               0th dimension to make a single component tensor.  All of the components
               in the dequeued tuple will have size <c>n</c> in the 0th dimension.
               
               This operation has <c>k</c> outputs, where <c>k</c> is the number of components in
               the tuples stored in the given queue, and output <c>i</c> is the ith
               component of the dequeued tuple.
               
               N.B. If the queue is empty, this operation will block until <c>n</c> elements
               have been dequeued (or 'timeout_ms' elapses, if specified).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.queue_dequeue_many_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],System.Nullable{System.Int32},System.String)">
            <summary>
               Dequeues <c>n</c> tuples of one or more tensors from the given queue.
            </summary>
            <param name="handle">
               The handle to a queue.
            </param>
            <param name="n">
               The number of tuples to dequeue.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QueueDequeueManyV2'.
            </param>
            <param name="component_types">
               Optional argument
               The type of each component in a tuple.
            </param>
            <param name="timeout_ms">
               If the queue has fewer than n elements, this operation
               will block for up to timeout_ms milliseconds.
               Note: This option is not supported yet.
            </param>
            <returns>
               One or more tensors that were dequeued as a tuple.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               If the queue is closed and there are fewer than <c>n</c> elements, then an
               OutOfRange error is returned.
               
               This operation concatenates queue-element component tensors along the
               0th dimension to make a single component tensor.  All of the components
               in the dequeued tuple will have size <c>n</c> in the 0th dimension.
               
               This operation has <c>k</c> outputs, where <c>k</c> is the number of components in
               the tuples stored in the given queue, and output <c>i</c> is the ith
               component of the dequeued tuple.
               
               N.B. If the queue is empty, this operation will block until <c>n</c> elements
               have been dequeued (or 'timeout_ms' elapses, if specified).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.queue_dequeue_up_to(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],System.Nullable{System.Int32},System.String)">
            <summary>
               Dequeues <c>n</c> tuples of one or more tensors from the given queue.
            </summary>
            <param name="handle">
               The handle to a queue.
            </param>
            <param name="n">
               The number of tuples to dequeue.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QueueDequeueUpTo'.
            </param>
            <param name="component_types">
               Optional argument
               The type of each component in a tuple.
            </param>
            <param name="timeout_ms">
               If the queue has fewer than n elements, this operation
               will block for up to timeout_ms milliseconds.
               Note: This option is not supported yet.
            </param>
            <returns>
               One or more tensors that were dequeued as a tuple.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation is not supported by all queues.  If a queue does not support
               DequeueUpTo, then an Unimplemented error is returned.
               
               If the queue is closed and there are more than 0 but less than <c>n</c>
               elements remaining, then instead of returning an OutOfRange error like
               QueueDequeueMany, less than <c>n</c> elements are returned immediately.  If
               the queue is closed and there are 0 elements left in the queue, then
               an OutOfRange error is returned just like in QueueDequeueMany.
               Otherwise the behavior is identical to QueueDequeueMany:
               
               This operation concatenates queue-element component tensors along the
               0th dimension to make a single component tensor.  All of the components
               in the dequeued tuple will have size <c>n</c> in the 0th dimension.
               
               This operation has k outputs, where <c>k</c> is the number of components in
               the tuples stored in the given queue, and output <c>i</c> is the ith
               component of the dequeued tuple.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.queue_dequeue_up_to_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],System.Nullable{System.Int32},System.String)">
            <summary>
               Dequeues <c>n</c> tuples of one or more tensors from the given queue.
            </summary>
            <param name="handle">
               The handle to a queue.
            </param>
            <param name="n">
               The number of tuples to dequeue.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QueueDequeueUpToV2'.
            </param>
            <param name="component_types">
               Optional argument
               The type of each component in a tuple.
            </param>
            <param name="timeout_ms">
               If the queue has fewer than n elements, this operation
               will block for up to timeout_ms milliseconds.
               Note: This option is not supported yet.
            </param>
            <returns>
               One or more tensors that were dequeued as a tuple.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation is not supported by all queues.  If a queue does not support
               DequeueUpTo, then an Unimplemented error is returned.
               
               If the queue is closed and there are more than 0 but less than <c>n</c>
               elements remaining, then instead of returning an OutOfRange error like
               QueueDequeueMany, less than <c>n</c> elements are returned immediately.  If
               the queue is closed and there are 0 elements left in the queue, then
               an OutOfRange error is returned just like in QueueDequeueMany.
               Otherwise the behavior is identical to QueueDequeueMany:
               
               This operation concatenates queue-element component tensors along the
               0th dimension to make a single component tensor.  All of the components
               in the dequeued tuple will have size n in the 0th dimension.
               
               This operation has <c>k</c> outputs, where <c>k</c> is the number of components in
               the tuples stored in the given queue, and output <c>i</c> is the ith
               component of the dequeued tuple.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.queue_dequeue_v2(Tensorflow.Tensor,Tensorflow.TF_DataType[],System.Nullable{System.Int32},System.String)">
            <summary>
               Dequeues a tuple of one or more tensors from the given queue.
            </summary>
            <param name="handle">
               The handle to a queue.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QueueDequeueV2'.
            </param>
            <param name="component_types">
               Optional argument
               The type of each component in a tuple.
            </param>
            <param name="timeout_ms">
               If the queue is empty, this operation will block for up to
               timeout_ms milliseconds.
               Note: This option is not supported yet.
            </param>
            <returns>
               One or more tensors that were dequeued as a tuple.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation has k outputs, where k is the number of components
               in the tuples stored in the given queue, and output i is the ith
               component of the dequeued tuple.
               
               N.B. If the queue is empty, this operation will block until an element
               has been dequeued (or 'timeout_ms' elapses, if specified).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.queue_enqueue(Tensorflow.Tensor,Tensorflow.Tensor[],System.Nullable{System.Int32},System.String)">
            <summary>
               Enqueues a tuple of one or more tensors in the given queue.
            </summary>
            <param name="handle">
               The handle to a queue.
            </param>
            <param name="components">
               One or more tensors from which the enqueued tensors should be taken.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QueueEnqueue'.
            </param>
            <param name="timeout_ms">
               If the queue is full, this operation will block for up to
               timeout_ms milliseconds.
               Note: This option is not supported yet.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               The components input has k elements, which correspond to the components of
               tuples stored in the given queue.
               
               N.B. If the queue is full, this operation will block until the given
               element has been enqueued (or 'timeout_ms' elapses, if specified).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.queue_enqueue_many(Tensorflow.Tensor,Tensorflow.Tensor[],System.Nullable{System.Int32},System.String)">
            <summary>
               Enqueues zero or more tuples of one or more tensors in the given queue.
            </summary>
            <param name="handle">
               The handle to a queue.
            </param>
            <param name="components">
               One or more tensors from which the enqueued tensors should
               be taken.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QueueEnqueueMany'.
            </param>
            <param name="timeout_ms">
               If the queue is too full, this operation will block for up
               to timeout_ms milliseconds.
               Note: This option is not supported yet.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               This operation slices each component tensor along the 0th dimension to
               make multiple queue elements. All of the tuple components must have the
               same size in the 0th dimension.
               
               The components input has k elements, which correspond to the components of
               tuples stored in the given queue.
               
               N.B. If the queue is full, this operation will block until the given
               elements have been enqueued (or 'timeout_ms' elapses, if specified).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.queue_enqueue_many_v2(Tensorflow.Tensor,Tensorflow.Tensor[],System.Nullable{System.Int32},System.String)">
            <summary>
               Enqueues zero or more tuples of one or more tensors in the given queue.
            </summary>
            <param name="handle">
               The handle to a queue.
            </param>
            <param name="components">
               One or more tensors from which the enqueued tensors should
               be taken.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QueueEnqueueManyV2'.
            </param>
            <param name="timeout_ms">
               If the queue is too full, this operation will block for up
               to timeout_ms milliseconds.
               Note: This option is not supported yet.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               This operation slices each component tensor along the 0th dimension to
               make multiple queue elements. All of the tuple components must have the
               same size in the 0th dimension.
               
               The components input has k elements, which correspond to the components of
               tuples stored in the given queue.
               
               N.B. If the queue is full, this operation will block until the given
               elements have been enqueued (or 'timeout_ms' elapses, if specified).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.queue_enqueue_v2(Tensorflow.Tensor,Tensorflow.Tensor[],System.Nullable{System.Int32},System.String)">
            <summary>
               Enqueues a tuple of one or more tensors in the given queue.
            </summary>
            <param name="handle">
               The handle to a queue.
            </param>
            <param name="components">
               One or more tensors from which the enqueued tensors should be taken.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QueueEnqueueV2'.
            </param>
            <param name="timeout_ms">
               If the queue is full, this operation will block for up to
               timeout_ms milliseconds.
               Note: This option is not supported yet.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               The components input has k elements, which correspond to the components of
               tuples stored in the given queue.
               
               N.B. If the queue is full, this operation will block until the given
               element has been enqueued (or 'timeout_ms' elapses, if specified).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.queue_is_closed(Tensorflow.Tensor,System.String)">
            <summary>
               Returns true if queue is closed.
            </summary>
            <param name="handle">
               The handle to a queue.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QueueIsClosed'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation returns true if the queue is closed and false if the queue
               is open.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.queue_is_closed_v2(Tensorflow.Tensor,System.String)">
            <summary>
               Returns true if queue is closed.
            </summary>
            <param name="handle">
               The handle to a queue.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QueueIsClosedV2'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation returns true if the queue is closed and false if the queue
               is open.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.queue_size(Tensorflow.Tensor,System.String)">
            <summary>
               Computes the number of elements in the given queue.
            </summary>
            <param name="handle">
               The handle to a queue.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QueueSize'.
            </param>
            <returns>
               The number of elements in the given queue.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.queue_size_v2(Tensorflow.Tensor,System.String)">
            <summary>
               Computes the number of elements in the given queue.
            </summary>
            <param name="handle">
               The handle to a queue.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'QueueSizeV2'.
            </param>
            <returns>
               The number of elements in the given queue.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.r_f_f_t(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Real-valued fast Fourier transform.
            </summary>
            <param name="input">
               A float32 tensor.
            </param>
            <param name="fft_length">
               An int32 tensor of shape [1]. The FFT length.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RFFT'.
            </param>
            <returns>
               A complex64 tensor of the same rank as <c>input</c>. The inner-most
               dimension of <c>input</c> is replaced with the <c>fft_length / 2 + 1</c> unique
               frequency components of its 1D Fourier transform.
               
               @compatibility(numpy)
               Equivalent to np.fft.rfft
               @end_compatibility
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Computes the 1-dimensional discrete Fourier transform of a real-valued signal
               over the inner-most dimension of <c>input</c>.
               
               Since the DFT of a real signal is Hermitian-symmetric, <c>RFFT</c> only returns the
               <c>fft_length / 2 + 1</c> unique components of the FFT: the zero-frequency term,
               followed by the <c>fft_length / 2</c> positive-frequency terms.
               
               Along the axis <c>RFFT</c> is computed on, if <c>fft_length</c> is smaller than the
               corresponding dimension of <c>input</c>, the dimension is cropped. If it is larger,
               the dimension is padded with zeros.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.r_f_f_t2d(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               2D real-valued fast Fourier transform.
            </summary>
            <param name="input">
               A float32 tensor.
            </param>
            <param name="fft_length">
               An int32 tensor of shape [2]. The FFT length for each dimension.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RFFT2D'.
            </param>
            <returns>
               A complex64 tensor of the same rank as <c>input</c>. The inner-most 2
               dimensions of <c>input</c> are replaced with their 2D Fourier transform. The
               inner-most dimension contains <c>fft_length / 2 + 1</c> unique frequency
               components.
               
               @compatibility(numpy)
               Equivalent to np.fft.rfft2
               @end_compatibility
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Computes the 2-dimensional discrete Fourier transform of a real-valued signal
               over the inner-most 2 dimensions of <c>input</c>.
               
               Since the DFT of a real signal is Hermitian-symmetric, <c>RFFT2D</c> only returns the
               <c>fft_length / 2 + 1</c> unique components of the FFT for the inner-most dimension
               of <c>output</c>: the zero-frequency term, followed by the <c>fft_length / 2</c>
               positive-frequency terms.
               
               Along each axis <c>RFFT2D</c> is computed on, if <c>fft_length</c> is smaller than the
               corresponding dimension of <c>input</c>, the dimension is cropped. If it is larger,
               the dimension is padded with zeros.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.r_f_f_t3d(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               3D real-valued fast Fourier transform.
            </summary>
            <param name="input">
               A float32 tensor.
            </param>
            <param name="fft_length">
               An int32 tensor of shape [3]. The FFT length for each dimension.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RFFT3D'.
            </param>
            <returns>
               A complex64 tensor of the same rank as <c>input</c>. The inner-most 3
               dimensions of <c>input</c> are replaced with the their 3D Fourier transform. The
               inner-most dimension contains <c>fft_length / 2 + 1</c> unique frequency
               components.
               
               @compatibility(numpy)
               Equivalent to np.fft.rfftn with 3 dimensions.
               @end_compatibility
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Computes the 3-dimensional discrete Fourier transform of a real-valued signal
               over the inner-most 3 dimensions of <c>input</c>.
               
               Since the DFT of a real signal is Hermitian-symmetric, <c>RFFT3D</c> only returns the
               <c>fft_length / 2 + 1</c> unique components of the FFT for the inner-most dimension
               of <c>output</c>: the zero-frequency term, followed by the <c>fft_length / 2</c>
               positive-frequency terms.
               
               Along each axis <c>RFFT3D</c> is computed on, if <c>fft_length</c> is smaller than the
               corresponding dimension of <c>input</c>, the dimension is cropped. If it is larger,
               the dimension is padded with zeros.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.r_g_b_to_h_s_v(Tensorflow.Tensor,System.String)">
            <summary>
               Converts one or more images from RGB to HSV.
            </summary>
            <param name="images">
               1-D or higher rank. RGB data to convert. Last dimension must be size 3.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RGBToHSV'.
            </param>
            <returns>
               <c>images</c> converted to HSV.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Outputs a tensor of the same shape as the <c>images</c> tensor, containing the HSV
               value of the pixels. The output is only well defined if the value in <c>images</c>
               are in <c>[0,1]</c>.
               
               <c>output[..., 0]</c> contains hue, <c>output[..., 1]</c> contains saturation, and
               <c>output[..., 2]</c> contains value. All HSV values are in <c>[0,1]</c>. A hue of 0
               corresponds to pure red, hue 1/3 is pure green, and 2/3 is pure blue.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.random_crop(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Randomly crop <c>image</c>.
            </summary>
            <param name="image">
               3-D of shape <c>[height, width, channels]</c>.
            </param>
            <param name="size">
               1-D of length 2 containing: <c>crop_height</c>, <c>crop_width</c>..
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RandomCrop'.
            </param>
            <param name="seed">
               If either seed or seed2 are set to be non-zero, the random number
               generator is seeded by the given seed.  Otherwise, it is seeded by a
               random seed.
            </param>
            <param name="seed2">
               An second seed to avoid seed collision.
            </param>
            <returns>
               3-D of shape <c>[crop_height, crop_width, channels].</c>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               <c>size</c> is a 1-D int64 tensor with 2 elements representing the crop height and
               width.  The values must be non negative.
               
               This Op picks a random location in <c>image</c> and crops a <c>height</c> by <c>width</c>
               rectangle from that location.  The random location is picked so the cropped
               area will fit inside the original image.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.random_dataset(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Creates a Dataset that returns pseudorandom numbers.
            </summary>
            <param name="seed">
               A scalar seed for the random number generator. If either seed or
               seed2 is set to be non-zero, the random number generator is seeded
               by the given seed.  Otherwise, a random seed is used.
            </param>
            <param name="seed2">
               A second scalar seed to avoid seed collision.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RandomDataset'.
            </param>
            <param name="output_types">
               Optional argument
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.random_gamma(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Outputs random values from the Gamma distribution(s) described by alpha.
            </summary>
            <param name="shape">
               1-D integer tensor. Shape of independent samples to draw from each
               distribution described by the shape parameters given in alpha.
            </param>
            <param name="alpha">
               A tensor in which each scalar is a "shape" parameter describing the
               associated gamma distribution.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RandomGamma'.
            </param>
            <param name="seed">
               If either <c>seed</c> or <c>seed2</c> are set to be non-zero, the random number
               generator is seeded by the given seed.  Otherwise, it is seeded by a
               random seed.
            </param>
            <param name="seed2">
               A second seed to avoid seed collision.
            </param>
            <returns>
               A tensor with shape <c>shape + shape(alpha)</c>. Each slice
               <c>[:, ..., :, i0, i1, ...iN]</c> contains the samples drawn for
               <c>alpha[i0, i1, ...iN]</c>. The dtype of the output matches the dtype of alpha.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This op uses the algorithm by Marsaglia et al. to acquire samples via
               transformation-rejection from pairs of uniform and normal random variables.
               See http://dl.acm.org/citation.cfm?id=358414
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.random_gamma_grad(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes the derivative of a Gamma random sample w.r.t. <c>alpha</c>.
            </summary>
            <param name="alpha">
            </param>
            <param name="sample">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RandomGammaGrad'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.random_poisson(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Use RandomPoissonV2 instead.
            </summary>
            <param name="shape">
            </param>
            <param name="rate">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RandomPoisson'.
            </param>
            <param name="seed">
            </param>
            <param name="seed2">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.random_poisson_v2(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Outputs random values from the Poisson distribution(s) described by rate.
            </summary>
            <param name="shape">
               1-D integer tensor. Shape of independent samples to draw from each
               distribution described by the shape parameters given in rate.
            </param>
            <param name="rate">
               A tensor in which each scalar is a "rate" parameter describing the
               associated poisson distribution.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RandomPoissonV2'.
            </param>
            <param name="seed">
               If either <c>seed</c> or <c>seed2</c> are set to be non-zero, the random number
               generator is seeded by the given seed.  Otherwise, it is seeded by a
               random seed.
            </param>
            <param name="seed2">
               A second seed to avoid seed collision.
            </param>
            <param name="dtype">
            </param>
            <returns>
               A tensor with shape <c>shape + shape(rate)</c>. Each slice
               <c>[:, ..., :, i0, i1, ...iN]</c> contains the samples drawn for
               <c>rate[i0, i1, ...iN]</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This op uses two algorithms, depending on rate. If rate &amp;gt;= 10, then
               the algorithm by Hormann is used to acquire samples via
               transformation-rejection.
               See http://www.sciencedirect.com/science/article/pii/0167668793909974.
               
               Otherwise, Knuth's algorithm is used to acquire samples via multiplying uniform
               random variables.
               See Donald E. Knuth (1969). Seminumerical Algorithms. The Art of Computer
               Programming, Volume 2. Addison Wesley
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.random_shuffle(Tensorflow.Tensor,System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Randomly shuffles a tensor along its first dimension.
            </summary>
            <param name="value">
               The tensor to be shuffled.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RandomShuffle'.
            </param>
            <param name="seed">
               If either <c>seed</c> or <c>seed2</c> are set to be non-zero, the random number
               generator is seeded by the given seed.  Otherwise, it is seeded by a
               random seed.
            </param>
            <param name="seed2">
               A second seed to avoid seed collision.
            </param>
            <returns>
               A tensor of same shape and type as <c>value</c>, shuffled along its first
               dimension.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The tensor is shuffled along dimension 0, such that each <c>value[j]</c> is mapped
               to one and only one <c>output[i]</c>. For example, a mapping that might occur for a
               3x2 tensor is:
               
              <code>
               [[1, 2],       [[5, 6],
               [3, 4],  ==&amp;gt;   [1, 2],
               [5, 6]]        [3, 4]]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.random_shuffle_queue(Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               A queue that randomizes the order of elements.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RandomShuffleQueue'.
            </param>
            <param name="component_types">
               Optional argument
               The type of each component in a value.
            </param>
            <param name="shapes">
               The shape of each component in a value. The length of this attr must
               be either 0 or the same as the length of component_types. If the length of
               this attr is 0, the shapes of queue elements are not constrained, and
               only one element may be dequeued at a time.
            </param>
            <param name="capacity">
               The upper bound on the number of elements in this queue.
               Negative numbers mean no limit.
            </param>
            <param name="min_after_dequeue">
               Dequeue will block unless there would be this
               many elements after the dequeue or the queue is closed. This
               ensures a minimum level of mixing of elements.
            </param>
            <param name="seed">
               If either seed or seed2 is set to be non-zero, the random number
               generator is seeded by the given seed.  Otherwise, a random seed is used.
            </param>
            <param name="seed2">
               A second seed to avoid seed collision.
            </param>
            <param name="container">
               If non-empty, this queue is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this queue will be shared under the given name
               across multiple sessions.
            </param>
            <returns>
               The handle to the queue.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.random_shuffle_queue_v2(Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               A queue that randomizes the order of elements.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RandomShuffleQueueV2'.
            </param>
            <param name="component_types">
               Optional argument
               The type of each component in a value.
            </param>
            <param name="shapes">
               The shape of each component in a value. The length of this attr must
               be either 0 or the same as the length of component_types. If the length of
               this attr is 0, the shapes of queue elements are not constrained, and
               only one element may be dequeued at a time.
            </param>
            <param name="capacity">
               The upper bound on the number of elements in this queue.
               Negative numbers mean no limit.
            </param>
            <param name="min_after_dequeue">
               Dequeue will block unless there would be this
               many elements after the dequeue or the queue is closed. This
               ensures a minimum level of mixing of elements.
            </param>
            <param name="seed">
               If either seed or seed2 is set to be non-zero, the random number
               generator is seeded by the given seed.  Otherwise, a random seed is used.
            </param>
            <param name="seed2">
               A second seed to avoid seed collision.
            </param>
            <param name="container">
               If non-empty, this queue is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this queue will be shared under the given name
               across multiple sessions.
            </param>
            <returns>
               The handle to the queue.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.random_standard_normal(Tensorflow.Tensor,Tensorflow.TF_DataType,System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Outputs random values from a normal distribution.
            </summary>
            <param name="shape">
               The shape of the output tensor.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RandomStandardNormal'.
            </param>
            <param name="dtype">
               Optional argument
               The type of the output.
            </param>
            <param name="seed">
               If either <c>seed</c> or <c>seed2</c> are set to be non-zero, the random number
               generator is seeded by the given seed.  Otherwise, it is seeded by a
               random seed.
            </param>
            <param name="seed2">
               A second seed to avoid seed collision.
            </param>
            <returns>
               A tensor of the specified shape filled with random normal values.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The generated values will have mean 0 and standard deviation 1.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.random_uniform(Tensorflow.Tensor,Tensorflow.TF_DataType,System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Outputs random values from a uniform distribution.
            </summary>
            <param name="shape">
               The shape of the output tensor.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RandomUniform'.
            </param>
            <param name="dtype">
               Optional argument
               The type of the output.
            </param>
            <param name="seed">
               If either <c>seed</c> or <c>seed2</c> are set to be non-zero, the random number
               generator is seeded by the given seed.  Otherwise, it is seeded by a
               random seed.
            </param>
            <param name="seed2">
               A second seed to avoid seed collision.
            </param>
            <returns>
               A tensor of the specified shape filled with uniform random values.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The generated values follow a uniform distribution in the range <c>[0, 1)</c>. The
               lower bound 0 is included in the range, while the upper bound 1 is excluded.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.random_uniform_int(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Outputs random integers from a uniform distribution.
            </summary>
            <param name="shape">
               The shape of the output tensor.
            </param>
            <param name="minval">
               0-D.  Inclusive lower bound on the generated integers.
            </param>
            <param name="maxval">
               0-D.  Exclusive upper bound on the generated integers.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RandomUniformInt'.
            </param>
            <param name="seed">
               If either <c>seed</c> or <c>seed2</c> are set to be non-zero, the random number
               generator is seeded by the given seed.  Otherwise, it is seeded by a
               random seed.
            </param>
            <param name="seed2">
               A second seed to avoid seed collision.
            </param>
            <returns>
               A tensor of the specified shape filled with uniform random integers.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The generated values are uniform integers in the range <c>[minval, maxval)</c>.
               The lower bound <c>minval</c> is included in the range, while the upper bound
               <c>maxval</c> is excluded.
               
               The random integers are slightly biased unless <c>maxval - minval</c> is an exact
               power of two.  The bias is small for values of <c>maxval - minval</c> significantly
               smaller than the range of the output (either <c>2^32</c> or <c>2^64</c>).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.range(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Creates a sequence of numbers.
            </summary>
            <param name="start">
               0-D (scalar). First entry in the sequence.
            </param>
            <param name="limit">
               0-D (scalar). Upper limit of sequence, exclusive.
            </param>
            <param name="delta">
               0-D (scalar). Optional. Default is 1. Number that increments <c>start</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Range'.
            </param>
            <returns>
               1-D.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation creates a sequence of numbers that begins at <c>start</c> and
               extends by increments of <c>delta</c> up to but not including <c>limit</c>.
               
               For example:
               
              <code>
               # 'start' is 3
               # 'limit' is 18
               # 'delta' is 3
               tf.range(start, limit, delta) ==&amp;gt; [3, 6, 9, 12, 15]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.range_dataset(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Creates a dataset with a range of values. Corresponds to python's xrange.
            </summary>
            <param name="start">
               corresponds to start in python's xrange().
            </param>
            <param name="stop">
               corresponds to stop in python's xrange().
            </param>
            <param name="step">
               corresponds to step in python's xrange().
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RangeDataset'.
            </param>
            <param name="output_types">
               Optional argument
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.rank(Tensorflow.Tensor,System.String)">
            <summary>
               Returns the rank of a tensor.
            </summary>
            <param name="input">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Rank'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation returns an integer representing the rank of <c>input</c>.
               
               For example:
               
              <code>
               # 't' is [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]
               # shape of tensor 't' is [2, 2, 3]
               rank(t) ==&amp;gt; 3
              </code>
               
               **Note**: The rank of a tensor is not the same as the rank of a matrix. The rank
               of a tensor is the number of indices required to uniquely select each element
               of the tensor. Rank is also known as "order", "degree", or "ndims."
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.read_file(Tensorflow.Tensor,System.String)">
            <summary>
               Reads and outputs the entire contents of the input filename.
            </summary>
            <param name="filename">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ReadFile'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.read_variable_op(Tensorflow.Tensor,Tensorflow.TF_DataType,System.String)">
            <summary>
               Reads the value of a variable.
            </summary>
            <param name="resource">
               handle to the resource in which to store the variable.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ReadVariableOp'.
            </param>
            <param name="dtype">
               Optional argument
               the dtype of the value.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The tensor returned by this operation is immutable.
               
               The value returned by this operation is guaranteed to be influenced by all the
               writes on which this operation depends directly or indirectly, and to not be
               influenced by any of the writes which depend directly or indirectly on this
               operation.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.reader_num_records_produced(Tensorflow.Tensor,System.String)">
            <summary>
               Returns the number of records this Reader has produced.
            </summary>
            <param name="reader_handle">
               Handle to a Reader.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ReaderNumRecordsProduced'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This is the same as the number of ReaderRead executions that have
               succeeded.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.reader_num_records_produced_v2(Tensorflow.Tensor,System.String)">
            <summary>
               Returns the number of records this Reader has produced.
            </summary>
            <param name="reader_handle">
               Handle to a Reader.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ReaderNumRecordsProducedV2'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This is the same as the number of ReaderRead executions that have
               succeeded.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.reader_num_work_units_completed(Tensorflow.Tensor,System.String)">
            <summary>
               Returns the number of work units this Reader has finished processing.
            </summary>
            <param name="reader_handle">
               Handle to a Reader.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ReaderNumWorkUnitsCompleted'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.reader_num_work_units_completed_v2(Tensorflow.Tensor,System.String)">
            <summary>
               Returns the number of work units this Reader has finished processing.
            </summary>
            <param name="reader_handle">
               Handle to a Reader.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ReaderNumWorkUnitsCompletedV2'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.reader_read(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns the next record (key, value pair) produced by a Reader.
            </summary>
            <param name="reader_handle">
               Handle to a Reader.
            </param>
            <param name="queue_handle">
               Handle to a Queue, with string work items.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ReaderRead'.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               key : A scalar.
               value : A scalar.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Will dequeue from the input queue if necessary (e.g. when the
               Reader needs to start reading from a new file since it has finished
               with the previous file).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.reader_read_up_to(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns up to <c>num_records</c> (key, value) pairs produced by a Reader.
            </summary>
            <param name="reader_handle">
               Handle to a <c>Reader</c>.
            </param>
            <param name="queue_handle">
               Handle to a <c>Queue</c>, with string work items.
            </param>
            <param name="num_records">
               number of records to read from <c>Reader</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ReaderReadUpTo'.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               keys : A 1-D tensor.
               values : A 1-D tensor.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Will dequeue from the input queue if necessary (e.g. when the
               Reader needs to start reading from a new file since it has finished
               with the previous file).
               It may return less than <c>num_records</c> even before the last batch.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.reader_read_up_to_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns up to <c>num_records</c> (key, value) pairs produced by a Reader.
            </summary>
            <param name="reader_handle">
               Handle to a <c>Reader</c>.
            </param>
            <param name="queue_handle">
               Handle to a <c>Queue</c>, with string work items.
            </param>
            <param name="num_records">
               number of records to read from <c>Reader</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ReaderReadUpToV2'.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               keys : A 1-D tensor.
               values : A 1-D tensor.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Will dequeue from the input queue if necessary (e.g. when the
               Reader needs to start reading from a new file since it has finished
               with the previous file).
               It may return less than <c>num_records</c> even before the last batch.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.reader_read_v2(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns the next record (key, value pair) produced by a Reader.
            </summary>
            <param name="reader_handle">
               Handle to a Reader.
            </param>
            <param name="queue_handle">
               Handle to a Queue, with string work items.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ReaderReadV2'.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               key : A scalar.
               value : A scalar.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Will dequeue from the input queue if necessary (e.g. when the
               Reader needs to start reading from a new file since it has finished
               with the previous file).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.reader_reset(Tensorflow.Tensor,System.String)">
            <summary>
               Restore a Reader to its initial clean state.
            </summary>
            <param name="reader_handle">
               Handle to a Reader.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ReaderReset'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.reader_reset_v2(Tensorflow.Tensor,System.String)">
            <summary>
               Restore a Reader to its initial clean state.
            </summary>
            <param name="reader_handle">
               Handle to a Reader.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ReaderResetV2'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.reader_restore_state(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Restore a reader to a previously saved state.
            </summary>
            <param name="reader_handle">
               Handle to a Reader.
            </param>
            <param name="state">
               Result of a ReaderSerializeState of a Reader with type
               matching reader_handle.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ReaderRestoreState'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               Not all Readers support being restored, so this can produce an
               Unimplemented error.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.reader_restore_state_v2(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Restore a reader to a previously saved state.
            </summary>
            <param name="reader_handle">
               Handle to a Reader.
            </param>
            <param name="state">
               Result of a ReaderSerializeState of a Reader with type
               matching reader_handle.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ReaderRestoreStateV2'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               Not all Readers support being restored, so this can produce an
               Unimplemented error.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.reader_serialize_state(Tensorflow.Tensor,System.String)">
            <summary>
               Produce a string tensor that encodes the state of a Reader.
            </summary>
            <param name="reader_handle">
               Handle to a Reader.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ReaderSerializeState'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Not all Readers support being serialized, so this can produce an
               Unimplemented error.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.reader_serialize_state_v2(Tensorflow.Tensor,System.String)">
            <summary>
               Produce a string tensor that encodes the state of a Reader.
            </summary>
            <param name="reader_handle">
               Handle to a Reader.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ReaderSerializeStateV2'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Not all Readers support being serialized, so this can produce an
               Unimplemented error.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.real(Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Returns the real part of a complex number.
            </summary>
            <param name="input">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Real'.
            </param>
            <param name="Tout">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Given a tensor <c>input</c> of complex numbers, this operation returns a tensor of
               type <c>float</c> that is the real part of each element in <c>input</c>. All elements in
               <c>input</c> must be complex numbers of the form \\(a + bj\\), where *a* is the real
               part returned by this operation and *b* is the imaginary part.
               
               For example:
               
              <code>
               # tensor 'input' is [-2.25 + 4.75j, 3.25 + 5.75j]
               tf.real(input) ==&amp;gt; [-2.25, 3.25]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.real_div(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns x / y element-wise for real types.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RealDiv'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               If <c>x</c> and <c>y</c> are reals, this will return the floating-point division.
               
               *NOTE*: <c>Div</c> supports broadcasting. More about broadcasting
               [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.reciprocal(Tensorflow.Tensor,System.String)">
            <summary>
               Computes the reciprocal of x element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Reciprocal'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               I.e., \\(y = 1 / x\\).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.reciprocal_grad(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes the gradient for the inverse of <c>x</c> wrt its input.
            </summary>
            <param name="y">
            </param>
            <param name="dy">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ReciprocalGrad'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Specifically, <c>grad = -dy * y*y</c>, where <c>y = 1/x</c>, and <c>dy</c>
               is the corresponding input gradient.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.record_input(System.String,System.Nullable{System.Int32},System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.String,System.String)">
            <summary>
               Emits randomized records.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RecordInput'.
            </param>
            <param name="file_pattern">
               Optional argument
               Glob pattern for the data files.
            </param>
            <param name="file_random_seed">
               Random seeds used to produce randomized records.
            </param>
            <param name="file_shuffle_shift_ratio">
               Shifts the list of files after the list is randomly
               shuffled.
            </param>
            <param name="file_buffer_size">
               The randomization shuffling buffer.
            </param>
            <param name="file_parallelism">
               How many sstables are opened and concurrently iterated over.
            </param>
            <param name="batch_size">
               The batch size.
            </param>
            <param name="compression_type">
               The type of compression for the file. Currently ZLIB and
               GZIP are supported. Defaults to none.
            </param>
            <returns>
               A tensor of shape [batch_size].
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.reduce_join(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String,System.String)">
            <summary>
               Joins a string Tensor across the given dimensions.
            </summary>
            <param name="inputs">
               The input to be joined.  All reduced indices must have non-zero size.
            </param>
            <param name="reduction_indices">
               The dimensions to reduce over.  Dimensions are reduced in the
               order specified.  Omitting <c>reduction_indices</c> is equivalent to passing
               <c>[n-1, n-2, ..., 0]</c>.  Negative indices from <c>-n</c> to <c>-1</c> are supported.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ReduceJoin'.
            </param>
            <param name="keep_dims">
               If <c>True</c>, retain reduced dimensions with length <c>1</c>.
            </param>
            <param name="separator">
               The separator to use when joining.
            </param>
            <returns>
               Has shape equal to that of the input with reduced dimensions removed or
               set to <c>1</c> depending on <c>keep_dims</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Computes the string join across dimensions in the given string Tensor of shape
               <c>[\\(d_0, d_1, ..., d_{n-1}\\)]</c>.  Returns a new Tensor created by joining the input
               strings with the given separator (default: empty string).  Negative indices are
               counted backwards from the end, with <c>-1</c> being equivalent to <c>n - 1</c>.  If
               indices are not specified, joins across all dimensions beginning from <c>n - 1</c>
               through <c>0</c>.
               
               For example:
               
              <code>
               # tensor <c>a</c> is [["a", "b"], ["c", "d"]]
               tf.reduce_join(a, 0) ==&amp;gt; ["ac", "bd"]
               tf.reduce_join(a, 1) ==&amp;gt; ["ab", "cd"]
               tf.reduce_join(a, -2) = tf.reduce_join(a, 0) ==&amp;gt; ["ac", "bd"]
               tf.reduce_join(a, -1) = tf.reduce_join(a, 1) ==&amp;gt; ["ab", "cd"]
               tf.reduce_join(a, 0, keep_dims=True) ==&amp;gt; [["ac", "bd"]]
               tf.reduce_join(a, 1, keep_dims=True) ==&amp;gt; [["ab"], ["cd"]]
               tf.reduce_join(a, 0, separator=".") ==&amp;gt; ["a.c", "b.d"]
               tf.reduce_join(a, [0, 1]) ==&amp;gt; "acbd"
               tf.reduce_join(a, [1, 0]) ==&amp;gt; "abcd"
               tf.reduce_join(a, []) ==&amp;gt; [["a", "b"], ["c", "d"]]
               tf.reduce_join(a) = tf.reduce_join(a, [1, 0]) ==&amp;gt; "abcd"
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.ref_enter(Tensorflow.Tensor,System.String,System.Nullable{System.Boolean},System.Nullable{System.Int32},System.String)">
            <summary>
               Creates or finds a child frame, and makes <c>data</c> available to the child frame.
            </summary>
            <param name="data">
               The tensor to be made available to the child frame.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RefEnter'.
            </param>
            <param name="frame_name">
               Optional argument
               The name of the child frame.
            </param>
            <param name="is_constant">
               If true, the output is constant within the child frame.
            </param>
            <param name="parallel_iterations">
               The number of iterations allowed to run in parallel.
            </param>
            <returns>
               The same tensor as <c>data</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The unique <c>frame_name</c> is used by the <c>Executor</c> to identify frames. If
               <c>is_constant</c> is true, <c>output</c> is a constant in the child frame; otherwise
               it may be changed in the child frame. At most <c>parallel_iterations</c> iterations
               are run in parallel in the child frame.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.ref_exit(Tensorflow.Tensor,System.String)">
            <summary>
               Exits the current frame to its parent frame.
            </summary>
            <param name="data">
               The tensor to be made available to the parent frame.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RefExit'.
            </param>
            <returns>
               The same tensor as <c>data</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Exit makes its input <c>data</c> available to the parent frame.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.ref_identity(Tensorflow.Tensor,System.String)">
            <summary>
               Return the same ref tensor as the input ref tensor.
            </summary>
            <param name="input">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RefIdentity'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.ref_merge(Tensorflow.Tensor[],System.String)">
            <summary>
               Forwards the value of an available tensor from <c>inputs</c> to <c>output</c>.
            </summary>
            <param name="inputs">
               The input tensors, exactly one of which will become available.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RefMerge'.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output : Will be set to the available input tensor.
               value_index : The index of the chosen input tensor in <c>inputs</c>.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               <c>Merge</c> waits for at least one of the tensors in <c>inputs</c> to become available.
               It is usually combined with <c>Switch</c> to implement branching.
               
               <c>Merge</c> forwards the first tensor for become available to <c>output</c>, and sets
               <c>value_index</c> to its index in <c>inputs</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.ref_next_iteration(Tensorflow.Tensor,System.String)">
            <summary>
               Makes its input available to the next iteration.
            </summary>
            <param name="data">
               The tensor to be made available to the next iteration.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RefNextIteration'.
            </param>
            <returns>
               The same tensor as <c>data</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.ref_select(Tensorflow.Tensor,Tensorflow.Tensor[],System.String)">
            <summary>
               Forwards the <c>index</c>th element of <c>inputs</c> to <c>output</c>.
            </summary>
            <param name="index">
               A scalar that determines the input that gets selected.
            </param>
            <param name="inputs">
               A list of ref tensors, one of which will be forwarded to <c>output</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RefSelect'.
            </param>
            <returns>
               The forwarded tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.ref_switch(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Forwards the ref tensor <c>data</c> to the output port determined by <c>pred</c>.
            </summary>
            <param name="data">
               The ref tensor to be forwarded to the appropriate output.
            </param>
            <param name="pred">
               A scalar that specifies which output port will receive data.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RefSwitch'.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output_false : If <c>pred</c> is false, data will be forwarded to this output.
               output_true : If <c>pred</c> is true, data will be forwarded to this output.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               If <c>pred</c> is true, the <c>data</c> input is forwarded to <c>output_true</c>. Otherwise,
               the data goes to <c>output_false</c>.
               
               See also <c>Switch</c> and <c>Merge</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.regex_full_match(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Check if the input matches the regex pattern.
            </summary>
            <param name="input">
               A string tensor of the text to be processed.
            </param>
            <param name="pattern">
               A scalar string tensor containing the regular expression to match the input.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RegexFullMatch'.
            </param>
            <returns>
               A bool tensor with the same shape as <c>input</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The input is a string tensor of any shape. The pattern is a scalar
               string tensor which is applied to every element of the input tensor.
               The boolean values (True or False) of the output tensor indicate
               if the input matches the regex pattern provided.
               
               The pattern follows the re2 syntax (https://github.com/google/re2/wiki/Syntax)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.regex_replace(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Replaces the match of pattern in input with rewrite.
            </summary>
            <param name="input">
               The text to be processed.
            </param>
            <param name="pattern">
               The regular expression to match the input.
            </param>
            <param name="rewrite">
               The rewrite to be applied to the matched expresion.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RegexReplace'.
            </param>
            <param name="replace_global">
               If True, the replacement is global, otherwise the replacement
               is done only on the first match.
            </param>
            <returns>
               The text after applying pattern and rewrite.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               It follows the re2 syntax (https://github.com/google/re2/wiki/Syntax)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.relu(Tensorflow.Tensor,System.String)">
            <summary>
               Computes rectified linear: <c>max(features, 0)</c>.
            </summary>
            <param name="features">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Relu'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.relu6(Tensorflow.Tensor,System.String)">
            <summary>
               Computes rectified linear 6: <c>min(max(features, 0), 6)</c>.
            </summary>
            <param name="features">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Relu6'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.relu6grad(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes rectified linear 6 gradients for a Relu6 operation.
            </summary>
            <param name="gradients">
               The backpropagated gradients to the corresponding Relu6 operation.
            </param>
            <param name="features">
               The features passed as input to the corresponding Relu6 operation, or
               its output; using either one produces the same result.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Relu6Grad'.
            </param>
            <returns>
               The gradients:
               <c>gradients * (features &amp;gt; 0) * (features &amp;lt; 6)</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.relu_grad(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes rectified linear gradients for a Relu operation.
            </summary>
            <param name="gradients">
               The backpropagated gradients to the corresponding Relu operation.
            </param>
            <param name="features">
               The features passed as input to the corresponding Relu operation, OR
               the outputs of that operation (both work equivalently).
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ReluGrad'.
            </param>
            <returns>
               <c>gradients * (features &amp;gt; 0)</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.remote_fused_graph_execute(Tensorflow.Tensor[],Tensorflow.TF_DataType[],System.String,System.String)">
            <summary>
               Execute a sub graph on a remote processor.
            </summary>
            <param name="inputs">
               Arbitrary number of tensors with arbitrary data types
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RemoteFusedGraphExecute'.
            </param>
            <param name="Toutputs">
               Optional argument
            </param>
            <param name="serialized_remote_fused_graph_execute_info">
               Optional argument
               Serialized protocol buffer
               of RemoteFusedGraphExecuteInfo which contains graph specifications.
            </param>
            <returns>
               Arbitrary number of tensors with arbitrary data types
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The graph specifications(such as graph itself, input tensors and output names)
               are stored as a serialized protocol buffer of RemoteFusedGraphExecuteInfo
               as serialized_remote_fused_graph_execute_info.
               The specifications will be passed to a dedicated registered
               remote fused graph executor.  The executor will send the graph specifications
               to a remote processor and execute that graph.  The execution results
               will be passed to consumer nodes as outputs of this node.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.repeat_dataset(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Creates a dataset that emits the outputs of <c>input_dataset</c> <c>count</c> times.
            </summary>
            <param name="input_dataset">
            </param>
            <param name="count">
               A scalar representing the number of times that <c>input_dataset</c> should
               be repeated. A value of <c>-1</c> indicates that it should be repeated infinitely.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RepeatDataset'.
            </param>
            <param name="output_types">
               Optional argument
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.requantization_range(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Given a quantized tensor described by (input, input_min, input_max), outputs a
            </summary>
            <param name="input">
            </param>
            <param name="input_min">
               The float value that the minimum quantized input value represents.
            </param>
            <param name="input_max">
               The float value that the maximum quantized input value represents.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RequantizationRange'.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output_min : The computed min output.
               output_max : the computed max output.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               range that covers the actual values present in that tensor.  This op is
               typically used to produce the requested_output_min and requested_output_max for
               Requantize.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.requantize(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType,System.String)">
            <summary>
               Convert the quantized 'input' tensor into a lower-precision 'output', using the
            </summary>
            <param name="input">
            </param>
            <param name="input_min">
               The float value that the minimum quantized input value represents.
            </param>
            <param name="input_max">
               The float value that the maximum quantized input value represents.
            </param>
            <param name="requested_output_min">
               The float value that the minimum quantized output value represents.
            </param>
            <param name="requested_output_max">
               The float value that the maximum quantized output value represents.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Requantize'.
            </param>
            <param name="out_type">
               Optional argument
               The type of the output. Should be a lower bit depth than Tinput.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output :
               output_min : The requested_output_min value is copied into this output.
               output_max : The requested_output_max value is copied into this output.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               output range specified with 'requested_output_min' and 'requested_output_max'.
               
               [input_min, input_max] are scalar floats that specify the range for the float
               interpretation of the 'input' data. For example, if input_min is -1.0f and
               input_max is 1.0f, and we are dealing with quint16 quantized data, then a 0
               value in the 16-bit data should be interpreted as -1.0f, and a 65535 means 1.0f.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.reshape(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Reshapes a tensor.
            </summary>
            <param name="tensor">
            </param>
            <param name="shape">
               Defines the shape of the output tensor.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Reshape'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Given <c>tensor</c>, this operation returns a tensor that has the same values
               as <c>tensor</c> with shape <c>shape</c>.
               
               If one component of <c>shape</c> is the special value -1, the size of that dimension
               is computed so that the total size remains constant.  In particular, a <c>shape</c>
               of <c>[-1]</c> flattens into 1-D.  At most one component of <c>shape</c> can be -1.
               
               If <c>shape</c> is 1-D or higher, then the operation returns a tensor with shape
               <c>shape</c> filled with the values of <c>tensor</c>. In this case, the number of elements
               implied by <c>shape</c> must be the same as the number of elements in <c>tensor</c>.
               
               For example:
               
              <code>
               # tensor 't' is [1, 2, 3, 4, 5, 6, 7, 8, 9]
               # tensor 't' has shape [9]
               reshape(t, [3, 3]) ==&amp;gt; [[1, 2, 3],
               [4, 5, 6],
               [7, 8, 9]]
               
               # tensor 't' is [[[1, 1], [2, 2]],
               #                [[3, 3], [4, 4]]]
               # tensor 't' has shape [2, 2, 2]
               reshape(t, [2, 4]) ==&amp;gt; [[1, 1, 2, 2],
               [3, 3, 4, 4]]
               
               # tensor 't' is [[[1, 1, 1],
               #                 [2, 2, 2]],
               #                [[3, 3, 3],
               #                 [4, 4, 4]],
               #                [[5, 5, 5],
               #                 [6, 6, 6]]]
               # tensor 't' has shape [3, 2, 3]
               # pass '[-1]' to flatten 't'
               reshape(t, [-1]) ==&amp;gt; [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6]
               
               # -1 can also be used to infer the shape
               
               # -1 is inferred to be 9:
               reshape(t, [2, -1]) ==&amp;gt; [[1, 1, 1, 2, 2, 2, 3, 3, 3],
               [4, 4, 4, 5, 5, 5, 6, 6, 6]]
               # -1 is inferred to be 2:
               reshape(t, [-1, 9]) ==&amp;gt; [[1, 1, 1, 2, 2, 2, 3, 3, 3],
               [4, 4, 4, 5, 5, 5, 6, 6, 6]]
               # -1 is inferred to be 3:
               reshape(t, [ 2, -1, 3]) ==&amp;gt; [[[1, 1, 1],
               [2, 2, 2],
               [3, 3, 3]],
               [[4, 4, 4],
               [5, 5, 5],
               [6, 6, 6]]]
               
               # tensor 't' is [7]
               # shape <c>[]</c> reshapes to a scalar
               reshape(t, []) ==&amp;gt; 7
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resize_area(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Resize <c>images</c> to <c>size</c> using area interpolation.
            </summary>
            <param name="images">
               4-D with shape <c>[batch, height, width, channels]</c>.
            </param>
            <param name="size">
               = A 1-D int32 Tensor of 2 elements: <c>new_height, new_width</c>.  The
               new size for the images.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResizeArea'.
            </param>
            <param name="align_corners">
               If true, the centers of the 4 corner pixels of the input and output tensors are
               aligned, preserving the values at the corner pixels. Defaults to false.
            </param>
            <returns>
               4-D with shape
               <c>[batch, new_height, new_width, channels]</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Input images can be of different types but output images are always float.
               
               The range of pixel values for the output image might be slightly different
               from the range for the input image because of limited numerical precision.
               To guarantee an output range, for example <c>[0.0, 1.0]</c>, apply
               <c>tf.clip_by_value</c> to the output.
               
               Each output pixel is computed by first transforming the pixel's footprint into
               the input tensor and then averaging the pixels that intersect the footprint. An
               input pixel's contribution to the average is weighted by the fraction of its
               area that intersects the footprint.  This is the same as OpenCV's INTER_AREA.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resize_bicubic(Tensorflow.Tensor,Tensorflow.Tensor,System.Boolean,System.Boolean,System.String)">
            <summary>
               Resize <c>images</c> to <c>size</c> using bicubic interpolation.
            </summary>
            <param name="images">
               4-D with shape <c>[batch, height, width, channels]</c>.
            </param>
            <param name="size">
               = A 1-D int32 Tensor of 2 elements: <c>new_height, new_width</c>.  The
               new size for the images.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResizeBicubic'.
            </param>
            <param name="align_corners">
               If true, the centers of the 4 corner pixels of the input and output tensors are
               aligned, preserving the values at the corner pixels. Defaults to false.
            </param>
            <returns>
               4-D with shape
               <c>[batch, new_height, new_width, channels]</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Input images can be of different types but output images are always float.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resize_bicubic_grad(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Computes the gradient of bicubic interpolation.
            </summary>
            <param name="grads">
               4-D with shape <c>[batch, height, width, channels]</c>.
            </param>
            <param name="original_image">
               4-D with shape <c>[batch, orig_height, orig_width, channels]</c>,
               The image tensor that was resized.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResizeBicubicGrad'.
            </param>
            <param name="align_corners">
               If true, the centers of the 4 corner pixels of the input and grad tensors are
               aligned. Defaults to false.
            </param>
            <returns>
               4-D with shape <c>[batch, orig_height, orig_width, channels]</c>.
               Gradients with respect to the input image. Input image must have been
               float or double.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resize_bilinear(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Resize <c>images</c> to <c>size</c> using bilinear interpolation.
            </summary>
            <param name="images">
               4-D with shape <c>[batch, height, width, channels]</c>.
            </param>
            <param name="size">
               = A 1-D int32 Tensor of 2 elements: <c>new_height, new_width</c>.  The
               new size for the images.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResizeBilinear'.
            </param>
            <param name="align_corners">
               If true, the centers of the 4 corner pixels of the input and output tensors are
               aligned, preserving the values at the corner pixels. Defaults to false.
            </param>
            <returns>
               4-D with shape
               <c>[batch, new_height, new_width, channels]</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Input images can be of different types but output images are always float.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resize_bilinear_grad(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Computes the gradient of bilinear interpolation.
            </summary>
            <param name="grads">
               4-D with shape <c>[batch, height, width, channels]</c>.
            </param>
            <param name="original_image">
               4-D with shape <c>[batch, orig_height, orig_width, channels]</c>,
               The image tensor that was resized.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResizeBilinearGrad'.
            </param>
            <param name="align_corners">
               If true, the centers of the 4 corner pixels of the input and grad tensors are
               aligned. Defaults to false.
            </param>
            <returns>
               4-D with shape <c>[batch, orig_height, orig_width, channels]</c>.
               Gradients with respect to the input image. Input image must have been
               float or double.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resize_nearest_neighbor(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Resize <c>images</c> to <c>size</c> using nearest neighbor interpolation.
            </summary>
            <param name="images">
               4-D with shape <c>[batch, height, width, channels]</c>.
            </param>
            <param name="size">
               = A 1-D int32 Tensor of 2 elements: <c>new_height, new_width</c>.  The
               new size for the images.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResizeNearestNeighbor'.
            </param>
            <param name="align_corners">
               If true, the centers of the 4 corner pixels of the input and output tensors are
               aligned, preserving the values at the corner pixels. Defaults to false.
            </param>
            <returns>
               4-D with shape
               <c>[batch, new_height, new_width, channels]</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resize_nearest_neighbor_grad(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Computes the gradient of nearest neighbor interpolation.
            </summary>
            <param name="grads">
               4-D with shape <c>[batch, height, width, channels]</c>.
            </param>
            <param name="size">
               = A 1-D int32 Tensor of 2 elements: <c>orig_height, orig_width</c>. The
               original input size.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResizeNearestNeighborGrad'.
            </param>
            <param name="align_corners">
               If true, the centers of the 4 corner pixels of the input and grad tensors are
               aligned. Defaults to false.
            </param>
            <returns>
               4-D with shape <c>[batch, orig_height, orig_width, channels]</c>. Gradients
               with respect to the input image.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_apply_ada_max(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' according to the AdaMax algorithm.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="m">
               Should be from a Variable().
            </param>
            <param name="v">
               Should be from a Variable().
            </param>
            <param name="beta1_power">
               Must be a scalar.
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="beta1">
               Momentum factor. Must be a scalar.
            </param>
            <param name="beta2">
               Momentum factor. Must be a scalar.
            </param>
            <param name="epsilon">
               Ridge term. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceApplyAdaMax'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var, m, and v tensors will be protected
               by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               m_t &amp;lt;- beta1 * m_{t-1} + (1 - beta1) * g
               v_t &amp;lt;- max(beta2 * v_{t-1}, abs(g))
               variable &amp;lt;- variable - learning_rate / (1 - beta1^t) * m_t / (v_t + epsilon)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_apply_adadelta(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' according to the adadelta scheme.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="accum">
               Should be from a Variable().
            </param>
            <param name="accum_update">
               Should be from a Variable().
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="rho">
               Decay factor. Must be a scalar.
            </param>
            <param name="epsilon">
               Constant factor. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceApplyAdadelta'.
            </param>
            <param name="use_locking">
               If True, updating of the var, accum and update_accum tensors will be protected by
               a lock; otherwise the behavior is undefined, but may exhibit less contention.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               accum = rho() * accum + (1 - rho()) * grad.square();
               update = (update_accum + epsilon).sqrt() * (accum + epsilon()).rsqrt() * grad;
               update_accum = rho() * update_accum + (1 - rho()) * update.square();
               var -= update;
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_apply_adagrad(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' according to the adagrad scheme.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="accum">
               Should be from a Variable().
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceApplyAdagrad'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var and accum tensors will be protected
               by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <param name="update_slots">
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               accum += grad * grad
               var -= lr * grad * (1 / sqrt(accum))
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_apply_adagrad_d_a(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' according to the proximal adagrad scheme.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="gradient_accumulator">
               Should be from a Variable().
            </param>
            <param name="gradient_squared_accumulator">
               Should be from a Variable().
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="l1">
               L1 regularization. Must be a scalar.
            </param>
            <param name="l2">
               L2 regularization. Must be a scalar.
            </param>
            <param name="global_step">
               Training step number. Must be a scalar.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceApplyAdagradDA'.
            </param>
            <param name="use_locking">
               If True, updating of the var and accum tensors will be protected by
               a lock; otherwise the behavior is undefined, but may exhibit less contention.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_apply_adam(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' according to the Adam algorithm.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="m">
               Should be from a Variable().
            </param>
            <param name="v">
               Should be from a Variable().
            </param>
            <param name="beta1_power">
               Must be a scalar.
            </param>
            <param name="beta2_power">
               Must be a scalar.
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="beta1">
               Momentum factor. Must be a scalar.
            </param>
            <param name="beta2">
               Momentum factor. Must be a scalar.
            </param>
            <param name="epsilon">
               Ridge term. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceApplyAdam'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var, m, and v tensors will be protected
               by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <param name="use_nesterov">
               If <c>True</c>, uses the nesterov update.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               $$lr_t := \text{learning\_rate} * \sqrt{1 - beta_2^t} / (1 - beta_1^t)$$
               $$m_t := beta_1 * m_{t-1} + (1 - beta_1) * g$$
               $$v_t := beta_2 * v_{t-1} + (1 - beta_2) * g * g$$
               $$variable := variable - lr_t * m_t / (\sqrt{v_t} + \epsilon)$$
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_apply_add_sign(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' according to the AddSign update.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="m">
               Should be from a Variable().
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="alpha">
               Must be a scalar.
            </param>
            <param name="sign_decay">
               Must be a scalar.
            </param>
            <param name="beta">
               Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceApplyAddSign'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var and m tensors is
               protected by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               m_t &amp;lt;- beta1 * m_{t-1} + (1 - beta1) * g
               update &amp;lt;- (alpha + sign_decay * sign(g) *sign(m)) * g
               variable &amp;lt;- variable - lr_t * update
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_apply_centered_r_m_s_prop(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' according to the centered RMSProp algorithm.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="mg">
               Should be from a Variable().
            </param>
            <param name="ms">
               Should be from a Variable().
            </param>
            <param name="mom">
               Should be from a Variable().
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="rho">
               Decay rate. Must be a scalar.
            </param>
            <param name="momentum">
            </param>
            <param name="epsilon">
               Ridge term. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceApplyCenteredRMSProp'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var, mg, ms, and mom tensors is
               protected by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               The centered RMSProp algorithm uses an estimate of the centered second moment
               (i.e., the variance) for normalization, as opposed to regular RMSProp, which
               uses the (uncentered) second moment. This often helps with training, but is
               slightly more expensive in terms of computation and memory.
               
               Note that in dense implementation of this algorithm, mg, ms, and mom will
               update even if the grad is zero, but in this sparse implementation, mg, ms,
               and mom will not update in iterations during which the grad is zero.
               
               mean_square = decay * mean_square + (1-decay) * gradient ** 2
               mean_grad = decay * mean_grad + (1-decay) * gradient
               
               Delta = learning_rate * gradient / sqrt(mean_square + epsilon - mean_grad ** 2)
               
               mg &amp;lt;- rho * mg_{t-1} + (1-rho) * grad
               ms &amp;lt;- rho * ms_{t-1} + (1-rho) * grad * grad
               mom &amp;lt;- momentum * mom_{t-1} + lr * grad / sqrt(ms - mg * mg + epsilon)
               var &amp;lt;- var - mom
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_apply_ftrl(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' according to the Ftrl-proximal scheme.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="accum">
               Should be from a Variable().
            </param>
            <param name="linear">
               Should be from a Variable().
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="l1">
               L1 regulariation. Must be a scalar.
            </param>
            <param name="l2">
               L2 regulariation. Must be a scalar.
            </param>
            <param name="lr_power">
               Scaling factor. Must be a scalar.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceApplyFtrl'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var and accum tensors will be protected
               by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               accum_new = accum + grad * grad
               linear += grad - (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var
               quadratic = 1.0 / (accum_new^(lr_power) * lr) + 2 * l2
               var = (sign(linear) * l1 - linear) / quadratic if |linear| &amp;gt; l1 else 0.0
               accum = accum_new
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_apply_ftrl_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' according to the Ftrl-proximal scheme.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="accum">
               Should be from a Variable().
            </param>
            <param name="linear">
               Should be from a Variable().
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="l1">
               L1 regulariation. Must be a scalar.
            </param>
            <param name="l2">
               L2 shrinkage regulariation. Must be a scalar.
            </param>
            <param name="l2_shrinkage">
            </param>
            <param name="lr_power">
               Scaling factor. Must be a scalar.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceApplyFtrlV2'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var and accum tensors will be protected
               by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               grad_with_shrinkage = grad + 2 * l2_shrinkage * var
               accum_new = accum + grad_with_shrinkage * grad_with_shrinkage
               linear += grad_with_shrinkage +
               (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var
               quadratic = 1.0 / (accum_new^(lr_power) * lr) + 2 * l2
               var = (sign(linear) * l1 - linear) / quadratic if |linear| &amp;gt; l1 else 0.0
               accum = accum_new
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_apply_gradient_descent(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' by subtracting 'alpha' * 'delta' from it.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="alpha">
               Scaling factor. Must be a scalar.
            </param>
            <param name="delta">
               The change.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceApplyGradientDescent'.
            </param>
            <param name="use_locking">
               If <c>True</c>, the subtraction will be protected by a lock;
               otherwise the behavior is undefined, but may exhibit less contention.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_apply_momentum(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' according to the momentum scheme. Set use_nesterov = True if you
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="accum">
               Should be from a Variable().
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="momentum">
               Momentum. Must be a scalar.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceApplyMomentum'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var and accum tensors will be protected
               by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <param name="use_nesterov">
               If <c>True</c>, the tensor passed to compute grad will be
               var - lr * momentum * accum, so in the end, the var you get is actually
               var - lr * momentum * accum.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               want to use Nesterov momentum.
               
               accum = accum * momentum + grad
               var -= lr * accum
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_apply_power_sign(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' according to the AddSign update.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="m">
               Should be from a Variable().
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="logbase">
               Must be a scalar.
            </param>
            <param name="sign_decay">
               Must be a scalar.
            </param>
            <param name="beta">
               Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceApplyPowerSign'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var and m tensors is
               protected by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               m_t &amp;lt;- beta1 * m_{t-1} + (1 - beta1) * g
               update &amp;lt;- exp(logbase * sign_decay * sign(g) * sign(m_t)) * g
               variable &amp;lt;- variable - lr_t * update
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_apply_proximal_adagrad(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' and '*accum' according to FOBOS with Adagrad learning rate.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="accum">
               Should be from a Variable().
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="l1">
               L1 regularization. Must be a scalar.
            </param>
            <param name="l2">
               L2 regularization. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceApplyProximalAdagrad'.
            </param>
            <param name="use_locking">
               If True, updating of the var and accum tensors will be protected by
               a lock; otherwise the behavior is undefined, but may exhibit less contention.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               accum += grad * grad
               prox_v = var - lr * grad * (1 / sqrt(accum))
               var = sign(prox_v)/(1+lr*l2) * max{|prox_v|-lr*l1,0}
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_apply_proximal_gradient_descent(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' as FOBOS algorithm with fixed learning rate.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="alpha">
               Scaling factor. Must be a scalar.
            </param>
            <param name="l1">
               L1 regularization. Must be a scalar.
            </param>
            <param name="l2">
               L2 regularization. Must be a scalar.
            </param>
            <param name="delta">
               The change.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceApplyProximalGradientDescent'.
            </param>
            <param name="use_locking">
               If True, the subtraction will be protected by a lock;
               otherwise the behavior is undefined, but may exhibit less contention.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               prox_v = var - alpha * delta
               var = sign(prox_v)/(1+alpha*l2) * max{|prox_v|-alpha*l1,0}
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_apply_r_m_s_prop(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' according to the RMSProp algorithm.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="ms">
               Should be from a Variable().
            </param>
            <param name="mom">
               Should be from a Variable().
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="rho">
               Decay rate. Must be a scalar.
            </param>
            <param name="momentum">
            </param>
            <param name="epsilon">
               Ridge term. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceApplyRMSProp'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var, ms, and mom tensors is protected
               by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               Note that in dense implementation of this algorithm, ms and mom will
               update even if the grad is zero, but in this sparse implementation, ms
               and mom will not update in iterations during which the grad is zero.
               
               mean_square = decay * mean_square + (1-decay) * gradient ** 2
               Delta = learning_rate * gradient / sqrt(mean_square + epsilon)
               
               ms &amp;lt;- rho * ms_{t-1} + (1-rho) * grad * grad
               mom &amp;lt;- momentum * mom_{t-1} + lr * grad / sqrt(ms + epsilon)
               var &amp;lt;- var - mom
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_count_up_to(Tensorflow.Tensor,System.Int32,Tensorflow.TF_DataType,System.String)">
            <summary>
               Increments variable pointed to by 'resource' until it reaches 'limit'.
            </summary>
            <param name="resource">
               Should be from a scalar <c>Variable</c> node.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceCountUpTo'.
            </param>
            <param name="limit">
               Optional argument
               If incrementing ref would bring it above limit, instead generates an
               'OutOfRange' error.
            </param>
            <param name="T">
               Optional argument
            </param>
            <returns>
               A copy of the input before increment. If nothing else modifies the
               input, the values produced will all be distinct.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_gather(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType,System.Nullable{System.Boolean},System.String)">
            <summary>
               Gather slices from the variable pointed to by <c>resource</c> according to <c>indices</c>.
            </summary>
            <param name="resource">
            </param>
            <param name="indices">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceGather'.
            </param>
            <param name="dtype">
               Optional argument
            </param>
            <param name="validate_indices">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               <c>indices</c> must be an integer tensor of any dimension (usually 0-D or 1-D).
               Produces an output tensor with shape <c>indices.shape + params.shape[1:]</c> where:
               
              <code>
               # Scalar indices
               output[:, ..., :] = params[indices, :, ... :]
               
               # Vector indices
               output[i, :, ..., :] = params[indices[i], :, ... :]
               
               # Higher rank indices
               output[i, ..., j, :, ... :] = params[indices[i, ..., j], :, ..., :]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_scatter_add(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Adds sparse updates to the variable referenced by <c>resource</c>.
            </summary>
            <param name="resource">
               Should be from a <c>Variable</c> node.
            </param>
            <param name="indices">
               A tensor of indices into the first dimension of <c>ref</c>.
            </param>
            <param name="updates">
               A tensor of updated values to add to <c>ref</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceScatterAdd'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               This operation computes
               
               # Scalar indices
               ref[indices, ...] += updates[...]
               
               # Vector indices (for each i)
               ref[indices[i], ...] += updates[i, ...]
               
               # High rank indices (for each i, ..., j)
               ref[indices[i, ..., j], ...] += updates[i, ..., j, ...]
               
               Duplicate entries are handled correctly: if multiple <c>indices</c> reference
               the same location, their contributions add.
               
               Requires <c>updates.shape = indices.shape + ref.shape[1:]</c> or <c>updates.shape = []</c>.
               
               &amp;lt;div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;"&amp;gt;
               &amp;lt;img style="width:100%" src='https://www.tensorflow.org/images/ScatterAdd.png' alt&amp;gt;
               &amp;lt;/div&amp;gt;
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_scatter_div(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Divides sparse updates into the variable referenced by <c>resource</c>.
            </summary>
            <param name="resource">
               Should be from a <c>Variable</c> node.
            </param>
            <param name="indices">
               A tensor of indices into the first dimension of <c>ref</c>.
            </param>
            <param name="updates">
               A tensor of updated values to add to <c>ref</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceScatterDiv'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               This operation computes
               
               # Scalar indices
               ref[indices, ...] /= updates[...]
               
               # Vector indices (for each i)
               ref[indices[i], ...] /= updates[i, ...]
               
               # High rank indices (for each i, ..., j)
               ref[indices[i, ..., j], ...] /= updates[i, ..., j, ...]
               
               Duplicate entries are handled correctly: if multiple <c>indices</c> reference
               the same location, their contributions multiply.
               
               Requires <c>updates.shape = indices.shape + ref.shape[1:]</c> or <c>updates.shape = []</c>.
               
               &amp;lt;div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;"&amp;gt;
               &amp;lt;img style="width:100%" src='https://www.tensorflow.org/images/ScatterAdd.png' alt&amp;gt;
               &amp;lt;/div&amp;gt;
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_scatter_max(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Reduces sparse updates into the variable referenced by <c>resource</c> using the <c>max</c> operation.
            </summary>
            <param name="resource">
               Should be from a <c>Variable</c> node.
            </param>
            <param name="indices">
               A tensor of indices into the first dimension of <c>ref</c>.
            </param>
            <param name="updates">
               A tensor of updated values to add to <c>ref</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceScatterMax'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               This operation computes
               
               # Scalar indices
               ref[indices, ...] = max(ref[indices, ...], updates[...])
               
               # Vector indices (for each i)
               ref[indices[i], ...] = max(ref[indices[i], ...], updates[i, ...])
               
               # High rank indices (for each i, ..., j)
               ref[indices[i, ..., j], ...] = max(ref[indices[i, ..., j], ...], updates[i, ..., j, ...])
               
               Duplicate entries are handled correctly: if multiple <c>indices</c> reference
               the same location, their contributions are combined.
               
               Requires <c>updates.shape = indices.shape + ref.shape[1:]</c> or <c>updates.shape = []</c>.
               
               &amp;lt;div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;"&amp;gt;
               &amp;lt;img style="width:100%" src='https://www.tensorflow.org/images/ScatterAdd.png' alt&amp;gt;
               &amp;lt;/div&amp;gt;
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_scatter_min(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Reduces sparse updates into the variable referenced by <c>resource</c> using the <c>min</c> operation.
            </summary>
            <param name="resource">
               Should be from a <c>Variable</c> node.
            </param>
            <param name="indices">
               A tensor of indices into the first dimension of <c>ref</c>.
            </param>
            <param name="updates">
               A tensor of updated values to add to <c>ref</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceScatterMin'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               This operation computes
               
               # Scalar indices
               ref[indices, ...] = min(ref[indices, ...], updates[...])
               
               # Vector indices (for each i)
               ref[indices[i], ...] = min(ref[indices[i], ...], updates[i, ...])
               
               # High rank indices (for each i, ..., j)
               ref[indices[i, ..., j], ...] = min(ref[indices[i, ..., j], ...], updates[i, ..., j, ...])
               
               Duplicate entries are handled correctly: if multiple <c>indices</c> reference
               the same location, their contributions are combined.
               
               Requires <c>updates.shape = indices.shape + ref.shape[1:]</c> or <c>updates.shape = []</c>.
               
               &amp;lt;div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;"&amp;gt;
               &amp;lt;img style="width:100%" src='https://www.tensorflow.org/images/ScatterAdd.png' alt&amp;gt;
               &amp;lt;/div&amp;gt;
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_scatter_mul(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Multiplies sparse updates into the variable referenced by <c>resource</c>.
            </summary>
            <param name="resource">
               Should be from a <c>Variable</c> node.
            </param>
            <param name="indices">
               A tensor of indices into the first dimension of <c>ref</c>.
            </param>
            <param name="updates">
               A tensor of updated values to add to <c>ref</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceScatterMul'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               This operation computes
               
               # Scalar indices
               ref[indices, ...] *= updates[...]
               
               # Vector indices (for each i)
               ref[indices[i], ...] *= updates[i, ...]
               
               # High rank indices (for each i, ..., j)
               ref[indices[i, ..., j], ...] *= updates[i, ..., j, ...]
               
               Duplicate entries are handled correctly: if multiple <c>indices</c> reference
               the same location, their contributions multiply.
               
               Requires <c>updates.shape = indices.shape + ref.shape[1:]</c> or <c>updates.shape = []</c>.
               
               &amp;lt;div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;"&amp;gt;
               &amp;lt;img style="width:100%" src='https://www.tensorflow.org/images/ScatterAdd.png' alt&amp;gt;
               &amp;lt;/div&amp;gt;
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_scatter_nd_add(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Adds sparse <c>updates</c> to individual values or slices within a given
            </summary>
            <param name="referecne">
               A resource handle. Must be from a VarHandleOp.
            </param>
            <param name="indices">
               A Tensor. Must be one of the following types: int32, int64.
               A tensor of indices into ref.
            </param>
            <param name="updates">
               A Tensor. Must have the same type as ref. A tensor of
               values to add to ref.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceScatterNdAdd'.
            </param>
            <param name="use_locking">
               An optional bool. Defaults to True. If True, the assignment will
               be protected by a lock; otherwise the behavior is undefined,
               but may exhibit less contention.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               variable according to <c>indices</c>.
               
               <c>ref</c> is a <c>Tensor</c> with rank <c>P</c> and <c>indices</c> is a <c>Tensor</c> of rank <c>Q</c>.
               
               <c>indices</c> must be integer tensor, containing indices into <c>ref</c>.
               It must be shape <c>[d_0, ..., d_{Q-2}, K]</c> where <c>0 &amp;lt; K &amp;lt;= P</c>.
               
               The innermost dimension of <c>indices</c> (with length <c>K</c>) corresponds to
               indices into elements (if <c>K = P</c>) or slices (if <c>K &amp;lt; P</c>) along the <c>K</c>th
               dimension of <c>ref</c>.
               
               <c>updates</c> is <c>Tensor</c> of rank <c>Q-1+P-K</c> with shape:
               
              <code>
               [d_0, ..., d_{Q-2}, ref.shape[K], ..., ref.shape[P-1]].
              </code>
               
               For example, say we want to update 4 scattered elements to a rank-1 tensor to
               8 elements. In Python, that update would look like this:
               
              <code>
               ref = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8], use_resource=True)
               indices = tf.constant([[4], [3], [1] ,[7]])
               updates = tf.constant([9, 10, 11, 12])
               update = tf.scatter_nd_add(ref, indices, updates)
               with tf.Session() as sess:
               print sess.run(update)
              </code>
               
               The resulting update to ref would look like this:
               
               [1, 12, 3, 14, 14, 6, 7, 20]
               
               See <c>tf.scatter_nd</c> for more details about how to make updates to
               slices.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_scatter_nd_update(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Applies sparse <c>updates</c> to individual values or slices within a given
            </summary>
            <param name="referecne">
               A resource handle. Must be from a VarHandleOp.
            </param>
            <param name="indices">
               A Tensor. Must be one of the following types: int32, int64.
               A tensor of indices into ref.
            </param>
            <param name="updates">
               A Tensor. Must have the same type as ref. A tensor of updated
               values to add to ref.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceScatterNdUpdate'.
            </param>
            <param name="use_locking">
               An optional bool. Defaults to True. If True, the assignment will
               be protected by a lock; otherwise the behavior is undefined,
               but may exhibit less contention.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               variable according to <c>indices</c>.
               
               <c>ref</c> is a <c>Tensor</c> with rank <c>P</c> and <c>indices</c> is a <c>Tensor</c> of rank <c>Q</c>.
               
               <c>indices</c> must be integer tensor, containing indices into <c>ref</c>.
               It must be shape <c>[d_0, ..., d_{Q-2}, K]</c> where <c>0 &amp;lt; K &amp;lt;= P</c>.
               
               The innermost dimension of <c>indices</c> (with length <c>K</c>) corresponds to
               indices into elements (if <c>K = P</c>) or slices (if <c>K &amp;lt; P</c>) along the <c>K</c>th
               dimension of <c>ref</c>.
               
               <c>updates</c> is <c>Tensor</c> of rank <c>Q-1+P-K</c> with shape:
               
              <code>
               [d_0, ..., d_{Q-2}, ref.shape[K], ..., ref.shape[P-1]].
              </code>
               
               For example, say we want to update 4 scattered elements to a rank-1 tensor to
               8 elements. In Python, that update would look like this:
               
              <code>
               ref = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])
               indices = tf.constant([[4], [3], [1] ,[7]])
               updates = tf.constant([9, 10, 11, 12])
               update = tf.scatter_nd_update(ref, indices, updates)
               with tf.Session() as sess:
               print sess.run(update)
              </code>
               
               The resulting update to ref would look like this:
               
               [1, 11, 3, 10, 9, 6, 7, 12]
               
               See <c>tf.scatter_nd</c> for more details about how to make updates to
               slices.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_scatter_sub(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Subtracts sparse updates from the variable referenced by <c>resource</c>.
            </summary>
            <param name="resource">
               Should be from a <c>Variable</c> node.
            </param>
            <param name="indices">
               A tensor of indices into the first dimension of <c>ref</c>.
            </param>
            <param name="updates">
               A tensor of updated values to add to <c>ref</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceScatterSub'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               This operation computes
               
               # Scalar indices
               ref[indices, ...] -= updates[...]
               
               # Vector indices (for each i)
               ref[indices[i], ...] -= updates[i, ...]
               
               # High rank indices (for each i, ..., j)
               ref[indices[i, ..., j], ...] -= updates[i, ..., j, ...]
               
               Duplicate entries are handled correctly: if multiple <c>indices</c> reference
               the same location, their contributions add.
               
               Requires <c>updates.shape = indices.shape + ref.shape[1:]</c> or <c>updates.shape = []</c>.
               
               &amp;lt;div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;"&amp;gt;
               &amp;lt;img style="width:100%" src='https://www.tensorflow.org/images/ScatterAdd.png' alt&amp;gt;
               &amp;lt;/div&amp;gt;
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_scatter_update(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Assigns sparse updates to the variable referenced by <c>resource</c>.
            </summary>
            <param name="resource">
               Should be from a <c>Variable</c> node.
            </param>
            <param name="indices">
               A tensor of indices into the first dimension of <c>ref</c>.
            </param>
            <param name="updates">
               A tensor of updated values to add to <c>ref</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceScatterUpdate'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               This operation computes
               
               # Scalar indices
               ref[indices, ...] = updates[...]
               
               # Vector indices (for each i)
               ref[indices[i], ...] = updates[i, ...]
               
               # High rank indices (for each i, ..., j)
               ref[indices[i, ..., j], ...] = updates[i, ..., j, ...]
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_sparse_apply_adadelta(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               var: Should be from a Variable().
            </summary>
            <param name="var">
            </param>
            <param name="accum">
               Should be from a Variable().
            </param>
            <param name="accum_update">
               : Should be from a Variable().
            </param>
            <param name="lr">
               Learning rate. Must be a scalar.
            </param>
            <param name="rho">
               Decay factor. Must be a scalar.
            </param>
            <param name="epsilon">
               Constant factor. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="indices">
               A vector of indices into the first dimension of var and accum.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceSparseApplyAdadelta'.
            </param>
            <param name="use_locking">
               If True, updating of the var and accum tensors will be protected by
               a lock; otherwise the behavior is undefined, but may exhibit less contention.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_sparse_apply_adagrad(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.String)">
            <summary>
               Update relevant entries in '*var' and '*accum' according to the adagrad scheme.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="accum">
               Should be from a Variable().
            </param>
            <param name="lr">
               Learning rate. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="indices">
               A vector of indices into the first dimension of var and accum.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceSparseApplyAdagrad'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var and accum tensors will be protected
               by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <param name="update_slots">
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               That is for rows we have grad for, we update var and accum as follows:
               accum += grad * grad
               var -= lr * grad * (1 / sqrt(accum))
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_sparse_apply_adagrad_d_a(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update entries in '*var' and '*accum' according to the proximal adagrad scheme.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="gradient_accumulator">
               Should be from a Variable().
            </param>
            <param name="gradient_squared_accumulator">
               Should be from a Variable().
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="indices">
               A vector of indices into the first dimension of var and accum.
            </param>
            <param name="lr">
               Learning rate. Must be a scalar.
            </param>
            <param name="l1">
               L1 regularization. Must be a scalar.
            </param>
            <param name="l2">
               L2 regularization. Must be a scalar.
            </param>
            <param name="global_step">
               Training step number. Must be a scalar.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceSparseApplyAdagradDA'.
            </param>
            <param name="use_locking">
               If True, updating of the var and accum tensors will be protected by
               a lock; otherwise the behavior is undefined, but may exhibit less contention.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_sparse_apply_centered_r_m_s_prop(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' according to the centered RMSProp algorithm.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="mg">
               Should be from a Variable().
            </param>
            <param name="ms">
               Should be from a Variable().
            </param>
            <param name="mom">
               Should be from a Variable().
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="rho">
               Decay rate. Must be a scalar.
            </param>
            <param name="momentum">
            </param>
            <param name="epsilon">
               Ridge term. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="indices">
               A vector of indices into the first dimension of var, ms and mom.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceSparseApplyCenteredRMSProp'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var, mg, ms, and mom tensors is
               protected by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               The centered RMSProp algorithm uses an estimate of the centered second moment
               (i.e., the variance) for normalization, as opposed to regular RMSProp, which
               uses the (uncentered) second moment. This often helps with training, but is
               slightly more expensive in terms of computation and memory.
               
               Note that in dense implementation of this algorithm, mg, ms, and mom will
               update even if the grad is zero, but in this sparse implementation, mg, ms,
               and mom will not update in iterations during which the grad is zero.
               
               mean_square = decay * mean_square + (1-decay) * gradient ** 2
               mean_grad = decay * mean_grad + (1-decay) * gradient
               Delta = learning_rate * gradient / sqrt(mean_square + epsilon - mean_grad ** 2)
               
               ms &amp;lt;- rho * ms_{t-1} + (1-rho) * grad * grad
               mom &amp;lt;- momentum * mom_{t-1} + lr * grad / sqrt(ms + epsilon)
               var &amp;lt;- var - mom
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_sparse_apply_ftrl(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update relevant entries in '*var' according to the Ftrl-proximal scheme.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="accum">
               Should be from a Variable().
            </param>
            <param name="linear">
               Should be from a Variable().
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="indices">
               A vector of indices into the first dimension of var and accum.
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="l1">
               L1 regularization. Must be a scalar.
            </param>
            <param name="l2">
               L2 regularization. Must be a scalar.
            </param>
            <param name="lr_power">
               Scaling factor. Must be a scalar.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceSparseApplyFtrl'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var and accum tensors will be protected
               by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               That is for rows we have grad for, we update var, accum and linear as follows:
               accum_new = accum + grad * grad
               linear += grad + (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var
               quadratic = 1.0 / (accum_new^(lr_power) * lr) + 2 * l2
               var = (sign(linear) * l1 - linear) / quadratic if |linear| &amp;gt; l1 else 0.0
               accum = accum_new
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_sparse_apply_ftrl_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update relevant entries in '*var' according to the Ftrl-proximal scheme.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="accum">
               Should be from a Variable().
            </param>
            <param name="linear">
               Should be from a Variable().
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="indices">
               A vector of indices into the first dimension of var and accum.
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="l1">
               L1 regularization. Must be a scalar.
            </param>
            <param name="l2">
               L2 shrinkage regulariation. Must be a scalar.
            </param>
            <param name="l2_shrinkage">
            </param>
            <param name="lr_power">
               Scaling factor. Must be a scalar.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceSparseApplyFtrlV2'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var and accum tensors will be protected
               by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               That is for rows we have grad for, we update var, accum and linear as follows:
               grad_with_shrinkage = grad + 2 * l2_shrinkage * var
               accum_new = accum + grad_with_shrinkage * grad_with_shrinkage
               linear += grad_with_shrinkage +
               (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var
               quadratic = 1.0 / (accum_new^(lr_power) * lr) + 2 * l2
               var = (sign(linear) * l1 - linear) / quadratic if |linear| &amp;gt; l1 else 0.0
               accum = accum_new
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_sparse_apply_momentum(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.String)">
            <summary>
               Update relevant entries in '*var' and '*accum' according to the momentum scheme.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="accum">
               Should be from a Variable().
            </param>
            <param name="lr">
               Learning rate. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="indices">
               A vector of indices into the first dimension of var and accum.
            </param>
            <param name="momentum">
               Momentum. Must be a scalar.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceSparseApplyMomentum'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var and accum tensors will be protected
               by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <param name="use_nesterov">
               If <c>True</c>, the tensor passed to compute grad will be
               var - lr * momentum * accum, so in the end, the var you get is actually
               var - lr * momentum * accum.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               Set use_nesterov = True if you want to use Nesterov momentum.
               
               That is for rows we have grad for, we update var and accum as follows:
               
               accum = accum * momentum + grad
               var -= lr * accum
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_sparse_apply_proximal_adagrad(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Sparse update entries in '*var' and '*accum' according to FOBOS algorithm.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="accum">
               Should be from a Variable().
            </param>
            <param name="lr">
               Learning rate. Must be a scalar.
            </param>
            <param name="l1">
               L1 regularization. Must be a scalar.
            </param>
            <param name="l2">
               L2 regularization. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="indices">
               A vector of indices into the first dimension of var and accum.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceSparseApplyProximalAdagrad'.
            </param>
            <param name="use_locking">
               If True, updating of the var and accum tensors will be protected by
               a lock; otherwise the behavior is undefined, but may exhibit less contention.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               That is for rows we have grad for, we update var and accum as follows:
               accum += grad * grad
               prox_v = var
               prox_v -= lr * grad * (1 / sqrt(accum))
               var = sign(prox_v)/(1+lr*l2) * max{|prox_v|-lr*l1,0}
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_sparse_apply_proximal_gradient_descent(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Sparse update '*var' as FOBOS algorithm with fixed learning rate.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="alpha">
               Scaling factor. Must be a scalar.
            </param>
            <param name="l1">
               L1 regularization. Must be a scalar.
            </param>
            <param name="l2">
               L2 regularization. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="indices">
               A vector of indices into the first dimension of var and accum.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceSparseApplyProximalGradientDescent'.
            </param>
            <param name="use_locking">
               If True, the subtraction will be protected by a lock;
               otherwise the behavior is undefined, but may exhibit less contention.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               That is for rows we have grad for, we update var as follows:
               prox_v = var - alpha * grad
               var = sign(prox_v)/(1+alpha*l2) * max{|prox_v|-alpha*l1,0}
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_sparse_apply_r_m_s_prop(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' according to the RMSProp algorithm.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="ms">
               Should be from a Variable().
            </param>
            <param name="mom">
               Should be from a Variable().
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="rho">
               Decay rate. Must be a scalar.
            </param>
            <param name="momentum">
            </param>
            <param name="epsilon">
               Ridge term. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="indices">
               A vector of indices into the first dimension of var, ms and mom.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceSparseApplyRMSProp'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var, ms, and mom tensors is protected
               by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               Note that in dense implementation of this algorithm, ms and mom will
               update even if the grad is zero, but in this sparse implementation, ms
               and mom will not update in iterations during which the grad is zero.
               
               mean_square = decay * mean_square + (1-decay) * gradient ** 2
               Delta = learning_rate * gradient / sqrt(mean_square + epsilon)
               
               ms &amp;lt;- rho * ms_{t-1} + (1-rho) * grad * grad
               mom &amp;lt;- momentum * mom_{t-1} + lr * grad / sqrt(ms + epsilon)
               var &amp;lt;- var - mom
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.resource_strided_slice_assign(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Assign <c>value</c> to the sliced l-value reference of <c>ref</c>.
            </summary>
            <param name="referecne">
            </param>
            <param name="begin">
            </param>
            <param name="end">
            </param>
            <param name="strides">
            </param>
            <param name="value">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ResourceStridedSliceAssign'.
            </param>
            <param name="begin_mask">
            </param>
            <param name="end_mask">
            </param>
            <param name="ellipsis_mask">
            </param>
            <param name="new_axis_mask">
            </param>
            <param name="shrink_axis_mask">
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               The values of <c>value</c> are assigned to the positions in the variable
               <c>ref</c> that are selected by the slice parameters. The slice parameters
               <c>begin</c>, <c>end</c>, <c>strides</c>, etc. work exactly as in <c>StridedSlice</c>.
               
               NOTE this op currently does not support broadcasting and so <c>value</c>'s
               shape must be exactly the shape produced by the slice of <c>ref</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.restore(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType,System.Nullable{System.Int32},System.String)">
            <summary>
               Restores a tensor from checkpoint files.
            </summary>
            <param name="file_pattern">
               Must have a single element. The pattern of the files from
               which we read the tensor.
            </param>
            <param name="tensor_name">
               Must have a single element. The name of the tensor to be
               restored.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Restore'.
            </param>
            <param name="dt">
               Optional argument
               The type of the tensor to be restored.
            </param>
            <param name="preferred_shard">
               Index of file to open first if multiple files match
               <c>file_pattern</c>.
            </param>
            <returns>
               The restored tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Reads a tensor stored in one or several files. If there are several files (for
               instance because a tensor was saved as slices), <c>file_pattern</c> may contain
               wildcard symbols (<c>*</c> and <c>?</c>) in the filename portion only, not in the
               directory portion.
               
               If a <c>file_pattern</c> matches several files, <c>preferred_shard</c> can be used to hint
               in which file the requested tensor is likely to be found. This op will first
               open the file at index <c>preferred_shard</c> in the list of matching files and try
               to restore tensors from that file.  Only if some tensors or tensor slices are
               not found in that first file, then the Op opens all the files. Setting
               <c>preferred_shard</c> to match the value passed as the <c>shard</c> input
               of a matching <c>Save</c> Op may speed up Restore.  This attribute only affects
               performance, not correctness.  The default value -1 means files are processed in
               order.
               
               See also <c>RestoreSlice</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.restore_slice(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType,System.Nullable{System.Int32},System.String)">
            <summary>
               Restores a tensor from checkpoint files.
            </summary>
            <param name="file_pattern">
               Must have a single element. The pattern of the files from
               which we read the tensor.
            </param>
            <param name="tensor_name">
               Must have a single element. The name of the tensor to be
               restored.
            </param>
            <param name="shape_and_slice">
               Scalar. The shapes and slice specifications to use when
               restoring a tensors.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RestoreSlice'.
            </param>
            <param name="dt">
               Optional argument
               The type of the tensor to be restored.
            </param>
            <param name="preferred_shard">
               Index of file to open first if multiple files match
               <c>file_pattern</c>. See the documentation for <c>Restore</c>.
            </param>
            <returns>
               The restored tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This is like <c>Restore</c> except that restored tensor can be listed as filling
               only a slice of a larger tensor.  <c>shape_and_slice</c> specifies the shape of the
               larger tensor and the slice that the restored tensor covers.
               
               The <c>shape_and_slice</c> input has the same format as the
               elements of the <c>shapes_and_slices</c> input of the <c>SaveSlices</c> op.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.restore_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],System.String)">
            <summary>
               Restores tensors from a V2 checkpoint.
            </summary>
            <param name="prefix">
               Must have a single element.  The prefix of a V2 checkpoint.
            </param>
            <param name="tensor_names">
               shape {N}.  The names of the tensors to be restored.
            </param>
            <param name="shape_and_slices">
               shape {N}.  The slice specs of the tensors to be restored.
               Empty strings indicate that they are non-partitioned tensors.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RestoreV2'.
            </param>
            <param name="dtypes">
               Optional argument
               shape {N}.  The list of expected dtype for the tensors.  Must match
               those stored in the checkpoint.
            </param>
            <returns>
               shape {N}.  The restored tensors, whose shapes are read from the
               checkpoint directly.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               For backward compatibility with the V1 format, this Op currently allows
               restoring from a V1 checkpoint as well:
               - This Op first attempts to find the V2 index file pointed to by "prefix", and
               if found proceed to read it as a V2 checkpoint;
               - Otherwise the V1 read path is invoked.
               Relying on this behavior is not recommended, as the ability to fall back to read
               V1 might be deprecated and eventually removed.
               
               By default, restores the named tensors in full.  If the caller wishes to restore
               specific slices of stored tensors, "shape_and_slices" should be non-empty
               strings and correspondingly well-formed.
               
               Callers must ensure all the named tensors are indeed stored in the checkpoint.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.reverse(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Reverses specific dimensions of a tensor.
            </summary>
            <param name="tensor">
               Up to 8-D.
            </param>
            <param name="dims">
               1-D. The dimensions to reverse.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Reverse'.
            </param>
            <returns>
               The same shape as <c>tensor</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Given a <c>tensor</c>, and a <c>bool</c> tensor <c>dims</c> representing the dimensions
               of <c>tensor</c>, this operation reverses each dimension i of <c>tensor</c> where
               <c>dims[i]</c> is <c>True</c>.
               
               <c>tensor</c> can have up to 8 dimensions. The number of dimensions
               of <c>tensor</c> must equal the number of elements in <c>dims</c>. In other words:
               
               <c>rank(tensor) = size(dims)</c>
               
               For example:
               
              <code>
               # tensor 't' is [[[[ 0,  1,  2,  3],
               #                  [ 4,  5,  6,  7],
               #                  [ 8,  9, 10, 11]],
               #                 [[12, 13, 14, 15],
               #                  [16, 17, 18, 19],
               #                  [20, 21, 22, 23]]]]
               # tensor 't' shape is [1, 2, 3, 4]
               
               # 'dims' is [False, False, False, True]
               reverse(t, dims) ==&amp;gt; [[[[ 3,  2,  1,  0],
               [ 7,  6,  5,  4],
               [ 11, 10, 9, 8]],
               [[15, 14, 13, 12],
               [19, 18, 17, 16],
               [23, 22, 21, 20]]]]
               
               # 'dims' is [False, True, False, False]
               reverse(t, dims) ==&amp;gt; [[[[12, 13, 14, 15],
               [16, 17, 18, 19],
               [20, 21, 22, 23]
               [[ 0,  1,  2,  3],
               [ 4,  5,  6,  7],
               [ 8,  9, 10, 11]]]]
               
               # 'dims' is [False, False, True, False]
               reverse(t, dims) ==&amp;gt; [[[[8, 9, 10, 11],
               [4, 5, 6, 7],
               [0, 1, 2, 3]]
               [[20, 21, 22, 23],
               [16, 17, 18, 19],
               [12, 13, 14, 15]]]]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.reverse_sequence(Tensorflow.Tensor,Tensorflow.Tensor,System.Int32,System.Nullable{System.Int32},System.String)">
            <summary>
               Reverses variable length slices.
            </summary>
            <param name="input">
               The input to reverse.
            </param>
            <param name="seq_lengths">
               1-D with length <c>input.dims(batch_dim)</c> and
               <c>max(seq_lengths) &amp;lt;= input.dims(seq_dim)</c>
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ReverseSequence'.
            </param>
            <param name="seq_dim">
               Optional argument
               The dimension which is partially reversed.
            </param>
            <param name="batch_dim">
               The dimension along which reversal is performed.
            </param>
            <returns>
               The partially reversed input. It has the same shape as <c>input</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This op first slices <c>input</c> along the dimension <c>batch_dim</c>, and for each
               slice <c>i</c>, reverses the first <c>seq_lengths[i]</c> elements along
               the dimension <c>seq_dim</c>.
               
               The elements of <c>seq_lengths</c> must obey <c>seq_lengths[i] &amp;lt;= input.dims[seq_dim]</c>,
               and <c>seq_lengths</c> must be a vector of length <c>input.dims[batch_dim]</c>.
               
               The output slice <c>i</c> along dimension <c>batch_dim</c> is then given by input
               slice <c>i</c>, with the first <c>seq_lengths[i]</c> slices along dimension
               <c>seq_dim</c> reversed.
               
               For example:
               
              <code>
               # Given this:
               batch_dim = 0
               seq_dim = 1
               input.dims = (4, 8, ...)
               seq_lengths = [7, 2, 3, 5]
               
               # then slices of input are reversed on seq_dim, but only up to seq_lengths:
               output[0, 0:7, :, ...] = input[0, 7:0:-1, :, ...]
               output[1, 0:2, :, ...] = input[1, 2:0:-1, :, ...]
               output[2, 0:3, :, ...] = input[2, 3:0:-1, :, ...]
               output[3, 0:5, :, ...] = input[3, 5:0:-1, :, ...]
               
               # while entries past seq_lens are copied through:
               output[0, 7:, :, ...] = input[0, 7:, :, ...]
               output[1, 2:, :, ...] = input[1, 2:, :, ...]
               output[2, 3:, :, ...] = input[2, 3:, :, ...]
               output[3, 2:, :, ...] = input[3, 2:, :, ...]
              </code>
               
               In contrast, if:
               
              <code>
               # Given this:
               batch_dim = 2
               seq_dim = 0
               input.dims = (8, ?, 4, ...)
               seq_lengths = [7, 2, 3, 5]
               
               # then slices of input are reversed on seq_dim, but only up to seq_lengths:
               output[0:7, :, 0, :, ...] = input[7:0:-1, :, 0, :, ...]
               output[0:2, :, 1, :, ...] = input[2:0:-1, :, 1, :, ...]
               output[0:3, :, 2, :, ...] = input[3:0:-1, :, 2, :, ...]
               output[0:5, :, 3, :, ...] = input[5:0:-1, :, 3, :, ...]
               
               # while entries past seq_lens are copied through:
               output[7:, :, 0, :, ...] = input[7:, :, 0, :, ...]
               output[2:, :, 1, :, ...] = input[2:, :, 1, :, ...]
               output[3:, :, 2, :, ...] = input[3:, :, 2, :, ...]
               output[2:, :, 3, :, ...] = input[2:, :, 3, :, ...]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.reverse_v2(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Reverses specific dimensions of a tensor.
            </summary>
            <param name="tensor">
               Up to 8-D.
            </param>
            <param name="axis">
               1-D. The indices of the dimensions to reverse. Must be in the range
               <c>[-rank(tensor), rank(tensor))</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ReverseV2'.
            </param>
            <returns>
               The same shape as <c>tensor</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               NOTE <c>tf.reverse</c> has now changed behavior in preparation for 1.0.
               <c>tf.reverse_v2</c> is currently an alias that will be deprecated before TF 1.0.
               
               Given a <c>tensor</c>, and a <c>int32</c> tensor <c>axis</c> representing the set of
               dimensions of <c>tensor</c> to reverse. This operation reverses each dimension
               <c>i</c> for which there exists <c>j</c> s.t. <c>axis[j] == i</c>.
               
               <c>tensor</c> can have up to 8 dimensions. The number of dimensions specified
               in <c>axis</c> may be 0 or more entries. If an index is specified more than
               once, a InvalidArgument error is raised.
               
               For example:
               
              <code>
               # tensor 't' is [[[[ 0,  1,  2,  3],
               #                  [ 4,  5,  6,  7],
               #                  [ 8,  9, 10, 11]],
               #                 [[12, 13, 14, 15],
               #                  [16, 17, 18, 19],
               #                  [20, 21, 22, 23]]]]
               # tensor 't' shape is [1, 2, 3, 4]
               
               # 'dims' is [3] or 'dims' is [-1]
               reverse(t, dims) ==&amp;gt; [[[[ 3,  2,  1,  0],
               [ 7,  6,  5,  4],
               [ 11, 10, 9, 8]],
               [[15, 14, 13, 12],
               [19, 18, 17, 16],
               [23, 22, 21, 20]]]]
               
               # 'dims' is '[1]' (or 'dims' is '[-3]')
               reverse(t, dims) ==&amp;gt; [[[[12, 13, 14, 15],
               [16, 17, 18, 19],
               [20, 21, 22, 23]
               [[ 0,  1,  2,  3],
               [ 4,  5,  6,  7],
               [ 8,  9, 10, 11]]]]
               
               # 'dims' is '[2]' (or 'dims' is '[-2]')
               reverse(t, dims) ==&amp;gt; [[[[8, 9, 10, 11],
               [4, 5, 6, 7],
               [0, 1, 2, 3]]
               [[20, 21, 22, 23],
               [16, 17, 18, 19],
               [12, 13, 14, 15]]]]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.right_shift(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Elementwise computes the bitwise right-shift of <c>x</c> and <c>y</c>.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RightShift'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Performs a logical shift for unsigned integer types, and an arithmetic shift
               for signed integer types.
               
               If <c>y</c> is negative, or greater than or equal to than the width of <c>x</c> in bits
               the result is implementation defined.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.rint(Tensorflow.Tensor,System.String)">
            <summary>
               Returns element-wise integer closest to x.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Rint'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               If the result is midway between two representable values,
               the even representable is chosen.
               For example:
               
              <code>
               rint(-1.5) ==&amp;gt; -2.0
               rint(0.5000001) ==&amp;gt; 1.0
               rint([-1.7, -1.5, -0.2, 0.2, 1.5, 1.7, 2.0]) ==&amp;gt; [-2., -2., -0., 0., 2., 2., 2.]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.roll(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Rolls the elements of a tensor along an axis.
            </summary>
            <param name="input">
            </param>
            <param name="shift">
               Dimension must be 0-D or 1-D. <c>shift[i]</c> specifies the number of places by which
               elements are shifted positively (towards larger indices) along the dimension
               specified by <c>axis[i]</c>. Negative shifts will roll the elements in the opposite
               direction.
            </param>
            <param name="axis">
               Dimension must be 0-D or 1-D. <c>axis[i]</c> specifies the dimension that the shift
               <c>shift[i]</c> should occur. If the same axis is referenced more than once, the
               total shift for that axis will be the sum of all the shifts that belong to that
               axis.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Roll'.
            </param>
            <returns>
               Has the same shape and size as the input. The elements are shifted
               positively (towards larger indices) by the offsets of <c>shift</c> along the
               dimensions of <c>axis</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The elements are shifted positively (towards larger indices) by the offset of
               <c>shift</c> along the dimension of <c>axis</c>. Negative <c>shift</c> values will shift
               elements in the opposite direction. Elements that roll passed the last position
               will wrap around to the first and vice versa. Multiple shifts along multiple
               axes may be specified.
               
               For example:
               
              <code>
               # 't' is [0, 1, 2, 3, 4]
               roll(t, shift=2, axis=0) ==&amp;gt; [3, 4, 0, 1, 2]
               
               # shifting along multiple dimensions
               # 't' is [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]
               roll(t, shift=[1, -2], axis=[0, 1]) ==&amp;gt; [[7, 8, 9, 5, 6], [2, 3, 4, 0, 1]]
               
               # shifting along the same axis multiple times
               # 't' is [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]
               roll(t, shift=[2, -3], axis=[1, 1]) ==&amp;gt; [[1, 2, 3, 4, 0], [6, 7, 8, 9, 5]]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.round(Tensorflow.Tensor,System.String)">
            <summary>
               Rounds the values of a tensor to the nearest integer, element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Round'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Rounds half to even.  Also known as bankers rounding. If you want to round
               according to the current system rounding mode use std::cint.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.rpc(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.Nullable{System.Boolean},System.Nullable{System.Int32},System.String)">
            <summary>
               Perform batches of RPC requests.
            </summary>
            <param name="address">
               <c>0-D</c> or <c>1-D</c>.  The address (i.e. host_name:port) of the RPC server.
               If this tensor has more than 1 element, then multiple parallel rpc requests
               are sent.  This argument broadcasts with <c>method</c> and <c>request</c>.
            </param>
            <param name="method">
               <c>0-D</c> or <c>1-D</c>.  The method address on the RPC server.
               If this tensor has more than 1 element, then multiple parallel rpc requests
               are sent.  This argument broadcasts with <c>address</c> and <c>request</c>.
            </param>
            <param name="request">
               <c>0-D</c> or <c>1-D</c>.  Serialized proto strings: the rpc request argument.
               If this tensor has more than 1 element, then multiple parallel rpc requests
               are sent.  This argument broadcasts with <c>address</c> and <c>method</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Rpc'.
            </param>
            <param name="protocol">
               RPC protocol to use.  Empty string means use the default protocol.
               Options include 'grpc'.
            </param>
            <param name="fail_fast">
               <c>boolean</c>. If <c>true</c> (default), then failures to connect
               (i.e., the server does not immediately respond) cause an RPC failure.
            </param>
            <param name="timeout_in_ms">
               <c>int</c>. If <c>0</c> (default), then the kernel will run the RPC
               request and only time out if the RPC deadline passes or the session times out.
               If this value is greater than <c>0</c>, then the op will raise an exception if
               the RPC takes longer than <c>timeout_in_ms</c>.
            </param>
            <returns>
               Same shape as <c>request</c>. Serialized proto strings: the rpc responses.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This op asynchronously performs either a single RPC request, or a batch
               of requests.  RPC requests are defined by three main parameters:
               
               - <c>address</c> (the host+port or BNS address of the request)
               - <c>method</c> (the RPC method name for the request)
               - <c>request</c> (the serialized proto string, or vector of strings,
               of the RPC request argument).
               
               For example, if you have an RPC service running on port localhost:2345,
               and its interface is configured with the following proto declaration:
               
              <code>
               service MyService {
               rpc MyMethod(MyRequestProto) returns (MyResponseProto) {
               }
               };
              </code>
               
               then call this op with arguments:
               
              <code>
               address = "localhost:2345"
               method = "MyService/MyMethod"
              </code>
               
               The <c>request</c> tensor is a string tensor representing serialized <c>MyRequestProto</c>
               strings; and the output string tensor <c>response</c> will have the same shape
               and contain (upon successful completion) corresponding serialized
               <c>MyResponseProto</c> strings.
               
               For example, to send a single, empty, <c>MyRequestProto</c>, call
               this op with <c>request = ""</c>.  To send 5 **parallel** empty requests,
               call this op with <c>request = ["", "", "", "", ""]</c>.
               
               More generally, one can create a batch of <c>MyRequestProto</c> serialized protos
               from regular batched tensors using the <c>encode_proto</c> op, and convert
               the response <c>MyResponseProto</c> serialized protos to batched tensors
               using the <c>decode_proto</c> op.
               
               **NOTE** Working with serialized proto strings is faster than instantiating
               actual proto objects in memory, so no performance degradation is expected
               compared to writing custom kernels for this workflow.
               
               If the connection fails or the remote worker returns an error
               status, the op reraises this exception locally.
               
               See the <c>TryRpc</c> op if you prefer to handle RPC failures manually in the graph.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.rsqrt(Tensorflow.Tensor,System.String)">
            <summary>
               Computes reciprocal of square root of x element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Rsqrt'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               I.e., \\(y = 1 / \sqrt{x}\\).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.rsqrt_grad(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes the gradient for the rsqrt of <c>x</c> wrt its input.
            </summary>
            <param name="y">
            </param>
            <param name="dy">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'RsqrtGrad'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Specifically, <c>grad = dy * -0.5 * y^3</c>, where <c>y = rsqrt(x)</c>, and <c>dy</c>
               is the corresponding input gradient.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sample_distorted_bounding_box(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Single},System.Single[],System.Single[],System.Nullable{System.Int32},System.Nullable{System.Boolean},System.String)">
            <summary>
               Generate a single randomly distorted bounding box for an image.
            </summary>
            <param name="image_size">
               1-D, containing <c>[height, width, channels]</c>.
            </param>
            <param name="bounding_boxes">
               3-D with shape <c>[batch, N, 4]</c> describing the N bounding boxes
               associated with the image.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SampleDistortedBoundingBox'.
            </param>
            <param name="seed">
               If either <c>seed</c> or <c>seed2</c> are set to non-zero, the random number
               generator is seeded by the given <c>seed</c>.  Otherwise, it is seeded by a random
               seed.
            </param>
            <param name="seed2">
               A second seed to avoid seed collision.
            </param>
            <param name="min_object_covered">
               The cropped area of the image must contain at least this
               fraction of any bounding box supplied. The value of this parameter should be
               non-negative. In the case of 0, the cropped area does not need to overlap
               any of the bounding boxes supplied.
            </param>
            <param name="aspect_ratio_range">
               The cropped area of the image must have an aspect ratio =
               width / height within this range.
            </param>
            <param name="area_range">
               The cropped area of the image must contain a fraction of the
               supplied image within this range.
            </param>
            <param name="max_attempts">
               Number of attempts at generating a cropped region of the image
               of the specified constraints. After <c>max_attempts</c> failures, return the entire
               image.
            </param>
            <param name="use_image_if_no_bounding_boxes">
               Controls behavior if no bounding boxes supplied.
               If true, assume an implicit bounding box covering the whole input. If false,
               raise an error.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               begin : 1-D, containing <c>[offset_height, offset_width, 0]</c>. Provide as input to
               <c>tf.slice</c>.
               size : 1-D, containing <c>[target_height, target_width, -1]</c>. Provide as input to
               <c>tf.slice</c>.
               bboxes : 3-D with shape <c>[1, 1, 4]</c> containing the distorted bounding box.
               Provide as input to <c>tf.image.draw_bounding_boxes</c>.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Bounding box annotations are often supplied in addition to ground-truth labels
               in image recognition or object localization tasks. A common technique for
               training such a system is to randomly distort an image while preserving
               its content, i.e. *data augmentation*. This Op outputs a randomly distorted
               localization of an object, i.e. bounding box, given an <c>image_size</c>,
               <c>bounding_boxes</c> and a series of constraints.
               
               The output of this Op is a single bounding box that may be used to crop the
               original image. The output is returned as 3 tensors: <c>begin</c>, <c>size</c> and
               <c>bboxes</c>. The first 2 tensors can be fed directly into <c>tf.slice</c> to crop the
               image. The latter may be supplied to <c>tf.image.draw_bounding_boxes</c> to visualize
               what the bounding box looks like.
               
               Bounding boxes are supplied and returned as <c>[y_min, x_min, y_max, x_max]</c>. The
               bounding box coordinates are floats in <c>[0.0, 1.0]</c> relative to the width and
               height of the underlying image.
               
               For example,
               
              <code>
               # Generate a single distorted bounding box.
               begin, size, bbox_for_draw = tf.image.sample_distorted_bounding_box(
               tf.shape(image),
               bounding_boxes=bounding_boxes)
               
               # Draw the bounding box in an image summary.
               image_with_box = tf.image.draw_bounding_boxes(tf.expand_dims(image, 0),
               bbox_for_draw)
               tf.summary.image('images_with_box', image_with_box)
               
               # Employ the bounding box to distort the image.
               distorted_image = tf.slice(image, begin, size)
              </code>
               
               Note that if no bounding box information is available, setting
               <c>use_image_if_no_bounding_boxes = true</c> will assume there is a single implicit
               bounding box covering the whole image. If <c>use_image_if_no_bounding_boxes</c> is
               false and no bounding boxes are supplied, an error is raised.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sample_distorted_bounding_box_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Int32},System.Nullable{System.Int32},System.Single[],System.Single[],System.Nullable{System.Int32},System.Nullable{System.Boolean},System.String)">
            <summary>
               Generate a single randomly distorted bounding box for an image.
            </summary>
            <param name="image_size">
               1-D, containing <c>[height, width, channels]</c>.
            </param>
            <param name="bounding_boxes">
               3-D with shape <c>[batch, N, 4]</c> describing the N bounding boxes
               associated with the image.
            </param>
            <param name="min_object_covered">
               The cropped area of the image must contain at least this
               fraction of any bounding box supplied. The value of this parameter should be
               non-negative. In the case of 0, the cropped area does not need to overlap
               any of the bounding boxes supplied.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SampleDistortedBoundingBoxV2'.
            </param>
            <param name="seed">
               If either <c>seed</c> or <c>seed2</c> are set to non-zero, the random number
               generator is seeded by the given <c>seed</c>.  Otherwise, it is seeded by a random
               seed.
            </param>
            <param name="seed2">
               A second seed to avoid seed collision.
            </param>
            <param name="aspect_ratio_range">
               The cropped area of the image must have an aspect ratio =
               width / height within this range.
            </param>
            <param name="area_range">
               The cropped area of the image must contain a fraction of the
               supplied image within this range.
            </param>
            <param name="max_attempts">
               Number of attempts at generating a cropped region of the image
               of the specified constraints. After <c>max_attempts</c> failures, return the entire
               image.
            </param>
            <param name="use_image_if_no_bounding_boxes">
               Controls behavior if no bounding boxes supplied.
               If true, assume an implicit bounding box covering the whole input. If false,
               raise an error.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               begin : 1-D, containing <c>[offset_height, offset_width, 0]</c>. Provide as input to
               <c>tf.slice</c>.
               size : 1-D, containing <c>[target_height, target_width, -1]</c>. Provide as input to
               <c>tf.slice</c>.
               bboxes : 3-D with shape <c>[1, 1, 4]</c> containing the distorted bounding box.
               Provide as input to <c>tf.image.draw_bounding_boxes</c>.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Bounding box annotations are often supplied in addition to ground-truth labels
               in image recognition or object localization tasks. A common technique for
               training such a system is to randomly distort an image while preserving
               its content, i.e. *data augmentation*. This Op outputs a randomly distorted
               localization of an object, i.e. bounding box, given an <c>image_size</c>,
               <c>bounding_boxes</c> and a series of constraints.
               
               The output of this Op is a single bounding box that may be used to crop the
               original image. The output is returned as 3 tensors: <c>begin</c>, <c>size</c> and
               <c>bboxes</c>. The first 2 tensors can be fed directly into <c>tf.slice</c> to crop the
               image. The latter may be supplied to <c>tf.image.draw_bounding_boxes</c> to visualize
               what the bounding box looks like.
               
               Bounding boxes are supplied and returned as <c>[y_min, x_min, y_max, x_max]</c>. The
               bounding box coordinates are floats in <c>[0.0, 1.0]</c> relative to the width and
               height of the underlying image.
               
               For example,
               
              <code>
               # Generate a single distorted bounding box.
               begin, size, bbox_for_draw = tf.image.sample_distorted_bounding_box(
               tf.shape(image),
               bounding_boxes=bounding_boxes)
               
               # Draw the bounding box in an image summary.
               image_with_box = tf.image.draw_bounding_boxes(tf.expand_dims(image, 0),
               bbox_for_draw)
               tf.summary.image('images_with_box', image_with_box)
               
               # Employ the bounding box to distort the image.
               distorted_image = tf.slice(image, begin, size)
              </code>
               
               Note that if no bounding box information is available, setting
               <c>use_image_if_no_bounding_boxes = true</c> will assume there is a single implicit
               bounding box covering the whole image. If <c>use_image_if_no_bounding_boxes</c> is
               false and no bounding boxes are supplied, an error is raised.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.save(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor[],System.String)">
            <summary>
               Saves the input tensors to disk.
            </summary>
            <param name="filename">
               Must have a single element. The name of the file to which we write
               the tensor.
            </param>
            <param name="tensor_names">
               Shape <c>[N]</c>. The names of the tensors to be saved.
            </param>
            <param name="data">
               <c>N</c> tensors to save.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Save'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               The size of <c>tensor_names</c> must match the number of tensors in <c>data</c>. <c>data[i]</c>
               is written to <c>filename</c> with name <c>tensor_names[i]</c>.
               
               See also <c>SaveSlices</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.save_slices(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor[],System.String)">
            <summary>
               Saves input tensors slices to disk.
            </summary>
            <param name="filename">
               Must have a single element. The name of the file to which we write the
               tensor.
            </param>
            <param name="tensor_names">
               Shape <c>[N]</c>. The names of the tensors to be saved.
            </param>
            <param name="shapes_and_slices">
               Shape <c>[N]</c>.  The shapes and slice specifications to use when
               saving the tensors.
            </param>
            <param name="data">
               <c>N</c> tensors to save.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SaveSlices'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               This is like <c>Save</c> except that tensors can be listed in the saved file as being
               a slice of a larger tensor.  <c>shapes_and_slices</c> specifies the shape of the
               larger tensor and the slice that this tensor covers. <c>shapes_and_slices</c> must
               have as many elements as <c>tensor_names</c>.
               
               Elements of the <c>shapes_and_slices</c> input must either be:
               
               *  The empty string, in which case the corresponding tensor is
               saved normally.
               *  A string of the form <c>dim0 dim1 ... dimN-1 slice-spec</c> where the
               <c>dimI</c> are the dimensions of the larger tensor and <c>slice-spec</c>
               specifies what part is covered by the tensor to save.
               
               <c>slice-spec</c> itself is a <c>:</c>-separated list: <c>slice0:slice1:...:sliceN-1</c>
               where each <c>sliceI</c> is either:
               
               *  The string <c>-</c> meaning that the slice covers all indices of this dimension
               *  <c>start,length</c> where <c>start</c> and <c>length</c> are integers.  In that
               case the slice covers <c>length</c> indices starting at <c>start</c>.
               
               See also <c>Save</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.save_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor[],System.String)">
            <summary>
               Saves tensors in V2 checkpoint format.
            </summary>
            <param name="prefix">
               Must have a single element. The prefix of the V2 checkpoint to which we
               write the tensors.
            </param>
            <param name="tensor_names">
               shape {N}. The names of the tensors to be saved.
            </param>
            <param name="shape_and_slices">
               shape {N}.  The slice specs of the tensors to be saved.
               Empty strings indicate that they are non-partitioned tensors.
            </param>
            <param name="tensors">
               <c>N</c> tensors to save.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SaveV2'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               By default, saves the named tensors in full.  If the caller wishes to save
               specific slices of full tensors, "shape_and_slices" should be non-empty strings
               and correspondingly well-formed.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.scalar_summary(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Outputs a <c>Summary</c> protocol buffer with scalar values.
            </summary>
            <param name="tags">
               Tags for the summary.
            </param>
            <param name="values">
               Same shape as <c>tags</c>.  Values for the summary.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ScalarSummary'.
            </param>
            <returns>
               Scalar.  Serialized <c>Summary</c> protocol buffer.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The input <c>tags</c> and <c>values</c> must have the same shape.  The generated summary
               has a summary value for each tag-value pair in <c>tags</c> and <c>values</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.scatter_add(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Adds sparse updates to a variable reference.
            </summary>
            <param name="referecne">
               Should be from a <c>Variable</c> node.
            </param>
            <param name="indices">
               A tensor of indices into the first dimension of <c>ref</c>.
            </param>
            <param name="updates">
               A tensor of updated values to add to <c>ref</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ScatterAdd'.
            </param>
            <param name="use_locking">
               If True, the addition will be protected by a lock;
               otherwise the behavior is undefined, but may exhibit less contention.
            </param>
            <returns>
               = Same as <c>ref</c>.  Returned as a convenience for operations that want
               to use the updated values after the update is done.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation computes
               
               # Scalar indices
               ref[indices, ...] += updates[...]
               
               # Vector indices (for each i)
               ref[indices[i], ...] += updates[i, ...]
               
               # High rank indices (for each i, ..., j)
               ref[indices[i, ..., j], ...] += updates[i, ..., j, ...]
               
               This operation outputs <c>ref</c> after the update is done.
               This makes it easier to chain operations that need to use the reset value.
               
               Duplicate entries are handled correctly: if multiple <c>indices</c> reference
               the same location, their contributions add.
               
               Requires <c>updates.shape = indices.shape + ref.shape[1:]</c> or <c>updates.shape = []</c>.
               
               &amp;lt;div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;"&amp;gt;
               &amp;lt;img style="width:100%" src="https://www.tensorflow.org/images/ScatterAdd.png" alt&amp;gt;
               &amp;lt;/div&amp;gt;
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.scatter_div(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Divides a variable reference by sparse updates.
            </summary>
            <param name="referecne">
               Should be from a <c>Variable</c> node.
            </param>
            <param name="indices">
               A tensor of indices into the first dimension of <c>ref</c>.
            </param>
            <param name="updates">
               A tensor of values that <c>ref</c> is divided by.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ScatterDiv'.
            </param>
            <param name="use_locking">
               If True, the operation will be protected by a lock;
               otherwise the behavior is undefined, but may exhibit less contention.
            </param>
            <returns>
               = Same as <c>ref</c>.  Returned as a convenience for operations that want
               to use the updated values after the update is done.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation computes
               
              <code>
               # Scalar indices
               ref[indices, ...] /= updates[...]
               
               # Vector indices (for each i)
               ref[indices[i], ...] /= updates[i, ...]
               
               # High rank indices (for each i, ..., j)
               ref[indices[i, ..., j], ...] /= updates[i, ..., j, ...]
              </code>
               
               This operation outputs <c>ref</c> after the update is done.
               This makes it easier to chain operations that need to use the reset value.
               
               Duplicate entries are handled correctly: if multiple <c>indices</c> reference
               the same location, their contributions divide.
               
               Requires <c>updates.shape = indices.shape + ref.shape[1:]</c> or <c>updates.shape = []</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.scatter_max(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Reduces sparse updates into a variable reference using the <c>max</c> operation.
            </summary>
            <param name="referecne">
               Should be from a <c>Variable</c> node.
            </param>
            <param name="indices">
               A tensor of indices into the first dimension of <c>ref</c>.
            </param>
            <param name="updates">
               A tensor of updated values to reduce into <c>ref</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ScatterMax'.
            </param>
            <param name="use_locking">
               If True, the update will be protected by a lock;
               otherwise the behavior is undefined, but may exhibit less contention.
            </param>
            <returns>
               = Same as <c>ref</c>.  Returned as a convenience for operations that want
               to use the updated values after the update is done.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation computes
               
               # Scalar indices
               ref[indices, ...] = max(ref[indices, ...], updates[...])
               
               # Vector indices (for each i)
               ref[indices[i], ...] = max(ref[indices[i], ...], updates[i, ...])
               
               # High rank indices (for each i, ..., j)
               ref[indices[i, ..., j], ...] = max(ref[indices[i, ..., j], ...], updates[i, ..., j, ...])
               
               This operation outputs <c>ref</c> after the update is done.
               This makes it easier to chain operations that need to use the reset value.
               
               Duplicate entries are handled correctly: if multiple <c>indices</c> reference
               the same location, their contributions combine.
               
               Requires <c>updates.shape = indices.shape + ref.shape[1:]</c> or <c>updates.shape = []</c>.
               
               &amp;lt;div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;"&amp;gt;
               &amp;lt;img style="width:100%" src="https://www.tensorflow.org/images/ScatterAdd.png" alt&amp;gt;
               &amp;lt;/div&amp;gt;
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.scatter_min(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Reduces sparse updates into a variable reference using the <c>min</c> operation.
            </summary>
            <param name="referecne">
               Should be from a <c>Variable</c> node.
            </param>
            <param name="indices">
               A tensor of indices into the first dimension of <c>ref</c>.
            </param>
            <param name="updates">
               A tensor of updated values to reduce into <c>ref</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ScatterMin'.
            </param>
            <param name="use_locking">
               If True, the update will be protected by a lock;
               otherwise the behavior is undefined, but may exhibit less contention.
            </param>
            <returns>
               = Same as <c>ref</c>.  Returned as a convenience for operations that want
               to use the updated values after the update is done.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation computes
               
               # Scalar indices
               ref[indices, ...] = min(ref[indices, ...], updates[...])
               
               # Vector indices (for each i)
               ref[indices[i], ...] = min(ref[indices[i], ...], updates[i, ...])
               
               # High rank indices (for each i, ..., j)
               ref[indices[i, ..., j], ...] = min(ref[indices[i, ..., j], ...], updates[i, ..., j, ...])
               
               This operation outputs <c>ref</c> after the update is done.
               This makes it easier to chain operations that need to use the reset value.
               
               Duplicate entries are handled correctly: if multiple <c>indices</c> reference
               the same location, their contributions combine.
               
               Requires <c>updates.shape = indices.shape + ref.shape[1:]</c> or <c>updates.shape = []</c>.
               
               &amp;lt;div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;"&amp;gt;
               &amp;lt;img style="width:100%" src="https://www.tensorflow.org/images/ScatterAdd.png" alt&amp;gt;
               &amp;lt;/div&amp;gt;
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.scatter_mul(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Multiplies sparse updates into a variable reference.
            </summary>
            <param name="referecne">
               Should be from a <c>Variable</c> node.
            </param>
            <param name="indices">
               A tensor of indices into the first dimension of <c>ref</c>.
            </param>
            <param name="updates">
               A tensor of updated values to multiply to <c>ref</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ScatterMul'.
            </param>
            <param name="use_locking">
               If True, the operation will be protected by a lock;
               otherwise the behavior is undefined, but may exhibit less contention.
            </param>
            <returns>
               = Same as <c>ref</c>.  Returned as a convenience for operations that want
               to use the updated values after the update is done.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation computes
               
              <code>
               # Scalar indices
               ref[indices, ...] *= updates[...]
               
               # Vector indices (for each i)
               ref[indices[i], ...] *= updates[i, ...]
               
               # High rank indices (for each i, ..., j)
               ref[indices[i, ..., j], ...] *= updates[i, ..., j, ...]
              </code>
               
               This operation outputs <c>ref</c> after the update is done.
               This makes it easier to chain operations that need to use the reset value.
               
               Duplicate entries are handled correctly: if multiple <c>indices</c> reference
               the same location, their contributions multiply.
               
               Requires <c>updates.shape = indices.shape + ref.shape[1:]</c> or <c>updates.shape = []</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.scatter_nd(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Scatter <c>updates</c> into a new tensor according to <c>indices</c>.
            </summary>
            <param name="indices">
               Index tensor.
            </param>
            <param name="updates">
               Updates to scatter into output.
            </param>
            <param name="shape">
               1-D. The shape of the resulting tensor.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ScatterNd'.
            </param>
            <returns>
               A new tensor with the given shape and updates applied according
               to the indices.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Creates a new tensor by applying sparse <c>updates</c> to individual values or
               slices within a tensor (initially zero for numeric, empty for string) of
               the given <c>shape</c> according to indices.  This operator is the inverse of the
               <c>tf.gather_nd</c> operator which extracts values or slices from a given tensor.
               
               If <c>indices</c> contains duplicates, then their updates are accumulated (summed).
               
               **WARNING**: The order in which updates are applied is nondeterministic, so the
               output will be nondeterministic if <c>indices</c> contains duplicates -- because
               of some numerical approximation issues, numbers summed in different order
               may yield different results.
               
               <c>indices</c> is an integer tensor containing indices into a new tensor of shape
               <c>shape</c>.  The last dimension of <c>indices</c> can be at most the rank of <c>shape</c>:
               
               indices.shape[-1] &amp;lt;= shape.rank
               
               The last dimension of <c>indices</c> corresponds to indices into elements
               (if <c>indices.shape[-1] = shape.rank</c>) or slices
               (if <c>indices.shape[-1] &amp;lt; shape.rank</c>) along dimension <c>indices.shape[-1]</c> of
               <c>shape</c>.  <c>updates</c> is a tensor with shape
               
               indices.shape[:-1] + shape[indices.shape[-1]:]
               
               The simplest form of scatter is to insert individual elements in a tensor by
               index. For example, say we want to insert 4 scattered elements in a rank-1
               tensor with 8 elements.
               
               &amp;lt;div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;"&amp;gt;
               &amp;lt;img style="width:100%" src="https://www.tensorflow.org/images/ScatterNd1.png" alt&amp;gt;
               &amp;lt;/div&amp;gt;
               
               In Python, this scatter operation would look like this:
               
              <code>
               indices = tf.constant([[4], [3], [1], [7]])
               updates = tf.constant([9, 10, 11, 12])
               shape = tf.constant([8])
               scatter = tf.scatter_nd(indices, updates, shape)
               with tf.Session() as sess:
               print(sess.run(scatter))
              </code>
               
               The resulting tensor would look like this:
               
               [0, 11, 0, 10, 9, 0, 0, 12]
               
               We can also, insert entire slices of a higher rank tensor all at once. For
               example, if we wanted to insert two slices in the first dimension of a
               rank-3 tensor with two matrices of new values.
               
               &amp;lt;div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;"&amp;gt;
               &amp;lt;img style="width:100%" src="https://www.tensorflow.org/images/ScatterNd2.png" alt&amp;gt;
               &amp;lt;/div&amp;gt;
               
               In Python, this scatter operation would look like this:
               
              <code>
               indices = tf.constant([[0], [2]])
               updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],
               [7, 7, 7, 7], [8, 8, 8, 8]],
               [[5, 5, 5, 5], [6, 6, 6, 6],
               [7, 7, 7, 7], [8, 8, 8, 8]]])
               shape = tf.constant([4, 4, 4])
               scatter = tf.scatter_nd(indices, updates, shape)
               with tf.Session() as sess:
               print(sess.run(scatter))
              </code>
               
               The resulting tensor would look like this:
               
               [[[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],
               [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]],
               [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],
               [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]]
               
               Note that on CPU, if an out of bound index is found, an error is returned.
               On GPU, if an out of bound index is found, the index is ignored.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.scatter_nd_add(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Applies sparse addition between <c>updates</c> and individual values or slices
            </summary>
            <param name="referecne">
               A mutable Tensor. Should be from a Variable node.
            </param>
            <param name="indices">
               A Tensor. Must be one of the following types: int32, int64.
               A tensor of indices into ref.
            </param>
            <param name="updates">
               A Tensor. Must have the same type as ref. A tensor of updated values
               to add to ref.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ScatterNdAdd'.
            </param>
            <param name="use_locking">
               An optional bool. Defaults to True. If True, the assignment will
               be protected by a lock; otherwise the behavior is undefined,
               but may exhibit less contention.
            </param>
            <returns>
               Same as ref. Returned as a convenience for operations that want
               to use the updated values after the update is done.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               within a given variable according to <c>indices</c>.
               
               <c>ref</c> is a <c>Tensor</c> with rank <c>P</c> and <c>indices</c> is a <c>Tensor</c> of rank <c>Q</c>.
               
               <c>indices</c> must be integer tensor, containing indices into <c>ref</c>.
               It must be shape <c>\\([d_0, ..., d_{Q-2}, K]\\)</c> where <c>0 &amp;lt; K &amp;lt;= P</c>.
               
               The innermost dimension of <c>indices</c> (with length <c>K</c>) corresponds to
               indices into elements (if <c>K = P</c>) or slices (if <c>K &amp;lt; P</c>) along the <c>K</c>th
               dimension of <c>ref</c>.
               
               <c>updates</c> is <c>Tensor</c> of rank <c>Q-1+P-K</c> with shape:
               
               $$[d_0, ..., d_{Q-2}, ref.shape[K], ..., ref.shape[P-1]].$$
               
               For example, say we want to add 4 scattered elements to a rank-1 tensor to 8
               elements. In Python, that addition would look like this:
               
               ref = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])
               indices = tf.constant([[4], [3], [1], [7]])
               updates = tf.constant([9, 10, 11, 12])
               add = tf.scatter_nd_add(ref, indices, updates)
               with tf.Session() as sess:
               print sess.run(add)
               
               The resulting update to ref would look like this:
               
               [1, 13, 3, 14, 14, 6, 7, 20]
               
               See <c>tf.scatter_nd</c> for more details about how to make updates to
               slices.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.scatter_nd_non_aliasing_add(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Applies sparse addition to <c>input</c> using individual values or slices
            </summary>
            <param name="input">
               A Tensor.
            </param>
            <param name="indices">
               A Tensor. Must be one of the following types: <c>int32</c>, <c>int64</c>.
               A tensor of indices into <c>input</c>.
            </param>
            <param name="updates">
               A Tensor. Must have the same type as ref. A tensor of updated values
               to add to <c>input</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ScatterNdNonAliasingAdd'.
            </param>
            <returns>
               A <c>Tensor</c> with the same shape as <c>input</c>, containing values of <c>input</c>
               updated with <c>updates</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               from <c>updates</c> according to indices <c>indices</c>.  The updates are non-aliasing:
               <c>input</c> is only modified in-place if no other operations will use it.
               Otherwise, a copy of <c>input</c> is made.  This operation has a gradient with
               respect to both <c>input</c> and <c>updates</c>.
               
               <c>input</c> is a <c>Tensor</c> with rank <c>P</c> and <c>indices</c> is a <c>Tensor</c> of rank <c>Q</c>.
               
               <c>indices</c> must be integer tensor, containing indices into <c>input</c>.
               It must be shape \\([d_0, ..., d_{Q-2}, K]\\) where <c>0 &amp;lt; K &amp;lt;= P</c>.
               
               The innermost dimension of <c>indices</c> (with length <c>K</c>) corresponds to
               indices into elements (if <c>K = P</c>) or <c>(P-K)</c>-dimensional slices
               (if <c>K &amp;lt; P</c>) along the <c>K</c>th dimension of <c>input</c>.
               
               <c>updates</c> is <c>Tensor</c> of rank <c>Q-1+P-K</c> with shape:
               
               $$[d_0, ..., d_{Q-2}, input.shape[K], ..., input.shape[P-1]].$$
               
               For example, say we want to add 4 scattered elements to a rank-1 tensor to 8
               elements. In Python, that addition would look like this:
               
               input = tf.constant([1, 2, 3, 4, 5, 6, 7, 8])
               indices = tf.constant([[4], [3], [1], [7]])
               updates = tf.constant([9, 10, 11, 12])
               output = tf.scatter_nd_non_aliasing_add(input, indices, updates)
               with tf.Session() as sess:
               print(sess.run(output))
               
               The resulting value <c>output</c> would look like this:
               
               [1, 13, 3, 14, 14, 6, 7, 20]
               
               See <c>tf.scatter_nd</c> for more details about how to make updates to slices.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.scatter_nd_sub(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Applies sparse subtraction between <c>updates</c> and individual values or slices
            </summary>
            <param name="referecne">
               A mutable Tensor. Should be from a Variable node.
            </param>
            <param name="indices">
               A Tensor. Must be one of the following types: int32, int64.
               A tensor of indices into ref.
            </param>
            <param name="updates">
               A Tensor. Must have the same type as ref. A tensor of updated values
               to subtract from ref.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ScatterNdSub'.
            </param>
            <param name="use_locking">
               An optional bool. Defaults to True. If True, the assignment will
               be protected by a lock; otherwise the behavior is undefined,
               but may exhibit less contention.
            </param>
            <returns>
               Same as ref. Returned as a convenience for operations that want
               to use the updated values after the update is done.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               within a given variable according to <c>indices</c>.
               
               <c>ref</c> is a <c>Tensor</c> with rank <c>P</c> and <c>indices</c> is a <c>Tensor</c> of rank <c>Q</c>.
               
               <c>indices</c> must be integer tensor, containing indices into <c>ref</c>.
               It must be shape \\([d_0, ..., d_{Q-2}, K]\\) where <c>0 &amp;lt; K &amp;lt;= P</c>.
               
               The innermost dimension of <c>indices</c> (with length <c>K</c>) corresponds to
               indices into elements (if <c>K = P</c>) or slices (if <c>K &amp;lt; P</c>) along the <c>K</c>th
               dimension of <c>ref</c>.
               
               <c>updates</c> is <c>Tensor</c> of rank <c>Q-1+P-K</c> with shape:
               
               $$[d_0, ..., d_{Q-2}, ref.shape[K], ..., ref.shape[P-1]].$$
               
               For example, say we want to subtract 4 scattered elements from a rank-1 tensor
               with 8 elements. In Python, that subtraction would look like this:
               
               ref = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])
               indices = tf.constant([[4], [3], [1], [7]])
               updates = tf.constant([9, 10, 11, 12])
               sub = tf.scatter_nd_sub(ref, indices, updates)
               with tf.Session() as sess:
               print sess.run(sub)
               
               The resulting update to ref would look like this:
               
               [1, -9, 3, -6, -4, 6, 7, -4]
               
               See <c>tf.scatter_nd</c> for more details about how to make updates to
               slices.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.scatter_nd_update(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Applies sparse <c>updates</c> to individual values or slices within a given
            </summary>
            <param name="referecne">
               A mutable Tensor. Should be from a Variable node.
            </param>
            <param name="indices">
               A Tensor. Must be one of the following types: int32, int64.
               A tensor of indices into ref.
            </param>
            <param name="updates">
               A Tensor. Must have the same type as ref. A tensor of updated
               values to add to ref.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ScatterNdUpdate'.
            </param>
            <param name="use_locking">
               An optional bool. Defaults to True. If True, the assignment will
               be protected by a lock; otherwise the behavior is undefined,
               but may exhibit less contention.
            </param>
            <returns>
               Same as ref. Returned as a convenience for operations that want to
               use the updated values after the update is done.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               variable according to <c>indices</c>.
               
               <c>ref</c> is a <c>Tensor</c> with rank <c>P</c> and <c>indices</c> is a <c>Tensor</c> of rank <c>Q</c>.
               
               <c>indices</c> must be integer tensor, containing indices into <c>ref</c>.
               It must be shape \\([d_0, ..., d_{Q-2}, K]\\) where <c>0 &amp;lt; K &amp;lt;= P</c>.
               
               The innermost dimension of <c>indices</c> (with length <c>K</c>) corresponds to
               indices into elements (if <c>K = P</c>) or slices (if <c>K &amp;lt; P</c>) along the <c>K</c>th
               dimension of <c>ref</c>.
               
               <c>updates</c> is <c>Tensor</c> of rank <c>Q-1+P-K</c> with shape:
               
               $$[d_0, ..., d_{Q-2}, ref.shape[K], ..., ref.shape[P-1]].$$
               
               For example, say we want to update 4 scattered elements to a rank-1 tensor to
               8 elements. In Python, that update would look like this:
               
              <code>
               ref = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])
               indices = tf.constant([[4], [3], [1] ,[7]])
               updates = tf.constant([9, 10, 11, 12])
               update = tf.scatter_nd_update(ref, indices, updates)
               with tf.Session() as sess:
               print sess.run(update)
              </code>
               
               The resulting update to ref would look like this:
               
               [1, 11, 3, 10, 9, 6, 7, 12]
               
               See <c>tf.scatter_nd</c> for more details about how to make updates to
               slices.
               
               See also <c>tf.scatter_update</c> and <c>tf.batch_scatter_update</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.scatter_sub(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Subtracts sparse updates to a variable reference.
            </summary>
            <param name="referecne">
               Should be from a <c>Variable</c> node.
            </param>
            <param name="indices">
               A tensor of indices into the first dimension of <c>ref</c>.
            </param>
            <param name="updates">
               A tensor of updated values to subtract from <c>ref</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ScatterSub'.
            </param>
            <param name="use_locking">
               If True, the subtraction will be protected by a lock;
               otherwise the behavior is undefined, but may exhibit less contention.
            </param>
            <returns>
               = Same as <c>ref</c>.  Returned as a convenience for operations that want
               to use the updated values after the update is done.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
              <code>
               # Scalar indices
               ref[indices, ...] -= updates[...]
               
               # Vector indices (for each i)
               ref[indices[i], ...] -= updates[i, ...]
               
               # High rank indices (for each i, ..., j)
               ref[indices[i, ..., j], ...] -= updates[i, ..., j, ...]
              </code>
               
               This operation outputs <c>ref</c> after the update is done.
               This makes it easier to chain operations that need to use the reset value.
               
               Duplicate entries are handled correctly: if multiple <c>indices</c> reference
               the same location, their (negated) contributions add.
               
               Requires <c>updates.shape = indices.shape + ref.shape[1:]</c> or <c>updates.shape = []</c>.
               
               &amp;lt;div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;"&amp;gt;
               &amp;lt;img style="width:100%" src="https://www.tensorflow.org/images/ScatterSub.png" alt&amp;gt;
               &amp;lt;/div&amp;gt;
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.scatter_update(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Applies sparse updates to a variable reference.
            </summary>
            <param name="referecne">
               Should be from a <c>Variable</c> node.
            </param>
            <param name="indices">
               A tensor of indices into the first dimension of <c>ref</c>.
            </param>
            <param name="updates">
               A tensor of updated values to store in <c>ref</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ScatterUpdate'.
            </param>
            <param name="use_locking">
               If True, the assignment will be protected by a lock;
               otherwise the behavior is undefined, but may exhibit less contention.
            </param>
            <returns>
               = Same as <c>ref</c>.  Returned as a convenience for operations that want
               to use the updated values after the update is done.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation computes
               
              <code>
               # Scalar indices
               ref[indices, ...] = updates[...]
               
               # Vector indices (for each i)
               ref[indices[i], ...] = updates[i, ...]
               
               # High rank indices (for each i, ..., j)
               ref[indices[i, ..., j], ...] = updates[i, ..., j, ...]
              </code>
               
               This operation outputs <c>ref</c> after the update is done.
               This makes it easier to chain operations that need to use the reset value.
               
               If values in <c>ref</c> is to be updated more than once, because there are
               duplicate entries in <c>indices</c>, the order at which the updates happen
               for each value is undefined.
               
               Requires <c>updates.shape = indices.shape + ref.shape[1:]</c> or <c>updates.shape = []</c>.
               
               &amp;lt;div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;"&amp;gt;
               &amp;lt;img style="width:100%" src="https://www.tensorflow.org/images/ScatterUpdate.png" alt&amp;gt;
               &amp;lt;/div&amp;gt;
               
               See also <c>tf.batch_scatter_update</c> and <c>tf.scatter_nd_update</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sdca_fprint(Tensorflow.Tensor,System.String)">
            <summary>
               Computes fingerprints of the input strings.
            </summary>
            <param name="input">
               vector of strings to compute fingerprints on.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SdcaFprint'.
            </param>
            <returns>
               a (N,2) shaped matrix where N is the number of elements in the input
               vector. Each row contains the low and high parts of the fingerprint.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sdca_optimizer(Tensorflow.Tensor[],Tensorflow.Tensor[],Tensorflow.Tensor[],Tensorflow.Tensor[],Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor[],Tensorflow.Tensor[],Tensorflow.Tensor[],Tensorflow.Tensor,System.String,System.Single,System.Single,System.Int32,System.Int32,System.Nullable{System.Boolean},System.String)">
            <summary>
               Distributed version of Stochastic Dual Coordinate Ascent (SDCA) optimizer for
            </summary>
            <param name="sparse_example_indices">
               a list of vectors which contain example indices.
            </param>
            <param name="sparse_feature_indices">
               a list of vectors which contain feature indices.
            </param>
            <param name="sparse_feature_values">
               a list of vectors which contains feature value
               associated with each feature group.
            </param>
            <param name="dense_features">
               a list of matrices which contains the dense feature values.
            </param>
            <param name="example_weights">
               a vector which contains the weight associated with each
               example.
            </param>
            <param name="example_labels">
               a vector which contains the label/target associated with each
               example.
            </param>
            <param name="sparse_indices">
               a list of vectors where each value is the indices which has
               corresponding weights in sparse_weights. This field maybe omitted for the
               dense approach.
            </param>
            <param name="sparse_weights">
               a list of vectors where each value is the weight associated with
               a sparse feature group.
            </param>
            <param name="dense_weights">
               a list of vectors where the values are the weights associated
               with a dense feature group.
            </param>
            <param name="example_state_data">
               a list of vectors containing the example state data.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SdcaOptimizer'.
            </param>
            <param name="loss_type">
               Optional argument
               Type of the primal loss. Currently SdcaSolver supports logistic,
               squared and hinge losses.
            </param>
            <param name="l1">
               Optional argument
               Symmetric l1 regularization strength.
            </param>
            <param name="l2">
               Optional argument
               Symmetric l2 regularization strength.
            </param>
            <param name="num_loss_partitions">
               Optional argument
               Number of partitions of the global loss function.
            </param>
            <param name="num_inner_iterations">
               Optional argument
               Number of iterations per mini-batch.
            </param>
            <param name="adaptative">
               Whether to use Adaptive SDCA for the inner loop.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               out_example_state_data : a list of vectors containing the updated example state
               data.
               out_delta_sparse_weights : a list of vectors where each value is the delta
               weights associated with a sparse feature group.
               out_delta_dense_weights : a list of vectors where the values are the delta
               weights associated with a dense feature group.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               linear models with L1 + L2 regularization. As global optimization objective is
               strongly-convex, the optimizer optimizes the dual objective at each step. The
               optimizer applies each update one example at a time. Examples are sampled
               uniformly, and the optimizer is learning rate free and enjoys linear convergence
               rate.
               
               [Proximal Stochastic Dual Coordinate Ascent](http://arxiv.org/pdf/1211.2717v1.pdf).&amp;lt;br&amp;gt;
               Shai Shalev-Shwartz, Tong Zhang. 2012
               
               $$Loss Objective = \sum f_{i} (wx_{i}) + (l2 / 2) * |w|^2 + l1 * |w|$$
               
               [Adding vs. Averaging in Distributed Primal-Dual Optimization](http://arxiv.org/abs/1502.03508).&amp;lt;br&amp;gt;
               Chenxin Ma, Virginia Smith, Martin Jaggi, Michael I. Jordan,
               Peter Richtarik, Martin Takac. 2015
               
               [Stochastic Dual Coordinate Ascent with Adaptive Probabilities](https://arxiv.org/abs/1502.08053).&amp;lt;br&amp;gt;
               Dominik Csiba, Zheng Qu, Peter Richtarik. 2015
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sdca_shrink_l1(Tensorflow.Tensor[],System.Single,System.Single,System.String)">
            <summary>
               Applies L1 regularization shrink step on the parameters.
            </summary>
            <param name="weights">
               a list of vectors where each value is the weight associated with a
               feature group.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SdcaShrinkL1'.
            </param>
            <param name="l1">
               Optional argument
               Symmetric l1 regularization strength.
            </param>
            <param name="l2">
               Optional argument
               Symmetric l2 regularization strength. Should be a positive float.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.segment_max(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes the maximum along segments of a tensor.
            </summary>
            <param name="data">
            </param>
            <param name="segment_ids">
               A 1-D tensor whose size is equal to the size of <c>data</c>'s
               first dimension.  Values should be sorted and can be repeated.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SegmentMax'.
            </param>
            <returns>
               Has same shape as data, except for dimension 0 which
               has size <c>k</c>, the number of segments.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Read
               [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#Segmentation)
               for an explanation of segments.
               
               Computes a tensor such that
               \\(output_i = \max_j(data_j)\\) where <c>max</c> is over <c>j</c> such
               that <c>segment_ids[j] == i</c>.
               
               If the max is empty for a given segment ID <c>i</c>, <c>output[i] = 0</c>.
               
               &amp;lt;div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;"&amp;gt;
               &amp;lt;img style="width:100%" src="https://www.tensorflow.org/images/SegmentMax.png" alt&amp;gt;
               &amp;lt;/div&amp;gt;
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.segment_mean(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes the mean along segments of a tensor.
            </summary>
            <param name="data">
            </param>
            <param name="segment_ids">
               A 1-D tensor whose size is equal to the size of <c>data</c>'s
               first dimension.  Values should be sorted and can be repeated.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SegmentMean'.
            </param>
            <returns>
               Has same shape as data, except for dimension 0 which
               has size <c>k</c>, the number of segments.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Read
               [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#Segmentation)
               for an explanation of segments.
               
               Computes a tensor such that
               \\(output_i = \frac{\sum_j data_j}{N}\\) where <c>mean</c> is
               over <c>j</c> such that <c>segment_ids[j] == i</c> and <c>N</c> is the total number of
               values summed.
               
               If the mean is empty for a given segment ID <c>i</c>, <c>output[i] = 0</c>.
               
               &amp;lt;div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;"&amp;gt;
               &amp;lt;img style="width:100%" src="https://www.tensorflow.org/images/SegmentMean.png" alt&amp;gt;
               &amp;lt;/div&amp;gt;
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.segment_min(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes the minimum along segments of a tensor.
            </summary>
            <param name="data">
            </param>
            <param name="segment_ids">
               A 1-D tensor whose size is equal to the size of <c>data</c>'s
               first dimension.  Values should be sorted and can be repeated.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SegmentMin'.
            </param>
            <returns>
               Has same shape as data, except for dimension 0 which
               has size <c>k</c>, the number of segments.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Read
               [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#Segmentation)
               for an explanation of segments.
               
               Computes a tensor such that
               \\(output_i = \min_j(data_j)\\) where <c>min</c> is over <c>j</c> such
               that <c>segment_ids[j] == i</c>.
               
               If the min is empty for a given segment ID <c>i</c>, <c>output[i] = 0</c>.
               
               &amp;lt;div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;"&amp;gt;
               &amp;lt;img style="width:100%" src="https://www.tensorflow.org/images/SegmentMin.png" alt&amp;gt;
               &amp;lt;/div&amp;gt;
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.segment_prod(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes the product along segments of a tensor.
            </summary>
            <param name="data">
            </param>
            <param name="segment_ids">
               A 1-D tensor whose size is equal to the size of <c>data</c>'s
               first dimension.  Values should be sorted and can be repeated.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SegmentProd'.
            </param>
            <returns>
               Has same shape as data, except for dimension 0 which
               has size <c>k</c>, the number of segments.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Read
               [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#Segmentation)
               for an explanation of segments.
               
               Computes a tensor such that
               \\(output_i = \prod_j data_j\\) where the product is over <c>j</c> such
               that <c>segment_ids[j] == i</c>.
               
               If the product is empty for a given segment ID <c>i</c>, <c>output[i] = 1</c>.
               
               &amp;lt;div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;"&amp;gt;
               &amp;lt;img style="width:100%" src="https://www.tensorflow.org/images/SegmentProd.png" alt&amp;gt;
               &amp;lt;/div&amp;gt;
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.segment_sum(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes the sum along segments of a tensor.
            </summary>
            <param name="data">
            </param>
            <param name="segment_ids">
               A 1-D tensor whose size is equal to the size of <c>data</c>'s
               first dimension.  Values should be sorted and can be repeated.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SegmentSum'.
            </param>
            <returns>
               Has same shape as data, except for dimension 0 which
               has size <c>k</c>, the number of segments.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Read
               [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#Segmentation)
               for an explanation of segments.
               
               Computes a tensor such that
               \\(output_i = \sum_j data_j\\) where sum is over <c>j</c> such
               that <c>segment_ids[j] == i</c>.
               
               If the sum is empty for a given segment ID <c>i</c>, <c>output[i] = 0</c>.
               
               &amp;lt;div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;"&amp;gt;
               &amp;lt;img style="width:100%" src="https://www.tensorflow.org/images/SegmentSum.png" alt&amp;gt;
               &amp;lt;/div&amp;gt;
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.select(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Selects elements from <c>x</c> or <c>y</c>, depending on <c>condition</c>.
            </summary>
            <param name="condition">
            </param>
            <param name="t">
               = A <c>Tensor</c> which may have the same shape as <c>condition</c>.
               If <c>condition</c> is rank 1, <c>x</c> may have higher rank,
               but its first dimension must match the size of <c>condition</c>.
            </param>
            <param name="e">
               = A <c>Tensor</c> with the same type and shape as <c>x</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Select'.
            </param>
            <returns>
               = A <c>Tensor</c> with the same type and shape as <c>x</c> and <c>y</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The <c>x</c>, and <c>y</c> tensors must all have the same shape, and the
               output will also have that shape.
               
               The <c>condition</c> tensor must be a scalar if <c>x</c> and <c>y</c> are scalars.
               If <c>x</c> and <c>y</c> are vectors or higher rank, then <c>condition</c> must be either a
               scalar, a vector with size matching the first dimension of <c>x</c>, or must have
               the same shape as <c>x</c>.
               
               The <c>condition</c> tensor acts as a mask that chooses, based on the value at each
               element, whether the corresponding element / row in the output should be
               taken from <c>x</c> (if true) or <c>y</c> (if false).
               
               If <c>condition</c> is a vector and <c>x</c> and <c>y</c> are higher rank matrices, then
               it chooses which row (outer dimension) to copy from <c>x</c> and <c>y</c>.
               If <c>condition</c> has the same shape as <c>x</c> and <c>y</c>, then it chooses which
               element to copy from <c>x</c> and <c>y</c>.
               
               For example:
               
              <code>
               # 'condition' tensor is [[True,  False]
               #                        [False, True]]
               # 't' is [[1, 2],
               #         [3, 4]]
               # 'e' is [[5, 6],
               #         [7, 8]]
               select(condition, t, e)  # =&amp;gt; [[1, 6], [7, 4]]
               
               
               # 'condition' tensor is [True, False]
               # 't' is [[1, 2],
               #         [3, 4]]
               # 'e' is [[5, 6],
               #         [7, 8]]
               select(condition, t, e) ==&amp;gt; [[1, 2],
               [7, 8]]
               
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.self_adjoint_eig(Tensorflow.Tensor,System.String)">
            <summary>
               Computes the Eigen Decomposition of a batch of square self-adjoint matrices.
            </summary>
            <param name="input">
               Shape is <c>[..., M, M]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SelfAdjointEig'.
            </param>
            <returns>
               Shape is <c>[..., M+1, M]</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The input is a tensor of shape <c>[..., M, M]</c> whose inner-most 2 dimensions
               form square matrices, with the same constraints as the single matrix
               SelfAdjointEig.
               
               The result is a [..., M+1, M] matrix with [..., 0,:] containing the
               eigenvalues, and subsequent [...,1:, :] containing the eigenvectors. The eigenvalues
               are sorted in non-decreasing order.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.self_adjoint_eig_v2(Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Computes the eigen decomposition of one or more square self-adjoint matrices.
            </summary>
            <param name="input">
               <c>Tensor</c> input of shape <c>[N, N]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SelfAdjointEigV2'.
            </param>
            <param name="compute_v">
               If <c>True</c> then eigenvectors will be computed and returned in <c>v</c>.
               Otherwise, only the eigenvalues will be computed.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               e : Eigenvalues. Shape is <c>[N]</c>.
               v : Eigenvectors. Shape is <c>[N, N]</c>.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Computes the eigenvalues and (optionally) eigenvectors of each inner matrix in
               <c>input</c> such that <c>input[..., :, :] = v[..., :, :] * diag(e[..., :])</c>. The eigenvalues
               are sorted in non-decreasing order.
               
              <code>
               # a is a tensor.
               # e is a tensor of eigenvalues.
               # v is a tensor of eigenvectors.
               e, v = self_adjoint_eig(a)
               e = self_adjoint_eig(a, compute_v=False)
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.selu(Tensorflow.Tensor,System.String)">
            <summary>
               Computes scaled exponential linear: <c>scale * alpha * (exp(features) - 1)</c>
            </summary>
            <param name="features">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Selu'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               if &amp;lt; 0, <c>scale * features</c> otherwise.
               
               To be used together with
               <c>initializer = tf.variance_scaling_initializer(factor=1.0, mode='FAN_IN')</c>.
               For correct dropout, use <c>tf.contrib.nn.alpha_dropout</c>.
               
               See [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.selu_grad(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes gradients for the scaled exponential linear (Selu) operation.
            </summary>
            <param name="gradients">
               The backpropagated gradients to the corresponding Selu operation.
            </param>
            <param name="outputs">
               The outputs of the corresponding Selu operation.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SeluGrad'.
            </param>
            <returns>
               The gradients: <c>gradients * (outputs + scale * alpha)</c>
               if outputs &amp;lt; 0, <c>scale * gradients</c> otherwise.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.serialize_iterator(Tensorflow.Tensor,System.String)">
            <summary>
               Converts the given <c>resource_handle</c> representing an iterator to a variant tensor.
            </summary>
            <param name="resource_handle">
               A handle to an iterator resource.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SerializeIterator'.
            </param>
            <returns>
               A variant tensor storing the state of the iterator contained in the
               resource.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.serialize_many_sparse(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Serialize an <c>N</c>-minibatch <c>SparseTensor</c> into an <c>[N, 3]</c> <c>Tensor</c> object.
            </summary>
            <param name="sparse_indices">
               2-D.  The <c>indices</c> of the minibatch <c>SparseTensor</c>.
            </param>
            <param name="sparse_values">
               1-D.  The <c>values</c> of the minibatch <c>SparseTensor</c>.
            </param>
            <param name="sparse_shape">
               1-D.  The <c>shape</c> of the minibatch <c>SparseTensor</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SerializeManySparse'.
            </param>
            <param name="out_type">
               The <c>dtype</c> to use for serialization; the supported types are <c>string</c>
               (default) and <c>variant</c>.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The <c>SparseTensor</c> must have rank <c>R</c> greater than 1, and the first dimension
               is treated as the minibatch dimension.  Elements of the <c>SparseTensor</c>
               must be sorted in increasing order of this first dimension.  The serialized
               <c>SparseTensor</c> objects going into each row of <c>serialized_sparse</c> will have
               rank <c>R-1</c>.
               
               The minibatch size <c>N</c> is extracted from <c>sparse_shape[0]</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.serialize_sparse(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Serialize a <c>SparseTensor</c> into a <c>[3]</c> <c>Tensor</c> object.
            </summary>
            <param name="sparse_indices">
               2-D.  The <c>indices</c> of the <c>SparseTensor</c>.
            </param>
            <param name="sparse_values">
               1-D.  The <c>values</c> of the <c>SparseTensor</c>.
            </param>
            <param name="sparse_shape">
               1-D.  The <c>shape</c> of the <c>SparseTensor</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SerializeSparse'.
            </param>
            <param name="out_type">
               The <c>dtype</c> to use for serialization; the supported types are <c>string</c>
               (default) and <c>variant</c>.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.serialize_tensor(Tensorflow.Tensor,System.String)">
            <summary>
               Transforms a Tensor into a serialized TensorProto proto.
            </summary>
            <param name="tensor">
               A Tensor of type <c>T</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SerializeTensor'.
            </param>
            <returns>
               A serialized TensorProto proto of the input tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.set_size(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Number of unique elements along last dimension of input <c>set</c>.
            </summary>
            <param name="set_indices">
               2D <c>Tensor</c>, indices of a <c>SparseTensor</c>.
            </param>
            <param name="set_values">
               1D <c>Tensor</c>, values of a <c>SparseTensor</c>.
            </param>
            <param name="set_shape">
               1D <c>Tensor</c>, shape of a <c>SparseTensor</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SetSize'.
            </param>
            <param name="validate_indices">
            </param>
            <returns>
               For <c>set</c> ranked <c>n</c>, this is a <c>Tensor</c> with rank <c>n-1</c>, and the same 1st
               <c>n-1</c> dimensions as <c>set</c>. Each value is the number of unique elements in
               the corresponding <c>[0...n-1]</c> dimension of <c>set</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Input <c>set</c> is a <c>SparseTensor</c> represented by <c>set_indices</c>, <c>set_values</c>,
               and <c>set_shape</c>. The last dimension contains values in a set, duplicates are
               allowed but ignored.
               
               If <c>validate_indices</c> is <c>True</c>, this op validates the order and range of <c>set</c>
               indices.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.shape(Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Returns the shape of a tensor.
            </summary>
            <param name="input">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Shape'.
            </param>
            <param name="out_type">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation returns a 1-D integer tensor representing the shape of <c>input</c>.
               
               For example:
               
              <code>
               # 't' is [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]
               shape(t) ==&amp;gt; [2, 2, 3]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.shape_n(Tensorflow.Tensor[],System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Returns shape of tensors.
            </summary>
            <param name="input">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ShapeN'.
            </param>
            <param name="out_type">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation returns N 1-D integer tensors representing shape of <c>input[i]s</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sharded_filename(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Generate a sharded filename. The filename is printf formatted as
            </summary>
            <param name="basename">
            </param>
            <param name="shard">
            </param>
            <param name="num_shards">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ShardedFilename'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               %s-%05d-of-%05d, basename, shard, num_shards.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sharded_filespec(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Generate a glob pattern matching all sharded file names.
            </summary>
            <param name="basename">
            </param>
            <param name="num_shards">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ShardedFilespec'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.shuffle_and_repeat_dataset(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Creates a dataset that shuffles and repeats elements from <c>input_dataset</c>
            </summary>
            <param name="input_dataset">
            </param>
            <param name="buffer_size">
               The number of output elements to buffer in an iterator over
               this dataset. Compare with the <c>min_after_dequeue</c> attr when creating a
               <c>RandomShuffleQueue</c>.
            </param>
            <param name="seed">
               A scalar seed for the random number generator. If either <c>seed</c> or
               <c>seed2</c> is set to be non-zero, the random number generator is seeded
               by the given seed.  Otherwise, a random seed is used.
            </param>
            <param name="seed2">
               A second scalar seed to avoid seed collision.
            </param>
            <param name="count">
               A scalar representing the number of times the underlying dataset
               should be repeated. The default is <c>-1</c>, which results in infinite repetition.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ShuffleAndRepeatDataset'.
            </param>
            <param name="output_types">
               Optional argument
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               pseudorandomly.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.shuffle_dataset(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.Nullable{System.Boolean},System.String)">
            <summary>
               Creates a dataset that shuffles elements from <c>input_dataset</c> pseudorandomly.
            </summary>
            <param name="input_dataset">
            </param>
            <param name="buffer_size">
               The number of output elements to buffer in an iterator over
               this dataset. Compare with the <c>min_after_dequeue</c> attr when creating a
               <c>RandomShuffleQueue</c>.
            </param>
            <param name="seed">
               A scalar seed for the random number generator. If either <c>seed</c> or
               <c>seed2</c> is set to be non-zero, the random number generator is seeded
               by the given seed.  Otherwise, a random seed is used.
            </param>
            <param name="seed2">
               A second scalar seed to avoid seed collision.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ShuffleDataset'.
            </param>
            <param name="output_types">
               Optional argument
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <param name="reshuffle_each_iteration">
               If true, each iterator over this dataset will be given
               a different pseudorandomly generated seed, based on a sequence seeded by the
               <c>seed</c> and <c>seed2</c> inputs. If false, each iterator will be given the same
               seed, and repeated iteration over this dataset will yield the exact same
               sequence of results.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.shutdown_distributed_t_p_u(System.String)">
            <summary>
               An op that shuts down a running distributed TPU system. The Op returns
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ShutdownDistributedTPU'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               an error if no system is running.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sigmoid(Tensorflow.Tensor,System.String)">
            <summary>
               Computes sigmoid of <c>x</c> element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Sigmoid'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Specifically, <c>y = 1 / (1 + exp(-x))</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sigmoid_grad(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes the gradient of the sigmoid of <c>x</c> wrt its input.
            </summary>
            <param name="y">
            </param>
            <param name="dy">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SigmoidGrad'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Specifically, <c>grad = dy * y * (1 - y)</c>, where <c>y = sigmoid(x)</c>, and
               <c>dy</c> is the corresponding input gradient.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sign(Tensorflow.Tensor,System.String)">
            <summary>
               Returns an element-wise indication of the sign of a number.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Sign'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               <c>y = sign(x) = -1</c> if <c>x &amp;lt; 0</c>; 0 if <c>x == 0</c>; 1 if <c>x &amp;gt; 0</c>.
               
               For complex numbers, <c>y = sign(x) = x / |x|</c> if <c>x != 0</c>, otherwise <c>y = 0</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sin(Tensorflow.Tensor,System.String)">
            <summary>
               Computes sin of x element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Sin'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sinh(Tensorflow.Tensor,System.String)">
            <summary>
               Computes hyperbolic sine of x element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Sinh'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sink_dataset(Tensorflow.Tensor,System.String)">
            <summary>
               A placeholder for input pipeline graph optimizations.
            </summary>
            <param name="input_dataset">
               A variant tensor representing the input dataset.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SinkDataset'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               A placeholder for input pipeline graph optimizations.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.size(Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Returns the size of a tensor.
            </summary>
            <param name="input">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Size'.
            </param>
            <param name="out_type">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation returns an integer representing the number of elements in
               <c>input</c>.
               
               For example:
               
              <code>
               # 't' is [[[1, 1,, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]]
               size(t) ==&amp;gt; 12
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.skip_dataset(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Creates a dataset that skips <c>count</c> elements from the <c>input_dataset</c>.
            </summary>
            <param name="input_dataset">
            </param>
            <param name="count">
               A scalar representing the number of elements from the <c>input_dataset</c>
               that should be skipped.  If count is -1, skips everything.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SkipDataset'.
            </param>
            <param name="output_types">
               Optional argument
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.skipgram(System.String,System.Int32,System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Single},System.String)">
            <summary>
               Parses a text file and creates a batch of examples.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Skipgram'.
            </param>
            <param name="filename">
               Optional argument
               The corpus's text file name.
            </param>
            <param name="batch_size">
               Optional argument
               The size of produced batch.
            </param>
            <param name="window_size">
               The number of words to predict to the left and right of the target.
            </param>
            <param name="min_count">
               The minimum number of word occurrences for it to be included in the
               vocabulary.
            </param>
            <param name="subsample">
               Threshold for word occurrence. Words that appear with higher
               frequency will be randomly down-sampled. Set to 0 to disable.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               vocab_word : A vector of words in the corpus.
               vocab_freq : Frequencies of words. Sorted in the non-ascending order.
               words_per_epoch : Number of words per epoch in the data file.
               current_epoch : The current epoch number.
               total_words_processed : The total number of words processed so far.
               examples : A vector of word ids.
               labels : A vector of word ids.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.slice(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Return a slice from 'input'.
            </summary>
            <param name="input">
            </param>
            <param name="begin">
               begin[i] specifies the offset into the 'i'th dimension of
               'input' to slice from.
            </param>
            <param name="size">
               size[i] specifies the number of elements of the 'i'th dimension
               of 'input' to slice. If size[i] is -1, all remaining elements in dimension
               i are included in the slice (i.e. this is equivalent to setting
               size[i] = input.dim_size(i) - begin[i]).
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Slice'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The output tensor is a tensor with dimensions described by 'size'
               whose values are extracted from 'input' starting at the offsets in
               'begin'.
               
               *Requirements*:
               0 &amp;lt;= begin[i] &amp;lt;= begin[i] + size[i] &amp;lt;= Di  for i in [0, n)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.slide_dataset(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Creates a dataset that passes a sliding window over <c>input_dataset</c>.
            </summary>
            <param name="input_dataset">
            </param>
            <param name="window_size">
               A scalar representing the number of elements in the
               sliding window.
            </param>
            <param name="window_shift">
               A scalar representing the steps moving the sliding window
               forward in one iteration. It must be positive.
            </param>
            <param name="window_stride">
               A scalar representing the stride of the input elements of the sliding window.
               It must be positive.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SlideDataset'.
            </param>
            <param name="output_types">
               Optional argument
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.snapshot(Tensorflow.Tensor,System.String)">
            <summary>
               Returns a copy of the input tensor.
            </summary>
            <param name="input">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Snapshot'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.softmax(Tensorflow.Tensor,System.String)">
            <summary>
               Computes softmax activations.
            </summary>
            <param name="logits">
               2-D with shape <c>[batch_size, num_classes]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Softmax'.
            </param>
            <returns>
               Same shape as <c>logits</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               For each batch <c>i</c> and class <c>j</c> we have
               
               $$softmax[i, j] = exp(logits[i, j]) / sum_j(exp(logits[i, j]))$$
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.softmax_cross_entropy_with_logits(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes softmax cross entropy cost and gradients to backpropagate.
            </summary>
            <param name="features">
               batch_size x num_classes matrix
            </param>
            <param name="labels">
               batch_size x num_classes matrix
               The caller must ensure that each batch of labels represents a valid
               probability distribution.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SoftmaxCrossEntropyWithLogits'.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               loss : Per example loss (batch_size vector).
               backprop : backpropagated gradients (batch_size x num_classes matrix).
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Inputs are the logits, not probabilities.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.softplus(Tensorflow.Tensor,System.String)">
            <summary>
               Computes softplus: <c>log(exp(features) + 1)</c>.
            </summary>
            <param name="features">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Softplus'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.softplus_grad(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes softplus gradients for a softplus operation.
            </summary>
            <param name="gradients">
               The backpropagated gradients to the corresponding softplus operation.
            </param>
            <param name="features">
               The features passed as input to the corresponding softplus operation.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SoftplusGrad'.
            </param>
            <returns>
               The gradients: <c>gradients / (1 + exp(-features))</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.softsign(Tensorflow.Tensor,System.String)">
            <summary>
               Computes softsign: <c>features / (abs(features) + 1)</c>.
            </summary>
            <param name="features">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Softsign'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.softsign_grad(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes softsign gradients for a softsign operation.
            </summary>
            <param name="gradients">
               The backpropagated gradients to the corresponding softsign operation.
            </param>
            <param name="features">
               The features passed as input to the corresponding softsign operation.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SoftsignGrad'.
            </param>
            <returns>
               The gradients: <c>gradients / (1 + abs(features)) ** 2</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.space_to_batch(Tensorflow.Tensor,Tensorflow.Tensor,System.Int32,System.String)">
            <summary>
               SpaceToBatch for 4-D tensors of type T.
            </summary>
            <param name="input">
               4-D with shape <c>[batch, height, width, depth]</c>.
            </param>
            <param name="paddings">
               2-D tensor of non-negative integers with shape <c>[2, 2]</c>. It specifies
               the padding of the input with zeros across the spatial dimensions as follows:
               
               paddings = [[pad_top, pad_bottom], [pad_left, pad_right]]
               
               The effective spatial dimensions of the zero-padded input tensor will be:
               
               height_pad = pad_top + height + pad_bottom
               width_pad = pad_left + width + pad_right
               
               The attr <c>block_size</c> must be greater than one. It indicates the block size.
               
               * Non-overlapping blocks of size <c>block_size x block size</c> in the height and
               width dimensions are rearranged into the batch dimension at each location.
               * The batch of the output tensor is <c>batch * block_size * block_size</c>.
               * Both height_pad and width_pad must be divisible by block_size.
               
               The shape of the output will be:
               
               [batch*block_size*block_size, height_pad/block_size, width_pad/block_size,
               depth]
               
               Some examples:
               
               (1) For the following input of shape <c>[1, 2, 2, 1]</c> and block_size of 2:
               
              <code>
               x = [[[[1], [2]], [[3], [4]]]]
              </code>
               
               The output tensor has shape <c>[4, 1, 1, 1]</c> and value:
               
              <code>
               [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]
              </code>
               
               (2) For the following input of shape <c>[1, 2, 2, 3]</c> and block_size of 2:
               
              <code>
               x = [[[[1, 2, 3], [4, 5, 6]],
               [[7, 8, 9], [10, 11, 12]]]]
              </code>
               
               The output tensor has shape <c>[4, 1, 1, 3]</c> and value:
               
              <code>
               [[[1, 2, 3]], [[4, 5, 6]], [[7, 8, 9]], [[10, 11, 12]]]
              </code>
               
               (3) For the following input of shape <c>[1, 4, 4, 1]</c> and block_size of 2:
               
              <code>
               x = [[[[1],   [2],  [3],  [4]],
               [[5],   [6],  [7],  [8]],
               [[9],  [10], [11],  [12]],
               [[13], [14], [15],  [16]]]]
              </code>
               
               The output tensor has shape <c>[4, 2, 2, 1]</c> and value:
               
              <code>
               x = [[[[1], [3]], [[9], [11]]],
               [[[2], [4]], [[10], [12]]],
               [[[5], [7]], [[13], [15]]],
               [[[6], [8]], [[14], [16]]]]
              </code>
               
               (4) For the following input of shape <c>[2, 2, 4, 1]</c> and block_size of 2:
               
              <code>
               x = [[[[1],   [2],  [3],  [4]],
               [[5],   [6],  [7],  [8]]],
               [[[9],  [10], [11],  [12]],
               [[13], [14], [15],  [16]]]]
              </code>
               
               The output tensor has shape <c>[8, 1, 2, 1]</c> and value:
               
              <code>
               x = [[[[1], [3]]], [[[9], [11]]], [[[2], [4]]], [[[10], [12]]],
               [[[5], [7]]], [[[13], [15]]], [[[6], [8]]], [[[14], [16]]]]
              </code>
               
               Among others, this operation is useful for reducing atrous convolution into
               regular convolution.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SpaceToBatch'.
            </param>
            <param name="block_size">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This is a legacy version of the more general SpaceToBatchND.
               
               Zero-pads and then rearranges (permutes) blocks of spatial data into batch.
               More specifically, this op outputs a copy of the input tensor where values from
               the <c>height</c> and <c>width</c> dimensions are moved to the <c>batch</c> dimension. After
               the zero-padding, both <c>height</c> and <c>width</c> of the input must be divisible by the
               block size.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.space_to_batch_n_d(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               SpaceToBatch for N-D tensors of type T.
            </summary>
            <param name="input">
               N-D with shape <c>input_shape = [batch] + spatial_shape + remaining_shape</c>,
               where spatial_shape has <c>M</c> dimensions.
            </param>
            <param name="block_shape">
               1-D with shape <c>[M]</c>, all values must be &amp;gt;= 1.
            </param>
            <param name="paddings">
               2-D with shape <c>[M, 2]</c>, all values must be &amp;gt;= 0.
               <c>paddings[i] = [pad_start, pad_end]</c> specifies the padding for input dimension
               <c>i + 1</c>, which corresponds to spatial dimension <c>i</c>.  It is required that
               <c>block_shape[i]</c> divides <c>input_shape[i + 1] + pad_start + pad_end</c>.
               
               This operation is equivalent to the following steps:
               
               1. Zero-pad the start and end of dimensions <c>[1, ..., M]</c> of the
               input according to <c>paddings</c> to produce <c>padded</c> of shape <c>padded_shape</c>.
               
               2. Reshape <c>padded</c> to <c>reshaped_padded</c> of shape:
               
               [batch] +
               [padded_shape[1] / block_shape[0],
               block_shape[0],
               ...,
               padded_shape[M] / block_shape[M-1],
               block_shape[M-1]] +
               remaining_shape
               
               3. Permute dimensions of <c>reshaped_padded</c> to produce
               <c>permuted_reshaped_padded</c> of shape:
               
               block_shape +
               [batch] +
               [padded_shape[1] / block_shape[0],
               ...,
               padded_shape[M] / block_shape[M-1]] +
               remaining_shape
               
               4. Reshape <c>permuted_reshaped_padded</c> to flatten <c>block_shape</c> into the batch
               dimension, producing an output tensor of shape:
               
               [batch * prod(block_shape)] +
               [padded_shape[1] / block_shape[0],
               ...,
               padded_shape[M] / block_shape[M-1]] +
               remaining_shape
               
               Some examples:
               
               (1) For the following input of shape <c>[1, 2, 2, 1]</c>, <c>block_shape = [2, 2]</c>, and
               <c>paddings = [[0, 0], [0, 0]]</c>:
               
              <code>
               x = [[[[1], [2]], [[3], [4]]]]
              </code>
               
               The output tensor has shape <c>[4, 1, 1, 1]</c> and value:
               
              <code>
               [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]
              </code>
               
               (2) For the following input of shape <c>[1, 2, 2, 3]</c>, <c>block_shape = [2, 2]</c>, and
               <c>paddings = [[0, 0], [0, 0]]</c>:
               
              <code>
               x = [[[[1, 2, 3], [4, 5, 6]],
               [[7, 8, 9], [10, 11, 12]]]]
              </code>
               
               The output tensor has shape <c>[4, 1, 1, 3]</c> and value:
               
              <code>
               [[[1, 2, 3]], [[4, 5, 6]], [[7, 8, 9]], [[10, 11, 12]]]
              </code>
               
               (3) For the following input of shape <c>[1, 4, 4, 1]</c>, <c>block_shape = [2, 2]</c>, and
               <c>paddings = [[0, 0], [0, 0]]</c>:
               
              <code>
               x = [[[[1],   [2],  [3],  [4]],
               [[5],   [6],  [7],  [8]],
               [[9],  [10], [11],  [12]],
               [[13], [14], [15],  [16]]]]
              </code>
               
               The output tensor has shape <c>[4, 2, 2, 1]</c> and value:
               
              <code>
               x = [[[[1], [3]], [[9], [11]]],
               [[[2], [4]], [[10], [12]]],
               [[[5], [7]], [[13], [15]]],
               [[[6], [8]], [[14], [16]]]]
              </code>
               
               (4) For the following input of shape <c>[2, 2, 4, 1]</c>, block_shape = <c>[2, 2]</c>, and
               paddings = <c>[[0, 0], [2, 0]]</c>:
               
              <code>
               x = [[[[1],   [2],  [3],  [4]],
               [[5],   [6],  [7],  [8]]],
               [[[9],  [10], [11],  [12]],
               [[13], [14], [15],  [16]]]]
              </code>
               
               The output tensor has shape <c>[8, 1, 3, 1]</c> and value:
               
              <code>
               x = [[[[0], [1], [3]]], [[[0], [9], [11]]],
               [[[0], [2], [4]]], [[[0], [10], [12]]],
               [[[0], [5], [7]]], [[[0], [13], [15]]],
               [[[0], [6], [8]]], [[[0], [14], [16]]]]
              </code>
               
               Among others, this operation is useful for reducing atrous convolution into
               regular convolution.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SpaceToBatchND'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation divides "spatial" dimensions <c>[1, ..., M]</c> of the input into a
               grid of blocks of shape <c>block_shape</c>, and interleaves these blocks with the
               "batch" dimension (0) such that in the output, the spatial dimensions
               <c>[1, ..., M]</c> correspond to the position within the grid, and the batch
               dimension combines both the position within a spatial block and the original
               batch position.  Prior to division into blocks, the spatial dimensions of the
               input are optionally zero padded according to <c>paddings</c>.  See below for a
               precise description.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.space_to_depth(Tensorflow.Tensor,System.Int32,System.String,System.String)">
            <summary>
               SpaceToDepth for tensors of type T.
            </summary>
            <param name="input">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SpaceToDepth'.
            </param>
            <param name="block_size">
               Optional argument
               The size of the spatial block.
            </param>
            <param name="data_format">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Rearranges blocks of spatial data, into depth. More specifically,
               this op outputs a copy of the input tensor where values from the <c>height</c>
               and <c>width</c> dimensions are moved to the <c>depth</c> dimension.
               The attr <c>block_size</c> indicates the input block size.
               
               * Non-overlapping blocks of size <c>block_size x block size</c> are rearranged
               into depth at each location.
               * The depth of the output tensor is <c>block_size * block_size * input_depth</c>.
               * The Y, X coordinates within each block of the input become the high order
               component of the output channel index.
               * The input tensor's height and width must be divisible by block_size.
               
               The <c>data_format</c> attr specifies the layout of the input and output tensors
               with the following options:
               "NHWC": <c>[ batch, height, width, channels ]</c>
               "NCHW": <c>[ batch, channels, height, width ]</c>
               "NCHW_VECT_C":
               <c>qint8 [ batch, channels / 4, height, width, 4 ]</c>
               
               It is useful to consider the operation as transforming a 6-D Tensor.
               e.g. for data_format = NHWC,
               Each element in the input tensor can be specified via 6 coordinates,
               ordered by decreasing memory layout significance as:
               n,oY,bY,oX,bX,iC  (where n=batch index, oX, oY means X or Y coordinates
               within the output image, bX, bY means coordinates
               within the input block, iC means input channels).
               The output would be a transpose to the following layout:
               n,oY,oX,bY,bX,iC
               
               This operation is useful for resizing the activations between convolutions
               (but keeping all data), e.g. instead of pooling. It is also useful for training
               purely convolutional models.
               
               For example, given an input of shape <c>[1, 2, 2, 1]</c>, data_format = "NHWC" and
               block_size = 2:
               
              <code>
               x = [[[[1], [2]],
               [[3], [4]]]]
              </code>
               
               This operation will output a tensor of shape <c>[1, 1, 1, 4]</c>:
               
              <code>
               [[[[1, 2, 3, 4]]]]
              </code>
               
               Here, the input has a batch of 1 and each batch element has shape <c>[2, 2, 1]</c>,
               the corresponding output will have a single element (i.e. width and height are
               both 1) and will have a depth of 4 channels (1 * block_size * block_size).
               The output element shape is <c>[1, 1, 4]</c>.
               
               For an input tensor with larger depth, here of shape <c>[1, 2, 2, 3]</c>, e.g.
               
              <code>
               x = [[[[1, 2, 3], [4, 5, 6]],
               [[7, 8, 9], [10, 11, 12]]]]
              </code>
               
               This operation, for block_size of 2, will return the following tensor of shape
               <c>[1, 1, 1, 12]</c>
               
              <code>
               [[[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]]]
              </code>
               
               Similarly, for the following input of shape <c>[1 4 4 1]</c>, and a block size of 2:
               
              <code>
               x = [[[[1],   [2],  [5],  [6]],
               [[3],   [4],  [7],  [8]],
               [[9],  [10], [13],  [14]],
               [[11], [12], [15],  [16]]]]
              </code>
               
               the operator will return the following tensor of shape <c>[1 2 2 4]</c>:
               
              <code>
               x = [[[[1, 2, 3, 4],
               [5, 6, 7, 8]],
               [[9, 10, 11, 12],
               [13, 14, 15, 16]]]]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_accumulator_apply_gradient(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Boolean,System.String)">
            <summary>
               Applies a sparse gradient to a given accumulator.
            </summary>
            <param name="handle">
               The handle to a accumulator.
            </param>
            <param name="local_step">
               The local_step value at which the sparse gradient was computed.
            </param>
            <param name="gradient_indices">
               Indices of the sparse gradient to be accumulated. Must be a
               vector.
            </param>
            <param name="gradient_values">
               Values are the non-zero slices of the gradient, and must have
               the same first dimension as indices, i.e., the nnz represented by indices and
               values must be consistent.
            </param>
            <param name="gradient_shape">
               Shape of the sparse gradient to be accumulated.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseAccumulatorApplyGradient'.
            </param>
            <param name="has_known_shape">
               Optional argument
               Boolean indicating whether gradient_shape is unknown, in which
               case the input is ignored during validation.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               Does not add if local_step is smaller than the accumulator's
               global_step.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_accumulator_take_gradient(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType,System.String)">
            <summary>
               Extracts the average sparse gradient in a SparseConditionalAccumulator.
            </summary>
            <param name="handle">
               The handle to a SparseConditionalAccumulator.
            </param>
            <param name="num_required">
               Number of gradients required before we return an aggregate.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseAccumulatorTakeGradient'.
            </param>
            <param name="dtype">
               Optional argument
               The data type of accumulated gradients. Needs to correspond to the type
               of the accumulator.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               indices : Indices of the average of the accumulated sparse gradients.
               values : Values of the average of the accumulated sparse gradients.
               shape : Shape of the average of the accumulated sparse gradients.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               The op will blocks until sufficient (i.e., more than num_required)
               gradients have been accumulated. If the accumulator has already
               aggregated more than num_required gradients, it will return its
               average of the accumulated gradients.  Also automatically increments
               the recorded global_step in the accumulator by 1, and resets the
               aggregate to 0.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_add(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Adds two <c>SparseTensor</c> objects to produce another <c>SparseTensor</c>.
            </summary>
            <param name="a_indices">
               2-D.  The <c>indices</c> of the first <c>SparseTensor</c>, size <c>[nnz, ndims]</c> Matrix.
            </param>
            <param name="a_values">
               1-D.  The <c>values</c> of the first <c>SparseTensor</c>, size <c>[nnz]</c> Vector.
            </param>
            <param name="a_shape">
               1-D.  The <c>shape</c> of the first <c>SparseTensor</c>, size <c>[ndims]</c> Vector.
            </param>
            <param name="b_indices">
               2-D.  The <c>indices</c> of the second <c>SparseTensor</c>, size <c>[nnz, ndims]</c> Matrix.
            </param>
            <param name="b_values">
               1-D.  The <c>values</c> of the second <c>SparseTensor</c>, size <c>[nnz]</c> Vector.
            </param>
            <param name="b_shape">
               1-D.  The <c>shape</c> of the second <c>SparseTensor</c>, size <c>[ndims]</c> Vector.
            </param>
            <param name="thresh">
               0-D.  The magnitude threshold that determines if an output value/index
               pair takes space.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseAdd'.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               sum_indices :
               sum_values :
               sum_shape :
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               The input <c>SparseTensor</c> objects' indices are assumed ordered in standard
               lexicographic order.  If this is not the case, before this step run
               <c>SparseReorder</c> to restore index ordering.
               
               By default, if two values sum to zero at some index, the output <c>SparseTensor</c>
               would still include that particular location in its index, storing a zero in the
               corresponding value slot.  To override this, callers can specify <c>thresh</c>,
               indicating that if the sum has a magnitude strictly smaller than <c>thresh</c>, its
               corresponding value and index would then not be included.  In particular,
               <c>thresh == 0</c> (default) means everything is kept and actual thresholding happens
               only for a positive value.
               
               In the following shapes, <c>nnz</c> is the count after taking <c>thresh</c> into account.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_add_grad(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               The gradient operator for the SparseAdd op.
            </summary>
            <param name="backprop_val_grad">
               1-D with shape <c>[nnz(sum)]</c>.  The gradient with respect to
               the non-empty values of the sum.
            </param>
            <param name="a_indices">
               2-D.  The <c>indices</c> of the <c>SparseTensor</c> A, size <c>[nnz(A), ndims]</c>.
            </param>
            <param name="b_indices">
               2-D.  The <c>indices</c> of the <c>SparseTensor</c> B, size <c>[nnz(B), ndims]</c>.
            </param>
            <param name="sum_indices">
               2-D.  The <c>indices</c> of the sum <c>SparseTensor</c>, size
               <c>[nnz(sum), ndims]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseAddGrad'.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               a_val_grad : 1-D with shape <c>[nnz(A)]</c>. The gradient with respect to the
               non-empty values of A.
               b_val_grad : 1-D with shape <c>[nnz(B)]</c>. The gradient with respect to the
               non-empty values of B.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               The SparseAdd op calculates A + B, where A, B, and the sum are all represented
               as <c>SparseTensor</c> objects.  This op takes in the upstream gradient w.r.t.
               non-empty values of the sum, and outputs the gradients w.r.t. the non-empty
               values of A and B.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_apply_adadelta(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               var: Should be from a Variable().
            </summary>
            <param name="var">
            </param>
            <param name="accum">
               Should be from a Variable().
            </param>
            <param name="accum_update">
               : Should be from a Variable().
            </param>
            <param name="lr">
               Learning rate. Must be a scalar.
            </param>
            <param name="rho">
               Decay factor. Must be a scalar.
            </param>
            <param name="epsilon">
               Constant factor. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="indices">
               A vector of indices into the first dimension of var and accum.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseApplyAdadelta'.
            </param>
            <param name="use_locking">
               If True, updating of the var and accum tensors will be protected by
               a lock; otherwise the behavior is undefined, but may exhibit less contention.
            </param>
            <returns>
               Same as "var".
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_apply_adagrad(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.String)">
            <summary>
               Update relevant entries in '*var' and '*accum' according to the adagrad scheme.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="accum">
               Should be from a Variable().
            </param>
            <param name="lr">
               Learning rate. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="indices">
               A vector of indices into the first dimension of var and accum.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseApplyAdagrad'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var and accum tensors will be protected
               by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <param name="update_slots">
            </param>
            <returns>
               Same as "var".
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               That is for rows we have grad for, we update var and accum as follows:
               $$accum += grad * grad$$
               $$var -= lr * grad * (1 / sqrt(accum))$$
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_apply_adagrad_d_a(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update entries in '*var' and '*accum' according to the proximal adagrad scheme.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="gradient_accumulator">
               Should be from a Variable().
            </param>
            <param name="gradient_squared_accumulator">
               Should be from a Variable().
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="indices">
               A vector of indices into the first dimension of var and accum.
            </param>
            <param name="lr">
               Learning rate. Must be a scalar.
            </param>
            <param name="l1">
               L1 regularization. Must be a scalar.
            </param>
            <param name="l2">
               L2 regularization. Must be a scalar.
            </param>
            <param name="global_step">
               Training step number. Must be a scalar.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseApplyAdagradDA'.
            </param>
            <param name="use_locking">
               If True, updating of the var and accum tensors will be protected by
               a lock; otherwise the behavior is undefined, but may exhibit less contention.
            </param>
            <returns>
               Same as "var".
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_apply_centered_r_m_s_prop(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' according to the centered RMSProp algorithm.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="mg">
               Should be from a Variable().
            </param>
            <param name="ms">
               Should be from a Variable().
            </param>
            <param name="mom">
               Should be from a Variable().
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="rho">
               Decay rate. Must be a scalar.
            </param>
            <param name="momentum">
            </param>
            <param name="epsilon">
               Ridge term. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="indices">
               A vector of indices into the first dimension of var, ms and mom.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseApplyCenteredRMSProp'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var, mg, ms, and mom tensors is
               protected by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <returns>
               Same as "var".
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The centered RMSProp algorithm uses an estimate of the centered second moment
               (i.e., the variance) for normalization, as opposed to regular RMSProp, which
               uses the (uncentered) second moment. This often helps with training, but is
               slightly more expensive in terms of computation and memory.
               
               Note that in dense implementation of this algorithm, mg, ms, and mom will
               update even if the grad is zero, but in this sparse implementation, mg, ms,
               and mom will not update in iterations during which the grad is zero.
               
               mean_square = decay * mean_square + (1-decay) * gradient ** 2
               mean_grad = decay * mean_grad + (1-decay) * gradient
               Delta = learning_rate * gradient / sqrt(mean_square + epsilon - mean_grad ** 2)
               
               $$ms &amp;lt;- rho * ms_{t-1} + (1-rho) * grad * grad$$
               $$mom &amp;lt;- momentum * mom_{t-1} + lr * grad / sqrt(ms + epsilon)$$
               $$var &amp;lt;- var - mom$$
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_apply_ftrl(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update relevant entries in '*var' according to the Ftrl-proximal scheme.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="accum">
               Should be from a Variable().
            </param>
            <param name="linear">
               Should be from a Variable().
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="indices">
               A vector of indices into the first dimension of var and accum.
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="l1">
               L1 regularization. Must be a scalar.
            </param>
            <param name="l2">
               L2 regularization. Must be a scalar.
            </param>
            <param name="lr_power">
               Scaling factor. Must be a scalar.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseApplyFtrl'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var and accum tensors will be protected
               by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <returns>
               Same as "var".
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               That is for rows we have grad for, we update var, accum and linear as follows:
               $$accum_new = accum + grad * grad$$
               $$linear += grad + (accum_{new}^{-lr_{power}} - accum^{-lr_{power}} / lr * var$$
               $$quadratic = 1.0 / (accum_{new}^{lr_{power}} * lr) + 2 * l2$$
               $$var = (sign(linear) * l1 - linear) / quadratic\ if\ |linear| &amp;gt; l1\ else\ 0.0$$
               $$accum = accum_{new}$$
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_apply_ftrl_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update relevant entries in '*var' according to the Ftrl-proximal scheme.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="accum">
               Should be from a Variable().
            </param>
            <param name="linear">
               Should be from a Variable().
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="indices">
               A vector of indices into the first dimension of var and accum.
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="l1">
               L1 regularization. Must be a scalar.
            </param>
            <param name="l2">
               L2 shrinkage regulariation. Must be a scalar.
            </param>
            <param name="l2_shrinkage">
            </param>
            <param name="lr_power">
               Scaling factor. Must be a scalar.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseApplyFtrlV2'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var and accum tensors will be protected
               by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <returns>
               Same as "var".
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               That is for rows we have grad for, we update var, accum and linear as follows:
               grad_with_shrinkage = grad + 2 * l2_shrinkage * var
               accum_new = accum + grad_with_shrinkage * grad_with_shrinkage
               linear += grad_with_shrinkage +
               (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var
               quadratic = 1.0 / (accum_new^(lr_power) * lr) + 2 * l2
               var = (sign(linear) * l1 - linear) / quadratic if |linear| &amp;gt; l1 else 0.0
               accum = accum_new
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_apply_momentum(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.String)">
            <summary>
               Update relevant entries in '*var' and '*accum' according to the momentum scheme.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="accum">
               Should be from a Variable().
            </param>
            <param name="lr">
               Learning rate. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="indices">
               A vector of indices into the first dimension of var and accum.
            </param>
            <param name="momentum">
               Momentum. Must be a scalar.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseApplyMomentum'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var and accum tensors will be protected
               by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <param name="use_nesterov">
               If <c>True</c>, the tensor passed to compute grad will be
               var - lr * momentum * accum, so in the end, the var you get is actually
               var - lr * momentum * accum.
            </param>
            <returns>
               Same as "var".
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Set use_nesterov = True if you want to use Nesterov momentum.
               
               That is for rows we have grad for, we update var and accum as follows:
               
               $$accum = accum * momentum + grad$$
               $$var -= lr * accum$$
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_apply_proximal_adagrad(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Sparse update entries in '*var' and '*accum' according to FOBOS algorithm.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="accum">
               Should be from a Variable().
            </param>
            <param name="lr">
               Learning rate. Must be a scalar.
            </param>
            <param name="l1">
               L1 regularization. Must be a scalar.
            </param>
            <param name="l2">
               L2 regularization. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="indices">
               A vector of indices into the first dimension of var and accum.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseApplyProximalAdagrad'.
            </param>
            <param name="use_locking">
               If True, updating of the var and accum tensors will be protected by
               a lock; otherwise the behavior is undefined, but may exhibit less contention.
            </param>
            <returns>
               Same as "var".
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               That is for rows we have grad for, we update var and accum as follows:
               $$accum += grad * grad$$
               $$prox_v = var$$
               $$prox_v -= lr * grad * (1 / sqrt(accum))$$
               $$var = sign(prox_v)/(1+lr*l2) * max{|prox_v|-lr*l1,0}$$
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_apply_proximal_gradient_descent(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Sparse update '*var' as FOBOS algorithm with fixed learning rate.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="alpha">
               Scaling factor. Must be a scalar.
            </param>
            <param name="l1">
               L1 regularization. Must be a scalar.
            </param>
            <param name="l2">
               L2 regularization. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="indices">
               A vector of indices into the first dimension of var and accum.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseApplyProximalGradientDescent'.
            </param>
            <param name="use_locking">
               If True, the subtraction will be protected by a lock;
               otherwise the behavior is undefined, but may exhibit less contention.
            </param>
            <returns>
               Same as "var".
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               That is for rows we have grad for, we update var as follows:
               $$prox_v = var - alpha * grad$$
               $$var = sign(prox_v)/(1+alpha*l2) * max{|prox_v|-alpha*l1,0}$$
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_apply_r_m_s_prop(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Update '*var' according to the RMSProp algorithm.
            </summary>
            <param name="var">
               Should be from a Variable().
            </param>
            <param name="ms">
               Should be from a Variable().
            </param>
            <param name="mom">
               Should be from a Variable().
            </param>
            <param name="lr">
               Scaling factor. Must be a scalar.
            </param>
            <param name="rho">
               Decay rate. Must be a scalar.
            </param>
            <param name="momentum">
            </param>
            <param name="epsilon">
               Ridge term. Must be a scalar.
            </param>
            <param name="grad">
               The gradient.
            </param>
            <param name="indices">
               A vector of indices into the first dimension of var, ms and mom.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseApplyRMSProp'.
            </param>
            <param name="use_locking">
               If <c>True</c>, updating of the var, ms, and mom tensors is protected
               by a lock; otherwise the behavior is undefined, but may exhibit less
               contention.
            </param>
            <returns>
               Same as "var".
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Note that in dense implementation of this algorithm, ms and mom will
               update even if the grad is zero, but in this sparse implementation, ms
               and mom will not update in iterations during which the grad is zero.
               
               mean_square = decay * mean_square + (1-decay) * gradient ** 2
               Delta = learning_rate * gradient / sqrt(mean_square + epsilon)
               
               $$ms &amp;lt;- rho * ms_{t-1} + (1-rho) * grad * grad$$
               $$mom &amp;lt;- momentum * mom_{t-1} + lr * grad / sqrt(ms + epsilon)$$
               $$var &amp;lt;- var - mom$$
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_concat(Tensorflow.Tensor[],Tensorflow.Tensor[],Tensorflow.Tensor[],System.Int32,System.String)">
            <summary>
               Concatenates a list of <c>SparseTensor</c> along the specified dimension.
            </summary>
            <param name="indices">
               2-D.  Indices of each input <c>SparseTensor</c>.
            </param>
            <param name="values">
               1-D.  Non-empty values of each <c>SparseTensor</c>.
            </param>
            <param name="shapes">
               1-D.  Shapes of each <c>SparseTensor</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseConcat'.
            </param>
            <param name="concat_dim">
               Optional argument
               Dimension to concatenate along. Must be in range [-rank, rank),
               where rank is the number of dimensions in each input <c>SparseTensor</c>.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output_indices : 2-D.  Indices of the concatenated <c>SparseTensor</c>.
               output_values : 1-D.  Non-empty values of the concatenated <c>SparseTensor</c>.
               output_shape : 1-D.  Shape of the concatenated <c>SparseTensor</c>.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Concatenation is with respect to the dense versions of these sparse tensors.
               It is assumed that each input is a <c>SparseTensor</c> whose elements are ordered
               along increasing dimension number.
               
               All inputs' shapes must match, except for the concat dimension.  The
               <c>indices</c>, <c>values</c>, and <c>shapes</c> lists must have the same length.
               
               The output shape is identical to the inputs', except along the concat
               dimension, where it is the sum of the inputs' sizes along that dimension.
               
               The output elements will be resorted to preserve the sort order along
               increasing dimension number.
               
               This op runs in <c>O(M log M)</c> time, where <c>M</c> is the total number of non-empty
               values across all inputs. This is due to the need for an internal sort in
               order to concatenate efficiently across an arbitrary dimension.
               
               For example, if <c>concat_dim = 1</c> and the inputs are
               
               sp_inputs[0]: shape = [2, 3]
               [0, 2]: "a"
               [1, 0]: "b"
               [1, 1]: "c"
               
               sp_inputs[1]: shape = [2, 4]
               [0, 1]: "d"
               [0, 2]: "e"
               
               then the output will be
               
               shape = [2, 7]
               [0, 2]: "a"
               [0, 4]: "d"
               [0, 5]: "e"
               [1, 0]: "b"
               [1, 1]: "c"
               
               Graphically this is equivalent to doing
               
               [    a] concat [  d e  ] = [    a   d e  ]
               [b c  ]        [       ]   [b c          ]
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_conditional_accumulator(Tensorflow.TF_DataType,Tensorflow.TensorShape,System.String,System.String,System.String)">
            <summary>
               A conditional accumulator for aggregating sparse gradients.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseConditionalAccumulator'.
            </param>
            <param name="dtype">
               Optional argument
               The type of the value being accumulated.
            </param>
            <param name="shape">
               Optional argument
               The shape of the values.
            </param>
            <param name="container">
               If non-empty, this accumulator is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this accumulator will be shared under the given name
               across multiple sessions.
            </param>
            <returns>
               The handle to the accumulator.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The accumulator accepts gradients marked with local_step greater or
               equal to the most recent global_step known to the accumulator. The
               average can be extracted from the accumulator, provided sufficient
               gradients have been accumulated. Extracting the average automatically
               resets the aggregate to 0, and increments the global_step recorded by
               the accumulator.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_cross(Tensorflow.Tensor[],Tensorflow.Tensor[],Tensorflow.Tensor[],Tensorflow.Tensor[],System.Boolean,System.Int32,System.Int32,Tensorflow.TF_DataType,Tensorflow.TF_DataType,System.String)">
            <summary>
               Generates sparse cross from a list of sparse and dense tensors.
            </summary>
            <param name="indices">
               2-D.  Indices of each input <c>SparseTensor</c>.
            </param>
            <param name="values">
               1-D.   values of each <c>SparseTensor</c>.
            </param>
            <param name="shapes">
               1-D.   Shapes of each <c>SparseTensor</c>.
            </param>
            <param name="dense_inputs">
               2-D.    Columns represented by dense <c>Tensor</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseCross'.
            </param>
            <param name="hashed_output">
               Optional argument
               If true, returns the hash of the cross instead of the string.
               This will allow us avoiding string manipulations.
            </param>
            <param name="num_buckets">
               Optional argument
               It is used if hashed_output is true.
               output = hashed_value%num_buckets if num_buckets &amp;gt; 0 else hashed_value.
            </param>
            <param name="hash_key">
               Optional argument
               Specify the hash_key that will be used by the <c>FingerprintCat64</c>
               function to combine the crosses fingerprints.
            </param>
            <param name="out_type">
               Optional argument
            </param>
            <param name="internal_type">
               Optional argument
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output_indices : 2-D.  Indices of the concatenated <c>SparseTensor</c>.
               output_values : 1-D.  Non-empty values of the concatenated or hashed
               <c>SparseTensor</c>.
               output_shape : 1-D.  Shape of the concatenated <c>SparseTensor</c>.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               The op takes two lists, one of 2D <c>SparseTensor</c> and one of 2D <c>Tensor</c>, each
               representing features of one feature column. It outputs a 2D <c>SparseTensor</c> with
               the batchwise crosses of these features.
               
               For example, if the inputs are
               
               inputs[0]: SparseTensor with shape = [2, 2]
               [0, 0]: "a"
               [1, 0]: "b"
               [1, 1]: "c"
               
               inputs[1]: SparseTensor with shape = [2, 1]
               [0, 0]: "d"
               [1, 0]: "e"
               
               inputs[2]: Tensor [["f"], ["g"]]
               
               then the output will be
               
               shape = [2, 2]
               [0, 0]: "a_X_d_X_f"
               [1, 0]: "b_X_e_X_g"
               [1, 1]: "c_X_e_X_g"
               
               if hashed_output=true then the output will be
               
               shape = [2, 2]
               [0, 0]: FingerprintCat64(
               Fingerprint64("f"), FingerprintCat64(
               Fingerprint64("d"), Fingerprint64("a")))
               [1, 0]: FingerprintCat64(
               Fingerprint64("g"), FingerprintCat64(
               Fingerprint64("e"), Fingerprint64("b")))
               [1, 1]: FingerprintCat64(
               Fingerprint64("g"), FingerprintCat64(
               Fingerprint64("e"), Fingerprint64("c")))
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_dense_cwise_add(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Adds up a SparseTensor and a dense Tensor, using these special rules:
            </summary>
            <param name="sp_indices">
               2-D.  <c>N x R</c> matrix with the indices of non-empty values in a
               SparseTensor, possibly not in canonical ordering.
            </param>
            <param name="sp_values">
               1-D.  <c>N</c> non-empty values corresponding to <c>sp_indices</c>.
            </param>
            <param name="sp_shape">
               1-D.  Shape of the input SparseTensor.
            </param>
            <param name="dense">
               <c>R</c>-D.  The dense Tensor operand.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseDenseCwiseAdd'.
            </param>
            <returns>
               1-D.  The <c>N</c> values that are operated on.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               (1) Broadcasts the dense side to have the same shape as the sparse side, if
               eligible;
               (2) Then, only the dense values pointed to by the indices of the SparseTensor
               participate in the cwise addition.
               
               By these rules, the result is a logical SparseTensor with exactly the same
               indices and shape, but possibly with different non-zero values.  The output of
               this Op is the resultant non-zero values.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_dense_cwise_div(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Component-wise divides a SparseTensor by a dense Tensor.
            </summary>
            <param name="sp_indices">
               2-D.  <c>N x R</c> matrix with the indices of non-empty values in a
               SparseTensor, possibly not in canonical ordering.
            </param>
            <param name="sp_values">
               1-D.  <c>N</c> non-empty values corresponding to <c>sp_indices</c>.
            </param>
            <param name="sp_shape">
               1-D.  Shape of the input SparseTensor.
            </param>
            <param name="dense">
               <c>R</c>-D.  The dense Tensor operand.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseDenseCwiseDiv'.
            </param>
            <returns>
               1-D.  The <c>N</c> values that are operated on.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               *Limitation*: this Op only broadcasts the dense side to the sparse side, but not
               the other direction.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_dense_cwise_mul(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Component-wise multiplies a SparseTensor by a dense Tensor.
            </summary>
            <param name="sp_indices">
               2-D.  <c>N x R</c> matrix with the indices of non-empty values in a
               SparseTensor, possibly not in canonical ordering.
            </param>
            <param name="sp_values">
               1-D.  <c>N</c> non-empty values corresponding to <c>sp_indices</c>.
            </param>
            <param name="sp_shape">
               1-D.  Shape of the input SparseTensor.
            </param>
            <param name="dense">
               <c>R</c>-D.  The dense Tensor operand.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseDenseCwiseMul'.
            </param>
            <returns>
               1-D.  The <c>N</c> values that are operated on.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The output locations corresponding to the implicitly zero elements in the sparse
               tensor will be zero (i.e., will not take up storage space), regardless of the
               contents of the dense tensor (even if it's +/-INF and that INF*0 == NaN).
               
               *Limitation*: this Op only broadcasts the dense side to the sparse side, but not
               the other direction.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_fill_empty_rows(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Fills empty rows in the input 2-D <c>SparseTensor</c> with a default value.
            </summary>
            <param name="indices">
               2-D. the indices of the sparse tensor.
            </param>
            <param name="values">
               1-D. the values of the sparse tensor.
            </param>
            <param name="dense_shape">
               1-D. the shape of the sparse tensor.
            </param>
            <param name="default_value">
               0-D. default value to insert into location <c>[row, 0, ..., 0]</c>
               for rows missing from the input sparse tensor.
               output indices: 2-D. the indices of the filled sparse tensor.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseFillEmptyRows'.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output_indices :
               output_values : 1-D. the values of the filled sparse tensor.
               empty_row_indicator : 1-D. whether the dense row was missing in the
               input sparse tensor.
               reverse_index_map : 1-D. a map from the input indices to the output indices.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               The input <c>SparseTensor</c> is represented via the tuple of inputs
               (<c>indices</c>, <c>values</c>, <c>dense_shape</c>).  The output <c>SparseTensor</c> has the
               same <c>dense_shape</c> but with indices <c>output_indices</c> and values
               <c>output_values</c>.
               
               This op inserts a single entry for every row that doesn't have any values.
               The index is created as <c>[row, 0, ..., 0]</c> and the inserted value
               is <c>default_value</c>.
               
               For example, suppose <c>sp_input</c> has shape <c>[5, 6]</c> and non-empty values:
               
               [0, 1]: a
               [0, 3]: b
               [2, 0]: c
               [3, 1]: d
               
               Rows 1 and 4 are empty, so the output will be of shape <c>[5, 6]</c> with values:
               
               [0, 1]: a
               [0, 3]: b
               [1, 0]: default_value
               [2, 0]: c
               [3, 1]: d
               [4, 0]: default_value
               
               The output <c>SparseTensor</c> will be in row-major order and will have the
               same shape as the input.
               
               This op also returns an indicator vector shaped <c>[dense_shape[0]]</c> such that
               
               empty_row_indicator[i] = True iff row i was an empty row.
               
               And a reverse index map vector shaped <c>[indices.shape[0]]</c> that is used during
               backpropagation,
               
               reverse_index_map[j] = out_j s.t. indices[j, :] == output_indices[out_j, :]
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_fill_empty_rows_grad(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               The gradient of SparseFillEmptyRows.
            </summary>
            <param name="reverse_index_map">
               1-D.  The reverse index map from SparseFillEmptyRows.
            </param>
            <param name="grad_values">
               1-D.  The gradients from backprop.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseFillEmptyRowsGrad'.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               d_values : 1-D.  The backprop into values.
               d_default_value : 0-D.  The backprop into default_value.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Takes vectors reverse_index_map, shaped <c>[N]</c>, and grad_values,
               shaped <c>[N_full]</c>, where <c>N_full &amp;gt;= N</c> and copies data into either
               <c>d_values</c> or <c>d_default_value</c>.  Here <c>d_values</c> is shaped <c>[N]</c> and
               <c>d_default_value</c> is a scalar.
               
               d_values[j] = grad_values[reverse_index_map[j]]
               d_default_value = sum_{k : 0 .. N_full - 1} (
               grad_values[k] * 1{k not in reverse_index_map})
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_mat_mul(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.String)">
            <summary>
               Multiply matrix "a" by matrix "b".
            </summary>
            <param name="a">
            </param>
            <param name="b">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseMatMul'.
            </param>
            <param name="transpose_a">
            </param>
            <param name="transpose_b">
            </param>
            <param name="a_is_sparse">
            </param>
            <param name="b_is_sparse">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The inputs must be two-dimensional matrices and the inner dimension of "a" must
               match the outer dimension of "b". Both "a" and "b" must be <c>Tensor</c>s not
               <c>SparseTensor</c>s.  This op is optimized for the case where at least one of "a" or
               "b" is sparse, in the sense that they have a large proportion of zero values.
               The breakeven for using this versus a dense matrix multiply on one platform was
               30% zero values in the sparse matrix.
               
               The gradient computation of this operation will only take advantage of sparsity
               in the input gradient when that gradient comes from a Relu.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_reduce_max(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Computes the max of elements across dimensions of a SparseTensor.
            </summary>
            <param name="input_indices">
               2-D.  <c>N x R</c> matrix with the indices of non-empty values in a
               SparseTensor, possibly not in canonical ordering.
            </param>
            <param name="input_values">
               1-D.  <c>N</c> non-empty values corresponding to <c>input_indices</c>.
            </param>
            <param name="input_shape">
               1-D.  Shape of the input SparseTensor.
            </param>
            <param name="reduction_axes">
               1-D.  Length-<c>K</c> vector containing the reduction axes.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseReduceMax'.
            </param>
            <param name="keep_dims">
               If true, retain reduced dimensions with length 1.
            </param>
            <returns>
               <c>R-K</c>-D.  The reduced Tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This Op takes a SparseTensor and is the sparse counterpart to
               <c>tf.reduce_max()</c>.  In particular, this Op also returns a dense <c>Tensor</c>
               instead of a sparse one.
               
               Reduces <c>sp_input</c> along the dimensions given in <c>reduction_axes</c>.  Unless
               <c>keep_dims</c> is true, the rank of the tensor is reduced by 1 for each entry in
               <c>reduction_axes</c>. If <c>keep_dims</c> is true, the reduced dimensions are retained
               with length 1.
               
               If <c>reduction_axes</c> has no entries, all dimensions are reduced, and a tensor
               with a single element is returned.  Additionally, the axes can be negative,
               which are interpreted according to the indexing rules in Python.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_reduce_max_sparse(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Computes the max of elements across dimensions of a SparseTensor.
            </summary>
            <param name="input_indices">
               2-D.  <c>N x R</c> matrix with the indices of non-empty values in a
               SparseTensor, possibly not in canonical ordering.
            </param>
            <param name="input_values">
               1-D.  <c>N</c> non-empty values corresponding to <c>input_indices</c>.
            </param>
            <param name="input_shape">
               1-D.  Shape of the input SparseTensor.
            </param>
            <param name="reduction_axes">
               1-D.  Length-<c>K</c> vector containing the reduction axes.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseReduceMaxSparse'.
            </param>
            <param name="keep_dims">
               If true, retain reduced dimensions with length 1.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output_indices :
               output_values :
               output_shape :
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               This Op takes a SparseTensor and is the sparse counterpart to
               <c>tf.reduce_max()</c>.  In contrast to SparseReduceMax, this Op returns a
               SparseTensor.
               
               Reduces <c>sp_input</c> along the dimensions given in <c>reduction_axes</c>.  Unless
               <c>keep_dims</c> is true, the rank of the tensor is reduced by 1 for each entry in
               <c>reduction_axes</c>. If <c>keep_dims</c> is true, the reduced dimensions are retained
               with length 1.
               
               If <c>reduction_axes</c> has no entries, all dimensions are reduced, and a tensor
               with a single element is returned.  Additionally, the axes can be negative,
               which are interpreted according to the indexing rules in Python.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_reduce_sum(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Computes the sum of elements across dimensions of a SparseTensor.
            </summary>
            <param name="input_indices">
               2-D.  <c>N x R</c> matrix with the indices of non-empty values in a
               SparseTensor, possibly not in canonical ordering.
            </param>
            <param name="input_values">
               1-D.  <c>N</c> non-empty values corresponding to <c>input_indices</c>.
            </param>
            <param name="input_shape">
               1-D.  Shape of the input SparseTensor.
            </param>
            <param name="reduction_axes">
               1-D.  Length-<c>K</c> vector containing the reduction axes.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseReduceSum'.
            </param>
            <param name="keep_dims">
               If true, retain reduced dimensions with length 1.
            </param>
            <returns>
               <c>R-K</c>-D.  The reduced Tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This Op takes a SparseTensor and is the sparse counterpart to
               <c>tf.reduce_sum()</c>.  In particular, this Op also returns a dense <c>Tensor</c>
               instead of a sparse one.
               
               Reduces <c>sp_input</c> along the dimensions given in <c>reduction_axes</c>.  Unless
               <c>keep_dims</c> is true, the rank of the tensor is reduced by 1 for each entry in
               <c>reduction_axes</c>. If <c>keep_dims</c> is true, the reduced dimensions are retained
               with length 1.
               
               If <c>reduction_axes</c> has no entries, all dimensions are reduced, and a tensor
               with a single element is returned.  Additionally, the axes can be negative,
               which are interpreted according to the indexing rules in Python.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_reduce_sum_sparse(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Computes the sum of elements across dimensions of a SparseTensor.
            </summary>
            <param name="input_indices">
               2-D.  <c>N x R</c> matrix with the indices of non-empty values in a
               SparseTensor, possibly not in canonical ordering.
            </param>
            <param name="input_values">
               1-D.  <c>N</c> non-empty values corresponding to <c>input_indices</c>.
            </param>
            <param name="input_shape">
               1-D.  Shape of the input SparseTensor.
            </param>
            <param name="reduction_axes">
               1-D.  Length-<c>K</c> vector containing the reduction axes.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseReduceSumSparse'.
            </param>
            <param name="keep_dims">
               If true, retain reduced dimensions with length 1.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output_indices :
               output_values :
               output_shape :
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               This Op takes a SparseTensor and is the sparse counterpart to
               <c>tf.reduce_sum()</c>.  In contrast to SparseReduceSum, this Op returns a
               SparseTensor.
               
               Reduces <c>sp_input</c> along the dimensions given in <c>reduction_axes</c>.  Unless
               <c>keep_dims</c> is true, the rank of the tensor is reduced by 1 for each entry in
               <c>reduction_axes</c>. If <c>keep_dims</c> is true, the reduced dimensions are retained
               with length 1.
               
               If <c>reduction_axes</c> has no entries, all dimensions are reduced, and a tensor
               with a single element is returned.  Additionally, the axes can be negative,
               which are interpreted according to the indexing rules in Python.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_reorder(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Reorders a SparseTensor into the canonical, row-major ordering.
            </summary>
            <param name="input_indices">
               2-D.  <c>N x R</c> matrix with the indices of non-empty values in a
               SparseTensor, possibly not in canonical ordering.
            </param>
            <param name="input_values">
               1-D.  <c>N</c> non-empty values corresponding to <c>input_indices</c>.
            </param>
            <param name="input_shape">
               1-D.  Shape of the input SparseTensor.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseReorder'.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output_indices : 2-D.  <c>N x R</c> matrix with the same indices as input_indices, but
               in canonical row-major ordering.
               output_values : 1-D.  <c>N</c> non-empty values corresponding to <c>output_indices</c>.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Note that by convention, all sparse ops preserve the canonical ordering along
               increasing dimension number. The only time ordering can be violated is during
               manual manipulation of the indices and values vectors to add entries.
               
               Reordering does not affect the shape of the SparseTensor.
               
               If the tensor has rank <c>R</c> and <c>N</c> non-empty values, <c>input_indices</c> has
               shape <c>[N, R]</c>, input_values has length <c>N</c>, and input_shape has length <c>R</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_reshape(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Reshapes a SparseTensor to represent values in a new dense shape.
            </summary>
            <param name="input_indices">
               2-D.  <c>N x R_in</c> matrix with the indices of non-empty values in a
               SparseTensor.
            </param>
            <param name="input_shape">
               1-D.  <c>R_in</c> vector with the input SparseTensor's dense shape.
            </param>
            <param name="new_shape">
               1-D.  <c>R_out</c> vector with the requested new dense shape.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseReshape'.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output_indices : 2-D.  <c>N x R_out</c> matrix with the updated indices of non-empty
               values in the output SparseTensor.
               output_shape : 1-D.  <c>R_out</c> vector with the full dense shape of the output
               SparseTensor.  This is the same as <c>new_shape</c> but with any -1 dimensions
               filled in.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               This operation has the same semantics as reshape on the represented dense
               tensor.  The <c>input_indices</c> are recomputed based on the requested <c>new_shape</c>.
               
               If one component of <c>new_shape</c> is the special value -1, the size of that
               dimension is computed so that the total dense size remains constant.  At
               most one component of <c>new_shape</c> can be -1.  The number of dense elements
               implied by <c>new_shape</c> must be the same as the number of dense elements
               originally implied by <c>input_shape</c>.
               
               Reshaping does not affect the order of values in the SparseTensor.
               
               If the input tensor has rank <c>R_in</c> and <c>N</c> non-empty values, and <c>new_shape</c>
               has length <c>R_out</c>, then <c>input_indices</c> has shape <c>[N, R_in]</c>,
               <c>input_shape</c> has length <c>R_in</c>, <c>output_indices</c> has shape <c>[N, R_out]</c>, and
               <c>output_shape</c> has length <c>R_out</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_segment_mean(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes the mean along sparse segments of a tensor.
            </summary>
            <param name="data">
            </param>
            <param name="indices">
               A 1-D tensor. Has same rank as <c>segment_ids</c>.
            </param>
            <param name="segment_ids">
               A 1-D tensor. Values should be sorted and can be repeated.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseSegmentMean'.
            </param>
            <returns>
               Has same shape as data, except for dimension 0 which
               has size <c>k</c>, the number of segments.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Read
               [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#Segmentation)
               for an explanation of segments.
               
               Like <c>SegmentMean</c>, but <c>segment_ids</c> can have rank less than <c>data</c>'s first
               dimension, selecting a subset of dimension 0, specified by <c>indices</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_segment_mean_grad(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes gradients for SparseSegmentMean.
            </summary>
            <param name="grad">
               gradient propagated to the SparseSegmentMean op.
            </param>
            <param name="indices">
               indices passed to the corresponding SparseSegmentMean op.
            </param>
            <param name="segment_ids">
               segment_ids passed to the corresponding SparseSegmentMean op.
            </param>
            <param name="output_dim0">
               dimension 0 of "data" passed to SparseSegmentMean op.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseSegmentMeanGrad'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Returns tensor "output" with same shape as grad, except for dimension 0 whose
               value is output_dim0.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_segment_mean_with_num_segments(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes the mean along sparse segments of a tensor.
            </summary>
            <param name="data">
            </param>
            <param name="indices">
               A 1-D tensor. Has same rank as <c>segment_ids</c>.
            </param>
            <param name="segment_ids">
               A 1-D tensor. Values should be sorted and can be repeated.
            </param>
            <param name="num_segments">
               Should equal the number of distinct segment IDs.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseSegmentMeanWithNumSegments'.
            </param>
            <returns>
               Has same shape as data, except for dimension 0 which has size
               <c>num_segments</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Like <c>SparseSegmentMean</c>, but allows missing ids in <c>segment_ids</c>. If an id is
               misisng, the <c>output</c> tensor at that position will be zeroed.
               
               Read
               [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#Segmentation)
               for an explanation of segments.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_segment_sqrt_n(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes the sum along sparse segments of a tensor divided by the sqrt of N.
            </summary>
            <param name="data">
            </param>
            <param name="indices">
               A 1-D tensor. Has same rank as <c>segment_ids</c>.
            </param>
            <param name="segment_ids">
               A 1-D tensor. Values should be sorted and can be repeated.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseSegmentSqrtN'.
            </param>
            <returns>
               Has same shape as data, except for dimension 0 which
               has size <c>k</c>, the number of segments.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               N is the size of the segment being reduced.
               
               Read
               [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#Segmentation)
               for an explanation of segments.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_segment_sqrt_n_grad(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes gradients for SparseSegmentSqrtN.
            </summary>
            <param name="grad">
               gradient propagated to the SparseSegmentSqrtN op.
            </param>
            <param name="indices">
               indices passed to the corresponding SparseSegmentSqrtN op.
            </param>
            <param name="segment_ids">
               segment_ids passed to the corresponding SparseSegmentSqrtN op.
            </param>
            <param name="output_dim0">
               dimension 0 of "data" passed to SparseSegmentSqrtN op.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseSegmentSqrtNGrad'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Returns tensor "output" with same shape as grad, except for dimension 0 whose
               value is output_dim0.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_segment_sqrt_n_with_num_segments(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes the sum along sparse segments of a tensor divided by the sqrt of N.
            </summary>
            <param name="data">
            </param>
            <param name="indices">
               A 1-D tensor. Has same rank as <c>segment_ids</c>.
            </param>
            <param name="segment_ids">
               A 1-D tensor. Values should be sorted and can be repeated.
            </param>
            <param name="num_segments">
               Should equal the number of distinct segment IDs.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseSegmentSqrtNWithNumSegments'.
            </param>
            <returns>
               Has same shape as data, except for dimension 0 which
               has size <c>k</c>, the number of segments.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               N is the size of the segment being reduced.
               
               Like <c>SparseSegmentSqrtN</c>, but allows missing ids in <c>segment_ids</c>. If an id is
               misisng, the <c>output</c> tensor at that position will be zeroed.
               
               Read
               [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#Segmentation)
               for an explanation of segments.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_segment_sum(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes the sum along sparse segments of a tensor.
            </summary>
            <param name="data">
            </param>
            <param name="indices">
               A 1-D tensor. Has same rank as <c>segment_ids</c>.
            </param>
            <param name="segment_ids">
               A 1-D tensor. Values should be sorted and can be repeated.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseSegmentSum'.
            </param>
            <returns>
               Has same shape as data, except for dimension 0 which
               has size <c>k</c>, the number of segments.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Read
               [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#Segmentation)
               for an explanation of segments.
               
               Like <c>SegmentSum</c>, but <c>segment_ids</c> can have rank less than <c>data</c>'s first
               dimension, selecting a subset of dimension 0, specified by <c>indices</c>.
               
               For example:
               
              <code>
               c = tf.constant([[1,2,3,4], [-1,-2,-3,-4], [5,6,7,8]])
               
               # Select two rows, one segment.
               tf.sparse_segment_sum(c, tf.constant([0, 1]), tf.constant([0, 0]))
               # =&amp;gt; [[0 0 0 0]]
               
               # Select two rows, two segment.
               tf.sparse_segment_sum(c, tf.constant([0, 1]), tf.constant([0, 1]))
               # =&amp;gt; [[ 1  2  3  4]
               #     [-1 -2 -3 -4]]
               
               # Select all rows, two segments.
               tf.sparse_segment_sum(c, tf.constant([0, 1, 2]), tf.constant([0, 0, 1]))
               # =&amp;gt; [[0 0 0 0]
               #     [5 6 7 8]]
               
               # Which is equivalent to:
               tf.segment_sum(c, tf.constant([0, 0, 1]))
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_segment_sum_with_num_segments(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes the sum along sparse segments of a tensor.
            </summary>
            <param name="data">
            </param>
            <param name="indices">
               A 1-D tensor. Has same rank as <c>segment_ids</c>.
            </param>
            <param name="segment_ids">
               A 1-D tensor. Values should be sorted and can be repeated.
            </param>
            <param name="num_segments">
               Should equal the number of distinct segment IDs.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseSegmentSumWithNumSegments'.
            </param>
            <returns>
               Has same shape as data, except for dimension 0 which
               has size <c>num_segments</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Like <c>SparseSegmentSum</c>, but allows missing ids in <c>segment_ids</c>. If an id is
               misisng, the <c>output</c> tensor at that position will be zeroed.
               
               Read
               [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#Segmentation)
               for an explanation of segments.
               
               For example:
               
              <code>
               c = tf.constant([[1,2,3,4], [-1,-2,-3,-4], [5,6,7,8]])
               
               tf.sparse_segment_sum_with_num_segments(
               c, tf.constant([0, 1]), tf.constant([0, 0]), num_segments=3)
               # =&amp;gt; [[0 0 0 0]
               #     [0 0 0 0]
               #     [0 0 0 0]]
               
               tf.sparse_segment_sum_with_num_segments(c,
               tf.constant([0, 1]),
               tf.constant([0, 2],
               num_segments=4))
               # =&amp;gt; [[ 1  2  3  4]
               #     [ 0  0  0  0]
               #     [-1 -2 -3 -4]
               #     [ 0  0  0  0]]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_slice(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Slice a <c>SparseTensor</c> based on the <c>start</c> and <c>size</c>.
            </summary>
            <param name="indices">
               2-D tensor represents the indices of the sparse tensor.
            </param>
            <param name="values">
               1-D tensor represents the values of the sparse tensor.
            </param>
            <param name="shape">
               1-D. tensor represents the shape of the sparse tensor.
            </param>
            <param name="start">
               1-D. tensor represents the start of the slice.
            </param>
            <param name="size">
               1-D. tensor represents the size of the slice.
               output indices: A list of 1-D tensors represents the indices of the output
               sparse tensors.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseSlice'.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output_indices :
               output_values : A list of 1-D tensors represents the values of the output sparse
               tensors.
               output_shape : A list of 1-D tensors represents the shape of the output sparse
               tensors.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               For example, if the input is
               
               input_tensor = shape = [2, 7]
               [    a   d e  ]
               [b c          ]
               
               Graphically the output tensors are:
               
               sparse_slice([0, 0], [2, 4]) = shape = [2, 4]
               [    a  ]
               [b c    ]
               
               sparse_slice([0, 4], [2, 3]) = shape = [2, 3]
               [ d e  ]
               [      ]
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_slice_grad(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               The gradient operator for the SparseSlice op.
            </summary>
            <param name="backprop_val_grad">
               1-D. The gradient with respect to
               the non-empty values of the sliced <c>SparseTensor</c>.
            </param>
            <param name="input_indices">
               2-D.  The <c>indices</c> of the input <c>SparseTensor</c>.
            </param>
            <param name="input_start">
               1-D. tensor represents the start of the slice.
            </param>
            <param name="output_indices">
               2-D.  The <c>indices</c> of the sliced <c>SparseTensor</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseSliceGrad'.
            </param>
            <returns>
               1-D. The gradient with respect to the non-empty values of input <c>SparseTensor</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This op takes in the upstream gradient w.r.t. non-empty values of
               the sliced <c>SparseTensor</c>, and outputs the gradients w.r.t.
               the non-empty values of input <c>SparseTensor</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_softmax(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Applies softmax to a batched N-D <c>SparseTensor</c>.
            </summary>
            <param name="sp_indices">
               2-D.  <c>NNZ x R</c> matrix with the indices of non-empty values in a
               SparseTensor, in canonical ordering.
            </param>
            <param name="sp_values">
               1-D.  <c>NNZ</c> non-empty values corresponding to <c>sp_indices</c>.
            </param>
            <param name="sp_shape">
               1-D.  Shape of the input SparseTensor.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseSoftmax'.
            </param>
            <returns>
               1-D.  The <c>NNZ</c> values for the result <c>SparseTensor</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The inputs represent an N-D SparseTensor  with logical shape <c>[..., B, C]</c>
               (where <c>N &amp;gt;= 2</c>), and with indices sorted in the canonical lexicographic order.
               
               This op is equivalent to applying the normal <c>tf.nn.softmax()</c> to each innermost
               logical submatrix with shape <c>[B, C]</c>, but with the catch that *the implicitly
               zero elements do not participate*.  Specifically, the algorithm is equivalent
               to the following:
               
               (1) Applies <c>tf.nn.softmax()</c> to a densified view of each innermost submatrix
               with shape <c>[B, C]</c>, along the size-C dimension;
               (2) Masks out the original implicitly-zero locations;
               (3) Renormalizes the remaining elements.
               
               Hence, the <c>SparseTensor</c> result has exactly the same non-zero indices and
               shape.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_softmax_cross_entropy_with_logits(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes softmax cross entropy cost and gradients to backpropagate.
            </summary>
            <param name="features">
               batch_size x num_classes matrix
            </param>
            <param name="labels">
               batch_size vector with values in [0, num_classes).
               This is the label for the given minibatch entry.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseSoftmaxCrossEntropyWithLogits'.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               loss : Per example loss (batch_size vector).
               backprop : backpropagated gradients (batch_size x num_classes matrix).
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Unlike <c>SoftmaxCrossEntropyWithLogits</c>, this operation does not accept
               a matrix of label probabilities, but rather a single label per row
               of features.  This label is considered to have probability 1.0 for the
               given row.
               
               Inputs are the logits, not probabilities.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_sparse_maximum(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns the element-wise max of two SparseTensors.
            </summary>
            <param name="a_indices">
               2-D.  <c>N x R</c> matrix with the indices of non-empty values in a
               SparseTensor, in the canonical lexicographic ordering.
            </param>
            <param name="a_values">
               1-D.  <c>N</c> non-empty values corresponding to <c>a_indices</c>.
            </param>
            <param name="a_shape">
               1-D.  Shape of the input SparseTensor.
            </param>
            <param name="b_indices">
               counterpart to <c>a_indices</c> for the other operand.
            </param>
            <param name="b_values">
               counterpart to <c>a_values</c> for the other operand; must be of the same dtype.
            </param>
            <param name="b_shape">
               counterpart to <c>a_shape</c> for the other operand; the two shapes must be equal.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseSparseMaximum'.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output_indices : 2-D.  The indices of the output SparseTensor.
               output_values : 1-D.  The values of the output SparseTensor.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Assumes the two SparseTensors have the same shape, i.e., no broadcasting.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_sparse_minimum(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns the element-wise min of two SparseTensors.
            </summary>
            <param name="a_indices">
               2-D.  <c>N x R</c> matrix with the indices of non-empty values in a
               SparseTensor, in the canonical lexicographic ordering.
            </param>
            <param name="a_values">
               1-D.  <c>N</c> non-empty values corresponding to <c>a_indices</c>.
            </param>
            <param name="a_shape">
               1-D.  Shape of the input SparseTensor.
            </param>
            <param name="b_indices">
               counterpart to <c>a_indices</c> for the other operand.
            </param>
            <param name="b_values">
               counterpart to <c>a_values</c> for the other operand; must be of the same dtype.
            </param>
            <param name="b_shape">
               counterpart to <c>a_shape</c> for the other operand; the two shapes must be equal.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseSparseMinimum'.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output_indices : 2-D.  The indices of the output SparseTensor.
               output_values : 1-D.  The values of the output SparseTensor.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Assumes the two SparseTensors have the same shape, i.e., no broadcasting.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_split(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32,System.String)">
            <summary>
               Split a <c>SparseTensor</c> into <c>num_split</c> tensors along one dimension.
            </summary>
            <param name="split_dim">
               0-D.  The dimension along which to split.  Must be in the range
               <c>[0, rank(shape))</c>.
            </param>
            <param name="indices">
               2-D tensor represents the indices of the sparse tensor.
            </param>
            <param name="values">
               1-D tensor represents the values of the sparse tensor.
            </param>
            <param name="shape">
               1-D. tensor represents the shape of the sparse tensor.
               output indices: A list of 1-D tensors represents the indices of the output
               sparse tensors.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseSplit'.
            </param>
            <param name="num_split">
               Optional argument
               The number of ways to split.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output_indices :
               output_values : A list of 1-D tensors represents the values of the output sparse
               tensors.
               output_shape : A list of 1-D tensors represents the shape of the output sparse
               tensors.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               If the <c>shape[split_dim]</c> is not an integer multiple of <c>num_split</c>. Slices
               <c>[0 : shape[split_dim] % num_split]</c> gets one extra dimension.
               For example, if <c>split_dim = 1</c> and <c>num_split = 2</c> and the input is
               
               input_tensor = shape = [2, 7]
               [    a   d e  ]
               [b c          ]
               
               Graphically the output tensors are:
               
               output_tensor[0] = shape = [2, 4]
               [    a  ]
               [b c    ]
               
               output_tensor[1] = shape = [2, 3]
               [ d e  ]
               [      ]
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_tensor_dense_add(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Adds up a <c>SparseTensor</c> and a dense <c>Tensor</c>, producing a dense <c>Tensor</c>.
            </summary>
            <param name="a_indices">
               2-D.  The <c>indices</c> of the <c>SparseTensor</c>, with shape <c>[nnz, ndims]</c>.
            </param>
            <param name="a_values">
               1-D.  The <c>values</c> of the <c>SparseTensor</c>, with shape <c>[nnz]</c>.
            </param>
            <param name="a_shape">
               1-D.  The <c>shape</c> of the <c>SparseTensor</c>, with shape <c>[ndims]</c>.
            </param>
            <param name="b">
               <c>ndims</c>-D Tensor.  With shape <c>a_shape</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseTensorDenseAdd'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This Op does not require <c>a_indices</c> be sorted in standard lexicographic order.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_tensor_dense_mat_mul(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.String)">
            <summary>
               Multiply SparseTensor (of rank 2) "A" by dense matrix "B".
            </summary>
            <param name="a_indices">
               2-D.  The <c>indices</c> of the <c>SparseTensor</c>, size <c>[nnz, 2]</c> Matrix.
            </param>
            <param name="a_values">
               1-D.  The <c>values</c> of the <c>SparseTensor</c>, size <c>[nnz]</c> Vector.
            </param>
            <param name="a_shape">
               1-D.  The <c>shape</c> of the <c>SparseTensor</c>, size <c>[2]</c> Vector.
            </param>
            <param name="b">
               2-D.  A dense Matrix.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseTensorDenseMatMul'.
            </param>
            <param name="adjoint_a">
               Use the adjoint of A in the matrix multiply.  If A is complex, this
               is transpose(conj(A)).  Otherwise it's transpose(A).
            </param>
            <param name="adjoint_b">
               Use the adjoint of B in the matrix multiply.  If B is complex, this
               is transpose(conj(B)).  Otherwise it's transpose(B).
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               No validity checking is performed on the indices of A.  However, the following
               input format is recommended for optimal behavior:
               
               if adjoint_a == false:
               A should be sorted in lexicographically increasing order.  Use SparseReorder
               if you're not sure.
               if adjoint_a == true:
               A should be sorted in order of increasing dimension 1 (i.e., "column major"
               order instead of "row major" order).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_tensor_slice_dataset(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Creates a dataset that splits a SparseTensor into elements row-wise.
            </summary>
            <param name="indices">
            </param>
            <param name="values">
            </param>
            <param name="dense_shape">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseTensorSliceDataset'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_to_dense(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Converts a sparse representation into a dense tensor.
            </summary>
            <param name="sparse_indices">
               0-D, 1-D, or 2-D.  <c>sparse_indices[i]</c> contains the complete
               index where <c>sparse_values[i]</c> will be placed.
            </param>
            <param name="output_shape">
               1-D.  Shape of the dense output tensor.
            </param>
            <param name="sparse_values">
               1-D.  Values corresponding to each row of <c>sparse_indices</c>,
               or a scalar value to be used for all sparse indices.
            </param>
            <param name="default_value">
               Scalar value to set for indices not specified in
               <c>sparse_indices</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseToDense'.
            </param>
            <param name="validate_indices">
               If true, indices are checked to make sure they are sorted in
               lexicographic order and that there are no repeats.
            </param>
            <returns>
               Dense output tensor of shape <c>output_shape</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Builds an array <c>dense</c> with shape <c>output_shape</c> such that
               
              <code>
               # If sparse_indices is scalar
               dense[i] = (i == sparse_indices ? sparse_values : default_value)
               
               # If sparse_indices is a vector, then for each i
               dense[sparse_indices[i]] = sparse_values[i]
               
               # If sparse_indices is an n by d matrix, then for each i in [0, n)
               dense[sparse_indices[i][0], ..., sparse_indices[i][d-1]] = sparse_values[i]
              </code>
               
               All other values in <c>dense</c> are set to <c>default_value</c>.  If <c>sparse_values</c> is a
               scalar, all sparse indices are set to this single value.
               
               Indices should be sorted in lexicographic order, and indices must not
               contain any repeats. If <c>validate_indices</c> is true, these properties
               are checked during execution.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sparse_to_sparse_set_operation(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.Nullable{System.Boolean},System.String)">
            <summary>
               Applies set operation along last dimension of 2 <c>SparseTensor</c> inputs.
            </summary>
            <param name="set1_indices">
               2D <c>Tensor</c>, indices of a <c>SparseTensor</c>. Must be in row-major
               order.
            </param>
            <param name="set1_values">
               1D <c>Tensor</c>, values of a <c>SparseTensor</c>. Must be in row-major
               order.
            </param>
            <param name="set1_shape">
               1D <c>Tensor</c>, shape of a <c>SparseTensor</c>. <c>set1_shape[0...n-1]</c> must
               be the same as <c>set2_shape[0...n-1]</c>, <c>set1_shape[n]</c> is the
               max set size across <c>0...n-1</c> dimensions.
            </param>
            <param name="set2_indices">
               2D <c>Tensor</c>, indices of a <c>SparseTensor</c>. Must be in row-major
               order.
            </param>
            <param name="set2_values">
               1D <c>Tensor</c>, values of a <c>SparseTensor</c>. Must be in row-major
               order.
            </param>
            <param name="set2_shape">
               1D <c>Tensor</c>, shape of a <c>SparseTensor</c>. <c>set2_shape[0...n-1]</c> must
               be the same as <c>set1_shape[0...n-1]</c>, <c>set2_shape[n]</c> is the
               max set size across <c>0...n-1</c> dimensions.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseToSparseSetOperation'.
            </param>
            <param name="set_operation">
               Optional argument
            </param>
            <param name="validate_indices">
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               result_indices : 2D indices of a <c>SparseTensor</c>.
               result_values : 1D values of a <c>SparseTensor</c>.
               result_shape : 1D <c>Tensor</c> shape of a <c>SparseTensor</c>. <c>result_shape[0...n-1]</c> is
               the same as the 1st <c>n-1</c> dimensions of <c>set1</c> and <c>set2</c>, <c>result_shape[n]</c>
               is the max result set size across all <c>0...n-1</c> dimensions.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               See SetOperationOp::SetOperationFromContext for values of <c>set_operation</c>.
               
               If <c>validate_indices</c> is <c>True</c>, <c>SparseToSparseSetOperation</c> validates the
               order and range of <c>set1</c> and <c>set2</c> indices.
               
               Input <c>set1</c> is a <c>SparseTensor</c> represented by <c>set1_indices</c>, <c>set1_values</c>,
               and <c>set1_shape</c>. For <c>set1</c> ranked <c>n</c>, 1st <c>n-1</c> dimensions must be the same
               as <c>set2</c>. Dimension <c>n</c> contains values in a set, duplicates are allowed but
               ignored.
               
               Input <c>set2</c> is a <c>SparseTensor</c> represented by <c>set2_indices</c>, <c>set2_values</c>,
               and <c>set2_shape</c>. For <c>set2</c> ranked <c>n</c>, 1st <c>n-1</c> dimensions must be the same
               as <c>set1</c>. Dimension <c>n</c> contains values in a set, duplicates are allowed but
               ignored.
               
               If <c>validate_indices</c> is <c>True</c>, this op validates the order and range of <c>set1</c>
               and <c>set2</c> indices.
               
               Output <c>result</c> is a <c>SparseTensor</c> represented by <c>result_indices</c>,
               <c>result_values</c>, and <c>result_shape</c>. For <c>set1</c> and <c>set2</c> ranked <c>n</c>, this
               has rank <c>n</c> and the same 1st <c>n-1</c> dimensions as <c>set1</c> and <c>set2</c>. The <c>nth</c>
               dimension contains the result of <c>set_operation</c> applied to the corresponding
               <c>[0...n-1]</c> dimension of <c>set</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.split(Tensorflow.Tensor,Tensorflow.Tensor,System.Int32,System.String)">
            <summary>
               Splits a tensor into <c>num_split</c> tensors along one dimension.
            </summary>
            <param name="split_dim">
               0-D.  The dimension along which to split.  Must be in the range
               <c>[-rank(value), rank(value))</c>.
            </param>
            <param name="value">
               The tensor to split.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Split'.
            </param>
            <param name="num_split">
               Optional argument
               The number of ways to split.  Must evenly divide
               <c>value.shape[split_dim]</c>.
            </param>
            <returns>
               They are identically shaped tensors, whose shape matches that of <c>value</c>
               except along <c>axis</c>, where their sizes are
               <c>values.shape[split_dim] / num_split</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.split_v(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32,System.String)">
            <summary>
               Splits a tensor into <c>num_split</c> tensors along one dimension.
            </summary>
            <param name="value">
               The tensor to split.
            </param>
            <param name="size_splits">
               list containing the sizes of each output tensor along the split
               dimension. Must sum to the dimension of value along split_dim.
               Can contain one -1 indicating that dimension is to be inferred.
            </param>
            <param name="split_dim">
               0-D.  The dimension along which to split.  Must be in the range
               <c>[-rank(value), rank(value))</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SplitV'.
            </param>
            <param name="num_split">
               Optional argument
            </param>
            <returns>
               Tensors whose shape matches that of <c>value</c>
               except along <c>axis</c>, where their sizes are
               <c>size_splits[i]</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sql_dataset(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Creates a dataset that executes a SQL query and emits rows of the result set.
            </summary>
            <param name="driver_name">
               The database type. Currently, the only supported type is 'sqlite'.
            </param>
            <param name="data_source_name">
               A connection string to connect to the database.
            </param>
            <param name="query">
               A SQL query to execute.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SqlDataset'.
            </param>
            <param name="output_types">
               Optional argument
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sqrt(Tensorflow.Tensor,System.String)">
            <summary>
               Computes square root of x element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Sqrt'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               I.e., \\(y = \sqrt{x} = x^{1/2}\\).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sqrt_grad(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes the gradient for the sqrt of <c>x</c> wrt its input.
            </summary>
            <param name="y">
            </param>
            <param name="dy">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SqrtGrad'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Specifically, <c>grad = dy * 0.5 / y</c>, where <c>y = sqrt(x)</c>, and <c>dy</c>
               is the corresponding input gradient.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.square(Tensorflow.Tensor,System.String)">
            <summary>
               Computes square of x element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Square'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               I.e., \\(y = x * x = x^2\\).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.squared_difference(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns (x - y)(x - y) element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SquaredDifference'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               *NOTE*: <c>SquaredDifference</c> supports broadcasting. More about broadcasting
               [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.squeeze(Tensorflow.Tensor,System.Int32[],System.String)">
            <summary>
               Removes dimensions of size 1 from the shape of a tensor.
            </summary>
            <param name="input">
               The <c>input</c> to squeeze.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Squeeze'.
            </param>
            <param name="squeeze_dims">
               If specified, only squeezes the dimensions listed. The dimension
               index starts at 0. It is an error to squeeze a dimension that is not 1. Must
               be in the range <c>[-rank(input), rank(input))</c>.
            </param>
            <returns>
               Contains the same data as <c>input</c>, but has one or more dimensions of
               size 1 removed.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Given a tensor <c>input</c>, this operation returns a tensor of the same type with
               all dimensions of size 1 removed. If you don't want to remove all size 1
               dimensions, you can remove specific size 1 dimensions by specifying
               <c>axis</c>.
               
               For example:
               
              <code>
               # 't' is a tensor of shape [1, 2, 1, 3, 1, 1]
               shape(squeeze(t)) ==&amp;gt; [2, 3]
              </code>
               
               Or, to remove specific size 1 dimensions:
               
              <code>
               # 't' is a tensor of shape [1, 2, 1, 3, 1, 1]
               shape(squeeze(t, [2, 4])) ==&amp;gt; [1, 2, 3, 1]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.stack(Tensorflow.TF_DataType,System.String,System.String)">
            <summary>
               Deprecated, use StackV2.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Stack'.
            </param>
            <param name="elem_type">
               Optional argument
            </param>
            <param name="stack_name">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.stack_close(Tensorflow.Tensor,System.String)">
            <summary>
               Deprecated, use StackCloseV2.
            </summary>
            <param name="handle">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'StackClose'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.stack_close_v2(Tensorflow.Tensor,System.String)">
            <summary>
               Delete the stack from its resource container.
            </summary>
            <param name="handle">
               The handle to a stack.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'StackCloseV2'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.stack_pop(Tensorflow.Tensor,Tensorflow.TF_DataType,System.String)">
            <summary>
               Deprecated, use StackPopV2.
            </summary>
            <param name="handle">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'StackPop'.
            </param>
            <param name="elem_type">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.stack_pop_v2(Tensorflow.Tensor,Tensorflow.TF_DataType,System.String)">
            <summary>
               Pop the element at the top of the stack.
            </summary>
            <param name="handle">
               The handle to a stack.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'StackPopV2'.
            </param>
            <param name="elem_type">
               Optional argument
               The type of the elem that is popped.
            </param>
            <returns>
               The tensor that is popped from the top of the stack.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.stack_push(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Deprecated, use StackPushV2.
            </summary>
            <param name="handle">
            </param>
            <param name="elem">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'StackPush'.
            </param>
            <param name="swap_memory">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.stack_push_v2(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Push an element onto the stack.
            </summary>
            <param name="handle">
               The handle to a stack.
            </param>
            <param name="elem">
               The tensor to be pushed onto the stack.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'StackPushV2'.
            </param>
            <param name="swap_memory">
               Swap <c>elem</c> to CPU. Default to false.
            </param>
            <returns>
               The same tensor as the input 'elem'.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.stack_v2(Tensorflow.Tensor,Tensorflow.TF_DataType,System.String,System.String)">
            <summary>
               A stack that produces elements in first-in last-out order.
            </summary>
            <param name="max_size">
               The maximum size of the stack if non-negative. If negative, the stack
               size is unlimited.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'StackV2'.
            </param>
            <param name="elem_type">
               Optional argument
               The type of the elements on the stack.
            </param>
            <param name="stack_name">
               Overrides the name used for the temporary stack resource. Default
               value is the name of the 'Stack' op (which is guaranteed unique).
            </param>
            <returns>
               The handle to the stack.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.stage(Tensorflow.Tensor[],System.Nullable{System.Int32},System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               Stage values similar to a lightweight Enqueue.
            </summary>
            <param name="values">
               a list of tensors
               dtypes A list of data types that inserted values should adhere to.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Stage'.
            </param>
            <param name="capacity">
               Maximum number of elements in the Staging Area. If &amp;gt; 0, inserts
               on the container will block when the capacity is reached.
            </param>
            <param name="memory_limit">
               The maximum number of bytes allowed for Tensors in the Staging Area.
               If &amp;gt; 0, inserts will block until sufficient space is available.
            </param>
            <param name="container">
               If non-empty, this queue is placed in the given container. Otherwise,
               a default container is used.
            </param>
            <param name="shared_name">
               It is necessary to match this name to the matching Unstage Op.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               The basic functionality of this Op is similar to a queue with many
               fewer capabilities and options.  This Op is optimized for performance.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.stage_clear(Tensorflow.TF_DataType[],System.Nullable{System.Int32},System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               Op removes all elements in the underlying container.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'StageClear'.
            </param>
            <param name="dtypes">
               Optional argument
            </param>
            <param name="capacity">
            </param>
            <param name="memory_limit">
            </param>
            <param name="container">
            </param>
            <param name="shared_name">
            </param>
            <returns>
               Returns the description of the operation
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.stage_peek(Tensorflow.Tensor,Tensorflow.TF_DataType[],System.Nullable{System.Int32},System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               Op peeks at the values at the specified index.  If the
            </summary>
            <param name="index">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'StagePeek'.
            </param>
            <param name="dtypes">
               Optional argument
            </param>
            <param name="capacity">
            </param>
            <param name="memory_limit">
            </param>
            <param name="container">
            </param>
            <param name="shared_name">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               underlying container does not contain sufficient elements
               this op will block until it does.   This Op is optimized for
               performance.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.stage_size(Tensorflow.TF_DataType[],System.Nullable{System.Int32},System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               Op returns the number of elements in the underlying container.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'StageSize'.
            </param>
            <param name="dtypes">
               Optional argument
            </param>
            <param name="capacity">
            </param>
            <param name="memory_limit">
            </param>
            <param name="container">
            </param>
            <param name="shared_name">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.stateless_multinomial(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Draws samples from a multinomial distribution.
            </summary>
            <param name="logits">
               2-D Tensor with shape <c>[batch_size, num_classes]</c>.  Each slice <c>[i, :]</c>
               represents the unnormalized log probabilities for all classes.
            </param>
            <param name="num_samples">
               0-D.  Number of independent samples to draw for each row slice.
            </param>
            <param name="seed">
               2 seeds (shape [2]).
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'StatelessMultinomial'.
            </param>
            <param name="output_dtype">
            </param>
            <returns>
               2-D Tensor with shape <c>[batch_size, num_samples]</c>.  Each slice <c>[i, :]</c>
               contains the drawn class labels with range <c>[0, num_classes)</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.stateless_random_normal(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Outputs deterministic pseudorandom values from a normal distribution.
            </summary>
            <param name="shape">
               The shape of the output tensor.
            </param>
            <param name="seed">
               2 seeds (shape [2]).
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'StatelessRandomNormal'.
            </param>
            <param name="dtype">
               The type of the output.
            </param>
            <returns>
               Random values with specified shape.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The generated values will have mean 0 and standard deviation 1.
               
               The outputs are a deterministic function of <c>shape</c> and <c>seed</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.stateless_random_uniform(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Outputs deterministic pseudorandom random values from a uniform distribution.
            </summary>
            <param name="shape">
               The shape of the output tensor.
            </param>
            <param name="seed">
               2 seeds (shape [2]).
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'StatelessRandomUniform'.
            </param>
            <param name="dtype">
               The type of the output.
            </param>
            <returns>
               Random values with specified shape.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The generated values follow a uniform distribution in the range <c>[0, 1)</c>. The
               lower bound 0 is included in the range, while the upper bound 1 is excluded.
               
               The outputs are a deterministic function of <c>shape</c> and <c>seed</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.stateless_truncated_normal(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Outputs deterministic pseudorandom values from a truncated normal distribution.
            </summary>
            <param name="shape">
               The shape of the output tensor.
            </param>
            <param name="seed">
               2 seeds (shape [2]).
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'StatelessTruncatedNormal'.
            </param>
            <param name="dtype">
               The type of the output.
            </param>
            <returns>
               Random values with specified shape.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The generated values follow a normal distribution with mean 0 and standard
               deviation 1, except that values whose magnitude is more than 2 standard
               deviations from the mean are dropped and re-picked.
               
               The outputs are a deterministic function of <c>shape</c> and <c>seed</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.static_regex_replace(Tensorflow.Tensor,System.String,System.String,System.Nullable{System.Boolean},System.String)">
            <summary>
               Replaces the match of pattern in input with rewrite.
            </summary>
            <param name="input">
               The text to be processed.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'StaticRegexReplace'.
            </param>
            <param name="pattern">
               Optional argument
               The regular expression to match the input.
            </param>
            <param name="rewrite">
               Optional argument
               The rewrite to be applied to the matched expresion.
            </param>
            <param name="replace_global">
               If True, the replacement is global, otherwise the replacement
               is done only on the first match.
            </param>
            <returns>
               The text after applying pattern and rewrite.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               It follows the re2 syntax (https://github.com/google/re2/wiki/Syntax)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.stats_aggregator_handle(System.String,System.String,System.String)">
            <summary>
               Creates a statistics manager resource.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'StatsAggregatorHandle'.
            </param>
            <param name="container">
            </param>
            <param name="shared_name">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.stats_aggregator_summary(Tensorflow.Tensor,System.String)">
            <summary>
               Produces a summary of any statistics recorded by the given statistics manager.
            </summary>
            <param name="iterator">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'StatsAggregatorSummary'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.stop_gradient(Tensorflow.Tensor,System.String)">
            <summary>
               Stops gradient computation.
            </summary>
            <param name="input">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'StopGradient'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               When executed in a graph, this op outputs its input tensor as-is.
               
               When building ops to compute gradients, this op prevents the contribution of
               its inputs to be taken into account.  Normally, the gradient generator adds ops
               to a graph to compute the derivatives of a specified 'loss' by recursively
               finding out inputs that contributed to its computation.  If you insert this op
               in the graph it inputs are masked from the gradient generator.  They are not
               taken into account for computing gradients.
               
               This is useful any time you want to compute a value with TensorFlow but need
               to pretend that the value was a constant. Some examples include:
               
               *  The *EM* algorithm where the *M-step* should not involve backpropagation
               through the output of the *E-step*.
               *  Contrastive divergence training of Boltzmann machines where, when
               differentiating the energy function, the training must not backpropagate
               through the graph that generated the samples from the model.
               *  Adversarial training, where no backprop should happen through the adversarial
               example generation process.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.strided_slice(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Return a strided slice from <c>input</c>.
            </summary>
            <param name="input">
            </param>
            <param name="begin">
               <c>begin[k]</c> specifies the offset into the <c>k</c>th range specification.
               The exact dimension this corresponds to will be determined by context.
               Out-of-bounds values will be silently clamped. If the <c>k</c>th bit of
               <c>begin_mask</c> then <c>begin[k]</c> is ignored and the full range of the
               appropriate dimension is used instead. Negative values causes indexing
               to start from the highest element e.g. If <c>foo==[1,2,3]</c> then <c>foo[-1]==3</c>.
            </param>
            <param name="end">
               <c>end[i]</c> is like <c>begin</c> with the exception that <c>end_mask</c> is
               used to determine full ranges.
            </param>
            <param name="strides">
               <c>strides[i]</c> specifies the increment in the <c>i</c>th specification
               after extracting a given element. Negative indices will reverse
               the original order. Out or range values are
               clamped to <c>[0,dim[i]) if slice[i]&amp;gt;0</c> or <c>[-1,dim[i]-1] if slice[i] &amp;lt; 0</c>
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'StridedSlice'.
            </param>
            <param name="begin_mask">
               a bitmask where a bit i being 1 means to ignore the begin
               value and instead use the largest interval possible. At runtime
               begin[i] will be replaced with <c>[0, n-1)</c> if <c>stride[i] &amp;gt; 0</c> or
               <c>[-1, n-1]</c> if <c>stride[i] &amp;lt; 0</c>
            </param>
            <param name="end_mask">
               analogous to <c>begin_mask</c>
            </param>
            <param name="ellipsis_mask">
               a bitmask where bit <c>i</c> being 1 means the <c>i</c>th
               position is actually an ellipsis. One bit at most can be 1.
               If <c>ellipsis_mask == 0</c>, then an implicit ellipsis mask of <c>1 &amp;lt;&amp;lt; (m+1)</c>
               is provided. This means that <c>foo[3:5] == foo[3:5, ...]</c>. An ellipsis
               implicitly creates as many range specifications as necessary to fully
               specify the sliced range for every dimension. For example for a 4-dimensional
               tensor <c>foo</c> the slice <c>foo[2, ..., 5:8]</c> implies <c>foo[2, :, :, 5:8]</c>.
            </param>
            <param name="new_axis_mask">
               a bitmask where bit <c>i</c> being 1 means the <c>i</c>th
               specification creates a new shape 1 dimension. For example
               <c>foo[:4, tf.newaxis, :2]</c> would produce a shape <c>(4, 1, 2)</c> tensor.
            </param>
            <param name="shrink_axis_mask">
               a bitmask where bit <c>i</c> implies that the <c>i</c>th
               specification should shrink the dimensionality. begin and end
               must imply a slice of size 1 in the dimension. For example in
               python one might do <c>foo[:, 3, :]</c> which would result in
               <c>shrink_axis_mask</c> being 2.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Note, most python users will want to use the Python <c>Tensor.__getitem__</c>
               or <c>Variable.__getitem__</c> rather than this op directly.
               
               The goal of this op is to produce a new tensor with a subset of
               the elements from the <c>n</c> dimensional <c>input</c> tensor. The subset is chosen using
               a sequence of <c>m</c> sparse range specifications encoded into the arguments
               of this function. Note, in some cases
               <c>m</c> could be equal to <c>n</c>, but this need not be the case. Each
               range specification entry can be one of the following:
               
               - An ellipsis (...). Ellipses are used to imply zero or more
               dimensions of full-dimension selection and are produced using
               <c>ellipsis_mask</c>. For example, <c>foo[...]</c> is the identity slice.
               
               - A new axis. This is used to insert a new shape=1 dimension and is
               produced using <c>new_axis_mask</c>. For example, <c>foo[:, ...]</c> where
               <c>foo</c> is shape <c>(3, 4)</c> produces a <c>(1, 3, 4)</c> tensor.
               
               
               - A range <c>begin:end:stride</c>. This is used to specify how much to choose from
               a given dimension. <c>stride</c> can be any integer but 0.  <c>begin</c> is an integer
               which represents the index of the first value to select while <c>end</c> represents
               the index of the last value to select. The number of values selected in each
               dimension is <c>end - begin</c> if <c>stride &amp;gt; 0</c> and <c>begin - end</c> if <c>stride &amp;lt; 0</c>.
               <c>begin</c> and <c>end</c> can be negative where <c>-1</c> is the last element, <c>-2</c> is
               the second to last. <c>begin_mask</c> controls whether to replace the explicitly
               given <c>begin</c> with an implicit effective value of <c>0</c> if <c>stride &amp;gt; 0</c> and
               <c>-1</c> if <c>stride &amp;lt; 0</c>. <c>end_mask</c> is analogous but produces the number
               required to create the largest open interval. For example, given a shape
               <c>(3,)</c> tensor <c>foo[:]</c>, the effective <c>begin</c> and <c>end</c> are <c>0</c> and <c>3</c>. Do
               not assume this is equivalent to <c>foo[0:-1]</c> which has an effective <c>begin</c>
               and <c>end</c> of <c>0</c> and <c>2</c>. Another example is <c>foo[-2::-1]</c> which reverses the
               first dimension of a tensor while dropping the last two (in the original
               order elements). For example <c>foo = [1,2,3,4]; foo[-2::-1]</c> is <c>[4,3]</c>.
               
               - A single index. This is used to keep only elements that have a given
               index. For example (<c>foo[2, :]</c> on a shape <c>(5,6)</c> tensor produces a
               shape <c>(6,)</c> tensor. This is encoded in <c>begin</c> and <c>end</c> and
               <c>shrink_axis_mask</c>.
               
               Each conceptual range specification is encoded in the op's argument. This
               encoding is best understand by considering a non-trivial example. In
               particular,
               <c>foo[1, 2:4, None, ..., :-3:-1, :]</c> will be encoded as
               
              <code>
               begin = [1, 2, x, x, 0, x] # x denotes don't care (usually 0)
               end = [2, 4, x, x, -3, x]
               strides = [1, 1, x, x, -1, 1]
               begin_mask = 1&amp;lt;&amp;lt;4 | 1 &amp;lt;&amp;lt; 5 = 48
               end_mask = 1&amp;lt;&amp;lt;5 = 32
               ellipsis_mask = 1&amp;lt;&amp;lt;3 = 8
               new_axis_mask = 1&amp;lt;&amp;lt;2 4
               shrink_axis_mask = 1&amp;lt;&amp;lt;0
              </code>
               
               In this case if <c>foo.shape</c> is (5, 5, 5, 5, 5, 5) the final shape of
               the slice becomes (2, 1, 5, 5, 2, 5).
               Let us walk step by step through each argument specification.
               
               1.  The first argument in the example slice is turned into <c>begin = 1</c> and
               <c>end = begin + 1 = 2</c>. To disambiguate from the original spec <c>2:4</c> we
               also set the appropriate bit in <c>shrink_axis_mask</c>.
               
               2. <c>2:4</c> is contributes 2, 4, 1 to begin, end, and stride. All masks have
               zero bits contributed.
               
               3. None is a synonym for <c>tf.newaxis</c>. This means insert a dimension of size 1
               dimension in the final shape. Dummy values are contributed to begin,
               end and stride, while the new_axis_mask bit is set.
               
               4. <c>...</c> grab the full ranges from as many dimensions as needed to
               fully specify a slice for every dimension of the input shape.
               
               5. <c>:-3:-1</c> shows the use of negative indices. A negative index <c>i</c> associated
               with a dimension that has shape <c>s</c> is converted to a positive index
               <c>s + i</c>. So <c>-1</c> becomes <c>s-1</c> (i.e. the last element). This conversion
               is done internally so begin, end and strides receive x, -3, and -1.
               The appropriate begin_mask bit is set to indicate the start range is the
               full range (ignoring the x).
               
               6. <c>:</c> indicates that the entire contents of the corresponding dimension
               is selected. This is equivalent to <c>::</c> or <c>0::1</c>. begin, end, and strides
               receive 0, 0, and 1, respectively. The appropriate bits in <c>begin_mask</c> and
               <c>end_mask</c> are also set.
               
               *Requirements*:
               <c>0 != strides[i] for i in [0, m)</c>
               <c>ellipsis_mask must be a power of two (only one ellipsis)</c>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.strided_slice_assign(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Assign <c>value</c> to the sliced l-value reference of <c>ref</c>.
            </summary>
            <param name="referecne">
            </param>
            <param name="begin">
            </param>
            <param name="end">
            </param>
            <param name="strides">
            </param>
            <param name="value">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'StridedSliceAssign'.
            </param>
            <param name="begin_mask">
            </param>
            <param name="end_mask">
            </param>
            <param name="ellipsis_mask">
            </param>
            <param name="new_axis_mask">
            </param>
            <param name="shrink_axis_mask">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The values of <c>value</c> are assigned to the positions in the variable
               <c>ref</c> that are selected by the slice parameters. The slice parameters
               <c>begin</c>, <c>end</c>, <c>strides</c>, etc. work exactly as in <c>StridedSlice</c>.
               
               NOTE this op currently does not support broadcasting and so <c>value</c>'s
               shape must be exactly the shape produced by the slice of <c>ref</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.strided_slice_grad(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Returns the gradient of <c>StridedSlice</c>.
            </summary>
            <param name="shape">
            </param>
            <param name="begin">
            </param>
            <param name="end">
            </param>
            <param name="strides">
            </param>
            <param name="dy">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'StridedSliceGrad'.
            </param>
            <param name="begin_mask">
            </param>
            <param name="end_mask">
            </param>
            <param name="ellipsis_mask">
            </param>
            <param name="new_axis_mask">
            </param>
            <param name="shrink_axis_mask">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Since <c>StridedSlice</c> cuts out pieces of its <c>input</c> which is size
               <c>shape</c>, its gradient will have the same shape (which is passed here
               as <c>shape</c>). The gradient will be zero in any element that the slice
               does not select.
               
               Arguments are the same as StridedSliceGrad with the exception that
               <c>dy</c> is the input gradient to be propagated and <c>shape</c> is the
               shape of <c>StridedSlice</c>'s <c>input</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.string_join(Tensorflow.Tensor[],System.String,System.String)">
            <summary>
               Joins the strings in the given list of string tensors into one tensor;
            </summary>
            <param name="inputs">
               A list of string tensors.  The tensors must all have the same shape,
               or be scalars.  Scalars may be mixed in; these will be broadcast to the shape
               of non-scalar inputs.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'StringJoin'.
            </param>
            <param name="separator">
               string, an optional join separator.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               with the given separator (default is an empty separator).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.string_split(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Split elements of <c>input</c> based on <c>delimiter</c> into a <c>SparseTensor</c>.
            </summary>
            <param name="input">
               1-D. Strings to split.
            </param>
            <param name="delimiter">
               0-D. Delimiter characters (bytes), or empty string.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'StringSplit'.
            </param>
            <param name="skip_empty">
               A <c>bool</c>. If <c>True</c>, skip the empty strings from the result.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               indices : A dense matrix of int64 representing the indices of the sparse tensor.
               values : A vector of strings corresponding to the splited values.
               shape : a length-2 vector of int64 representing the shape of the sparse
               tensor, where the first value is N and the second value is the maximum number
               of tokens in a single input entry.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Let N be the size of source (typically N will be the batch size). Split each
               element of <c>input</c> based on <c>delimiter</c> and return a <c>SparseTensor</c>
               containing the splitted tokens. Empty tokens are ignored.
               
               <c>delimiter</c> can be empty, or a string of split characters. If <c>delimiter</c> is an
               empty string, each element of <c>input</c> is split into individual single-byte
               character strings, including splitting of UTF-8 multibyte sequences. Otherwise
               every character of <c>delimiter</c> is a potential split point.
               
               For example:
               N = 2, input[0] is 'hello world' and input[1] is 'a b c', then the output
               will be
               
               indices = [0, 0;
               0, 1;
               1, 0;
               1, 1;
               1, 2]
               shape = [2, 3]
               values = ['hello', 'world', 'a', 'b', 'c']
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.string_split_v2(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Int32},System.String)">
            <summary>
               Split elements of <c>source</c> based on <c>sep</c> into a <c>SparseTensor</c>.
            </summary>
            <param name="input">
               <c>1-D</c> string <c>Tensor</c>, the strings to split.
            </param>
            <param name="sep">
               <c>0-D</c> string <c>Tensor</c>, the delimiter character.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'StringSplitV2'.
            </param>
            <param name="maxsplit">
               An <c>int</c>. If <c>maxsplit &amp;gt; 0</c>, limit of the split of the result.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               indices :
               values :
               shape :
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Let N be the size of source (typically N will be the batch size). Split each
               element of <c>source</c> based on <c>sep</c> and return a <c>SparseTensor</c>
               containing the split tokens. Empty tokens are ignored.
               
               For example, N = 2, source[0] is 'hello world' and source[1] is 'a b c',
               then the output will be
              <code>
               st.indices = [0, 0;
               0, 1;
               1, 0;
               1, 1;
               1, 2]
               st.shape = [2, 3]
               st.values = ['hello', 'world', 'a', 'b', 'c']
              </code>
               
               If <c>sep</c> is given, consecutive delimiters are not grouped together and are
               deemed to delimit empty strings. For example, source of <c>"1&amp;lt;&amp;gt;2&amp;lt;&amp;gt;&amp;lt;&amp;gt;3"</c> and
               sep of <c>"&amp;lt;&amp;gt;"</c> returns <c>["1", "2", "", "3"]</c>. If <c>sep</c> is None or an empty
               string, consecutive whitespace are regarded as a single separator, and the
               result will contain no empty strings at the startor end if the string has
               leading or trailing whitespace.
               
               Note that the above mentioned behavior matches python's str.split.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.string_strip(Tensorflow.Tensor,System.String)">
            <summary>
               Strip leading and trailing whitespaces from the Tensor.
            </summary>
            <param name="input">
               A string <c>Tensor</c> of any shape.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'StringStrip'.
            </param>
            <returns>
               A string <c>Tensor</c> of the same shape as the input.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.string_to_hash_bucket(Tensorflow.Tensor,System.Int32,System.String)">
            <summary>
               Converts each string in the input Tensor to its hash mod by a number of buckets.
            </summary>
            <param name="string_tensor">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'StringToHashBucket'.
            </param>
            <param name="num_buckets">
               Optional argument
               The number of buckets.
            </param>
            <returns>
               A Tensor of the same shape as the input <c>string_tensor</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The hash function is deterministic on the content of the string within the
               process.
               
               Note that the hash function may change from time to time.
               This functionality will be deprecated and it's recommended to use
               <c>tf.string_to_hash_bucket_fast()</c> or <c>tf.string_to_hash_bucket_strong()</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.string_to_hash_bucket_fast(Tensorflow.Tensor,System.Int32,System.String)">
            <summary>
               Converts each string in the input Tensor to its hash mod by a number of buckets.
            </summary>
            <param name="input">
               The strings to assign a hash bucket.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'StringToHashBucketFast'.
            </param>
            <param name="num_buckets">
               Optional argument
               The number of buckets.
            </param>
            <returns>
               A Tensor of the same shape as the input <c>string_tensor</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The hash function is deterministic on the content of the string within the
               process and will never change. However, it is not suitable for cryptography.
               This function may be used when CPU time is scarce and inputs are trusted or
               unimportant. There is a risk of adversaries constructing inputs that all hash
               to the same bucket. To prevent this problem, use a strong hash function with
               <c>tf.string_to_hash_bucket_strong</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.string_to_hash_bucket_strong(Tensorflow.Tensor,System.Int32,System.Int32[],System.String)">
            <summary>
               Converts each string in the input Tensor to its hash mod by a number of buckets.
            </summary>
            <param name="input">
               The strings to assign a hash bucket.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'StringToHashBucketStrong'.
            </param>
            <param name="num_buckets">
               Optional argument
               The number of buckets.
            </param>
            <param name="key">
               Optional argument
               The key for the keyed hash function passed as a list of two uint64
               elements.
            </param>
            <returns>
               A Tensor of the same shape as the input <c>string_tensor</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The hash function is deterministic on the content of the string within the
               process. The hash function is a keyed hash function, where attribute <c>key</c>
               defines the key of the hash function. <c>key</c> is an array of 2 elements.
               
               A strong hash is important when inputs may be malicious, e.g. URLs with
               additional components. Adversaries could try to make their inputs hash to the
               same bucket for a denial-of-service attack or to skew the results. A strong
               hash prevents this by making it difficult, if not infeasible, to compute inputs
               that hash to the same bucket. This comes at a cost of roughly 4x higher compute
               time than <c>tf.string_to_hash_bucket_fast</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.string_to_number(Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Converts each string in the input Tensor to the specified numeric type.
            </summary>
            <param name="string_tensor">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'StringToNumber'.
            </param>
            <param name="out_type">
               The numeric type to interpret each string in <c>string_tensor</c> as.
            </param>
            <returns>
               A Tensor of the same shape as the input <c>string_tensor</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               (Note that int32 overflow results in an error while float overflow
               results in a rounded value.)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sub(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns x - y element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Sub'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               *NOTE*: <c>Subtract</c> supports broadcasting. More about broadcasting
               [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.substr(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Return substrings from <c>Tensor</c> of strings.
            </summary>
            <param name="input">
               Tensor of strings
            </param>
            <param name="pos">
               Scalar defining the position of first character in each substring
            </param>
            <param name="len">
               Scalar defining the number of characters to include in each substring
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Substr'.
            </param>
            <returns>
               Tensor of substrings
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               For each string in the input <c>Tensor</c>, creates a substring starting at index
               <c>pos</c> with a total length of <c>len</c>.
               
               If <c>len</c> defines a substring that would extend beyond the length of the input
               string, then as many characters as possible are used.
               
               A negative <c>pos</c> indicates distance within the string backwards from the end.
               
               If <c>pos</c> specifies an index which is out of range for any of the input strings,
               then an <c>InvalidArgumentError</c> is thrown.
               
               <c>pos</c> and <c>len</c> must have the same shape, otherwise a <c>ValueError</c> is thrown on
               Op creation.
               
               *NOTE*: <c>Substr</c> supports broadcasting up to two dimensions. More about
               broadcasting
               [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
               
               ---
               
               Examples
               
               Using scalar <c>pos</c> and <c>len</c>:
               
              <code>
               input = [b'Hello', b'World']
               position = 1
               length = 3
               
               output = [b'ell', b'orl']
              </code>
               
               Using <c>pos</c> and <c>len</c> with same shape as <c>input</c>:
               
              <code>
               input = [[b'ten', b'eleven', b'twelve'],
               [b'thirteen', b'fourteen', b'fifteen'],
               [b'sixteen', b'seventeen', b'eighteen']]
               position = [[1, 2, 3],
               [1, 2, 3],
               [1, 2, 3]]
               length =   [[2, 3, 4],
               [4, 3, 2],
               [5, 5, 5]]
               
               output = [[b'en', b'eve', b'lve'],
               [b'hirt', b'urt', b'te'],
               [b'ixtee', b'vente', b'hteen']]
              </code>
               
               Broadcasting <c>pos</c> and <c>len</c> onto <c>input</c>:
               
              <code>
               input = [[b'ten', b'eleven', b'twelve'],
               [b'thirteen', b'fourteen', b'fifteen'],
               [b'sixteen', b'seventeen', b'eighteen'],
               [b'nineteen', b'twenty', b'twentyone']]
               position = [1, 2, 3]
               length =   [1, 2, 3]
               
               output = [[b'e', b'ev', b'lve'],
               [b'h', b'ur', b'tee'],
               [b'i', b've', b'hte'],
               [b'i', b'en', b'nty']]
              </code>
               
               Broadcasting <c>input</c> onto <c>pos</c> and <c>len</c>:
               
              <code>
               input = b'thirteen'
               position = [1, 5, 7]
               length =   [3, 2, 1]
               
               output = [b'hir', b'ee', b'n']
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.sum(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Computes the sum of elements across dimensions of a tensor.
            </summary>
            <param name="input">
               The tensor to reduce.
            </param>
            <param name="reduction_indices">
               The dimensions to reduce. Must be in the range
               <c>[-rank(input), rank(input))</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Sum'.
            </param>
            <param name="keep_dims">
               If true, retain reduced dimensions with length 1.
            </param>
            <returns>
               The reduced tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Reduces <c>input</c> along the dimensions given in <c>axis</c>. Unless
               <c>keep_dims</c> is true, the rank of the tensor is reduced by 1 for each entry in
               <c>axis</c>. If <c>keep_dims</c> is true, the reduced dimensions are
               retained with length 1.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.svd(Tensorflow.Tensor,System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.String)">
            <summary>
               Computes the singular value decompositions of one or more matrices.
            </summary>
            <param name="input">
               A tensor of shape <c>[..., M, N]</c> whose inner-most 2 dimensions
               form matrices of size <c>[M, N]</c>. Let <c>P</c> be the minimum of <c>M</c> and <c>N</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Svd'.
            </param>
            <param name="compute_uv">
               If true, left and right singular vectors will be
               computed and returned in <c>u</c> and <c>v</c>, respectively.
               If false, <c>u</c> and <c>v</c> are not set and should never referenced.
            </param>
            <param name="full_matrices">
               If true, compute full-sized <c>u</c> and <c>v</c>. If false
               (the default), compute only the leading <c>P</c> singular vectors.
               Ignored if <c>compute_uv</c> is <c>False</c>.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               s : Singular values. Shape is <c>[..., P]</c>.
               u : Left singular vectors. If <c>full_matrices</c> is <c>False</c> then shape is
               <c>[..., M, P]</c>; if <c>full_matrices</c> is <c>True</c> then shape is
               <c>[..., M, M]</c>. Undefined if <c>compute_uv</c> is <c>False</c>.
               v : Left singular vectors. If <c>full_matrices</c> is <c>False</c> then shape is
               <c>[..., N, P]</c>. If <c>full_matrices</c> is <c>True</c> then shape is <c>[..., N, N]</c>.
               Undefined if <c>compute_uv</c> is false.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Computes the SVD of each inner matrix in <c>input</c> such that
               <c>input[..., :, :] = u[..., :, :] * diag(s[..., :, :]) * transpose(v[..., :, :])</c>
               
              <code>
               # a is a tensor containing a batch of matrices.
               # s is a tensor of singular values for each matrix.
               # u is the tensor containing of left singular vectors for each matrix.
               # v is the tensor containing of right singular vectors for each matrix.
               s, u, v = svd(a)
               s, _, _ = svd(a, compute_uv=False)
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.switch_(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Forwards <c>data</c> to the output port determined by <c>pred</c>.
            </summary>
            <param name="data">
               The tensor to be forwarded to the appropriate output.
            </param>
            <param name="pred">
               A scalar that specifies which output port will receive data.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Switch'.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output_false : If <c>pred</c> is false, data will be forwarded to this output.
               output_true : If <c>pred</c> is true, data will be forwarded to this output.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               If <c>pred</c> is true, the <c>data</c> input is forwarded to <c>output_true</c>. Otherwise,
               the data goes to <c>output_false</c>.
               
               See also <c>RefSwitch</c> and <c>Merge</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.t_f_record_dataset(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Creates a dataset that emits the records from one or more TFRecord files.
            </summary>
            <param name="filenames">
               A scalar or vector containing the name(s) of the file(s) to be
               read.
            </param>
            <param name="compression_type">
               A scalar containing either (i) the empty string (no
               compression), (ii) "ZLIB", or (iii) "GZIP".
            </param>
            <param name="buffer_size">
               A scalar representing the number of bytes to buffer. A value of
               0 means no buffering will be performed.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TFRecordDataset'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.t_f_record_reader(System.String,System.String,System.String,System.String)">
            <summary>
               A Reader that outputs the records from a TensorFlow Records file.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TFRecordReader'.
            </param>
            <param name="container">
               If non-empty, this reader is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this reader is named in the given bucket
               with this shared_name. Otherwise, the node name is used instead.
            </param>
            <param name="compression_type">
            </param>
            <returns>
               The handle to reference the Reader.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.t_f_record_reader_v2(System.String,System.String,System.String,System.String)">
            <summary>
               A Reader that outputs the records from a TensorFlow Records file.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TFRecordReaderV2'.
            </param>
            <param name="container">
               If non-empty, this reader is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this reader is named in the given bucket
               with this shared_name. Otherwise, the node name is used instead.
            </param>
            <param name="compression_type">
            </param>
            <returns>
               The handle to reference the Reader.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.t_p_u_embedding_activations(Tensorflow.Tensor,Tensorflow.Tensor,System.Int32,System.Int32,System.String)">
            <summary>
               An op enabling differentiation of TPU Embeddings.
            </summary>
            <param name="embedding_variable">
               A trainable variable, enabling optimizers to find this op.
            </param>
            <param name="sliced_activations">
               The embedding activations Tensor to return.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TPUEmbeddingActivations'.
            </param>
            <param name="table_id">
               Optional argument
               The id of the table in the embedding layer configuration from which
               these activations were computed.
            </param>
            <param name="lookup_id">
               Optional argument
               Identifier of the set of embedding indices which produced these
               activations.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This op simply returns its first input, which is assumed to have been sliced
               from the Tensors returned by TPUEmbeddingDequeueActivations. The presence of this
               op, and its first argument being a trainable Variable, enables automatic
               differentiation of graphs containing embeddings via the TPU Embedding Python
               libraries.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.t_p_u_embedding_enqueue_sparse_batch(Tensorflow.Tensor[],Tensorflow.Tensor[],Tensorflow.Tensor[],System.Nullable{System.Int32},System.String)">
            <summary>
               An op that feeds a batch of embedding indices and weights to the TPU.
            </summary>
            <param name="sample_indices">
               A list of rank 1 Tensors specifying row indices of the COO
               sparse matrix representing the embedding lookups for each table.
            </param>
            <param name="embedding_indices">
               A list of rank 1 Tensors  specifying column indices of the
               COO sparse matrix representing the embedding lookups for each table.
            </param>
            <param name="aggregation_weights">
               A list of rank 1 Tensors specifying the nonzero values
               of the COO sparse matrix representing the embedding lookups for each table.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TPUEmbeddingEnqueueSparseBatch'.
            </param>
            <param name="device_ordinal">
               The TPU device to use. This should be -1 when the Op
               is running on a TPU device, and &amp;gt;= 0 when the Op is running on the CPU
               device.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               Embedding lookups are equivalent to sparse-dense matrix multiplications: the
               sparse matrix contains nonzeros in column j in order to retrieve row j from the
               embedding table.
               
               The three Tensor list arguments (sample_indices, embedding_indices, and
               aggregation_weights) represent these sparse matrices in COO format. The Tensor
               lists each have one entry for each embedding table specified in the model.
               For the kth embedding table, the three Tensors at position k in the list
               specify a COO-format sparse matrix. For the kth table, the row indices,
               column indices, and nonzero values of the COO sparse matrix are specified by
               sample_indices[k], embedding_indices[k], and aggregation_weights[k],
               respectively. Entries must be sorted by row index, then by column index.
               
               There should be at most one TPUEmbeddingEnqueueSparseBatch op in a signle
               training step per TPU shard.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.t_p_u_embedding_load_adagrad_parameters(Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.Int32,System.Int32,System.Int32,System.String)">
            <summary>
               Load an embedding table shard into TensorNode memories for use with Adagrad.
            </summary>
            <param name="parameters">
               The shard of the embedding table resident on the host executing this
               op. For single-TPU models, this is the entire embedding table.
            </param>
            <param name="accumulators">
               Shard of the Adagrad accumulators resident on the host executing
               this op.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TPUEmbeddingLoadAdagradParameters'.
            </param>
            <param name="tpu_embedding_config">
               Optional argument
               Serialized TPUEmbeddingConfiguration proto.
            </param>
            <param name="table_id">
               Optional argument
               The id of the table specified in the embedding_config.
            </param>
            <param name="num_hosts">
               Optional argument
               The number of CPU hosts in the distributed training job.
            </param>
            <param name="host_id">
               Optional argument
               Which CPU host in the distributed training job will execute this op.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               TPU embeddings use dedicated per-optimizer Ops for loading and retrieving
               trainable variables and optimizer state from TPU memory. This op enables
               functionality equivalent to AdagradOptimizer.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.t_p_u_embedding_load_gradient_descent_parameters(Tensorflow.Tensor,System.String,System.Int32,System.Int32,System.Int32,System.String)">
            <summary>
               Load an embedding table shard into TPU memory for use with GradientDescent.
            </summary>
            <param name="parameters">
               The shard of the embedding table resident on the host executing this
               op. For single-TPU models, this is the entire embedding table.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TPUEmbeddingLoadGradientDescentParameters'.
            </param>
            <param name="tpu_embedding_config">
               Optional argument
               Serialized TPUEmbeddingConfiguration proto.
            </param>
            <param name="table_id">
               Optional argument
               The id of the table specified in the tpu_embedding_config.
            </param>
            <param name="num_hosts">
               Optional argument
               The number of CPU hosts in the distributed training job.
            </param>
            <param name="host_id">
               Optional argument
               Which CPU host in the distributed training job will execute this op.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               TPU embeddings use dedicated per-optimizer Ops for loading and retrieving
               trainable variables and optimizer state from TPU memory. This op enables
               functionality equivalent to GradientDescentOptimizer.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.t_p_u_embedding_receive_activations(System.Int32,System.String,System.String)">
            <summary>
               An op that receives embedding activations on the TPU.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TPUEmbeddingReceiveActivations'.
            </param>
            <param name="num_tables">
               Optional argument
               The number of output activation tensors, equal to the number of
               embedding tables in the model.
            </param>
            <param name="tpu_embedding_config">
               Optional argument
               Serialized TPUEmbeddingConfiguration proto.
            </param>
            <returns>
               A TensorList of embedding activations containing one Tensor per
               embedding table in the model.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The TPU system performs the embedding lookups and aggregations specified by
               the arguments to TPUEmbeddingEnqueueSparseBatch. The results of these
               aggregations are visible to the Tensorflow Graph as the outputs of a
               TPUEmbeddingDequeueActivations Op. This op returns a list containing one
               Tensor of activations per table specified in the model. There can be at most
               one ReceieveActivations op in the TPU graph.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.t_p_u_embedding_retrieve_adagrad_parameters(System.String,System.Int32,System.Int32,System.Int32,System.String)">
            <summary>
               Retrieve an embedding table shard from TPU memory.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TPUEmbeddingRetrieveAdagradParameters'.
            </param>
            <param name="tpu_embedding_config">
               Optional argument
               Serialized TPUEmbeddingConfiguration proto.
            </param>
            <param name="table_id">
               Optional argument
               The id of the table specified in the embedding_config_json.
            </param>
            <param name="num_hosts">
               Optional argument
               The number of CPU hosts in the distributed training job.
            </param>
            <param name="host_id">
               Optional argument
               Which CPU host in the distributed training job will execute this op.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               parameters :
               accumulators :
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               TPU embeddings use dedicated per-optimizer Ops for loading and retrieving
               trainable variables and optimizer state from TPU memory. This op enables
               functionality equivalent to AdagradOptimizer.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.t_p_u_embedding_retrieve_gradient_descent_parameters(System.String,System.Int32,System.Int32,System.Int32,System.String)">
            <summary>
               Retrieve an embedding table shard from TPU memory.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TPUEmbeddingRetrieveGradientDescentParameters'.
            </param>
            <param name="tpu_embedding_config">
               Optional argument
               Serialized TPUEmbeddingConfiguration proto.
            </param>
            <param name="table_id">
               Optional argument
               The id of the table specified in tpu_embedding_config.
            </param>
            <param name="num_hosts">
               Optional argument
               The number of CPU hosts in the distributed training job.
            </param>
            <param name="host_id">
               Optional argument
               Which CPU host in the distributed training job will execute this op.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               TPU embeddings use dedicated per-optimizer Ops for loading and retrieving
               trainable variables and optimizer state from TPU memory. This op enables
               functionality equivalent to GradientDescentOptimizer.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.t_p_u_embedding_send_gradients(Tensorflow.Tensor[],System.String,System.String)">
            <summary>
               An op that performs gradient updates of embedding tables.
            </summary>
            <param name="gradients">
               A TensorList of gradients with which to update embedding tables.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TPUEmbeddingSendGradients'.
            </param>
            <param name="tpu_embedding_config">
               Optional argument
               Serialized TPUEmbeddingConfiguration proto.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               The TensorList argument has the same length and shapes as the return value of
               TPUEmbeddingReceiveActivations, but contains gradients of the model's loss
               with respect to the embedding activations. The embedding tables are updated
               from these gradients via the optimizer specified in the configuration given
               to tpu.initialize_system.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.t_p_u_replicated_input(Tensorflow.Tensor[],System.String)">
            <summary>
               Operator that connects N unreplicated inputs to an N-way replicated TPU computation.
            </summary>
            <param name="inputs">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TPUReplicatedInput'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.t_p_u_replicated_output(Tensorflow.Tensor,System.Int32,System.String)">
            <summary>
               Operator that connects the output of an N-way replicated TPU computation to N separate outputs.
            </summary>
            <param name="input">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TPUReplicatedOutput'.
            </param>
            <param name="num_replicas">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.take_dataset(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Creates a dataset that contains <c>count</c> elements from the <c>input_dataset</c>.
            </summary>
            <param name="input_dataset">
            </param>
            <param name="count">
               A scalar representing the number of elements from the <c>input_dataset</c>
               that should be taken. A value of <c>-1</c> indicates that all of <c>input_dataset</c>
               is taken.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TakeDataset'.
            </param>
            <param name="output_types">
               Optional argument
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.take_many_sparse_from_tensors_map(Tensorflow.Tensor,Tensorflow.TF_DataType,System.String,System.String,System.String)">
            <summary>
               Read <c>SparseTensors</c> from a <c>SparseTensorsMap</c> and concatenate them.
            </summary>
            <param name="sparse_handles">
               1-D, The <c>N</c> serialized <c>SparseTensor</c> objects.
               Shape: <c>[N]</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TakeManySparseFromTensorsMap'.
            </param>
            <param name="dtype">
               Optional argument
               The <c>dtype</c> of the <c>SparseTensor</c> objects stored in the
               <c>SparseTensorsMap</c>.
            </param>
            <param name="container">
               The container name for the <c>SparseTensorsMap</c> read by this op.
            </param>
            <param name="shared_name">
               The shared name for the <c>SparseTensorsMap</c> read by this op.
               It should not be blank; rather the <c>shared_name</c> or unique Operation name
               of the Op that created the original <c>SparseTensorsMap</c> should be used.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               sparse_indices : 2-D.  The <c>indices</c> of the minibatch <c>SparseTensor</c>.
               sparse_values : 1-D.  The <c>values</c> of the minibatch <c>SparseTensor</c>.
               sparse_shape : 1-D.  The <c>shape</c> of the minibatch <c>SparseTensor</c>.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               The input <c>sparse_handles</c> must be an <c>int64</c> matrix of shape <c>[N, 1]</c> where
               <c>N</c> is the minibatch size and the rows correspond to the output handles of
               <c>AddSparseToTensorsMap</c> or <c>AddManySparseToTensorsMap</c>.  The ranks of the
               original <c>SparseTensor</c> objects that went into the given input ops must all
               match.  When the final <c>SparseTensor</c> is created, it has rank one
               higher than the ranks of the incoming <c>SparseTensor</c> objects
               (they have been concatenated along a new row dimension on the left).
               
               The output <c>SparseTensor</c> object's shape values for all dimensions but the
               first are the max across the input <c>SparseTensor</c> objects' shape values
               for the corresponding dimensions.  Its first shape value is <c>N</c>, the minibatch
               size.
               
               The input <c>SparseTensor</c> objects' indices are assumed ordered in
               standard lexicographic order.  If this is not the case, after this
               step run <c>SparseReorder</c> to restore index ordering.
               
               For example, if the handles represent an input, which is a <c>[2, 3]</c> matrix
               representing two original <c>SparseTensor</c> objects:
               
              <code>
               index = [ 0]
               [10]
               [20]
               values = [1, 2, 3]
               shape = [50]
              </code>
               
               and
               
              <code>
               index = [ 2]
               [10]
               values = [4, 5]
               shape = [30]
              </code>
               
               then the final <c>SparseTensor</c> will be:
               
              <code>
               index = [0  0]
               [0 10]
               [0 20]
               [1  2]
               [1 10]
               values = [1, 2, 3, 4, 5]
               shape = [2 50]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tan(Tensorflow.Tensor,System.String)">
            <summary>
               Computes tan of x element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Tan'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tanh(Tensorflow.Tensor,System.String)">
            <summary>
               Computes hyperbolic tangent of <c>x</c> element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Tanh'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tanh_grad(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes the gradient for the tanh of <c>x</c> wrt its input.
            </summary>
            <param name="y">
            </param>
            <param name="dy">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TanhGrad'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Specifically, <c>grad = dy * (1 - y*y)</c>, where <c>y = tanh(x)</c>, and <c>dy</c>
               is the corresponding input gradient.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.temporary_variable(Tensorflow.TensorShape,Tensorflow.TF_DataType,System.String,System.String)">
            <summary>
               Returns a tensor that may be mutated, but only persists within a single step.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TemporaryVariable'.
            </param>
            <param name="shape">
               Optional argument
               The shape of the variable tensor.
            </param>
            <param name="dtype">
               Optional argument
               The type of elements in the variable tensor.
            </param>
            <param name="var_name">
               Overrides the name used for the temporary variable resource. Default
               value is the name of the 'TemporaryVariable' op (which is guaranteed unique).
            </param>
            <returns>
               A reference to the variable tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This is an experimental op for internal use only and it is possible to use this
               op in unsafe ways.  DO NOT USE unless you fully understand the risks.
               
               It is the caller's responsibility to ensure that 'ref' is eventually passed to a
               matching 'DestroyTemporaryVariable' op after all other uses have completed.
               
               Outputs a ref to the tensor state so it may be read or modified.
               
               E.g.
               var = state_ops._temporary_variable([1, 2], types.float_)
               var_name = var.op.name
               var = state_ops.assign(var, [[4.0, 5.0]])
               var = state_ops.assign_add(var, [[6.0, 7.0]])
               final = state_ops._destroy_temporary_variable(var, var_name=var_name)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_array_close_v2(Tensorflow.Tensor,System.String)">
            <summary>
               Deprecated. Use TensorArrayCloseV3
            </summary>
            <param name="handle">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorArrayCloseV2'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_array_close_v3(Tensorflow.Tensor,System.String)">
            <summary>
               Delete the TensorArray from its resource container.
            </summary>
            <param name="handle">
               The handle to a TensorArray (output of TensorArray or TensorArrayGrad).
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorArrayCloseV3'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               This enables the user to close and release the resource in the middle
               of a step/run.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_array_concat_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType,Tensorflow.TensorShape,System.String)">
            <summary>
               Deprecated. Use TensorArrayConcatV3
            </summary>
            <param name="handle">
            </param>
            <param name="flow_in">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorArrayConcatV2'.
            </param>
            <param name="dtype">
               Optional argument
            </param>
            <param name="element_shape_except0">
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               value :
               lengths :
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_array_concat_v3(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType,Tensorflow.TensorShape,System.String)">
            <summary>
               Concat the elements from the TensorArray into value <c>value</c>.
            </summary>
            <param name="handle">
               The handle to a TensorArray.
            </param>
            <param name="flow_in">
               A float scalar that enforces proper chaining of operations.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorArrayConcatV3'.
            </param>
            <param name="dtype">
               Optional argument
               The type of the elem that is returned.
            </param>
            <param name="element_shape_except0">
               The expected shape of an element, if known,
               excluding the first dimension. Used to validate the shapes of
               TensorArray elements. If this shape is not fully specified, concatenating
               zero-size TensorArrays is an error.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               value : All of the elements in the TensorArray, concatenated along the first
               axis.
               lengths : A vector of the row sizes of the original T elements in the
               value output.  In the example above, this would be the values:
               <c>(n1, n2, ..., n(T-1))</c>.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Takes <c>T</c> elements of shapes
               
              <code>
               (n0 x d0 x d1 x ...), (n1 x d0 x d1 x ...), ..., (n(T-1) x d0 x d1 x ...)
              </code>
               
               and concatenates them into a Tensor of shape:
               
              <code>
               (n0 + n1 + ... + n(T-1) x d0 x d1 x ...)
               </code>
               
               All elements must have the same shape (excepting the first dimension).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_array_gather_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType,Tensorflow.TensorShape,System.String)">
            <summary>
               Deprecated. Use TensorArrayGatherV3
            </summary>
            <param name="handle">
            </param>
            <param name="indices">
            </param>
            <param name="flow_in">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorArrayGatherV2'.
            </param>
            <param name="dtype">
               Optional argument
            </param>
            <param name="element_shape">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_array_gather_v3(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType,Tensorflow.TensorShape,System.String)">
            <summary>
               Gather specific elements from the TensorArray into output <c>value</c>.
            </summary>
            <param name="handle">
               The handle to a TensorArray.
            </param>
            <param name="indices">
               The locations in the TensorArray from which to read tensor elements.
            </param>
            <param name="flow_in">
               A float scalar that enforces proper chaining of operations.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorArrayGatherV3'.
            </param>
            <param name="dtype">
               Optional argument
               The type of the elem that is returned.
            </param>
            <param name="element_shape">
               The expected shape of an element, if known. Used to
               validate the shapes of TensorArray elements. If this shape is not
               fully specified, gathering zero-size TensorArrays is an error.
            </param>
            <returns>
               All of the elements in the TensorArray, concatenated along a new
               axis (the new dimension 0).
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               All elements selected by <c>indices</c> must have the same shape.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_array_grad_v2(Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.String)">
            <summary>
               Deprecated. Use TensorArrayGradV3
            </summary>
            <param name="handle">
            </param>
            <param name="flow_in">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorArrayGradV2'.
            </param>
            <param name="source">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_array_grad_v3(Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.String)">
            <summary>
               Creates a TensorArray for storing the gradients of values in the given handle.
            </summary>
            <param name="handle">
               The handle to the forward TensorArray.
            </param>
            <param name="flow_in">
               A float scalar that enforces proper chaining of operations.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorArrayGradV3'.
            </param>
            <param name="source">
               Optional argument
               The gradient source string, used to decide which gradient TensorArray
               to return.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               grad_handle :
               flow_out :
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               If the given TensorArray gradient already exists, returns a reference to it.
               
               Locks the size of the original TensorArray by disabling its dynamic size flag.
               
               **A note about the input flow_in:**
               
               The handle flow_in forces the execution of the gradient lookup to occur
               only after certain other operations have occurred.  For example, when
               the forward TensorArray is dynamically sized, writes to this TensorArray
               may resize the object.  The gradient TensorArray is statically sized based
               on the size of the forward TensorArray when this operation executes.
               Furthermore, the size of the forward TensorArray is frozen by this call.
               As a result, the flow is used to ensure that the call to generate the gradient
               TensorArray only happens after all writes are executed.
               
               In the case of dynamically sized TensorArrays, gradient computation should
               only be performed on read operations that have themselves been chained via
               flow to occur only after all writes have executed. That way the final size
               of the forward TensorArray is known when this operation is called.
               
               **A note about the source attribute:**
               
               TensorArray gradient calls use an accumulator TensorArray object.  If
               multiple gradients are calculated and run in the same session, the multiple
               gradient nodes may accidentally flow through the same accumulator TensorArray.
               This double counts and generally breaks the TensorArray gradient flow.
               
               The solution is to identify which gradient call this particular
               TensorArray gradient is being called in.  This is performed by identifying
               a unique string (e.g. "gradients", "gradients_1", ...) from the input
               gradient Tensor's name.  This string is used as a suffix when creating
               the TensorArray gradient object here (the attribute <c>source</c>).
               
               The attribute <c>source</c> is added as a suffix to the forward TensorArray's
               name when performing the creation / lookup, so that each separate gradient
               calculation gets its own TensorArray accumulator.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_array_grad_with_shape(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.String)">
            <summary>
               Creates a TensorArray for storing multiple gradients of values in the given handle.
            </summary>
            <param name="handle">
               The handle to the forward TensorArray.
            </param>
            <param name="flow_in">
               A float scalar that enforces proper chaining of operations.
            </param>
            <param name="shape_to_prepend">
               An int32 vector representing a shape. Elements in the gradient accumulator will
               have shape which is this shape_to_prepend value concatenated with shape of the
               elements in the TensorArray corresponding to the input handle.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorArrayGradWithShape'.
            </param>
            <param name="source">
               Optional argument
               The gradient source string, used to decide which gradient TensorArray
               to return.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               grad_handle :
               flow_out :
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Similar to TensorArrayGradV3. However it creates an accumulator with an
               expanded shape compared to the input TensorArray whose gradient is being
               computed. This enables multiple gradients for the same TensorArray to be
               calculated using the same accumulator.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_array_read_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType,System.String)">
            <summary>
               Deprecated. Use TensorArrayReadV3
            </summary>
            <param name="handle">
            </param>
            <param name="index">
            </param>
            <param name="flow_in">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorArrayReadV2'.
            </param>
            <param name="dtype">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_array_read_v3(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType,System.String)">
            <summary>
               Read an element from the TensorArray into output <c>value</c>.
            </summary>
            <param name="handle">
               The handle to a TensorArray.
            </param>
            <param name="index">
            </param>
            <param name="flow_in">
               A float scalar that enforces proper chaining of operations.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorArrayReadV3'.
            </param>
            <param name="dtype">
               Optional argument
               The type of the elem that is returned.
            </param>
            <returns>
               The tensor that is read from the TensorArray.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_array_scatter_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Deprecated. Use TensorArrayScatterV3
            </summary>
            <param name="handle">
            </param>
            <param name="indices">
            </param>
            <param name="value">
            </param>
            <param name="flow_in">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorArrayScatterV2'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_array_scatter_v3(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Scatter the data from the input value into specific TensorArray elements.
            </summary>
            <param name="handle">
               The handle to a TensorArray.
            </param>
            <param name="indices">
               The locations at which to write the tensor elements.
            </param>
            <param name="value">
               The concatenated tensor to write to the TensorArray.
            </param>
            <param name="flow_in">
               A float scalar that enforces proper chaining of operations.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorArrayScatterV3'.
            </param>
            <returns>
               A float scalar that enforces proper chaining of operations.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               <c>indices</c> must be a vector, its length must match the first dim of <c>value</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_array_size_v2(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Deprecated. Use TensorArraySizeV3
            </summary>
            <param name="handle">
            </param>
            <param name="flow_in">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorArraySizeV2'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_array_size_v3(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Get the current size of the TensorArray.
            </summary>
            <param name="handle">
               The handle to a TensorArray (output of TensorArray or TensorArrayGrad).
            </param>
            <param name="flow_in">
               A float scalar that enforces proper chaining of operations.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorArraySizeV3'.
            </param>
            <returns>
               The current size of the TensorArray.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_array_split_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Deprecated. Use TensorArraySplitV3
            </summary>
            <param name="handle">
            </param>
            <param name="value">
            </param>
            <param name="lengths">
            </param>
            <param name="flow_in">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorArraySplitV2'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_array_split_v3(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Split the data from the input value into TensorArray elements.
            </summary>
            <param name="handle">
               The handle to a TensorArray.
            </param>
            <param name="value">
               The concatenated tensor to write to the TensorArray.
            </param>
            <param name="lengths">
               The vector of lengths, how to split the rows of value into the
               TensorArray.
            </param>
            <param name="flow_in">
               A float scalar that enforces proper chaining of operations.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorArraySplitV3'.
            </param>
            <returns>
               A float scalar that enforces proper chaining of operations.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Assuming that <c>lengths</c> takes on values
               
              <code>
               (n0, n1, ..., n(T-1))
               </code>
               
               and that <c>value</c> has shape
               
              <code>
               (n0 + n1 + ... + n(T-1) x d0 x d1 x ...)</code>,
               
               this splits values into a TensorArray with T tensors.
               
               TensorArray index t will be the subtensor of values with starting position
               
              <code>
               (n0 + n1 + ... + n(t-1), 0, 0, ...)
               </code>
               
               and having size
               
              <code>
               nt x d0 x d1 x ...
               </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_array_v2(Tensorflow.Tensor,Tensorflow.TF_DataType,Tensorflow.TensorShape,System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.String,System.String)">
            <summary>
               Deprecated. Use TensorArrayV3
            </summary>
            <param name="size">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorArrayV2'.
            </param>
            <param name="dtype">
               Optional argument
            </param>
            <param name="element_shape">
            </param>
            <param name="dynamic_size">
            </param>
            <param name="clear_after_read">
            </param>
            <param name="tensor_array_name">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_array_v3(Tensorflow.Tensor,Tensorflow.TF_DataType,Tensorflow.TensorShape,System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.String,System.String)">
            <summary>
               An array of Tensors of given size.
            </summary>
            <param name="size">
               The size of the array.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorArrayV3'.
            </param>
            <param name="dtype">
               Optional argument
               The type of the elements on the tensor_array.
            </param>
            <param name="element_shape">
               The expected shape of an element, if known. Used to
               validate the shapes of TensorArray elements. If this shape is not
               fully specified, gathering zero-size TensorArrays is an error.
            </param>
            <param name="dynamic_size">
               A boolean that determines whether writes to the TensorArray
               are allowed to grow the size.  By default, this is not allowed.
            </param>
            <param name="clear_after_read">
               If true (default), Tensors in the TensorArray are cleared
               after being read.  This disables multiple read semantics but allows early
               release of memory.
            </param>
            <param name="identical_element_shapes">
               If true (default is false), then all
               elements in the TensorArray will be expected to have have identical shapes.
               This allows certain behaviors, like dynamically checking for
               consistent shapes on write, and being able to fill in properly
               shaped zero tensors on stack -- even if the element_shape attribute
               is not fully defined.
            </param>
            <param name="tensor_array_name">
               Overrides the name used for the temporary tensor_array
               resource. Default value is the name of the 'TensorArray' op (which
               is guaranteed unique).
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               handle : The handle to the TensorArray.
               flow : A scalar used to control gradient flow.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Write data via Write and read via Read or Pack.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_array_write_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Deprecated. Use TensorArrayGradV3
            </summary>
            <param name="handle">
            </param>
            <param name="index">
            </param>
            <param name="value">
            </param>
            <param name="flow_in">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorArrayWriteV2'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_array_write_v3(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Push an element onto the tensor_array.
            </summary>
            <param name="handle">
               The handle to a TensorArray.
            </param>
            <param name="index">
               The position to write to inside the TensorArray.
            </param>
            <param name="value">
               The tensor to write to the TensorArray.
            </param>
            <param name="flow_in">
               A float scalar that enforces proper chaining of operations.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorArrayWriteV3'.
            </param>
            <returns>
               A float scalar that enforces proper chaining of operations.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_dataset(Tensorflow.Tensor[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Creates a dataset that emits <c>components</c> as a tuple of tensors once.
            </summary>
            <param name="components">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorDataset'.
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_list_element_shape(Tensorflow.Tensor,Tensorflow.TF_DataType,System.String)">
            <summary>
               The shape of the elements of the given list, as a tensor.
            </summary>
            <param name="input_handle">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorListElementShape'.
            </param>
            <param name="shape_type">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               input_handle: the list
               element_shape: the shape of elements of the list
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_list_from_tensor(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Creates a TensorList which, when stacked, has the value of <c>tensor</c>.
            </summary>
            <param name="tensor">
            </param>
            <param name="element_shape">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorListFromTensor'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Each tensor in the result list corresponds to one row of the input tensor.
               
               tensor: The input tensor.
               output_handle: The list.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_list_gather(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType,System.String)">
            <summary>
               Creates a Tensor by indexing into the TensorList.
            </summary>
            <param name="input_handle">
            </param>
            <param name="indices">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorListGather'.
            </param>
            <param name="element_dtype">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Each row in the produced Tensor corresponds to the element in the TensorList
               specified by the given index (see <c>tf.gather</c>).
               
               input_handle: The input tensor list.
               indices: The indices used to index into the list.
               values: The tensor.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_list_get_item(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType,System.String)">
            <summary>
               Returns the item in the list with the given index.
            </summary>
            <param name="input_handle">
            </param>
            <param name="index">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorListGetItem'.
            </param>
            <param name="element_dtype">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               input_handle: the list
               index: the position in the list from which an element will be retrieved
               item: the element at that position
               
               
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_list_length(Tensorflow.Tensor,System.String)">
            <summary>
               Returns the number of tensors in the input tensor list.
            </summary>
            <param name="input_handle">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorListLength'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               input_handle: the input list
               length: the number of tensors in the list
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_list_pop_back(Tensorflow.Tensor,Tensorflow.TF_DataType,System.String)">
            <summary>
               Returns the last element of the input list as well as a list with all but that element.
            </summary>
            <param name="input_handle">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorListPopBack'.
            </param>
            <param name="element_dtype">
               Optional argument
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               output_handle :
               tensor :
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Fails if the list is empty.
               
               input_handle: the input list
               tensor: the withdrawn last element of the list
               element_dtype: the type of elements in the list
               element_shape: the shape of the output tensor
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_list_push_back(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns a list list which has the passed-in <c>Tensor</c> as last element and the other elements of the given list in <c>input_handle</c>.
            </summary>
            <param name="input_handle">
            </param>
            <param name="tensor">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorListPushBack'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               tensor: The tensor to put on the list.
               input_handle: The old list.
               output_handle: A list with the elements of the old list followed by tensor.
               element_dtype: the type of elements in the list.
               element_shape: a shape compatible with that of elements in the list.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_list_reserve(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType,System.String)">
            <summary>
               List of the given size with empty elements.
            </summary>
            <param name="element_shape">
            </param>
            <param name="num_elements">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorListReserve'.
            </param>
            <param name="element_dtype">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               element_shape: the shape of the future elements of the list
               num_elements: the number of elements to reserve
               handle: the output list
               element_dtype: the desired type of elements in the list.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_list_scatter(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Creates a TensorList by indexing into a Tensor.
            </summary>
            <param name="tensor">
            </param>
            <param name="indices">
            </param>
            <param name="element_shape">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorListScatter'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Each member of the TensorList corresponds to one row of the input tensor,
               specified by the given index (see <c>tf.gather</c>).
               
               tensor: The input tensor.
               indices: The indices used to index into the list.
               element_shape: The shape of the elements in the list (can be less specified than
               the shape of the tensor).
               output_handle: The TensorList.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_list_set_item(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Sets the index-th position of the list to contain the given tensor.
            </summary>
            <param name="input_handle">
            </param>
            <param name="index">
            </param>
            <param name="item">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorListSetItem'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               input_handle: the list
               index: the position in the list to which the tensor will be assigned
               item: the element to be assigned to that position
               output_handle: the new list, with the element in the proper position
               
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_list_stack(Tensorflow.Tensor,Tensorflow.TF_DataType,System.Nullable{System.Int32},System.String)">
            <summary>
               Stacks all tensors in the list.
            </summary>
            <param name="input_handle">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorListStack'.
            </param>
            <param name="element_dtype">
               Optional argument
            </param>
            <param name="num_elements">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Requires that all tensors have the same shape.
               
               input_handle: the input list
               tensor: the gathered result
               num_elements: optional. If not -1, the number of elements in the list.
               
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_slice_dataset(Tensorflow.Tensor[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Creates a dataset that emits each dim-0 slice of <c>components</c> once.
            </summary>
            <param name="components">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorSliceDataset'.
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_summary(Tensorflow.Tensor,System.String,System.String[],System.String,System.String)">
            <summary>
               Outputs a <c>Summary</c> protocol buffer with a tensor.
            </summary>
            <param name="tensor">
               A tensor to serialize.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorSummary'.
            </param>
            <param name="description">
               A json-encoded SummaryDescription proto.
            </param>
            <param name="labels">
               An unused list of strings.
            </param>
            <param name="display_name">
               An unused string.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This op is being phased out in favor of TensorSummaryV2, which lets callers pass
               a tag as well as a serialized SummaryMetadata proto string that contains
               plugin-specific data. We will keep this op to maintain backwards compatibility.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tensor_summary_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Outputs a <c>Summary</c> protocol buffer with a tensor and per-plugin data.
            </summary>
            <param name="tag">
               A string attached to this summary. Used for organization in TensorBoard.
            </param>
            <param name="tensor">
               A tensor to serialize.
            </param>
            <param name="serialized_summary_metadata">
               A serialized SummaryMetadata proto. Contains plugin
               data.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TensorSummaryV2'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.text_line_dataset(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Creates a dataset that emits the lines of one or more text files.
            </summary>
            <param name="filenames">
               A scalar or a vector containing the name(s) of the file(s) to be
               read.
            </param>
            <param name="compression_type">
               A scalar containing either (i) the empty string (no
               compression), (ii) "ZLIB", or (iii) "GZIP".
            </param>
            <param name="buffer_size">
               A scalar containing the number of bytes to buffer.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TextLineDataset'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.text_line_reader(System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               A Reader that outputs the lines of a file delimited by '\n'.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TextLineReader'.
            </param>
            <param name="skip_header_lines">
               Number of lines to skip from the beginning of every file.
            </param>
            <param name="container">
               If non-empty, this reader is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this reader is named in the given bucket
               with this shared_name. Otherwise, the node name is used instead.
            </param>
            <returns>
               The handle to reference the Reader.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.text_line_reader_v2(System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               A Reader that outputs the lines of a file delimited by '\n'.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TextLineReaderV2'.
            </param>
            <param name="skip_header_lines">
               Number of lines to skip from the beginning of every file.
            </param>
            <param name="container">
               If non-empty, this reader is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this reader is named in the given bucket
               with this shared_name. Otherwise, the node name is used instead.
            </param>
            <returns>
               The handle to reference the Reader.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.thread_unsafe_unigram_candidate_sampler(Tensorflow.Tensor,System.Int32,System.Int32,System.Boolean,System.Int32,System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Generates labels for candidate sampling with a learned unigram distribution.
            </summary>
            <param name="true_classes">
               A batch_size * num_true matrix, in which each row contains the
               IDs of the num_true target_classes in the corresponding original label.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ThreadUnsafeUnigramCandidateSampler'.
            </param>
            <param name="num_true">
               Optional argument
               Number of true labels per context.
            </param>
            <param name="num_sampled">
               Optional argument
               Number of candidates to randomly sample.
            </param>
            <param name="unique">
               Optional argument
               If unique is true, we sample with rejection, so that all sampled
               candidates in a batch are unique. This requires some approximation to
               estimate the post-rejection sampling probabilities.
            </param>
            <param name="range_max">
               Optional argument
               The sampler will sample integers from the interval [0, range_max).
            </param>
            <param name="seed">
               If either seed or seed2 are set to be non-zero, the random number
               generator is seeded by the given seed.  Otherwise, it is seeded by a
               random seed.
            </param>
            <param name="seed2">
               An second seed to avoid seed collision.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               sampled_candidates : A vector of length num_sampled, in which each element is
               the ID of a sampled candidate.
               true_expected_count : A batch_size * num_true matrix, representing
               the number of times each candidate is expected to occur in a batch
               of sampled candidates. If unique=true, then this is a probability.
               sampled_expected_count : A vector of length num_sampled, for each sampled
               candidate representing the number of times the candidate is expected
               to occur in a batch of sampled candidates.  If unique=true, then this is a
               probability.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               See explanations of candidate sampling and the data formats at
               go/candidate-sampling.
               
               For each batch, this op picks a single set of sampled candidate labels.
               
               The advantages of sampling candidates per-batch are simplicity and the
               possibility of efficient dense matrix multiplication. The disadvantage is that
               the sampled candidates must be chosen independently of the context and of the
               true labels.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tile(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Constructs a tensor by tiling a given tensor.
            </summary>
            <param name="input">
               1-D or higher.
            </param>
            <param name="multiples">
               1-D. Length must be the same as the number of dimensions in <c>input</c>
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Tile'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation creates a new tensor by replicating <c>input</c> <c>multiples</c> times.
               The output tensor's i'th dimension has <c>input.dims(i) * multiples[i]</c> elements,
               and the values of <c>input</c> are replicated <c>multiples[i]</c> times along the 'i'th
               dimension. For example, tiling <c>[a b c d]</c> by <c>[2]</c> produces
               <c>[a b c d a b c d]</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.tile_grad(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns the gradient of <c>Tile</c>.
            </summary>
            <param name="input">
            </param>
            <param name="multiples">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TileGrad'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Since <c>Tile</c> takes an input and repeats the input <c>multiples</c> times
               along each dimension, <c>TileGrad</c> takes in <c>multiples</c> and aggregates
               each repeated tile of <c>input</c> into <c>output</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.timestamp(System.String)">
            <summary>
               Provides the time since epoch in seconds.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Timestamp'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Returns the timestamp as a <c>float64</c> for seconds since the Unix epoch.
               
               Note: the timestamp is computed when the op is executed, not when it is added
               to the graph.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.top_k(Tensorflow.Tensor,System.Int32,System.Nullable{System.Boolean},System.String)">
            <summary>
               Finds values and indices of the <c>k</c> largest elements for the last dimension.
            </summary>
            <param name="input">
               1-D or higher with last dimension at least <c>k</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TopK'.
            </param>
            <param name="k">
               Optional argument
               Number of top elements to look for along the last dimension (along each
               row for matrices).
            </param>
            <param name="sorted">
               If true the resulting <c>k</c> elements will be sorted by the values in
               descending order.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               values : The <c>k</c> largest elements along each last dimensional slice.
               indices : The indices of <c>values</c> within the last dimension of <c>input</c>.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               If the input is a vector (rank-1), finds the <c>k</c> largest entries in the vector
               and outputs their values and indices as vectors.  Thus <c>values[j]</c> is the
               <c>j</c>-th largest entry in <c>input</c>, and its index is <c>indices[j]</c>.
               
               For matrices (resp. higher rank input), computes the top <c>k</c> entries in each
               row (resp. vector along the last dimension).  Thus,
               
               values.shape = indices.shape = input.shape[:-1] + [k]
               
               If two elements are equal, the lower-index element appears first.
               
               If <c>k</c> varies dynamically, use <c>TopKV2</c> below.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.top_k_v2(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Boolean},System.String)">
            <summary>
               Finds values and indices of the <c>k</c> largest elements for the last dimension.
            </summary>
            <param name="input">
               1-D or higher with last dimension at least <c>k</c>.
            </param>
            <param name="k">
               0-D.  Number of top elements to look for along the last dimension (along each
               row for matrices).
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TopKV2'.
            </param>
            <param name="sorted">
               If true the resulting <c>k</c> elements will be sorted by the values in
               descending order.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               values : The <c>k</c> largest elements along each last dimensional slice.
               indices : The indices of <c>values</c> within the last dimension of <c>input</c>.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               If the input is a vector (rank-1), finds the <c>k</c> largest entries in the vector
               and outputs their values and indices as vectors.  Thus <c>values[j]</c> is the
               <c>j</c>-th largest entry in <c>input</c>, and its index is <c>indices[j]</c>.
               
               For matrices (resp. higher rank input), computes the top <c>k</c> entries in each
               row (resp. vector along the last dimension).  Thus,
               
               values.shape = indices.shape = input.shape[:-1] + [k]
               
               If two elements are equal, the lower-index element appears first.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.transpose(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Shuffle dimensions of x according to a permutation.
            </summary>
            <param name="x">
            </param>
            <param name="perm">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Transpose'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The output <c>y</c> has the same rank as <c>x</c>. The shapes of <c>x</c> and <c>y</c> satisfy:
               <c>y.shape[i] == x.shape[perm[i]] for i in [0, 1, ..., rank(x) - 1]</c>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.truncate_div(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns x / y element-wise for integer types.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TruncateDiv'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Truncation designates that negative numbers will round fractional quantities
               toward zero. I.e. -7 / 5 = -1. This matches C semantics but it is different
               than Python semantics. See <c>FloorDiv</c> for a division function that matches
               Python Semantics.
               
               *NOTE*: <c>TruncateDiv</c> supports broadcasting. More about broadcasting
               [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.truncate_mod(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns element-wise remainder of division. This emulates C semantics in that
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TruncateMod'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               the result here is consistent with a truncating divide. E.g. <c>truncate(x / y) *
               y + truncate_mod(x, y) = x</c>.
               
               *NOTE*: <c>TruncateMod</c> supports broadcasting. More about broadcasting
               [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.truncated_normal(Tensorflow.Tensor,Tensorflow.TF_DataType,System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Outputs random values from a truncated normal distribution.
            </summary>
            <param name="shape">
               The shape of the output tensor.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TruncatedNormal'.
            </param>
            <param name="dtype">
               Optional argument
               The type of the output.
            </param>
            <param name="seed">
               If either <c>seed</c> or <c>seed2</c> are set to be non-zero, the random number
               generator is seeded by the given seed.  Otherwise, it is seeded by a
               random seed.
            </param>
            <param name="seed2">
               A second seed to avoid seed collision.
            </param>
            <returns>
               A tensor of the specified shape filled with random truncated normal
               values.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The generated values follow a normal distribution with mean 0 and standard
               deviation 1, except that values whose magnitude is more than 2 standard
               deviations from the mean are dropped and re-picked.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.try_rpc(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.Nullable{System.Boolean},System.Nullable{System.Int32},System.String)">
            <summary>
               Perform batches of RPC requests.
            </summary>
            <param name="address">
               <c>0-D</c> or <c>1-D</c>.  The address (i.e. host_name:port) of the RPC server.
               If this tensor has more than 1 element, then multiple parallel rpc requests
               are sent.  This argument broadcasts with <c>method</c> and <c>request</c>.
            </param>
            <param name="method">
               <c>0-D</c> or <c>1-D</c>.  The method address on the RPC server.
               If this tensor has more than 1 element, then multiple parallel rpc requests
               are sent.  This argument broadcasts with <c>address</c> and <c>request</c>.
            </param>
            <param name="request">
               <c>0-D</c> or <c>1-D</c>.  Serialized proto strings: the rpc request argument.
               If this tensor has more than 1 element, then multiple parallel rpc requests
               are sent.  This argument broadcasts with <c>address</c> and <c>method</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'TryRpc'.
            </param>
            <param name="protocol">
               RPC protocol to use.  Empty string means use the default protocol.
               Options include 'grpc'.
            </param>
            <param name="fail_fast">
               <c>boolean</c>. If <c>true</c> (default), then failures to connect
               (i.e., the server does not immediately respond) cause an RPC failure.
            </param>
            <param name="timeout_in_ms">
               <c>int</c>. If <c>0</c> (default), then the kernel will run the RPC
               request and only time out if the RPC deadline passes or the session times out.
               If this value is greater than <c>0</c>, then the op will raise an exception if
               the RPC takes longer than <c>timeout_in_ms</c>.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               response : Same shape as <c>request</c>. Serialized proto strings: the rpc responses.
               status_code : Same shape as <c>request</c>.  Values correspond to tensorflow Status enum codes.
               status_message : Same shape as <c>request</c>.  Values correspond to Status messages
               returned from the RPC calls.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               This op asynchronously performs either a single RPC request, or a batch
               of requests.  RPC requests are defined by three main parameters:
               
               - <c>address</c> (the host+port or BNS address of the request)
               - <c>method</c> (the method name for the request)
               - <c>request</c> (the serialized proto string, or vector of strings,
               of the RPC request argument).
               
               For example, if you have an RPC service running on port localhost:2345,
               and its interface is configured with the following proto declaration:
               
              <code>
               service MyService {
               rpc MyMethod(MyRequestProto) returns (MyResponseProto) {
               }
               };
              </code>
               
               then call this op with arguments:
               
              <code>
               address = "localhost:2345"
               method = "MyService/MyMethod"
              </code>
               
               The <c>request</c> tensor is a string tensor representing serialized <c>MyRequestProto</c>
               strings; and the output string tensor <c>response</c> will have the same shape
               and contain (upon successful completion) corresponding serialized
               <c>MyResponseProto</c> strings.
               
               For example, to send a single, empty, <c>MyRequestProto</c>, call
               this op with <c>request = ""</c>.  To send 5 **parallel** empty requests,
               call this op with <c>request = ["", "", "", "", ""]</c>.
               
               More generally, one can create a batch of <c>MyRequestProto</c> serialized protos
               from regular batched tensors using the <c>encode_proto</c> op, and convert
               the response <c>MyResponseProto</c> serialized protos to batched tensors
               using the <c>decode_proto</c> op.
               
               **NOTE** Working with serialized proto strings is faster than instantiating
               actual proto objects in memory, so no performance degradation is expected
               compared to writing custom kernels for this workflow.
               
               Unlike the standard <c>Rpc</c> op, if the connection fails or the remote worker
               returns an error status, this op does **not** reraise the exception.
               Instead, the <c>status_code</c> and <c>status_message</c> entry for the corresponding RPC
               call is set with the error returned from the RPC call.  The <c>response</c> tensor
               will contain valid response values for those minibatch entries whose RPCs did
               not fail; the rest of the entries will have empty strings.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.unbatch(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32,System.String,System.String,System.String)">
            <summary>
               Reverses the operation of Batch for a single output Tensor.
            </summary>
            <param name="batched_tensor">
            </param>
            <param name="batch_index">
            </param>
            <param name="id">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Unbatch'.
            </param>
            <param name="timeout_micros">
               Optional argument
            </param>
            <param name="container">
            </param>
            <param name="shared_name">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               An instance of Unbatch either receives an empty batched_tensor, in which case it
               asynchronously waits until the values become available from a concurrently
               running instance of Unbatch with the same container and shared_name, or receives
               a non-empty batched_tensor in which case it finalizes all other concurrently
               running instances and outputs its own element from the batch.
               
               batched_tensor: The possibly transformed output of Batch. The size of the first
               dimension should remain unchanged by the transformations for the operation to
               work.
               batch_index: The matching batch_index obtained from Batch.
               id: The id scalar emitted by Batch.
               unbatched_tensor: The Tensor corresponding to this execution.
               timeout_micros: Maximum amount of time (in microseconds) to wait to receive the
               batched input tensor associated with a given invocation of the op.
               container: Container to control resource sharing.
               shared_name: Instances of Unbatch with the same container and shared_name are
               assumed to possibly belong to the same batch. If left empty, the op name will
               be used as the shared name.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.unbatch_dataset(Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               A dataset that splits the elements of its input into multiple elements.
            </summary>
            <param name="input_dataset">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'UnbatchDataset'.
            </param>
            <param name="output_types">
               Optional argument
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.unbatch_grad(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.String,System.String)">
            <summary>
               Gradient of Unbatch.
            </summary>
            <param name="original_input">
            </param>
            <param name="batch_index">
            </param>
            <param name="grad">
            </param>
            <param name="id">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'UnbatchGrad'.
            </param>
            <param name="container">
            </param>
            <param name="shared_name">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Acts like Batch but using the given batch_index index of batching things as they
               become available. This ensures that the gradients are propagated back in the
               same session which did the forward pass.
               
               original_input: The input to the Unbatch operation this is the gradient of.
               batch_index: The batch_index given to the Unbatch operation this is the gradient
               of.
               grad: The downstream gradient.
               id: The id scalar emitted by Batch.
               batched_grad: The return value, either an empty tensor or the batched gradient.
               container: Container to control resource sharing.
               shared_name: Instances of UnbatchGrad with the same container and shared_name
               are assumed to possibly belong to the same batch. If left empty, the op name
               will be used as the shared name.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.uniform_candidate_sampler(Tensorflow.Tensor,System.Int32,System.Int32,System.Boolean,System.Int32,System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
               Generates labels for candidate sampling with a uniform distribution.
            </summary>
            <param name="true_classes">
               A batch_size * num_true matrix, in which each row contains the
               IDs of the num_true target_classes in the corresponding original label.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'UniformCandidateSampler'.
            </param>
            <param name="num_true">
               Optional argument
               Number of true labels per context.
            </param>
            <param name="num_sampled">
               Optional argument
               Number of candidates to randomly sample.
            </param>
            <param name="unique">
               Optional argument
               If unique is true, we sample with rejection, so that all sampled
               candidates in a batch are unique. This requires some approximation to
               estimate the post-rejection sampling probabilities.
            </param>
            <param name="range_max">
               Optional argument
               The sampler will sample integers from the interval [0, range_max).
            </param>
            <param name="seed">
               If either seed or seed2 are set to be non-zero, the random number
               generator is seeded by the given seed.  Otherwise, it is seeded by a
               random seed.
            </param>
            <param name="seed2">
               An second seed to avoid seed collision.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               sampled_candidates : A vector of length num_sampled, in which each element is
               the ID of a sampled candidate.
               true_expected_count : A batch_size * num_true matrix, representing
               the number of times each candidate is expected to occur in a batch
               of sampled candidates. If unique=true, then this is a probability.
               sampled_expected_count : A vector of length num_sampled, for each sampled
               candidate representing the number of times the candidate is expected
               to occur in a batch of sampled candidates.  If unique=true, then this is a
               probability.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               See explanations of candidate sampling and the data formats at
               go/candidate-sampling.
               
               For each batch, this op picks a single set of sampled candidate labels.
               
               The advantages of sampling candidates per-batch are simplicity and the
               possibility of efficient dense matrix multiplication. The disadvantage is that
               the sampled candidates must be chosen independently of the context and of the
               true labels.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.unique(Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Finds unique elements in a 1-D tensor.
            </summary>
            <param name="x">
               1-D.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Unique'.
            </param>
            <param name="out_idx">
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               y : 1-D.
               idx : 1-D.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               This operation returns a tensor <c>y</c> containing all of the unique elements of <c>x</c>
               sorted in the same order that they occur in <c>x</c>. This operation also returns a
               tensor <c>idx</c> the same size as <c>x</c> that contains the index of each value of <c>x</c>
               in the unique output <c>y</c>. In other words:
               
               <c>y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]</c>
               
               For example:
               
              <code>
               # tensor 'x' is [1, 1, 2, 4, 4, 4, 7, 8, 8]
               y, idx = unique(x)
               y ==&amp;gt; [1, 2, 4, 7, 8]
               idx ==&amp;gt; [0, 0, 1, 2, 2, 2, 3, 4, 4]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.unique_v2(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Finds unique elements along an axis of a tensor.
            </summary>
            <param name="x">
               A <c>Tensor</c>.
            </param>
            <param name="axis">
               A <c>Tensor</c> of type <c>int32</c> (default: None). The axis of the Tensor to
               find the unique elements.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'UniqueV2'.
            </param>
            <param name="out_idx">
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               y : A <c>Tensor</c>. Unique elements along the <c>axis</c> of <c>Tensor</c> x.
               idx : A 1-D Tensor. Has the same type as x that contains the index of each
               value of x in the output y.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               This operation either returns a tensor <c>y</c> containing unique elements
               along the <c>axis</c> of a tensor. The returned unique elements is sorted
               in the same order as they occur along <c>axis</c> in <c>x</c>.
               This operation also returns a tensor <c>idx</c> that is the same size as
               the number of the elements in <c>x</c> along the <c>axis</c> dimension. It
               contains the index in the unique output <c>y</c>.
               In other words, for an <c>1-D</c> tensor <c>x</c> with <c>axis = None</c>:
               
               <c>y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]</c>
               
               For example:
               
              <code>
               # tensor 'x' is [1, 1, 2, 4, 4, 4, 7, 8, 8]
               y, idx = unique(x)
               y ==&amp;gt; [1, 2, 4, 7, 8]
               idx ==&amp;gt; [0, 0, 1, 2, 2, 2, 3, 4, 4]
              </code>
               
               For an <c>2-D</c> tensor <c>x</c> with <c>axis = 0</c>:
               
              <code>
               # tensor 'x' is [[1, 0, 0],
               #                [1, 0, 0],
               #                [2, 0, 0]]
               y, idx = unique(x, axis=0)
               y ==&amp;gt; [[1, 0, 0],
               [2, 0, 0]]
               idx ==&amp;gt; [0, 0, 1]
              </code>
               
               For an <c>2-D</c> tensor <c>x</c> with <c>axis = 1</c>:
               
              <code>
               # tensor 'x' is [[1, 0, 0],
               #                [1, 0, 0],
               #                [2, 0, 0]]
               y, idx = unique(x, axis=1)
               y ==&amp;gt; [[1, 0],
               [1, 0],
               [2, 0]]
               idx ==&amp;gt; [0, 1, 1]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.unique_with_counts(Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Finds unique elements in a 1-D tensor.
            </summary>
            <param name="x">
               1-D.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'UniqueWithCounts'.
            </param>
            <param name="out_idx">
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               y : 1-D.
               idx : 1-D.
               count : 1-D.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               This operation returns a tensor <c>y</c> containing all of the unique elements of <c>x</c>
               sorted in the same order that they occur in <c>x</c>. This operation also returns a
               tensor <c>idx</c> the same size as <c>x</c> that contains the index of each value of <c>x</c>
               in the unique output <c>y</c>. Finally, it returns a third tensor <c>count</c> that
               contains the count of each element of <c>y</c> in <c>x</c>. In other words:
               
               <c>y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]</c>
               
               For example:
               
              <code>
               # tensor 'x' is [1, 1, 2, 4, 4, 4, 7, 8, 8]
               y, idx, count = unique_with_counts(x)
               y ==&amp;gt; [1, 2, 4, 7, 8]
               idx ==&amp;gt; [0, 0, 1, 2, 2, 2, 3, 4, 4]
               count ==&amp;gt; [2, 1, 3, 1, 2]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.unique_with_counts_v2(Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Finds unique elements along an axis of a tensor.
            </summary>
            <param name="x">
               A <c>Tensor</c>.
            </param>
            <param name="axis">
               A <c>Tensor</c> of type <c>int32</c> (default: None). The axis of the Tensor to
               find the unique elements.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'UniqueWithCountsV2'.
            </param>
            <param name="out_idx">
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               y : A <c>Tensor</c>. Unique elements along the <c>axis</c> of <c>Tensor</c> x.
               idx : A 1-D Tensor. Has the same type as x that contains the index of each
               value of x in the output y.
               count : A 1-D Tensor. The count of each value of x in the output y.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               This operation either returns a tensor <c>y</c> containing unique elements
               along the <c>axis</c> of a tensor. The returned unique elements is sorted
               in the same order as they occur along <c>axis</c> in <c>x</c>.
               This operation also returns a tensor <c>idx</c> and a tensor <c>count</c>
               that are the same size as the number of the elements in <c>x</c> along the
               <c>axis</c> dimension. The <c>idx</c> contains the index in the unique output <c>y</c>
               and the <c>count</c> contains the count in the unique output <c>y</c>.
               In other words, for an <c>1-D</c> tensor <c>x</c> with <c>axis = None</c>:
               
               <c>y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]</c>
               
               For example:
               
              <code>
               # tensor 'x' is [1, 1, 2, 4, 4, 4, 7, 8, 8]
               y, idx, count = unique_with_counts(x)
               y ==&amp;gt; [1, 2, 4, 7, 8]
               idx ==&amp;gt; [0, 0, 1, 2, 2, 2, 3, 4, 4]
               count ==&amp;gt; [2, 1, 3, 1, 2]
              </code>
               
               For an <c>2-D</c> tensor <c>x</c> with <c>axis = 0</c>:
               
              <code>
               # tensor 'x' is [[1, 0, 0],
               #                [1, 0, 0],
               #                [2, 0, 0]]
               y, idx, count = unique_with_counts(x, axis=0)
               y ==&amp;gt; [[1, 0, 0],
               [2, 0, 0]]
               idx ==&amp;gt; [0, 0, 1]
               count ==&amp;gt; [2, 1]
              </code>
               
               For an <c>2-D</c> tensor <c>x</c> with <c>axis = 1</c>:
               
              <code>
               # tensor 'x' is [[1, 0, 0],
               #                [1, 0, 0],
               #                [2, 0, 0]]
               y, idx, count = unique_with_counts(x, axis=1)
               y ==&amp;gt; [[1, 0],
               [1, 0],
               [2, 0]]
               idx ==&amp;gt; [0, 1, 1]
               count ==&amp;gt; [1, 2]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.unpack(Tensorflow.Tensor,System.Int32,System.Nullable{System.Int32},System.String)">
            <summary>
               Unpacks a given dimension of a rank-<c>R</c> tensor into <c>num</c> rank-<c>(R-1)</c> tensors.
            </summary>
            <param name="value">
               1-D or higher, with <c>axis</c> dimension size equal to <c>num</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Unpack'.
            </param>
            <param name="num">
               Optional argument
            </param>
            <param name="axis">
               Dimension along which to unpack.  Negative values wrap around, so the
               valid range is <c>[-R, R)</c>.
            </param>
            <returns>
               The list of tensors unpacked from <c>value</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Unpacks <c>num</c> tensors from <c>value</c> by chipping it along the <c>axis</c> dimension.
               For example, given a tensor of shape <c>(A, B, C, D)</c>;
               
               If <c>axis == 0</c> then the i'th tensor in <c>output</c> is the slice <c>value[i, :, :, :]</c>
               and each tensor in <c>output</c> will have shape <c>(B, C, D)</c>. (Note that the
               dimension unpacked along is gone, unlike <c>split</c>).
               
               If <c>axis == 1</c> then the i'th tensor in <c>output</c> is the slice <c>value[:, i, :, :]</c>
               and each tensor in <c>output</c> will have shape <c>(A, C, D)</c>.
               Etc.
               
               This is the opposite of <c>pack</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.unravel_index(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Converts a flat index or array of flat indices into a tuple of
            </summary>
            <param name="indices">
               An 0-D or 1-D <c>int</c> Tensor whose elements are indices into the
               flattened version of an array of dimensions dims.
            </param>
            <param name="dims">
               An 1-D <c>int</c> Tensor. The shape of the array to use for unraveling
               indices.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'UnravelIndex'.
            </param>
            <returns>
               An 2-D (or 1-D if indices is 0-D) tensor where each row has the
               same shape as the indices array.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               coordinate arrays.
               
               @compatibility(numpy)
               Equivalent to np.unravel_index
               @end_compatibility
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.unsorted_segment_max(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes the maximum along segments of a tensor.
            </summary>
            <param name="data">
            </param>
            <param name="segment_ids">
               A tensor whose shape is a prefix of <c>data.shape</c>.END
               }
               out_arg {
               name: "output"
               description: &amp;lt;&amp;lt;END
               Has same shape as data, except for the first <c>segment_ids.rank</c>
               dimensions, which are replaced with a single dimension which has size
               <c>num_segments</c>.
            </param>
            <param name="num_segments">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'UnsortedSegmentMax'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Read
               [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#Segmentation)
               for an explanation of segments.
               
               This operator is similar to the unsorted segment sum operator found
               [(here)](../../../api_docs/python/math_ops.md#UnsortedSegmentSum).
               Instead of computing the sum over segments, it computes the maximum such that:
               
               \\(output_i = \max_{j...} data[j...]\\) where max is over tuples <c>j...</c> such
               that <c>segment_ids[j...] == i</c>.
               
               If the maximum is empty for a given segment ID <c>i</c>, it outputs the smallest
               possible value for the specific numeric type,
               <c>output[i] = numeric_limits&amp;lt;T&amp;gt;::lowest()</c>.
               
               If the given segment ID <c>i</c> is negative, then the corresponding value is
               dropped, and will not be included in the result.
               
               &amp;lt;div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;"&amp;gt;
               &amp;lt;img style="width:100%" src="https://www.tensorflow.org/images/UnsortedSegmentMax.png" alt&amp;gt;
               &amp;lt;/div&amp;gt;
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.unsorted_segment_min(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes the minimum along segments of a tensor.
            </summary>
            <param name="data">
            </param>
            <param name="segment_ids">
               A tensor whose shape is a prefix of <c>data.shape</c>.
            </param>
            <param name="num_segments">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'UnsortedSegmentMin'.
            </param>
            <returns>
               Has same shape as data, except for the first <c>segment_ids.rank</c>
               dimensions, which are replaced with a single dimension which has size
               <c>num_segments</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Read
               [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#segmentation)
               for an explanation of segments.
               
               This operator is similar to the unsorted segment sum operator found
               [(here)](../../../api_docs/python/math_ops.md#UnsortedSegmentSum).
               Instead of computing the sum over segments, it computes the minimum such that:
               
               \\(output_i = \min_{j...} data_[j...]\\) where min is over tuples <c>j...</c> such
               that <c>segment_ids[j...] == i</c>.
               
               If the minimum is empty for a given segment ID <c>i</c>, it outputs the largest
               possible value for the specific numeric type,
               <c>output[i] = numeric_limits&amp;lt;T&amp;gt;::max()</c>.
               
               If the given segment ID <c>i</c> is negative, then the corresponding value is
               dropped, and will not be included in the result.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.unsorted_segment_prod(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes the product along segments of a tensor.
            </summary>
            <param name="data">
            </param>
            <param name="segment_ids">
               A tensor whose shape is a prefix of <c>data.shape</c>.
            </param>
            <param name="num_segments">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'UnsortedSegmentProd'.
            </param>
            <returns>
               Has same shape as data, except for the first <c>segment_ids.rank</c>
               dimensions, which are replaced with a single dimension which has size
               <c>num_segments</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Read
               [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#segmentation)
               for an explanation of segments.
               
               This operator is similar to the unsorted segment sum operator found
               [(here)](../../../api_docs/python/math_ops.md#UnsortedSegmentSum).
               Instead of computing the sum over segments, it computes the product of all
               entries belonging to a segment such that:
               
               \\(output_i = \prod_{j...} data[j...]\\) where the product is over tuples
               <c>j...</c> such that <c>segment_ids[j...] == i</c>.
               
               If there is no entry for a given segment ID <c>i</c>, it outputs 1.
               
               If the given segment ID <c>i</c> is negative, then the corresponding value is
               dropped, and will not be included in the result.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.unsorted_segment_sum(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes the sum along segments of a tensor.
            </summary>
            <param name="data">
            </param>
            <param name="segment_ids">
               A tensor whose shape is a prefix of <c>data.shape</c>.
            </param>
            <param name="num_segments">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'UnsortedSegmentSum'.
            </param>
            <returns>
               Has same shape as data, except for the first <c>segment_ids.rank</c>
               dimensions, which are replaced with a single dimension which has size
               <c>num_segments</c>.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Read
               [the section on segmentation](https://tensorflow.org/api_guides/python/math_ops#Segmentation)
               for an explanation of segments.
               
               Computes a tensor such that
               \\(output[i] = \sum_{j...} data[j...]\\) where the sum is over tuples <c>j...</c> such
               that <c>segment_ids[j...] == i</c>.  Unlike <c>SegmentSum</c>, <c>segment_ids</c>
               need not be sorted and need not cover all values in the full
               range of valid values.
               
               If the sum is empty for a given segment ID <c>i</c>, <c>output[i] = 0</c>.
               If the given segment ID <c>i</c> is negative, the value is dropped and will not be
               added to the sum of the segment.
               
               <c>num_segments</c> should equal the number of distinct segment IDs.
               
               &amp;lt;div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;"&amp;gt;
               &amp;lt;img style="width:100%" src="https://www.tensorflow.org/images/UnsortedSegmentSum.png" alt&amp;gt;
               &amp;lt;/div&amp;gt;
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.unstage(Tensorflow.TF_DataType[],System.Nullable{System.Int32},System.Nullable{System.Int32},System.String,System.String,System.String)">
            <summary>
               Op is similar to a lightweight Dequeue.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Unstage'.
            </param>
            <param name="dtypes">
               Optional argument
            </param>
            <param name="capacity">
            </param>
            <param name="memory_limit">
            </param>
            <param name="container">
            </param>
            <param name="shared_name">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The basic functionality is similar to dequeue with many fewer
               capabilities and options.  This Op is optimized for performance.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.var_handle_op(Tensorflow.TF_DataType,Tensorflow.TensorShape,System.String,System.String,System.String)">
            <summary>
               Creates a handle to a Variable resource.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'VarHandleOp'.
            </param>
            <param name="dtype">
               Optional argument
               the type of this variable. Must agree with the dtypes
               of all ops using this variable.
            </param>
            <param name="shape">
               Optional argument
               The (possibly partially specified) shape of this variable.
            </param>
            <param name="container">
               the container this variable is placed in.
            </param>
            <param name="shared_name">
               the name by which this variable is referred to.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.var_is_initialized_op(Tensorflow.Tensor,System.String)">
            <summary>
               Checks whether a resource handle-based variable has been initialized.
            </summary>
            <param name="resource">
               the input resource handle.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'VarIsInitializedOp'.
            </param>
            <returns>
               a scalar boolean which is true if the variable has been
               initialized.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.variable(Tensorflow.TensorShape,Tensorflow.TF_DataType,System.String,System.String,System.String)">
            <summary>
               Use VariableV2 instead.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Variable'.
            </param>
            <param name="shape">
               Optional argument
            </param>
            <param name="dtype">
               Optional argument
            </param>
            <param name="container">
            </param>
            <param name="shared_name">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.variable_shape(Tensorflow.Tensor,System.Nullable{Tensorflow.TF_DataType},System.String)">
            <summary>
               Returns the shape of the variable pointed to by <c>resource</c>.
            </summary>
            <param name="input">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'VariableShape'.
            </param>
            <param name="out_type">
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation returns a 1-D integer tensor representing the shape of <c>input</c>.
               
               For example:
               
              <code>
               # 't' is [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]
               shape(t) ==&amp;gt; [2, 2, 3]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.variable_v2(Tensorflow.TensorShape,Tensorflow.TF_DataType,System.String,System.String,System.String)">
            <summary>
               Holds state in the form of a tensor that persists across steps.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'VariableV2'.
            </param>
            <param name="shape">
               Optional argument
               The shape of the variable tensor.
            </param>
            <param name="dtype">
               Optional argument
               The type of elements in the variable tensor.
            </param>
            <param name="container">
               If non-empty, this variable is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this variable is named in the given bucket
               with this shared_name. Otherwise, the node name is used instead.
            </param>
            <returns>
               A reference to the variable tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Outputs a ref to the tensor state so it may be read or modified.
               TODO(zhifengc/mrry): Adds a pointer to a more detail document
               about sharing states in tensorflow.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.where(Tensorflow.Tensor,System.String)">
            <summary>
               Returns locations of nonzero / true values in a tensor.
            </summary>
            <param name="input">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Where'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This operation returns the coordinates of true elements in <c>condition</c>. The
               coordinates are returned in a 2-D tensor where the first dimension (rows)
               represents the number of true elements, and the second dimension (columns)
               represents the coordinates of the true elements. Keep in mind, the shape of
               the output tensor can vary depending on how many true values there are in
               <c>condition</c>. Indices are output in row-major order.
               
               For example:
               
              <code>
               # 'input' tensor is [[True, False]
               #                    [True, False]]
               # 'input' has two true values, so output has two coordinates.
               # 'input' has rank of 2, so coordinates have two indices.
               where(input) ==&amp;gt; [[0, 0],
               [1, 0]]
               
               # <c>condition</c> tensor is [[[True, False]
               #                     [True, False]]
               #                    [[False, True]
               #                     [False, True]]
               #                    [[False, False]
               #                     [False, True]]]
               # 'input' has 5 true values, so output has 5 coordinates.
               # 'input' has rank of 3, so coordinates have three indices.
               where(input) ==&amp;gt; [[0, 0, 0],
               [0, 1, 0],
               [1, 0, 1],
               [1, 1, 1],
               [2, 1, 1]]
               
               # <c>condition</c> tensor is [[[1.5,  0.0]
               #                     [-0.5, 0.0]]
               #                    [[0.0,  0.25]
               #                     [0.0,  0.75]]
               #                    [[0.0,  0.0]
               #                     [0.0,  0.01]]]
               # 'input' has 5 nonzero values, so output has 5 coordinates.
               # 'input' has rank of 3, so coordinates have three indices.
               where(input) ==&amp;gt; [[0, 0, 0],
               [0, 1, 0],
               [1, 0, 1],
               [1, 1, 1],
               [2, 1, 1]]
               
               # <c>condition</c> tensor is [[[1.5 + 0.0j, 0.0  + 0.0j]
               #                     [0.0 + 0.5j, 0.0  + 0.0j]]
               #                    [[0.0 + 0.0j, 0.25 + 1.5j]
               #                     [0.0 + 0.0j, 0.75 + 0.0j]]
               #                    [[0.0 + 0.0j, 0.0  + 0.0j]
               #                     [0.0 + 0.0j, 0.01 + 0.0j]]]
               # 'input' has 5 nonzero magnitude values, so output has 5 coordinates.
               # 'input' has rank of 3, so coordinates have three indices.
               where(input) ==&amp;gt; [[0, 0, 0],
               [0, 1, 0],
               [1, 0, 1],
               [1, 1, 1],
               [2, 1, 1]]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.whole_file_reader(System.String,System.String,System.String)">
            <summary>
               A Reader that outputs the entire contents of a file as a value.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'WholeFileReader'.
            </param>
            <param name="container">
               If non-empty, this reader is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this reader is named in the given bucket
               with this shared_name. Otherwise, the node name is used instead.
            </param>
            <returns>
               The handle to reference the Reader.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               To use, enqueue filenames in a Queue.  The output of ReaderRead will
               be a filename (key) and the contents of that file (value).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.whole_file_reader_v2(System.String,System.String,System.String)">
            <summary>
               A Reader that outputs the entire contents of a file as a value.
            </summary>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'WholeFileReaderV2'.
            </param>
            <param name="container">
               If non-empty, this reader is placed in the given container.
               Otherwise, a default container is used.
            </param>
            <param name="shared_name">
               If non-empty, this reader is named in the given bucket
               with this shared_name. Otherwise, the node name is used instead.
            </param>
            <returns>
               The handle to reference the Reader.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               To use, enqueue filenames in a Queue.  The output of ReaderRead will
               be a filename (key) and the contents of that file (value).
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.worker_heartbeat(Tensorflow.Tensor,System.String)">
            <summary>
               Worker heartbeat op.
            </summary>
            <param name="request">
               A string tensor containing a serialized WorkerHeartbeatRequest
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'WorkerHeartbeat'.
            </param>
            <returns>
               A string tensor containing a serialized WorkerHeartbeatResponse
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Heartbeats may be sent periodically to indicate the coordinator is still active,
               to retrieve the current worker status and to expedite shutdown when necessary.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.write_file(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Writes contents to the file at input filename. Creates file and recursively
            </summary>
            <param name="filename">
               scalar. The name of the file to which we write the contents.
            </param>
            <param name="contents">
               scalar. The content to be written to the output file.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'WriteFile'.
            </param>
            <returns>
               Returns the description of the operation
            </returns>
            <remarks>
               creates directory if not existing.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.zeros_like(Tensorflow.Tensor,System.String)">
            <summary>
               Returns a tensor of zeros with the same shape and type as x.
            </summary>
            <param name="x">
               a tensor of type T.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ZerosLike'.
            </param>
            <returns>
               a tensor of the same shape and type as x but filled with zeros.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.zeta(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Compute the Hurwitz zeta function \\(\zeta(x, q)\\).
            </summary>
            <param name="x">
            </param>
            <param name="q">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Zeta'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The Hurwitz zeta function is defined as:
               
               
               \\(\zeta(x, q) = \sum_{n=0}^{\infty} (q + n)^{-x}\\)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_ops.zip_dataset(Tensorflow.Tensor[],Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
               Creates a dataset that zips together <c>input_datasets</c>.
            </summary>
            <param name="input_datasets">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ZipDataset'.
            </param>
            <param name="output_types">
               Optional argument
            </param>
            <param name="output_shapes">
               Optional argument
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="T:Tensorflow.Operations.Initializers.VarianceScaling">
            <summary>
            Initializer capable of adapting its scale to the shape of weights tensors.
            </summary>
        </member>
        <member name="P:Tensorflow.Operations.BodyItemInRnnWhileLoop.time">
            <summary>
            int32 scalar Tensor.
            </summary>
        </member>
        <member name="P:Tensorflow.Operations.BodyItemInRnnWhileLoop.output_ta_t">
            <summary>
            List of `TensorArray`s that represent the output.
            </summary>
        </member>
        <member name="P:Tensorflow.Operations.BodyItemInRnnWhileLoop.state">
            <summary>
            nested tuple of vector tensors that represent the state.
            </summary>
        </member>
        <member name="P:Tensorflow.Operations.Conv2dParams.DataFormat">
            <summary>
            An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
            Specify the data format of the input and output data. With the
            default format "NHWC", the data is stored in the order of:
            [batch, height, width, channels].
            </summary>
        </member>
        <member name="P:Tensorflow.Operations.Conv2dParams.Input">
            <summary>
            Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
            A 4-D tensor. The dimension order is interpreted according to the value
            </summary>
        </member>
        <member name="P:Tensorflow.Operations.Conv2dParams.InputSizes">
            <summary>
            An integer vector representing the shape of `input`
            </summary>
        </member>
        <member name="P:Tensorflow.Operations.Conv2dParams.Filter">
            <summary>
            A 4-D tensor of shape
            </summary>
        </member>
        <member name="P:Tensorflow.Operations.Conv2dParams.FilterSizes">
            <summary>
            An integer vector representing the tensor shape of `filter`
            </summary>
        </member>
        <member name="P:Tensorflow.Operations.Conv2dParams.OutBackProp">
            <summary>
            A `Tensor`. Must have the same type as `filter`.
            4-D with shape `[batch, out_height, out_width, out_channels]`.
            </summary>
        </member>
        <member name="P:Tensorflow.Operations.Conv2dParams.Strides">
            <summary>
            The stride of the sliding window for each
            dimension of `input`. The dimension order is determined by the value of
            `data_format`, see below for details.
            </summary>
        </member>
        <member name="P:Tensorflow.Operations.Conv2dParams.Padding">
            <summary>
            A `string` from: `"SAME", "VALID", "EXPLICIT"`.
            </summary>
        </member>
        <member name="M:Tensorflow.Operations.gen_nn_ops.conv2d(Tensorflow.Operations.Conv2dParams)">
            <summary>
            Computes a 2-D convolution given 4-D `input` and `filter` tensors.
            
            Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
            and a filter / kernel tensor of shape
            `[filter_height, filter_width, in_channels, out_channels]`, this op
            performs the following:
            
            1. Flattens the filter to a 2-D matrix with shape
               `[filter_height * filter_width * in_channels, output_channels]`.
            2. Extracts image patches from the input tensor to form a *virtual*
               tensor of shape `[batch, out_height, out_width,
               filter_height * filter_width * in_channels]`.
            3. For each patch, right-multiplies the filter matrix and the image patch
               vector.
            </summary>
            <param name="parameters"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_nn_ops.conv2d_backprop_filter(Tensorflow.Operations.Conv2dParams)">
            <summary>
            Computes the gradients of convolution with respect to the filter.
            </summary>
            <param name="parameters"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_nn_ops.conv2d_backprop_input(Tensorflow.Operations.Conv2dParams)">
            <summary>
            Computes the gradients of convolution with respect to the input.
            </summary>
            <param name="parameters"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_nn_ops.elu(Tensorflow.Tensor,System.String)">
            <summary>
            Computes exponential linear: <c>exp(features) - 1</c> if &amp;lt; 0, <c>features</c> otherwise.
            </summary>
            <param name="features">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Elu'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               See [Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)
               ](http://arxiv.org/abs/1511.07289)
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_nn_ops.fused_batch_norm_grad(Tensorflow.Operations.FusedBatchNormParams)">
            <summary>
            Gradient for batch normalization.
            </summary>
            <param name="params"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_nn_ops.local_response_normalization(Tensorflow.Tensor,System.Int32,System.Int32,System.Int32,System.Single,System.String)">
            <summary>
            Local Response Normalization.
            </summary>
            <param name="input"></param>
            <param name="depth_radius"></param>
            <param name="bias"></param>
            <param name="alpha"></param>
            <param name="beta"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_nn_ops.in_top_kv2(Tensorflow.Tensor,Tensorflow.Tensor,System.Int32,System.String)">
            <summary>
            Says whether the targets are in the top `K` predictions.
            </summary>
            <param name="predictions"></param>
            <param name="targets"></param>
            <param name="k"></param>
            <param name="name"></param>
            <returns>A `Tensor` of type `bool`.</returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_nn_ops.softmax_cross_entropy_with_logits(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
            Computes softmax cross entropy cost and gradients to backpropagate.
            </summary>
            <param name="features"></param>
            <param name="labels"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Operations.gen_nn_ops.sparse_softmax_cross_entropy_with_logits(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes softmax cross entropy cost and gradients to backpropagate.
            </summary>
            <param name="features">
               batch_size x num_classes matrix
            </param>
            <param name="labels">
               batch_size vector with values in [0, num_classes).
               This is the label for the given minibatch entry.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SparseSoftmaxCrossEntropyWithLogits'.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               loss : Per example loss (batch_size vector).
               backprop : backpropagated gradients (batch_size x num_classes matrix).
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               Unlike <c>SoftmaxCrossEntropyWithLogits</c>, this operation does not accept
               a matrix of label probabilities, but rather a single label per row
               of features.  This label is considered to have probability 1.0 for the
               given row.
               
               Inputs are the logits, not probabilities.
            </remarks>
        </member>
        <member name="M:Tensorflow.Operations.gen_nn_ops.relu(Tensorflow.Tensor,System.String)">
            <summary>
            Computes rectified linear: `max(features, 0)`.
            </summary>
            <param name="features">A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`, `qint8`.</param>
            <param name="name">A name for the operation (optional).</param>
            <returns>A `Tensor`. Has the same type as `features`.</returns>
        </member>
        <member name="T:Tensorflow.Operations.LSTMStateTuple">
            <summary>
            Tuple used by LSTM Cells for `state_size`, `zero_state`, and output state.
            
            Stores two elements: `(c, h)`, in that order. Where `c` is the hidden state
            and `h` is the output.
            
            Only used when `state_is_tuple=True`.
            </summary>
        </member>
        <member name="T:Tensorflow.Operations.MaxPoolFunction">
            <summary>
            Performs the max pooling on the input.
            </summary>
        </member>
        <member name="M:Tensorflow.Operations.rnn.static_bidirectional_rnn(Tensorflow.BasicLstmCell,Tensorflow.BasicLstmCell,Tensorflow.Tensor[],Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType,Tensorflow.Tensor,System.String)">
            <summary>
            Creates a bidirectional recurrent neural network.
            </summary>
        </member>
        <member name="M:Tensorflow.Operations.rnn._dynamic_rnn_loop(Tensorflow.RnnCell,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32,System.Boolean,Tensorflow.Tensor,Tensorflow.TF_DataType)">
            <summary>
            Internal implementation of Dynamic RNN.
            </summary>
            <param name="cell"></param>
            <param name="inputs"></param>
            <param name="initial_state"></param>
            <param name="parallel_iterations"></param>
            <param name="swap_memory"></param>
            <param name="sequence_length"></param>
            <param name="dtype"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Operations.rnn._transpose_batch_time(Tensorflow.Tensor)">
            <summary>
            Transposes the batch and time dimensions of a Tensor.
            </summary>
            <param name="x"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Operations.rnn._best_effort_input_batch_size(System.Collections.Generic.List{Tensorflow.Tensor})">
            <summary>
            Get static input batch size if available, with fallback to the dynamic one.
            </summary>
            <param name="flat_input"></param>
            <returns></returns>
        </member>
        <member name="F:Tensorflow.Operations._GraphTensorArray._colocate_with_first_write_call">
            <summary>
            Used to keep track of what tensors the TensorArray should be
            colocated with.  We choose to colocate the TensorArray with the
            first tensor written to it.
            </summary>
        </member>
        <member name="M:Tensorflow.array_ops.prevent_gradient(Tensorflow.Tensor,System.String,System.String)">
            <summary>
               An identity op that triggers an error if a gradient is requested.
            </summary>
            <param name="input">
               any tensor.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'PreventGradient'.
            </param>
            <param name="message">
               Will be printed in the error when anyone tries to differentiate
               this operation.
            </param>
            <returns>
               the same input tensor.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               When executed in a graph, this op outputs its input tensor as-is.
               
               When building ops to compute gradients, the TensorFlow gradient system
               will return an error when trying to lookup the gradient of this op,
               because no gradient must ever be registered for this function.  This
               op exists to prevent subtle bugs from silently returning unimplemented
               gradients in some corner cases.
            </remarks>
        </member>
        <member name="M:Tensorflow.array_ops._autopacking_helper(System.Object[],Tensorflow.TF_DataType,System.String)">
            <summary>
            Converts the given list or tuple to a tensor by packing.
            </summary>
            <param name="list_or_tuple">A (possibly nested) list or tuple containing a tensor.</param>
            <param name="dtype"></param>
            <param name="name"></param>
            <returns>A `tf.Tensor` with value equivalent to `list_or_tuple`.</returns>
        </member>
        <member name="M:Tensorflow.array_ops.fill(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
            Creates a tensor filled with a scalar value.
            This operation creates a tensor of shape `dims` and fills it with `value`.
            </summary>
            <param name="dims">A 1-D sequence of non-negative numbers.</param>
            <param name="value">A value to fill the returned `tf.Tensor`.</param>
            <param name="name">Optional string. The name of the output `tf.Tensor`.</param>
            <returns>A `tf.Tensor` with shape `dims` and the same dtype as `value`.</returns>
        </member>
        <member name="M:Tensorflow.array_ops.rank(Tensorflow.Tensor,System.String)">
            <summary>
            Returns the rank of a tensor.
            </summary>
            <param name="input"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.array_ops.ones_like``1(``0,Tensorflow.TF_DataType,System.String,System.Boolean)">
            <summary>
            Creates a tensor with all elements set to 1.
            </summary>
            <param name="tensor"></param>
            <param name="dtype"></param>
            <param name="name"></param>
            <param name="optimize"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.array_ops.shape(Tensorflow.Tensor,System.String,Tensorflow.TF_DataType)">
            <summary>
            Returns the shape of a tensor.
            </summary>
            <param name="input">A `Tensor` or `SparseTensor`.</param>
            <param name="name">A name for the operation (optional).</param>
            <param name="out_type">
            (Optional) The specified output type of the operation
            (`int32` or `int64`). Defaults to `tf.int32`.
            </param>
            <returns>A `Tensor` of type `out_type`.</returns>
        </member>
        <member name="M:Tensorflow.array_ops.stop_gradient(Tensorflow.Tensor,System.String)">
            <summary>
              When building ops to compute gradients, this op prevents the contribution of
              its inputs to be taken into account.Normally, the gradient generator adds ops
              to a graph to compute the derivatives of a specified 'loss' by recursively
              finding out inputs that contributed to its computation.If you insert this op
              in the graph it inputs are masked from the gradient generator.  They are not
              taken into account for computing gradients.
            </summary>
            <param name="input"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.array_ops.strided_slice(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32,System.String)">
            <summary>
            Extracts a strided slice of a tensor (generalized python array indexing).
            </summary>
            <param name="input_"></param>
            <param name="begin"></param>
            <param name="end"></param>
            <param name="strides"></param>
            <param name="begin_mask"></param>
            <param name="end_mask"></param>
            <param name="ellipsis_mask"></param>
            <param name="new_axis_mask"></param>
            <param name="shrink_axis_mask"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.array_ops.squeeze(Tensorflow.Tensor,System.Int32[],System.String,System.Int32[])">
            <summary>
            Removes dimensions of size 1 from the shape of a tensor.
            Given a tensor `input`, this operation returns a tensor of the same type with
            all dimensions of size 1 removed.If you don't want to remove all size 1
            dimensions, you can remove specific size 1 dimensions by specifying
            `axis`.
            </summary>
            <param name="input"> A `Tensor`. The `input` to squeeze.</param>
            <param name="axis"> An optional list of `ints`. Defaults to `[]`.
            If specified, only squeezes the dimensions listed.The dimension
            index starts at 0. It is an error to squeeze a dimension that is not 1.
            Must be in the range `[-rank(input), rank(input))`.</param>
            <param name="name"> A name for the operation (optional).</param>
            <param name="squeeze_dims" >Deprecated keyword argument that is now axis.</param>
            <returns>A `Tensor`. Has the same type as `input`.
            Contains the same data as `input`, but has one or more dimensions of
            size 1 removed.</returns>
        </member>
        <member name="M:Tensorflow.array_ops.broadcast_dynamic_shape(Tensorflow.Tensor,Tensorflow.Tensor)">
            <summary>
            Computes the shape of a broadcast given symbolic shapes.
            When shape_x and shape_y are Tensors representing shapes(i.e.the result of
            calling tf.shape on another Tensor) this computes a Tensor which is the shape
            of the result of a broadcasting op applied in tensors of shapes shape_x and
            shape_y.
            For example, if shape_x is [1, 2, 3] and shape_y is [5, 1, 3], the result is a
            Tensor whose value is [5, 2, 3].
            This is useful when validating the result of a broadcasting operation when the
            tensors do not have statically known shapes.
            </summary>
            <param name="shape_x"> A rank 1 integer `Tensor`, representing the shape of x.</param>
            <param name="shape_y"> A rank 1 integer `Tensor`, representing the shape of y.</param>
            <returns> A rank 1 integer `Tensor` representing the broadcasted shape.</returns>
        </member>
        <member name="M:Tensorflow.array_ops.concat(Tensorflow.Tensor[],System.Int32,System.String)">
            <summary>
            Concatenates tensors along one dimension.
            </summary>
            <param name="values"></param>
            <param name="axis"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.check_ops.assert_equal``2(``0,``1,System.Object[],System.String,System.String)">
            <summary>
            Assert the condition `x == y` holds element-wise.
            </summary>
            <param name="t1"></param>
            <param name="t2"></param>
            <param name="name"></param>
        </member>
        <member name="M:Tensorflow.confusion_matrix.remove_squeezable_dimensions(Tensorflow.Tensor,Tensorflow.Tensor,System.Int32,System.String)">
            <summary>
            Squeeze last dim if ranks differ from expected by exactly 1.
            </summary>
            <param name="labels"></param>
            <param name="predictions"></param>
            <param name="expected_rank_diff"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.control_flow_ops._EnforceShapeInvariant(Tensorflow.Tensor,Tensorflow.Tensor)">
            <summary>
            Check if the shapes of the loops variables are invariants.
            </summary>
            <param name="merge_var"></param>
            <param name="next_var"></param>
        </member>
        <member name="M:Tensorflow.control_flow_ops.no_op(System.String)">
            <summary>
            Does nothing. Only useful as a placeholder for control edges.
            </summary>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.control_flow_ops.MaybeCreateControlFlowState(System.Collections.Generic.List{Tensorflow.Operation},System.Collections.Generic.List{Tensorflow.Operation},System.Boolean)">
            <summary>
            Create the state for all the while loops involved in one gradients().
            </summary>
            <param name="between_op_list"></param>
            <param name="between_ops"></param>
            <param name="colocate_gradients_with_ops"></param>
        </member>
        <member name="M:Tensorflow.control_flow_ops.with_dependencies(Tensorflow.Operation[],Tensorflow.Tensor,System.String)">
            <summary>
            Produces the content of `output_tensor` only after `dependencies`.
            
            In some cases, a user may want the output of an operation to be
            consumed externally only after some other dependencies have run
            first.This function ensures returns `output_tensor`, but only after all
            operations in `dependencies` have run.Note that this means that there is
            no guarantee that `output_tensor` will be evaluated after any `dependencies`
            have run.
            
            See also `tf.tuple` and `tf.group`.
            </summary>
            <param name="dependencies">Iterable of operations to run before this op finishes.</param>
            <param name="output_tensor">A `Tensor` or `IndexedSlices` that will be returned.</param>
            <param name="name">(Optional) A name for this operation.</param>
            <returns>Same as `output_tensor`.</returns>
        </member>
        <member name="M:Tensorflow.control_flow_ops._SwitchRefOrTensor(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
             <summary>
             Forwards `data` to an output determined by `pred`.
             If `pred` is false, the `data` input is forwarded to the first output.
             Otherwise, the data goes to the second output.
             
             This op handles `Tensor`s and `IndexedSlices`.
             </summary>
             <param name="data">The tensor to be forwarded to the appropriate output.</param>
             <param name="pred">A scalar that specifies which output port will receive data.</param>
            <param name="name"> A name for this operation (optional).</param>
            <returns>
             `(output_false, output_true)`: If `pred` is true, data will be forwarded to
            `output_true`, otherwise it goes to `output_false`.
            </returns>
        </member>
        <member name="M:Tensorflow.control_flow_ops.cond(Tensorflow.Tensor,System.Func{Tensorflow.ITensorOrOperation},System.Func{Tensorflow.ITensorOrOperation},System.String)">
            <summary>
            Return `true_fn()` if the predicate `pred` is true else `false_fn()`.
            
            `true_fn` and `false_fn` both return lists of output tensors. `true_fn` and
            `false_fn` must have the same non-zero number and type of outputs.
            
            **WARNING**: Any Tensors or Operations created outside of `true_fn` and
            `false_fn` will be executed regardless of which branch is selected at runtime.
            
            Although this behavior is consistent with the dataflow model of TensorFlow,
            it has frequently surprised users who expected a lazier semantics.
            Consider the following simple program:
            
            z = tf.multiply(a, b)
            result = tf.cond(x &lt; y, ()=> tf.add(x, z), ()=> tf.square(y))
            
            If `x&lt;y`, the `tf.add` operation will be executed and `tf.square`
            operation will not be executed.Since `z` is needed for at least one
            branch of the `cond`, the `tf.multiply` operation is always executed,
            unconditionally.
            
            Note that `cond` calls `true_fn` and `false_fn` *exactly once* (inside the
            call to `cond`, and not at all during `Session.run()`). `cond`
            stitches together the graph fragments created during the `true_fn` and
            `false_fn` calls with some additional graph nodes to ensure that the right
            branch gets executed depending on the value of `pred`.
            
            `tf.cond` supports nested structures as implemented in
            `tensorflow.python.util.nest`. Both `true_fn` and `false_fn` must return the
            same(possibly nested) value structure of lists, tuples, and/or named tuples.
            Singleton lists and tuples form the only exceptions to this: when returned by
            `true_fn` and/or `false_fn`, they are implicitly unpacked to single values.
            This behavior is disabled by passing `strict= True`.
            </summary>
            <param name="pred"> A scalar determining whether to return the result of `true_fn` or
            `false_fn`.</param>
            <param name="true_fn">The callable to be performed if pred is true.</param>
            <param name="false_fn">The callable to be performed if pred is false.</param>
            <param name="strict"> A boolean that enables/disables 'strict' mode; see above.</param>
            <param name="name">Optional name prefix for the returned tensors.</param>
            <returns>Tensors returned by the call to either `true_fn` or `false_fn`. If the
            callables return a singleton list, the element is extracted from the list.</returns>
        </member>
        <member name="M:Tensorflow.control_flow_ops.merge(Tensorflow.Tensor[],System.String)">
            <summary>
            Returns the value of an available element of `inputs`.
            
            This op tests each of the tensors in `inputs` in turn to determine if any of
            them is available.If it finds an available tensor, it returns it and its
            index in `inputs`.
            
            It is an error if more than one tensor in `inputs` is available.If no tensor
            in `inputs` is available, the returned tensor and index are not set.
            
            This op handles both `Tensor`s and `IndexedSlices`. If inputs has a mix of
            `Tensor`s and `IndexedSlices`, all inputs are converted to IndexedSlices
            before merging.
            </summary>
            <param name="inputs">inputs: The input tensors, at most one of which is available.</param>
            <param name="name">A name for this operation (optional).</param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.control_flow_ops.switch(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType,System.String)">
            <summary>
            Forwards `data` to an output determined by `pred`.
            </summary>
            <param name="data"></param>
            <param name="pred"></param>
            <param name="dtype"></param>
            <param name="name"></param>
        </member>
        <member name="M:Tensorflow.control_flow_ops.while_loop``1(System.Func{``0,Tensorflow.Tensor},System.Func{``0,``0},``0,Tensorflow.TensorShape[],System.Int32,System.Boolean,System.Boolean,System.String,Tensorflow.Tensor,System.Boolean)">
            <summary>
            Repeat `body` while the condition `cond` is true.
            </summary>
            <param name="cond"></param>
            <param name="body"></param>
            <param name="loop_vars"></param>
            <param name="shape_invariants"></param>
        </member>
        <member name="M:Tensorflow.control_flow_ops._Enter(Tensorflow.Tensor,System.String,System.Boolean,System.Int32,System.Boolean,System.Boolean,System.String)">
            <summary>
            Creates or finds a child frame, and makes `data` available to it.
            </summary>
            <param name="data"></param>
            <param name="frame_name"></param>
            <param name="is_constant"></param>
            <param name="parallel_iterations"></param>
            <param name="use_ref"></param>
            <param name="use_input_shape"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.control_flow_util.IsLoopExit(Tensorflow.Operation)">
            <summary>
            Return true if `op` is an Exit.
            </summary>
            <param name="op"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.control_flow_util.IsLoopEnter(Tensorflow.Operation)">
            <summary>
            Returns true if `op` is an Enter.
            </summary>
            <param name="op"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.control_flow_util.IsLoopConstantEnter(Tensorflow.Operation)">
            <summary>
            Return true iff op is a loop invariant.
            </summary>
            <param name="op"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.control_flow_util.IsSwitch(Tensorflow.Operation)">
            <summary>
            Return true if `op` is a Switch.
            </summary>
            <param name="op"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.control_flow_util.GetOutputContext(Tensorflow.Operation)">
            <summary>
            Return the control flow context for the output of an op.
            </summary>
        </member>
        <member name="M:Tensorflow.ctc_ops.ctc_greedy_decoder(Tensorflow.Tensor,Tensorflow.Tensor,System.Boolean,System.String)">
            <summary>
               Performs greedy decoding on the logits given in inputs.
            </summary>
            <param name="inputs">
               3-D, shape: <c>(max_time x batch_size x num_classes)</c>, the logits.
            </param>
            <param name="sequence_length">
               A vector containing sequence lengths, size <c>(batch_size)</c>.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'CTCGreedyDecoder'.
            </param>
            <param name="merge_repeated">
               If True, merge repeated classes in output.
            </param>
            <returns>
               Returns a tuple with multiple values, as follows:
               decoded_indices : Indices matrix, size <c>(total_decoded_outputs x 2)</c>,
               of a <c>SparseTensor&amp;lt;int64, 2&amp;gt;</c>.  The rows store: [batch, time].
               decoded_values : Values vector, size: <c>(total_decoded_outputs)</c>,
               of a <c>SparseTensor&amp;lt;int64, 2&amp;gt;</c>.  The vector stores the decoded classes.
               decoded_shape : Shape vector, size <c>(2)</c>, of the decoded SparseTensor.
               Values are: <c>[batch_size, max_decoded_length]</c>.
               log_probability : Matrix, size <c>(batch_size x 1)</c>, containing sequence
               log-probabilities.
               The Operation can be fetched from any of the Tensorreturned in the tuple values, by fetching the Operation property.
            </returns>
            <remarks>
               A note about the attribute merge_repeated: if enabled, when
               consecutive logits' maximum indices are the same, only the first of
               these is emitted.  Labeling the blank '*', the sequence "A B B * B B"
               becomes "A B B" if merge_repeated = True and "A B B B B" if
               merge_repeated = False.
               
               Regardless of the value of merge_repeated, if the maximum index of a given
               time and batch corresponds to the blank, index <c>(num_classes - 1)</c>, no new
               element is emitted.
            </remarks>
        </member>
        <member name="M:Tensorflow.dataset_ops.tensor_slice_dataset(Tensorflow.Tensor[],Tensorflow.TensorShape[],System.String)">
            <summary>
            Creates a dataset that emits each dim-0 slice of `components` once.
            </summary>
            <param name="components"></param>
            <param name="output_shapes"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.dataset_ops.batch_dataset_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.Boolean,System.String)">
            <summary>
            Creates a dataset that batches `batch_size` elements from `input_dataset`.
            </summary>
            <param name="input_dataset"></param>
            <param name="buffer_size"></param>
            <param name="drop_remainder"></param>
            <param name="output_types"></param>
            <param name="output_shapes"></param>
            <param name="parallel_copy"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.dataset_ops.dummy_memory_cache(System.String)">
            <summary>
            
            </summary>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.dataset_ops.prefetch_dataset(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.Nullable{System.Int32},System.Boolean,System.String)">
            <summary>
            Creates a dataset that asynchronously prefetches elements from `input_dataset`.
            </summary>
            <param name="input_dataset"></param>
            <param name="buffer_size"></param>
            <param name="output_types"></param>
            <param name="output_shapes"></param>
            <param name="slack_period"></param>
            <param name="legacy_autotune"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.dataset_ops.take_dataset(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
            Creates a dataset that contains `count` elements from the `input_dataset`.
            </summary>
            <param name="input_dataset"></param>
            <param name="count"></param>
            <param name="output_types"></param>
            <param name="output_shapes"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.dataset_ops.optimize_dataset(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String[],System.String)">
            <summary>
            Creates a dataset by applying optimizations to `input_dataset`.
            </summary>
            <param name="input_dataset"></param>
            <param name="optimizations"></param>
            <param name="output_types"></param>
            <param name="output_shapes"></param>
            <param name="optimization_configs"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.dataset_ops.model_dataset(Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],Tensorflow.Framework.Models.AutotuneAlgorithm,System.Int64,System.String)">
            <summary>
            Identity transformation that models performance.
            </summary>
            <param name="input_dataset"></param>
            <param name="output_types"></param>
            <param name="output_shapes"></param>
            <param name="algorithm"></param>
            <param name="cpu_budget"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.dataset_ops.anonymous_iterator_v2(Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
            A container for an iterator resource.
            </summary>
            <param name="output_types"></param>
            <param name="output_shapes"></param>
            <param name="name"></param>
            <returns>A tuple of `Tensor` objects (handle, deleter).</returns>
        </member>
        <member name="M:Tensorflow.dataset_ops.make_iterator(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
            Makes a new iterator from the given `dataset` and stores it in `iterator`.
            </summary>
            <param name="dataset"></param>
            <param name="iterator"></param>
            <param name="name"></param>
            <returns>The created Operation.</returns>
        </member>
        <member name="M:Tensorflow.dataset_ops.map_dataset(Tensorflow.Tensor,Tensorflow.Functions.ConcreteFunction,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.Boolean,System.Boolean,System.String)">
            <summary>
            
            </summary>
            <param name="dataset"></param>
            <param name="iterator"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.dataset_ops.delete_iterator(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
            A container for an iterator resource.
            </summary>
            <param name="handle"></param>
            <param name="deleter"></param>
            <param name="name"></param>
            <returns>The created Operation.</returns>
        </member>
        <member name="M:Tensorflow.dataset_ops.iterator_get_next(Tensorflow.Tensor,Tensorflow.TF_DataType[],Tensorflow.TensorShape[],System.String)">
            <summary>
            Gets the next output from the given iterator .
            </summary>
            <param name="iterator"></param>
            <param name="output_types"></param>
            <param name="output_shapes"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Distribution">
            <summary>
            A generic probability distribution base class.
            Distribution is a base class for constructing and organizing properties
            (e.g., mean, variance) of random variables (e.g, Bernoulli, Gaussian). 
            </summary>
        </member>
        <member name="M:Tensorflow.Distribution.log_prob(Tensorflow.Tensor,System.String)">
            <summary>
            Log probability density/mass function.
            </summary>
            <param name="value"> `Tensor`.</param>
            <param name="name"> Python `str` prepended to names of ops created by this function.</param>
            <returns>log_prob: a `Tensor` of shape `sample_shape(x) + self.batch_shape` with values of type `self.dtype`.</returns>
        </member>
        <member name="T:Tensorflow.ReparameterizationType">
            <summary>
            Instances of this class represent how sampling is reparameterized.
            Two static instances exist in the distributions library, signifying
            one of two possible properties for samples from a distribution:
            `FULLY_REPARAMETERIZED`: Samples from the distribution are fully
            reparameterized, and straight-through gradients are supported.
            `NOT_REPARAMETERIZED`: Samples from the distribution are not fully
            reparameterized, and straight-through gradients are either partially
            unsupported or are not supported at all. In this case, for purposes of
            e.g. RL or variational inference, it is generally safest to wrap the
            sample results in a `stop_gradients` call and use policy
            gradients / surrogate loss instead.
            </summary>
        </member>
        <member name="M:Tensorflow.Normal.#ctor(Tensorflow.Tensor,Tensorflow.Tensor,System.Boolean,System.Boolean,System.String)">
            <summary>
            The Normal distribution with location `loc` and `scale` parameters.
            Mathematical details
            The probability density function(pdf) is,
            '''
            pdf(x; mu, sigma) = exp(-0.5 (x - mu)**2 / sigma**2) / Z
            Z = (2 pi sigma**2)**0.5
            '''
            where `loc = mu` is the mean, `scale = sigma` is the std.deviation, and, `Z`
            is the normalization constant.
            </summary>
            <param name="loc"></param>
            <param name="scale"></param>
            <param name="validate_args"></param>
            <param name="allow_nan_stats"></param>
            <param name="name"></param>
        </member>
        <member name="M:Tensorflow.Normal.loc">
            <summary>
            Distribution parameter for the mean.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Normal.scale">
            <summary>
            Distribution parameter for standard deviation."
            </summary>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Normal._z(Tensorflow.Tensor)">
            <summary>
            Standardize input `x` to a unit normal.
            </summary>
            <param name="x"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.embedding_ops._embedding_lookup_and_transform(Tensorflow.RefVariable,Tensorflow.Tensor,System.String,System.String,System.String)">
            <summary>
            Helper function for embedding_lookup and _compute_sampled_logits.
            </summary>
            <param name="params"></param>
            <param name="ids"></param>
            <param name="partition_strategy"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.embedding_ops._embedding_lookup_and_transform(Tensorflow.IVariableV1,Tensorflow.Tensor,System.String,System.String,System.String)">
            <summary>
            Helper function for embedding_lookup and _compute_sampled_logits.
            </summary>
            <param name="params"></param>
            <param name="ids"></param>
            <param name="partition_strategy"></param>
            <param name="name"></param>
            <param name="max_norm"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_array_ops.concat_v2``2(``0[],``1,System.String)">
            <summary>
            Concatenates tensors along one dimension.
            </summary>
            <param name="values"></param>
            <param name="axis"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_array_ops.diag(Tensorflow.Tensor,System.String)">
            <summary>
               Returns a diagonal tensor with a given diagonal values.
            </summary>
            <param name="diagonal">
               Rank k tensor where k is at most 1.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Diag'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Given a <c>diagonal</c>, this operation returns a tensor with the <c>diagonal</c> and
               everything else padded with zeros. The diagonal is computed as follows:
               
               Assume <c>diagonal</c> has dimensions [D1,..., Dk], then the output is a tensor of
               rank 2k with dimensions [D1,..., Dk, D1,..., Dk] where:
               
               <c>output[i1,..., ik, i1,..., ik] = diagonal[i1, ..., ik]</c> and 0 everywhere else.
               
               For example:
               
              <code>
               # 'diagonal' is [1, 2, 3, 4]
               tf.diag(diagonal) ==&amp;gt; [[1, 0, 0, 0]
               [0, 2, 0, 0]
               [0, 0, 3, 0]
               [0, 0, 0, 4]]
              </code>
            </remarks>
        </member>
        <member name="M:Tensorflow.gen_array_ops.identity(Tensorflow.Tensor,System.String)">
            <summary>
            Return a tensor with the same shape and contents as the input tensor or value.
            </summary>
            <param name="input"></param>
            <param name="name"></param>
        </member>
        <member name="M:Tensorflow.gen_array_ops.fill``1(Tensorflow.Tensor,``0,System.String)">
            <summary>
            Creates a tensor filled with a scalar value.
            </summary>
            <param name="dims">A `Tensor`.</param>
            <param name="value">A `Tensor`. 0-D (scalar). Value to fill the returned tensor.</param>
            <param name="name">A name for the operation (optional).</param>
            <returns>A `Tensor`. Has the same type as `value`.</returns>
        </member>
        <member name="M:Tensorflow.gen_array_ops.broadcast_gradient_args(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
            Return the reduction indices for computing gradients of s0 op s1 with broadcast.
            </summary>
            <param name="s0">A `Tensor`. Must be one of the following types: `int32`, `int64`.</param>
            <param name="s1">A `Tensor`. Must have the same type as `s0`.</param>
            <param name="name">A name for the operation (optional).</param>
            <returns>A tuple of `Tensor` objects (r0, r1).</returns>
        </member>
        <member name="M:Tensorflow.gen_array_ops.unique(Tensorflow.Tensor,Tensorflow.TF_DataType,System.String)">
            <summary>
            Finds unique elements in a 1-D tensor.
            </summary>
            <param name="x"></param>
            <param name="out_idx"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_array_ops.placeholder_with_default``1(``0,System.Int32[],System.String)">
            <summary>
            A placeholder op that passes through `input` when its output is not fed.
            </summary>
            <param name="input">The default value to produce when output is not fed.</param>
            <param name="shape"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_array_ops.shape_n(Tensorflow.Tensor[],Tensorflow.TF_DataType,System.String)">
            <summary>
            Returns shape of tensors.
            </summary>
            <param name="input"></param>
            <param name="out_type"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_array_ops.slice(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
            Return a slice from 'input'
            </summary>
            <param name="input"></param>
            <param name="begin"></param>
            <param name="size"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_array_ops.strided_slice_grad(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32,System.String)">
            <summary>
            Returns the gradient of `StridedSlice`.
            
            Since `StridedSlice` cuts out pieces of its `input` which is size
            `shape`, its gradient will have the same shape (which is passed here
            as `shape`). The gradient will be zero in any element that the slice
            does not select.
            </summary>
            <param name="shape">Must be one of the following types: `int32`, `int64`.</param>
            <param name="begin">Must have the same type as `shape`.</param>
            <param name="end">Must have the same type as `shape`.</param>
            <param name="strides">Must have the same type as `shape`.</param>
            <param name="dy">A `Tensor`.</param>
            <param name="begin_mask">An optional `int`. Defaults to `0`.</param>
            <param name="end_mask">An optional `int`. Defaults to `0`.</param>
            <param name="ellipsis_mask">An optional `int`. Defaults to `0`.</param>
            <param name="new_axis_mask">An optional `int`. Defaults to `0`.</param>
            <param name="shrink_axis_mask">An optional `int`. Defaults to `0`.</param>
            <param name="name">A name for the operation (optional).</param>
            <returns>A `Tensor`. Has the same type as `dy`.</returns>
        </member>
        <member name="M:Tensorflow.gen_array_ops.squeeze(Tensorflow.Tensor,System.Int32[],System.String)">
            <summary>
            Removes dimensions of size 1 from the shape of a tensor.
            Given a tensor `input`, this operation returns a tensor of the same type with
            all dimensions of size 1 removed.If you don't want to remove all size 1
            dimensions, you can remove specific size 1 dimensions by specifying
            `axis`.
            </summary>
            <param name="input"> A `Tensor`. The `input` to squeeze.</param>
            <param name="axis"> An optional list of `ints`. Defaults to `[]`. If specified, only squeezes the dimensions listed.</param>
            <param name="name"> A name for the operation (optional).</param>
            <returns> A `Tensor`. Has the same type as `input`.</returns>
        </member>
        <member name="M:Tensorflow.gen_array_ops.broadcast_args(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
            Return the shape of s0 op s1 with broadcast.
            Given `s0` and `s1`, tensors that represent shapes, compute `r0`, the
            broadcasted shape. `s0`, `s1` and `r0` are all integer vectors.
            </summary>
            <param name="s0"> A `Tensor`. Must be one of the following types: `int32`, `int64`.</param>
            <param name="s1"> A `Tensor`. Must have the same type as `s0`.</param>
            <param name="name"> A name for the operation (optional).</param>
            <returns> `Tensor`. Has the same type as `s0`.</returns>
        </member>
        <member name="M:Tensorflow.gen_array_ops.broadcast_to``1(Tensorflow.Tensor,``0,System.String)">
            <summary>
            Broadcast an array for a compatible shape.
            </summary>
            <param name="input"></param>
            <param name="shape"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_control_flow_ops.enter(Tensorflow.Tensor,System.String,System.Boolean,System.Int32,System.String)">
            <summary>
            Creates or finds a child frame, and makes `data` available to the child frame.
            </summary>
            <param name="data"></param>
            <param name="frame_name"></param>
            <param name="is_constant"></param>
            <param name="parallel_iterations"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_control_flow_ops.loop_cond(Tensorflow.Tensor,System.String)">
            <summary>
            Forwards the input to the output.
            </summary>
            <param name="input"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_control_flow_ops.ref_next_iteration(Tensorflow.Tensor,System.String)">
            <summary>
            Makes its input available to the next iteration.
            </summary>
            <param name="data"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_control_flow_ops.next_iteration(Tensorflow.Tensor,System.String)">
            <summary>
            Makes its input available to the next iteration.
            </summary>
            <param name="data"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_control_flow_ops.ref_exit(Tensorflow.Tensor,System.String)">
            <summary>
            Exits the current frame to its parent frame.
            </summary>
            <param name="data"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_control_flow_ops._exit(Tensorflow.Tensor,System.String)">
            <summary>
            Exits the current frame to its parent frame.
            </summary>
            <param name="data"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_control_flow_ops.switch(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
            Forwards `data` to the output port determined by `pred`.
            
            If `pred` is true, the `data` input is forwarded to `output_true`. Otherwise,
            the data goes to `output_false`.
            
            See also `RefSwitch` and `Merge`.
            </summary>
            <param name="data">A `Tensor`. The tensor to be forwarded to the appropriate output.</param>
            <param name="pred">A `Tensor` of type `bool`.
            A scalar that specifies which output port will receive data.
            </param>
            <param name="name"> A name for the operation (optional).</param>
            <returns>A tuple of `Tensor` objects (output_false, output_true).
            
            output_false: A `Tensor`. Has the same type as `data`.
            output_true: A `Tensor`. Has the same type as `data`.
            </returns>
        </member>
        <member name="M:Tensorflow.gen_data_flow_ops.tensor_array_read_v3(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.TF_DataType,System.String)">
            <summary>
            Read an element from the TensorArray into output `value`.
            </summary>
            <param name="handle"></param>
            <param name="index"></param>
            <param name="flow_in"></param>
            <param name="dtype"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_logging_ops.scalar_summary(System.String,Tensorflow.Tensor,System.String)">
            <summary>
               Outputs a <c>Summary</c> protocol buffer with scalar values.
            </summary>
            <param name="tags">
               Tags for the summary.
            </param>
            <param name="values">
               Same shape as <c>tags</c>.  Values for the summary.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'ScalarSummary'.
            </param>
            <returns>
               Scalar.  Serialized <c>Summary</c> protocol buffer.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               The input <c>tags</c> and <c>values</c> must have the same shape.  The generated summary
               has a summary value for each tag-value pair in <c>tags</c> and <c>values</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.gen_logging_ops.merge_summary(Tensorflow.Tensor[],System.String)">
            <summary>
               Merges summaries.
            </summary>
            <param name="inputs">
               Can be of any shape.  Each must contain serialized <c>Summary</c> protocol
               buffers.
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'MergeSummary'.
            </param>
            <returns>
               Scalar. Serialized <c>Summary</c> protocol buffer.
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               This op creates a
               [<c>Summary</c>](https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto)
               protocol buffer that contains the union of all the values in the input
               summaries.
               
               When the Op is run, it reports an <c>InvalidArgument</c> error if multiple values
               in the summaries to merge use the same tag.
            </remarks>
        </member>
        <member name="M:Tensorflow.gen_math_ops.add_n(Tensorflow.Tensor[],System.String)">
            <summary>
            Add all input tensors element wise.
            </summary>
            <param name="inputs"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_math_ops.arg_max(Tensorflow.Tensor,System.Int32,Tensorflow.TF_DataType,System.String)">
            <summary>
            Returns the index with the largest value across dimensions of a tensor.
            </summary>
            <param name="input"></param>
            <param name="dimension"></param>
            <param name="output_type"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_math_ops.arg_min(Tensorflow.Tensor,System.Int32,Tensorflow.TF_DataType,System.String)">
            <summary>
            Returns the index with the smallest value across dimensions of a tensor.
            </summary>
            <param name="input"></param>
            <param name="dimension"></param>
            <param name="output_type"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_math_ops.digamma(Tensorflow.Tensor,System.String)">
            <summary>
            Computes Psi, the derivative of Lgamma (the log of the absolute value of
            `Gamma(x)`), element-wise.
            </summary>
            <param name="x"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_math_ops.div_no_nan(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns 0 if the denominator is zero.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DivNoNan'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               
               *NOTE*: <c>DivNoNan</c> supports broadcasting. More about broadcasting
               [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
            </remarks>
        </member>
        <member name="M:Tensorflow.gen_math_ops.mean``2(``0,``1,System.Boolean,System.String)">
            <summary>
            Computes the mean of elements across dimensions of a tensor.
            Reduces `input` along the dimensions given in `axis`. Unless
            `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
            `axis`. If `keep_dims` is true, the reduced dimensions are retained with length 1.
            </summary>
            <param name="input">A `Tensor`. Must be one of the following types: 
            `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`. 
            The tensor to reduce.</param>
            <param name="axis">A `Tensor`. Must be one of the following types: `int32`, `int64`. The dimensions to reduce.</param>
            <param name="keep_dims"> An optional `bool`. Defaults to `False`. If true, retain reduced dimensions with length 1.</param>
            <param name="name"> A name for the operation (optional).</param>
            <returns> A `Tensor`. Has the same type as `input`.</returns>
        </member>
        <member name="M:Tensorflow.gen_math_ops.sigmoid(Tensorflow.Tensor,System.String)">
            <summary>
               Computes sigmoid of <c>x</c> element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Sigmoid'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Specifically, <c>y = 1 / (1 + exp(-x))</c>.
            </remarks>
        </member>
        <member name="M:Tensorflow.gen_math_ops.sigmoid_grad(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Computes the gradient of the sigmoid of <c>x</c> wrt its input.
            </summary>
            <param name="y">
            </param>
            <param name="dy">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'SigmoidGrad'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Specifically, <c>grad = dy * y * (1 - y)</c>, where <c>y = sigmoid(x)</c>, and
               <c>dy</c> is the corresponding input gradient.
            </remarks>
        </member>
        <member name="M:Tensorflow.gen_math_ops.unsorted_segment_sum(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
            Computes the sum along segments of a tensor.
            </summary>
            <param name="data"></param>
            <param name="segment_ids"></param>
            <param name="num_segments"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_math_ops.tanh_grad(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
            Computes the gradient for the tanh of `x` wrt its input.
            </summary>
            <param name="y"></param>
            <param name="dy"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_math_ops.lgamma(Tensorflow.Tensor,System.String)">
            <summary>
            Computes the log of the absolute value of `Gamma(x)` element-wise.
            </summary>
            <param name="x">
            A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
            </param>
            <param name="name">
            </param>
            <returns>
            The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
        </member>
        <member name="M:Tensorflow.gen_math_ops.square(Tensorflow.Tensor,System.String)">
            <summary>
            Computes square of x element-wise.
            </summary>
            <param name="x"> A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.</param>
            <param name="name"> A name for the operation (optional).</param>
            <returns> A `Tensor`. Has the same type as `x`.</returns>
        </member>
        <member name="M:Tensorflow.gen_math_ops.is_finite(Tensorflow.Tensor,System.String)">
            <summary>
            Returns which elements of x are finite.
            </summary>
            <param name="x"> A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.</param>
            <param name="name"> A name for the operation (optional).</param>
            <returns> A `Tensor` of type `bool`.</returns>
        </member>
        <member name="M:Tensorflow.gen_math_ops.exp(Tensorflow.Tensor,System.String)">
            <summary>
            Computes exponential of x element-wise.  \\(y = e^x\\).
            </summary>
            <param name="x"> A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.</param>
            <param name="name"> A name for the operation (optional).</param>
            <returns> A `Tensor`. Has the same type as `x`.</returns>
        </member>
        <member name="M:Tensorflow.gen_math_ops.log(Tensorflow.Tensor,System.String)">
            <summary>
            Computes natural logarithm of x element-wise.
            </summary>
            <param name="x"> A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.</param>
            <param name="name"> name: A name for the operation (optional).</param>
            <returns> A `Tensor`. Has the same type as `x`.</returns>
        </member>
        <member name="M:Tensorflow.gen_math_ops.equal``2(``0,``1,System.String)">
            <summary>
            Returns the truth value of (x == y) element-wise.
            </summary>
            <param name="x"></param>
            <param name="y"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_math_ops.not_equal``2(``0,``1,System.String)">
            <summary>
            Returns the truth value of (x != y) element-wise.
            </summary>
            <typeparam name="Tx">The type of the x.</typeparam>
            <typeparam name="Ty">The type of the y.</typeparam>
            <param name="x">The x.</param>
            <param name="y">The y.</param>
            <param name="name">The name.</param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_math_ops.mat_mul(Tensorflow.Tensor,Tensorflow.Tensor,System.Boolean,System.Boolean,System.String)">
            <summary>
            Multiply the matrix "a" by the matrix "b".
            </summary>
            <param name="a"></param>
            <param name="b"></param>
            <param name="transpose_a"></param>
            <param name="transpose_b"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_math_ops.batch_mat_mul(Tensorflow.Tensor,Tensorflow.Tensor,System.Boolean,System.Boolean,System.String)">
             <summary>
             Multiply slices of the two matrices "x" and "y".
             </summary>
             <remarks>
             The `BatchMatMul` operation is embedded into the
             `MatMul` operation on the DLL side. However the expected
             attributes are not the same, hence we need to expose this
             method to have the right args list on the `_apply_op_helper`
             function.
            
             For each rank > 2 the first rank - 2 dimensions are considered
             as fixed, and have to be consistent across the two matrices. A
             common matrix multiplication is then applied over the residual
             2 dimensions.
            
             e.g.
                 x is (3, 6, 12); y is (3, 12, 6)
                 batch_matmul(x, y) ==> (3, 6, 6)
             </remarks>
             <param name="x"></param>
             <param name="y"></param>
             <param name="adj_x"></param>
             <param name="adj_y"></param>
             <param name="name"></param>
             <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_math_ops.maximum``2(``0,``1,System.String)">
            <summary>
            Returns the max of x and y (i.e. x > y ? x : y) element-wise.
            </summary>
            <param name="x"></param>
            <param name="y"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_math_ops.range(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
            Creates a sequence of numbers.
            </summary>
            <param name="start"></param>
            <param name="limit"></param>
            <param name="delta"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_math_ops.round(Tensorflow.Tensor,System.String)">
            <summary>
               Rounds the values of a tensor to the nearest integer, element-wise.
            </summary>
            <param name="x">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'Round'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               Rounds half to even.  Also known as bankers rounding. If you want to round
               according to the current system rounding mode use std::cint.
            </remarks>
        </member>
        <member name="M:Tensorflow.gen_math_ops.rsqrt(Tensorflow.Tensor,System.String)">
            <summary>
            Computes reciprocal of square root of x element-wise.
            </summary>
            <param name="x"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_math_ops.zero_fraction(Tensorflow.Tensor,System.String)">
            <summary>
            Returns the fraction of zeros in value.
            </summary>
            <param name="value">A tensor of numeric type.</param>
            <param name="name">A name for the operation (optional).</param>
            <returns>The fraction of zeros in value, with type float32.</returns>
        </member>
        <member name="M:Tensorflow.gen_random_ops.random_standard_normal(Tensorflow.Tensor,Tensorflow.TF_DataType,System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
            Outputs random values from a normal distribution.
            </summary>
            <param name="shape"></param>
            <param name="dtype"></param>
            <param name="seed"></param>
            <param name="seed2"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_random_ops.random_uniform_int(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
            Outputs random integers from a uniform distribution.
            </summary>
            <param name="shape"></param>
            <param name="minval"></param>
            <param name="maxval"></param>
            <param name="seed"></param>
            <param name="seed2"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_random_ops.random_uniform(Tensorflow.Tensor,Tensorflow.TF_DataType,System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
            Outputs random values from a uniform distribution.
            </summary>
            <param name="shape"></param>
            <param name="dtype"></param>
            <param name="seed"></param>
            <param name="seed2"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_random_ops.random_shuffle(Tensorflow.Tensor,System.Int32,System.Int32,System.String)">
            <summary>
            
            </summary>
            <param name="value"></param>
            <param name="seed"></param>
            <param name="seed2"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_random_ops.truncated_normal(Tensorflow.Tensor,Tensorflow.TF_DataType,System.Nullable{System.Int32},System.Nullable{System.Int32},System.String)">
            <summary>
            Outputs random values from a truncated normal distribution.
            </summary>
            <param name="shape"></param>
            <param name="dtype"></param>
            <param name="seed"></param>
            <param name="seed2"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_resource_variable_ops.assign_add_variable_op(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
            Adds a value to the current value of a variable.
            </summary>
            <param name="resource"></param>
            <param name="value"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_resource_variable_ops.var_handle_op(Tensorflow.TF_DataType,Tensorflow.TensorShape,System.String,System.String,System.String)">
            <summary>
            Creates a handle to a Variable resource.
            </summary>
            <param name="dtype"></param>
            <param name="shape"></param>
            <param name="container"></param>
            <param name="shared_name"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_resource_variable_ops.read_variable_op(Tensorflow.Tensor,Tensorflow.TF_DataType,System.String)">
            <summary>
            Reads the value of a variable.
            </summary>
            <param name="resource"></param>
            <param name="dtype"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_sparse_ops.sparse_to_dense``1(Tensorflow.Tensor,System.Int32[],``0,``0,System.Boolean,System.String)">
            <summary>
            Converts a sparse representation into a dense tensor.
            </summary>
            <param name="sparse_indices"></param>
            <param name="output_shape"></param>
            <param name="sparse_values"></param>
            <param name="default_value"></param>
            <param name="validate_indices"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.image_ops_impl.resize_images_v2(Tensorflow.Tensor,Tensorflow.TensorShape,System.String,System.Boolean,System.Boolean,System.String)">
            <summary>
            Resize `images` to `size` using the specified `method`.
            </summary>
            <param name="images"></param>
            <param name="size"></param>
            <param name="method"></param>
            <param name="preserve_aspect_ratio"></param>
            <param name="antialias"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.image_ops_impl.resize_nearest_neighbor``1(Tensorflow.Tensor,``0,System.Boolean,System.String,System.Boolean)">
            <summary>
            Resize `images` to `size` using nearest neighbor interpolation.
            </summary>
            <param name="images"></param>
            <param name="size"></param>
            <param name="align_corners"></param>
            <param name="name"></param>
            <param name="half_pixel_centers"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Operation">
            <summary>
            Represents a graph node that performs computation on tensors.
            
            An `Operation` is a node in a TensorFlow `Graph` that takes zero or
            more `Tensor` objects as input, and produces zero or more `Tensor`
            objects as output. Objects of type `Operation` are created by
            calling an op constructor(such as `tf.matmul`)
            or `tf.Graph.create_op`.
            
            For example `c = tf.matmul(a, b)` creates an `Operation` of type
            "MatMul" that takes tensors `a` and `b` as input, and produces `c`
            as output.
            
            After the graph has been launched in a session, an `Operation` can
            be executed by passing it to
            `tf.Session.run`.
            `op.run()` is a shortcut for calling `tf.get_default_session().run(op)`.
            </summary>
            <summary>
            Convert to other datatype implicitly
            </summary>
        </member>
        <member name="M:Tensorflow.Operation.map_fn(System.Func{Tensorflow.Tensor,Tensorflow.Tensor},Tensorflow.Tensor,Tensorflow.TF_DataType,System.Int32,System.Boolean,System.Boolean,System.Boolean,System.String)">
            <summary>
            map on the list of tensors unpacked from `elems` on dimension 0.
            </summary>
            <param name="fn"></param>
            <param name="elems"></param>
            <param name="dtype"></param>
            <param name="parallel_iterations"></param>
            <param name="back_prop"></param>
            <param name="swap_memory"></param>
            <param name="infer_shape"></param>
            <param name="name"></param>
            <returns>A tensor or (possibly nested) sequence of tensors.</returns>
        </member>
        <member name="M:Tensorflow.Operation._control_flow_post_processing">
            <summary>
            Add this op to its control flow context.
            
            This may add new ops and change this op's inputs. self.inputs must be
            available before calling this method.
            </summary>
        </member>
        <member name="M:Tensorflow.Operation.#ctor(Tensorflow.NodeDef,Tensorflow.Graph,Tensorflow.Tensor[],Tensorflow.TF_DataType[],Tensorflow.ITensorOrOperation[],Tensorflow.TF_DataType[],System.String,Tensorflow.OpDef)">
            <summary>
            Creates an `Operation`.
            </summary>
            <param name="node_def">`node_def_pb2.NodeDef`.  `NodeDef` for the `Operation`.</param>
            <param name="g">`Graph`. The parent graph.</param>
            <param name="inputs">list of `Tensor` objects. The inputs to this `Operation`.</param>
            <param name="output_types">list of `DType` objects.</param>
            <param name="control_inputs">
            list of operations or tensors from which to have a
            control dependency.
            </param>
            <param name="input_types">
            List of `DType` objects representing the
            types of the tensors accepted by the `Operation`. By default
            uses `[x.dtype.base_dtype for x in inputs]`.  Operations that expect
            reference-typed inputs must specify these explicitly.
            </param>
            <param name="original_op"></param>
            <param name="op_def"></param>
        </member>
        <member name="M:Tensorflow.Operation._update_input(System.Int32,Tensorflow.Tensor)">
            <summary>
            Update the input to this operation at the given index.
            
            NOTE: This is for TF internal use only.Please don't use it.
            </summary>
            <param name="index">the index of the input to update.</param>
            <param name="tensor"> the Tensor to be used as the input at the given index.</param>
        </member>
        <member name="M:Tensorflow.Operation._tf_output(System.Int32)">
            <summary>
            Create and return a new TF_Output for output_idx'th output of this op.
            </summary>
        </member>
        <member name="M:Tensorflow.Operation._tf_input(System.Int32)">
            <summary>
            Create and return a new TF_Input for input_idx'th input of this op.
            </summary>
        </member>
        <member name="P:Tensorflow.Operation.control_inputs">
            <summary>
            The `Operation` objects on which this op has a control dependency.
            
            Before this op is executed, TensorFlow will ensure that the
            operations in `self.control_inputs` have finished executing.This
            mechanism can be used to run ops sequentially for performance
            reasons, or to ensure that the side effects of an op are observed
            in the correct order.
            </summary>
        </member>
        <member name="M:Tensorflow.Operation.GetOperation(System.IntPtr)">
            <summary>
            Get operation by handle 
            </summary>
            <param name="handle"></param>
            <returns></returns>
        </member>
        <member name="P:Tensorflow.Operation._output_types">
            <summary>
            List this operation's output types.
            </summary>
        </member>
        <member name="T:Tensorflow.math_ops">
            <summary>
            python\ops\math_ops.py
            </summary>
        </member>
        <member name="M:Tensorflow.math_ops.add_n(Tensorflow.Tensor[],System.String)">
            <summary>
            Adds all input tensors element-wise.
            </summary>
            <param name="inputs"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.math_ops.digamma(Tensorflow.Tensor,System.String)">
            <summary>
            Computes Psi, the derivative of Lgamma (the log of the absolute value of
            `Gamma(x)`), element-wise.
            </summary>
            <param name="x"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.math_ops.div(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
            Divide two values using Python 2 semantics. Used for Tensor.__div__.
            </summary>
            <param name="x">`Tensor` numerator of real numeric type.</param>
            <param name="y">`Tensor` denominator of real numeric type.</param>
            <param name="name">A name for the operation</param>
            <returns>`x / y` returns the quotient of x and y.</returns>
        </member>
        <member name="M:Tensorflow.math_ops.div_no_nan(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
               Returns 0 if the denominator is zero.
            </summary>
            <param name="x">
            </param>
            <param name="y">
            </param>
            <param name="name">
            If specified, the created operation in the graph will be this one, otherwise it will be named 'DivNoNan'.
            </param>
            <returns>
               The Operation can be fetched from the resulting Tensor, by fetching the Operation property from the result.
            </returns>
            <remarks>
               
               *NOTE*: <c>DivNoNan</c> supports broadcasting. More about broadcasting
               [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
            </remarks>
        </member>
        <member name="M:Tensorflow.math_ops.reduce_mean(Tensorflow.Tensor,System.Int32[],System.Boolean,System.String,System.Nullable{System.Int32})">
            <summary>
            Computes the mean of elements across dimensions of a tensor.
            Reduces `input_tensor` along the dimensions given in `axis`.
            Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each
            entry in `axis`. If `keepdims` is true, the reduced dimensionsare retained with length 1.
            If `axis` is None, all dimensions are reduced, and a tensor with a single element is returned.
            </summary>
            <param name="input_tensor"> The tensor to reduce. Should have numeric type.</param>
            <param name="axis">The dimensions to reduce. If `None` (the default), reduces all
            dimensions.Must be in the range `[-rank(input_tensor), rank(input_tensor))`.</param>
            <param name="keepdims"> If true, retains reduced dimensions with length 1.</param>
            <param name="name"> A name for the operation (optional).</param>
        </member>
        <member name="M:Tensorflow.math_ops.reduce_prod(Tensorflow.Tensor,System.Int32[],System.Boolean,System.String)">
            <summary>
            Computes the product of elements across dimensions of a tensor.
            </summary>
            <param name="input_tensor"></param>
            <param name="axis"></param>
            <param name="keepdims"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.math_ops.square_difference(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
            Returns (x - y)(x - y) element-wise.
            </summary>
            <param name="x"> A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.</param>
            <param name="y"> A `Tensor`. Must have the same type as `x`.</param>
            <param name="name"> A name for the operation (optional).</param>
            <returns>A `Tensor`. Has the same type as `x`.</returns>
        </member>
        <member name="M:Tensorflow.math_ops.reduced_shape(Tensorflow.Tensor,Tensorflow.Tensor)">
            <summary>
            Helper function for reduction ops.
            </summary>
            <param name="input_shape">1-D Tensor, the shape of the Tensor being reduced.</param>
            <param name="axes">1-D Tensor, the reduction axes.</param>
            <returns>A 1-D Tensor, the output shape as if keepdims were set to True.</returns>
        </member>
        <member name="M:Tensorflow.math_ops.reciprocal(Tensorflow.Tensor,System.String)">
            <summary>
            Computes the reciprocal of x element-wise.
            </summary>
            <param name="x"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.math_ops.reduce_all(Tensorflow.Tensor,System.Int32[],System.Boolean,System.String)">
            <summary>
            Computes the "logical and" of elements across dimensions of a tensor.
            </summary>
            <param name="input_tensor"></param>
            <param name="axis"></param>
            <param name="keepdims"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.math_ops.reduce_logsumexp(Tensorflow.Tensor,System.Int32[],System.Boolean,System.String)">
             <summary>
             Computes log(sum(exp(elements across dimensions of a tensor))).
             Reduces `input_tensor` along the dimensions given in `axis`.
             Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each
             entry in `axis`. If `keepdims` is true, the reduced dimensions
             are retained with length 1.
            
             If `axis` has no entries, all dimensions are reduced, and a
             tensor with a single element is returned.
            
             This function is more numerically stable than log(sum(exp(input))). It avoids
             overflows caused by taking the exp of large inputs and underflows caused by
             taking the log of small inputs.
             </summary>
             <param name="input_tensor"> The tensor to reduce. Should have numeric type.</param>
             <param name="axis"> The dimensions to reduce. If `None` (the default), reduces all 
             dimensions.Must be in the range `[-rank(input_tensor), rank(input_tensor))`.</param>
             <param name="keepdims"></param>
             <returns> The reduced tensor.</returns>
        </member>
        <member name="M:Tensorflow.math_ops.unsorted_segment_sum(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
            Computes the sum along segments of a tensor.
            </summary>
            <param name="data"></param>
            <param name="segment_ids"></param>
            <param name="num_segments"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.math_ops.to_int32(Tensorflow.Tensor,System.String)">
            <summary>
            Casts a tensor to type `int32`.
            </summary>
            <param name="x">A `Tensor` or `SparseTensor` or `IndexedSlices`.</param>
            <param name="name">A name for the operation (optional).</param>
            <returns>A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` with type `int32`.</returns>
        </member>
        <member name="M:Tensorflow.math_ops.__case__(Tensorflow.Tensor,Tensorflow.TF_DataType,System.String)">
            <summary>
            Casts a tensor to a new type.
            </summary>
            <param name="x"></param>
            <param name="dtype"></param>
            <param name="name"></param>
            <returns>A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` and same type as `dtype`.</returns>
        </member>
        <member name="M:Tensorflow.math_ops.rsqrt(Tensorflow.Tensor,System.String)">
            <summary>
            Computes reciprocal of square root of x element-wise.
            </summary>
            <param name="x"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.math_ops.matmul(Tensorflow.Tensor,Tensorflow.Tensor,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.String)">
            <summary>
            Multiplies matrix `a` by matrix `b`, producing `a` * `b`.
            </summary>
            <param name="a"></param>
            <param name="b"></param>
            <param name="transpose_a">If `True`, `a` is transposed before multiplication.</param>
            <param name="transpose_b">If `True`, `b` is transposed before multiplication.</param>
            <param name="adjoint_a">If `True`, `a` is conjugated and transposed before multiplication.</param>
            <param name="adjoint_b">If `True`, `b` is conjugated and transposed before multiplication.</param>
            <param name="a_is_sparse">If `True`, `a` is treated as a sparse matrix.</param>
            <param name="b_is_sparse">If `True`, `b` is treated as a sparse matrix.</param>
            <param name="name">Name for the operation (optional).</param>
            <returns>
            A `Tensor` of the same type as `a` and `b` where each inner-most matrix is
            the product of the corresponding matrices in `a` and `b`, e.g. if all
            transpose or adjoint attributes are `False`:
            </returns>
        </member>
        <member name="M:Tensorflow.math_ops.conj(Tensorflow.Tensor,System.String)">
            <summary>
            Returns the complex conjugate of a complex number.
            </summary>
            <param name="x">`Tensor` to conjugate.  Must have numeric or variant type.</param>
            <param name="name">A name for the operation (optional).</param>
            <returns>A `Tensor` that is the conjugate of `x` (with the same type).</returns>
        </member>
        <member name="T:Tensorflow.BasicLstmCell">
            <summary>
            Basic LSTM recurrent network cell.
            The implementation is based on: http://arxiv.org/abs/1409.2329.
            </summary>
        </member>
        <member name="M:Tensorflow.BasicLstmCell.#ctor(System.Int32,System.Single,System.Boolean,Tensorflow.Operations.Activation.IActivation,System.Nullable{System.Boolean},System.String,Tensorflow.TF_DataType)">
            <summary>
            Initialize the basic LSTM cell.
            </summary>
            <param name="num_units">The number of units in the LSTM cell.</param>
            <param name="forget_bias"></param>
            <param name="state_is_tuple"></param>
            <param name="activation"></param>
            <param name="reuse"></param>
            <param name="name"></param>
            <param name="dtype"></param>
        </member>
        <member name="M:Tensorflow.BasicLstmCell.call(Tensorflow.Tensor,System.Boolean)">
            <summary>
            Long short-term memory cell (LSTM).
            </summary>
            <param name="inputs"></param>
            <param name="training"></param>
            <param name="state"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.BasicLstmCell.zero_state(Tensorflow.Tensor,Tensorflow.TF_DataType)">
            <summary>
            Return zero-filled state tensor(s).
            </summary>
            <param name="batch_size"></param>
            <param name="dtype"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.RnnCell">
            <summary>
            Abstract object representing an RNN cell.
            
            Every `RNNCell` must have the properties below and implement `call` with
            the signature `(output, next_state) = call(input, state)`.  The optional
            third input argument, `scope`, is allowed for backwards compatibility
            purposes; but should be left off for new subclasses.
            
            This definition of cell differs from the definition used in the literature.
            In the literature, 'cell' refers to an object with a single scalar output.
            This definition refers to a horizontal array of such units.
            
            An RNN cell, in the most abstract setting, is anything that has
            a state and performs some operation that takes a matrix of inputs.
            This operation results in an output matrix with `self.output_size` columns.
            If `self.state_size` is an integer, this operation also results in a new
            state matrix with `self.state_size` columns.  If `self.state_size` is a
            (possibly nested tuple of) TensorShape object(s), then it should return a
            matching structure of Tensors having shape `[batch_size].concatenate(s)`
            for each `s` in `self.batch_size`.
            </summary>
        </member>
        <member name="F:Tensorflow.RnnCell._is_tf_rnn_cell">
            <summary>
            Attribute that indicates whether the cell is a TF RNN cell, due the slight
            difference between TF and Keras RNN cell.
            </summary>
        </member>
        <member name="M:Tensorflow.RnnCell.zero_state(Tensorflow.Tensor,Tensorflow.TF_DataType)">
            <summary>
            Return zero-filled state tensor(s).
            </summary>
            <param name="batch_size"></param>
            <param name="dtype"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.nn_impl.l2_normalize(Tensorflow.Tensor,System.Int32,System.Single,System.String)">
            <summary>
            Normalizes along dimension `axis` using an L2 norm.
            </summary>
            <param name="x"></param>
            <param name="axis"></param>
            <param name="epsilon"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.nn_impl.moments(Tensorflow.Tensor,System.Int32[],System.String,System.Boolean)">
            <summary>
            Calculate the mean and variance of `x`
            </summary>
            <param name="x"> A `Tensor`.</param>
            <param name="axes"> Array of ints.  Axes along which to compute mean and variance.</param>
            <param name="name"> Name used to scope the operations that compute the moments.</param>
            <param name="keep_dims"> Produce moments with the same dimensionality as the input.</param>
            <returns> Two `Tensor` objects: `mean` and `variance`.</returns>
        </member>
        <member name="M:Tensorflow.nn_impl.fused_batch_norm(Tensorflow.Tensor,Tensorflow.IVariableV1,Tensorflow.IVariableV1,Tensorflow.Tensor,Tensorflow.Tensor,System.Single,System.String,System.Boolean,System.String)">
            <summary>
            Batch normalization.
            </summary>
            <param name="x"></param>
            <param name="scale"></param>
            <param name="offset"></param>
            <param name="mean"></param>
            <param name="variance"></param>
            <param name="epsilon"></param>
            <param name="data_format"></param>
            <param name="is_training"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.nn_impl._count_nonzero(Tensorflow.Tensor,Tensorflow.TF_DataType)">
            <summary>
            Same as math_ops.count_nonzero.
            The reduction is done in dtype, which can be faster for 32-bit dtypes.
            </summary>
            <param name="input_tensor">The numeric tensor.</param>
            <param name="dtype">The reduction dtype.</param>
            <returns>number of nonzero values with type dtype</returns>
        </member>
        <member name="M:Tensorflow.nn_impl.zero_fraction(Tensorflow.Tensor,System.String)">
            <summary>
            Returns the fraction of zeros in value.
            </summary>
            <param name="value">A tensor of numeric type.</param>
            <param name="name">A name for the operation (optional).</param>
            <returns>The fraction of zeros in value, with type float32.</returns>
        </member>
        <member name="M:Tensorflow.nn_ops.bias_add(Tensorflow.Tensor,Tensorflow.Tensor,System.String,System.String)">
            <summary>
            Adds `bias` to `value`.
            </summary>
            <param name="value"></param>
            <param name="bias"></param>
            <param name="data_format"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.nn_ops.dropout_v2(Tensorflow.Tensor,Tensorflow.Tensor,Tensorflow.Tensor,System.Nullable{System.Int32},System.String)">
            <summary>
            Computes dropout.
            </summary>
            <param name="x"></param>
            <param name="rate"></param>
            <param name="noise_shape"></param>
            <param name="seed"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.nn_ops.softmax(Tensorflow.Tensor,System.Int32,System.String)">
            <param name="axis">equivalent to `dim`</param>
        </member>
        <member name="M:Tensorflow.nn_ops.max_pool(Tensorflow.Tensor,System.Int32[],System.Int32[],System.String,System.String,System.String)">
            <summary>
            Performs the max pooling on the input.
            </summary>
            <param name="value">A 4-D `Tensor` of the format specified by `data_format`.</param>
            <param name="ksize">
            A list or tuple of 4 ints. The size of the window for each dimension
            of the input tensor.
            </param>
            <param name="strides">
            A list or tuple of 4 ints. The stride of the sliding window for
            each dimension of the input tensor.
            </param>
            <param name="padding">A string, either `'VALID'` or `'SAME'`. The padding algorithm.</param>
            <param name="data_format">A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported.</param>
            <param name="name">Optional name for the operation.</param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.nn_ops.sparse_softmax_cross_entropy_with_logits(Tensorflow.Tensor,Tensorflow.Tensor,System.String)">
            <summary>
            Computes sparse softmax cross entropy between `logits` and `labels`.
            </summary>
            <param name="labels"></param>
            <param name="logits"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.nn_ops._flatten_outer_dims(Tensorflow.Tensor)">
            <summary>
            Flattens logits' outer dimensions and keep its last dimension.
            </summary>
            <param name="logits"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Queues.PaddingFIFOQueue">
            <summary>
            A FIFOQueue that supports batching variable-sized tensors by padding.
            </summary>
        </member>
        <member name="M:Tensorflow.Queues.QueueBase.dequeue(System.String)">
            <summary>
            Dequeues one element from this queue.
            </summary>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Queues.RandomShuffleQueue">
            <summary>
            Create a queue that dequeues elements in a random order.
            </summary>
        </member>
        <member name="M:Tensorflow.random_ops.random_normal(Tensorflow.TensorShape,System.Single,System.Single,Tensorflow.TF_DataType,System.Nullable{System.Int32},System.String)">
            <summary>
            
            </summary>
            <param name="shape"></param>
            <param name="mean"></param>
            <param name="stddev"></param>
            <param name="dtype"></param>
            <param name="seed"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.random_ops.random_uniform(System.Int32[],System.Single,System.Single,Tensorflow.TF_DataType,System.Nullable{System.Int32},System.String)">
            <summary>
            Outputs random values from a uniform distribution.
            </summary>
            <param name="shape"></param>
            <param name="minval"></param>
            <param name="maxval"></param>
            <param name="dtype">The type of the output</param>
            <param name="seed">Used to create a random seed for the distribution.</param>
            <param name="name">A name for the operation</param>
            <returns>A tensor of the specified shape filled with random uniform values.</returns>
        </member>
        <member name="M:Tensorflow.random_ops.random_shuffle(Tensorflow.Tensor,System.Nullable{System.Int32},System.String)">
            <summary>
            Randomly shuffles a tensor along its first dimension.
            </summary>
            <param name="value"></param>
            <param name="seed"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.random_ops.multinomial_categorical_impl(Tensorflow.Tensor,System.Int32,Tensorflow.TF_DataType,System.Nullable{System.Int32})">
            <summary>
            Implementation for random.categorical (v1) and random.categorical (v2).
            </summary>
            <param name="logits"></param>
            <param name="num_samples"></param>
            <param name="dtype"></param>
            <param name="seed"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.resource_variable_ops">
            <summary>
            tensorflow\python\ops\resource_variable_ops.py
            </summary>
        </member>
        <member name="M:Tensorflow.resource_variable_ops.assign(Tensorflow.Tensor,Tensorflow.Tensor,System.Boolean,System.String,System.Boolean)">
            <summary>
            
            </summary>
            <param name="self"></param>
            <param name="value"></param>
            <param name="use_locking"></param>
            <param name="read_value"></param>
            <returns>
            If `read_value` is `True`, this method will return the new value of the
            variable after the assignment has completed.Otherwise, when in graph mode
            it will return the `Operation` that does the assignment, and when in eager
            mode it will return `None`.
            </returns>
        </member>
        <member name="M:Tensorflow.resource_variable_ops.eager_safe_variable_handle(Tensorflow.Tensor,Tensorflow.TensorShape,System.String,System.String,System.Boolean)">
            <summary>
            Creates a variable handle with information to do shape inference.
            </summary>
            <param name="initial_value"></param>
            <param name="shape"></param>
            <param name="shared_name"></param>
            <param name="name"></param>
            <param name="graph_mode"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.resource_variable_ops.variable_handle_from_shape_and_dtype(Tensorflow.TensorShape,Tensorflow.TF_DataType,System.String,System.String,System.Boolean,Tensorflow.Tensor)">
            <summary>
            Create a new variable handle, optionally copying in `extra_handle_data`
            </summary>
            <param name="shape"></param>
            <param name="dtype"></param>
            <param name="shared_name"></param>
            <param name="name"></param>
            <param name="graph_mode"></param>
            <param name="initial_value"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.resource_variable_ops._set_handle_shapes_and_types(Tensorflow.Tensor,Tensorflow.CppShapeInferenceResult.Types.HandleData,System.Boolean)">
            <summary>
            Sets the shape inference result HandleData on tensor.
            </summary>
            <param name="handle"></param>
            <param name="handle_data"></param>
            <param name="graph_mode"></param>
        </member>
        <member name="M:Tensorflow.resource_variable_ops._combine_handle_data(Tensorflow.Tensor,Tensorflow.Tensor)">
            <summary>
            Concats HandleData from tensors `handle` and `initial_value`.
            </summary>
            <param name="handle"></param>
            <param name="initial_value"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.sparse_ops.sparse_to_dense``1(Tensorflow.Tensor,System.Int32[],``0,``0,System.Boolean,System.String)">
            <summary>
            Converts a sparse representation into a dense tensor.
            </summary>
            <typeparam name="T"></typeparam>
            <param name="sparse_indices"></param>
            <param name="output_shape"></param>
            <param name="sparse_values"></param>
            <param name="default_value"></param>
            <param name="validate_indices"></param>
            <param name="name"></param>
            <returns>Dense `Tensor` of shape `output_shape`.  Has the same type as `sparse_values`.</returns>
        </member>
        <member name="M:Tensorflow.string_ops.substr``1(``0,System.Int32,System.Int32,System.String,System.String)">
            <summary>
            Return substrings from `Tensor` of strings.
            </summary>
            <param name="input"></param>
            <param name="pos"></param>
            <param name="len"></param>
            <param name="name"></param>
            <param name="uint"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensor_array_ops.build_ta_with_new_flow(Tensorflow.TensorArray,Tensorflow.Tensor)">
            <summary>
            Builds a TensorArray with a new `flow` tensor.
            </summary>
            <param name="old_ta"></param>
            <param name="flow"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.AllocationDescriptionReflection">
            <summary>Holder for reflection information generated from tensorflow/core/framework/allocation_description.proto</summary>
        </member>
        <member name="P:Tensorflow.AllocationDescriptionReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/framework/allocation_description.proto</summary>
        </member>
        <member name="F:Tensorflow.AllocationDescription.RequestedBytesFieldNumber">
            <summary>Field number for the "requested_bytes" field.</summary>
        </member>
        <member name="P:Tensorflow.AllocationDescription.RequestedBytes">
            <summary>
            Total number of bytes requested
            </summary>
        </member>
        <member name="F:Tensorflow.AllocationDescription.AllocatedBytesFieldNumber">
            <summary>Field number for the "allocated_bytes" field.</summary>
        </member>
        <member name="P:Tensorflow.AllocationDescription.AllocatedBytes">
            <summary>
            Total number of bytes allocated if known
            </summary>
        </member>
        <member name="F:Tensorflow.AllocationDescription.AllocatorNameFieldNumber">
            <summary>Field number for the "allocator_name" field.</summary>
        </member>
        <member name="P:Tensorflow.AllocationDescription.AllocatorName">
            <summary>
            Name of the allocator used
            </summary>
        </member>
        <member name="F:Tensorflow.AllocationDescription.AllocationIdFieldNumber">
            <summary>Field number for the "allocation_id" field.</summary>
        </member>
        <member name="P:Tensorflow.AllocationDescription.AllocationId">
            <summary>
            Identifier of the allocated buffer if known
            </summary>
        </member>
        <member name="F:Tensorflow.AllocationDescription.HasSingleReferenceFieldNumber">
            <summary>Field number for the "has_single_reference" field.</summary>
        </member>
        <member name="P:Tensorflow.AllocationDescription.HasSingleReference">
            <summary>
            Set if this tensor only has one remaining reference
            </summary>
        </member>
        <member name="F:Tensorflow.AllocationDescription.PtrFieldNumber">
            <summary>Field number for the "ptr" field.</summary>
        </member>
        <member name="P:Tensorflow.AllocationDescription.Ptr">
            <summary>
            Address of the allocation.
            </summary>
        </member>
        <member name="T:Tensorflow.ApiDefReflection">
            <summary>Holder for reflection information generated from tensorflow/core/framework/api_def.proto</summary>
        </member>
        <member name="P:Tensorflow.ApiDefReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/framework/api_def.proto</summary>
        </member>
        <member name="T:Tensorflow.ApiDef">
             <summary>
             Used to specify and override the default API &amp; behavior in the
             generated code for client languages, from what you would get from
             the OpDef alone. There will be a set of ApiDefs that are common
             to all client languages, and another set per client language.
             The per-client-language ApiDefs will inherit values from the
             common ApiDefs which it can either replace or modify.
            
             We separate the API definition from the OpDef so we can evolve the
             API while remaining backwards compatible when interpretting old
             graphs.  Overrides go in an "api_def.pbtxt" file with a text-format
             ApiDefs message.
            
             WARNING: Be *very* careful changing the API for any existing op --
             you can change the semantics of existing code.  These changes may
             need to wait until a major release of TensorFlow to avoid breaking
             our compatibility promises.
             </summary>
        </member>
        <member name="F:Tensorflow.ApiDef.GraphOpNameFieldNumber">
            <summary>Field number for the "graph_op_name" field.</summary>
        </member>
        <member name="P:Tensorflow.ApiDef.GraphOpName">
            <summary>
            Name of the op (in the OpDef) to specify the API for.
            </summary>
        </member>
        <member name="F:Tensorflow.ApiDef.DeprecationMessageFieldNumber">
            <summary>Field number for the "deprecation_message" field.</summary>
        </member>
        <member name="P:Tensorflow.ApiDef.DeprecationMessage">
            <summary>
            If this op is deprecated, set deprecation message to the message
            that should be logged when this op is used.
            The message should indicate alternative op to use, if any.
            </summary>
        </member>
        <member name="F:Tensorflow.ApiDef.DeprecationVersionFieldNumber">
            <summary>Field number for the "deprecation_version" field.</summary>
        </member>
        <member name="P:Tensorflow.ApiDef.DeprecationVersion">
            <summary>
            Major version when the op will be deleted. For e.g. set this
            value to 2 if op API should be removed in TensorFlow 2.0 and
            deprecated in versions before that.
            </summary>
        </member>
        <member name="F:Tensorflow.ApiDef.VisibilityFieldNumber">
            <summary>Field number for the "visibility" field.</summary>
        </member>
        <member name="F:Tensorflow.ApiDef.EndpointFieldNumber">
            <summary>Field number for the "endpoint" field.</summary>
        </member>
        <member name="F:Tensorflow.ApiDef.InArgFieldNumber">
            <summary>Field number for the "in_arg" field.</summary>
        </member>
        <member name="F:Tensorflow.ApiDef.OutArgFieldNumber">
            <summary>Field number for the "out_arg" field.</summary>
        </member>
        <member name="F:Tensorflow.ApiDef.ArgOrderFieldNumber">
            <summary>Field number for the "arg_order" field.</summary>
        </member>
        <member name="P:Tensorflow.ApiDef.ArgOrder">
            <summary>
            List of original in_arg names to specify new argument order.
            Length of arg_order should be either empty to keep current order
            or match size of in_arg.
            </summary>
        </member>
        <member name="F:Tensorflow.ApiDef.AttrFieldNumber">
            <summary>Field number for the "attr" field.</summary>
        </member>
        <member name="F:Tensorflow.ApiDef.SummaryFieldNumber">
            <summary>Field number for the "summary" field.</summary>
        </member>
        <member name="P:Tensorflow.ApiDef.Summary">
            <summary>
            One-line human-readable description of what the Op does.
            </summary>
        </member>
        <member name="F:Tensorflow.ApiDef.DescriptionFieldNumber">
            <summary>Field number for the "description" field.</summary>
        </member>
        <member name="P:Tensorflow.ApiDef.Description">
            <summary>
            Additional, longer human-readable description of what the Op does.
            </summary>
        </member>
        <member name="F:Tensorflow.ApiDef.DescriptionPrefixFieldNumber">
            <summary>Field number for the "description_prefix" field.</summary>
        </member>
        <member name="P:Tensorflow.ApiDef.DescriptionPrefix">
            <summary>
            Modify an existing/inherited description by adding text to the beginning
            or end.
            </summary>
        </member>
        <member name="F:Tensorflow.ApiDef.DescriptionSuffixFieldNumber">
            <summary>Field number for the "description_suffix" field.</summary>
        </member>
        <member name="T:Tensorflow.ApiDef.Types">
            <summary>Container for nested types declared in the ApiDef message type.</summary>
        </member>
        <member name="F:Tensorflow.ApiDef.Types.Visibility.DefaultVisibility">
            <summary>
            Normally this is "VISIBLE" unless you are inheriting a
            different value from another ApiDef.
            </summary>
        </member>
        <member name="F:Tensorflow.ApiDef.Types.Visibility.Visible">
            <summary>
            Publicly visible in the API.
            </summary>
        </member>
        <member name="F:Tensorflow.ApiDef.Types.Visibility.Skip">
            <summary>
            Do not include this op in the generated API. If visibility is
            set to 'SKIP', other fields are ignored for this op.
            </summary>
        </member>
        <member name="F:Tensorflow.ApiDef.Types.Visibility.Hidden">
            <summary>
            Hide this op by putting it into an internal namespace (or whatever
            is appropriate in the target language).
            </summary>
        </member>
        <member name="T:Tensorflow.ApiDef.Types.Endpoint">
            <summary>
            If you specify any endpoint, this will replace all of the
            inherited endpoints.  The first endpoint should be the
            "canonical" endpoint, and should not be deprecated (unless all
            endpoints are deprecated).
            </summary>
        </member>
        <member name="F:Tensorflow.ApiDef.Types.Endpoint.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Tensorflow.ApiDef.Types.Endpoint.Name">
            <summary>
            Name should be either like "CamelCaseName" or
            "Package.CamelCaseName". Client-language-specific ApiDefs may
            use a snake_case convention instead of CamelCase.
            </summary>
        </member>
        <member name="F:Tensorflow.ApiDef.Types.Endpoint.DeprecatedFieldNumber">
            <summary>Field number for the "deprecated" field.</summary>
        </member>
        <member name="P:Tensorflow.ApiDef.Types.Endpoint.Deprecated">
            <summary>
            Set if this endpoint is deprecated. If set to true, a message suggesting
            to use a non-deprecated endpoint instead will be printed. If all
            endpoints are deprecated, set deprecation_message in ApiDef instead.
            </summary>
        </member>
        <member name="F:Tensorflow.ApiDef.Types.Endpoint.DeprecationVersionFieldNumber">
            <summary>Field number for the "deprecation_version" field.</summary>
        </member>
        <member name="P:Tensorflow.ApiDef.Types.Endpoint.DeprecationVersion">
            <summary>
            Major version when an endpoint will be deleted. For e.g. set this
            value to 2 if endpoint should be removed in TensorFlow 2.0 and
            deprecated in versions before that.
            </summary>
        </member>
        <member name="F:Tensorflow.ApiDef.Types.Arg.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="F:Tensorflow.ApiDef.Types.Arg.RenameToFieldNumber">
            <summary>Field number for the "rename_to" field.</summary>
        </member>
        <member name="P:Tensorflow.ApiDef.Types.Arg.RenameTo">
            <summary>
            Change the name used to access this arg in the API from what
            is used in the GraphDef.  Note that these names in `backticks`
            will also be replaced in the summary &amp; description fields.
            </summary>
        </member>
        <member name="F:Tensorflow.ApiDef.Types.Arg.DescriptionFieldNumber">
            <summary>Field number for the "description" field.</summary>
        </member>
        <member name="P:Tensorflow.ApiDef.Types.Arg.Description">
            <summary>
            Note: this will replace any inherited arg doc. There is no
            current way of modifying arg descriptions (other than replacing
            them entirely) as can be done with op descriptions.
            </summary>
        </member>
        <member name="T:Tensorflow.ApiDef.Types.Attr">
            <summary>
            Description of the graph-construction-time configuration of this
            Op.  That is to say, this describes the attr fields that will
            be specified in the NodeDef.
            </summary>
        </member>
        <member name="F:Tensorflow.ApiDef.Types.Attr.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="F:Tensorflow.ApiDef.Types.Attr.RenameToFieldNumber">
            <summary>Field number for the "rename_to" field.</summary>
        </member>
        <member name="P:Tensorflow.ApiDef.Types.Attr.RenameTo">
            <summary>
            Change the name used to access this attr in the API from what
            is used in the GraphDef.  Note that these names in `backticks`
            will also be replaced in the summary &amp; description fields.
            </summary>
        </member>
        <member name="F:Tensorflow.ApiDef.Types.Attr.DefaultValueFieldNumber">
            <summary>Field number for the "default_value" field.</summary>
        </member>
        <member name="P:Tensorflow.ApiDef.Types.Attr.DefaultValue">
            <summary>
            Specify a new default value to use for this attr.  This default
            will be used when creating new graphs, as opposed to the
            default in the OpDef, which will be used when interpreting old
            GraphDefs.
            </summary>
        </member>
        <member name="F:Tensorflow.ApiDef.Types.Attr.DescriptionFieldNumber">
            <summary>Field number for the "description" field.</summary>
        </member>
        <member name="P:Tensorflow.ApiDef.Types.Attr.Description">
            <summary>
            Note: this will replace any inherited attr doc, there is no current
            way of modifying attr descriptions as can be done with op descriptions.
            </summary>
        </member>
        <member name="F:Tensorflow.ApiDefs.OpFieldNumber">
            <summary>Field number for the "op" field.</summary>
        </member>
        <member name="T:Tensorflow.AttrValueReflection">
            <summary>Holder for reflection information generated from tensorflow/core/framework/attr_value.proto</summary>
        </member>
        <member name="P:Tensorflow.AttrValueReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/framework/attr_value.proto</summary>
        </member>
        <member name="T:Tensorflow.AttrValue">
            <summary>
            Protocol buffer representing the value for an attr used to configure an Op.
            Comment indicates the corresponding attr type.  Only the field matching the
            attr type may be filled.
            </summary>
        </member>
        <member name="F:Tensorflow.AttrValue.SFieldNumber">
            <summary>Field number for the "s" field.</summary>
        </member>
        <member name="P:Tensorflow.AttrValue.S">
            <summary>
            "string"
            </summary>
        </member>
        <member name="F:Tensorflow.AttrValue.IFieldNumber">
            <summary>Field number for the "i" field.</summary>
        </member>
        <member name="P:Tensorflow.AttrValue.I">
            <summary>
            "int"
            </summary>
        </member>
        <member name="F:Tensorflow.AttrValue.FFieldNumber">
            <summary>Field number for the "f" field.</summary>
        </member>
        <member name="P:Tensorflow.AttrValue.F">
            <summary>
            "float"
            </summary>
        </member>
        <member name="F:Tensorflow.AttrValue.BFieldNumber">
            <summary>Field number for the "b" field.</summary>
        </member>
        <member name="P:Tensorflow.AttrValue.B">
            <summary>
            "bool"
            </summary>
        </member>
        <member name="F:Tensorflow.AttrValue.TypeFieldNumber">
            <summary>Field number for the "type" field.</summary>
        </member>
        <member name="P:Tensorflow.AttrValue.Type">
            <summary>
            "type"
            </summary>
        </member>
        <member name="F:Tensorflow.AttrValue.ShapeFieldNumber">
            <summary>Field number for the "shape" field.</summary>
        </member>
        <member name="P:Tensorflow.AttrValue.Shape">
            <summary>
            "shape"
            </summary>
        </member>
        <member name="F:Tensorflow.AttrValue.TensorFieldNumber">
            <summary>Field number for the "tensor" field.</summary>
        </member>
        <member name="P:Tensorflow.AttrValue.Tensor">
            <summary>
            "tensor"
            </summary>
        </member>
        <member name="F:Tensorflow.AttrValue.ListFieldNumber">
            <summary>Field number for the "list" field.</summary>
        </member>
        <member name="P:Tensorflow.AttrValue.List">
            <summary>
            any "list(...)"
            </summary>
        </member>
        <member name="F:Tensorflow.AttrValue.FuncFieldNumber">
            <summary>Field number for the "func" field.</summary>
        </member>
        <member name="P:Tensorflow.AttrValue.Func">
            <summary>
            "func" represents a function. func.name is a function's name or
            a primitive op's name. func.attr.first is the name of an attr
            defined for that function. func.attr.second is the value for
            that attr in the instantiation.
            </summary>
        </member>
        <member name="F:Tensorflow.AttrValue.PlaceholderFieldNumber">
            <summary>Field number for the "placeholder" field.</summary>
        </member>
        <member name="P:Tensorflow.AttrValue.Placeholder">
            <summary>
            This is a placeholder only used in nodes defined inside a
            function.  It indicates the attr value will be supplied when
            the function is instantiated.  For example, let us suppose a
            node "N" in function "FN". "N" has an attr "A" with value
            placeholder = "foo". When FN is instantiated with attr "foo"
            set to "bar", the instantiated node N's attr A will have been
            given the value "bar".
            </summary>
        </member>
        <member name="T:Tensorflow.AttrValue.ValueOneofCase">
            <summary>Enum of possible cases for the "value" oneof.</summary>
        </member>
        <member name="T:Tensorflow.AttrValue.Types">
            <summary>Container for nested types declared in the AttrValue message type.</summary>
        </member>
        <member name="T:Tensorflow.AttrValue.Types.ListValue">
            <summary>
            LINT.IfChange
            </summary>
        </member>
        <member name="F:Tensorflow.AttrValue.Types.ListValue.SFieldNumber">
            <summary>Field number for the "s" field.</summary>
        </member>
        <member name="P:Tensorflow.AttrValue.Types.ListValue.S">
            <summary>
            "list(string)"
            </summary>
        </member>
        <member name="F:Tensorflow.AttrValue.Types.ListValue.IFieldNumber">
            <summary>Field number for the "i" field.</summary>
        </member>
        <member name="P:Tensorflow.AttrValue.Types.ListValue.I">
            <summary>
            "list(int)"
            </summary>
        </member>
        <member name="F:Tensorflow.AttrValue.Types.ListValue.FFieldNumber">
            <summary>Field number for the "f" field.</summary>
        </member>
        <member name="P:Tensorflow.AttrValue.Types.ListValue.F">
            <summary>
            "list(float)"
            </summary>
        </member>
        <member name="F:Tensorflow.AttrValue.Types.ListValue.BFieldNumber">
            <summary>Field number for the "b" field.</summary>
        </member>
        <member name="P:Tensorflow.AttrValue.Types.ListValue.B">
            <summary>
            "list(bool)"
            </summary>
        </member>
        <member name="F:Tensorflow.AttrValue.Types.ListValue.TypeFieldNumber">
            <summary>Field number for the "type" field.</summary>
        </member>
        <member name="P:Tensorflow.AttrValue.Types.ListValue.Type">
            <summary>
            "list(type)"
            </summary>
        </member>
        <member name="F:Tensorflow.AttrValue.Types.ListValue.ShapeFieldNumber">
            <summary>Field number for the "shape" field.</summary>
        </member>
        <member name="P:Tensorflow.AttrValue.Types.ListValue.Shape">
            <summary>
            "list(shape)"
            </summary>
        </member>
        <member name="F:Tensorflow.AttrValue.Types.ListValue.TensorFieldNumber">
            <summary>Field number for the "tensor" field.</summary>
        </member>
        <member name="P:Tensorflow.AttrValue.Types.ListValue.Tensor">
            <summary>
            "list(tensor)"
            </summary>
        </member>
        <member name="F:Tensorflow.AttrValue.Types.ListValue.FuncFieldNumber">
            <summary>Field number for the "func" field.</summary>
        </member>
        <member name="P:Tensorflow.AttrValue.Types.ListValue.Func">
            <summary>
            "list(attr)"
            </summary>
        </member>
        <member name="T:Tensorflow.NameAttrList">
            <summary>
            A list of attr names and their values. The whole list is attached
            with a string name.  E.g., MatMul[T=float].
            </summary>
        </member>
        <member name="F:Tensorflow.NameAttrList.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="F:Tensorflow.NameAttrList.AttrFieldNumber">
            <summary>Field number for the "attr" field.</summary>
        </member>
        <member name="T:Tensorflow.CheckpointStateReflection">
            <summary>Holder for reflection information generated from tensorflow/python/training/checkpoint_state.proto</summary>
        </member>
        <member name="P:Tensorflow.CheckpointStateReflection.Descriptor">
            <summary>File descriptor for tensorflow/python/training/checkpoint_state.proto</summary>
        </member>
        <member name="T:Tensorflow.CheckpointState">
            <summary>
            Protocol buffer representing the checkpoint state.
            </summary>
        </member>
        <member name="F:Tensorflow.CheckpointState.ModelCheckpointPathFieldNumber">
            <summary>Field number for the "model_checkpoint_path" field.</summary>
        </member>
        <member name="P:Tensorflow.CheckpointState.ModelCheckpointPath">
            <summary>
            Path to the most-recent model checkpoint.
            </summary>
        </member>
        <member name="F:Tensorflow.CheckpointState.AllModelCheckpointPathsFieldNumber">
            <summary>Field number for the "all_model_checkpoint_paths" field.</summary>
        </member>
        <member name="P:Tensorflow.CheckpointState.AllModelCheckpointPaths">
            <summary>
            Paths to all not-yet-deleted model checkpoints, sorted from oldest to
            newest.
            Note that the value of model_checkpoint_path should be the last item in
            this list.
            </summary>
        </member>
        <member name="F:Tensorflow.CheckpointState.AllModelCheckpointTimestampsFieldNumber">
            <summary>Field number for the "all_model_checkpoint_timestamps" field.</summary>
        </member>
        <member name="P:Tensorflow.CheckpointState.AllModelCheckpointTimestamps">
            <summary>
            Unix timestamps corresponding to all_model_checkpoint_paths, indicating
            when each checkpoint was created.
            </summary>
        </member>
        <member name="F:Tensorflow.CheckpointState.LastPreservedTimestampFieldNumber">
            <summary>Field number for the "last_preserved_timestamp" field.</summary>
        </member>
        <member name="P:Tensorflow.CheckpointState.LastPreservedTimestamp">
            <summary>
            Unix timestamp indicating the creation time for the last preserved
            checkpoint.
            </summary>
        </member>
        <member name="T:Tensorflow.ClusterReflection">
            <summary>Holder for reflection information generated from tensorflow/core/protobuf/cluster.proto</summary>
        </member>
        <member name="P:Tensorflow.ClusterReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/protobuf/cluster.proto</summary>
        </member>
        <member name="T:Tensorflow.JobDef">
            <summary>
            Defines a single job in a TensorFlow cluster.
            </summary>
        </member>
        <member name="F:Tensorflow.JobDef.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Tensorflow.JobDef.Name">
            <summary>
            The name of this job.
            </summary>
        </member>
        <member name="F:Tensorflow.JobDef.TasksFieldNumber">
            <summary>Field number for the "tasks" field.</summary>
        </member>
        <member name="P:Tensorflow.JobDef.Tasks">
             <summary>
             Mapping from task ID to "hostname:port" string.
            
             If the `name` field contains "worker", and the `tasks` map contains a
             mapping from 7 to "example.org:2222", then the device prefix
             "/job:worker/task:7" will be assigned to "example.org:2222".
             </summary>
        </member>
        <member name="T:Tensorflow.ClusterDef">
            <summary>
            Defines a TensorFlow cluster as a set of jobs.
            </summary>
        </member>
        <member name="F:Tensorflow.ClusterDef.JobFieldNumber">
            <summary>Field number for the "job" field.</summary>
        </member>
        <member name="P:Tensorflow.ClusterDef.Job">
            <summary>
            The jobs that comprise the cluster.
            </summary>
        </member>
        <member name="T:Tensorflow.ConfigReflection">
            <summary>Holder for reflection information generated from tensorflow/core/protobuf/config.proto</summary>
        </member>
        <member name="P:Tensorflow.ConfigReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/protobuf/config.proto</summary>
        </member>
        <member name="F:Tensorflow.GPUOptions.PerProcessGpuMemoryFractionFieldNumber">
            <summary>Field number for the "per_process_gpu_memory_fraction" field.</summary>
        </member>
        <member name="P:Tensorflow.GPUOptions.PerProcessGpuMemoryFraction">
             <summary>
             Fraction of the available GPU memory to allocate for each process.
             1 means to allocate all of the GPU memory, 0.5 means the process
             allocates up to ~50% of the available GPU memory.
            
             GPU memory is pre-allocated unless the allow_growth option is enabled.
            
             If greater than 1.0, uses CUDA unified memory to potentially oversubscribe
             the amount of memory available on the GPU device by using host memory as a
             swap space. Accessing memory not available on the device will be
             significantly slower as that would require memory transfer between the host
             and the device. Options to reduce the memory requirement should be
             considered before enabling this option as this may come with a negative
             performance impact. Oversubscription using the unified memory requires
             Pascal class or newer GPUs and it is currently only supported on the Linux
             operating system. See
             https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-requirements
             for the detailed requirements.
             </summary>
        </member>
        <member name="F:Tensorflow.GPUOptions.AllowGrowthFieldNumber">
            <summary>Field number for the "allow_growth" field.</summary>
        </member>
        <member name="P:Tensorflow.GPUOptions.AllowGrowth">
            <summary>
            If true, the allocator does not pre-allocate the entire specified
            GPU memory region, instead starting small and growing as needed.
            </summary>
        </member>
        <member name="F:Tensorflow.GPUOptions.AllocatorTypeFieldNumber">
            <summary>Field number for the "allocator_type" field.</summary>
        </member>
        <member name="P:Tensorflow.GPUOptions.AllocatorType">
             <summary>
             The type of GPU allocation strategy to use.
            
             Allowed values:
             "": The empty string (default) uses a system-chosen default
                 which may change over time.
            
             "BFC": A "Best-fit with coalescing" algorithm, simplified from a
                    version of dlmalloc.
             </summary>
        </member>
        <member name="F:Tensorflow.GPUOptions.DeferredDeletionBytesFieldNumber">
            <summary>Field number for the "deferred_deletion_bytes" field.</summary>
        </member>
        <member name="P:Tensorflow.GPUOptions.DeferredDeletionBytes">
            <summary>
            Delay deletion of up to this many bytes to reduce the number of
            interactions with gpu driver code.  If 0, the system chooses
            a reasonable default (several MBs).
            </summary>
        </member>
        <member name="F:Tensorflow.GPUOptions.VisibleDeviceListFieldNumber">
            <summary>Field number for the "visible_device_list" field.</summary>
        </member>
        <member name="P:Tensorflow.GPUOptions.VisibleDeviceList">
             <summary>
             A comma-separated list of GPU ids that determines the 'visible'
             to 'virtual' mapping of GPU devices.  For example, if TensorFlow
             can see 8 GPU devices in the process, and one wanted to map
             visible GPU devices 5 and 3 as "/device:GPU:0", and "/device:GPU:1",
             then one would specify this field as "5,3".  This field is similar in
             spirit to the CUDA_VISIBLE_DEVICES environment variable, except
             it applies to the visible GPU devices in the process.
            
             NOTE:
             1. The GPU driver provides the process with the visible GPUs
                in an order which is not guaranteed to have any correlation to
                the *physical* GPU id in the machine.  This field is used for
                remapping "visible" to "virtual", which means this operates only
                after the process starts.  Users are required to use vendor
                specific mechanisms (e.g., CUDA_VISIBLE_DEVICES) to control the
                physical to visible device mapping prior to invoking TensorFlow.
             2. In the code, the ids in this list are also called "platform GPU id"s,
                and the 'virtual' ids of GPU devices (i.e. the ids in the device
                name "/device:GPU:&lt;id>") are also called "TF GPU id"s. Please
                refer to third_party/tensorflow/core/common_runtime/gpu/gpu_id.h
                for more information.
             </summary>
        </member>
        <member name="F:Tensorflow.GPUOptions.PollingActiveDelayUsecsFieldNumber">
            <summary>Field number for the "polling_active_delay_usecs" field.</summary>
        </member>
        <member name="P:Tensorflow.GPUOptions.PollingActiveDelayUsecs">
            <summary>
            In the event polling loop sleep this many microseconds between
            PollEvents calls, when the queue is not empty.  If value is not
            set or set to 0, gets set to a non-zero default.
            </summary>
        </member>
        <member name="F:Tensorflow.GPUOptions.PollingInactiveDelayMsecsFieldNumber">
            <summary>Field number for the "polling_inactive_delay_msecs" field.</summary>
        </member>
        <member name="P:Tensorflow.GPUOptions.PollingInactiveDelayMsecs">
            <summary>
            This field is deprecated and ignored.
            </summary>
        </member>
        <member name="F:Tensorflow.GPUOptions.ForceGpuCompatibleFieldNumber">
            <summary>Field number for the "force_gpu_compatible" field.</summary>
        </member>
        <member name="P:Tensorflow.GPUOptions.ForceGpuCompatible">
            <summary>
            Force all tensors to be gpu_compatible. On a GPU-enabled TensorFlow,
            enabling this option forces all CPU tensors to be allocated with Cuda
            pinned memory. Normally, TensorFlow will infer which tensors should be
            allocated as the pinned memory. But in case where the inference is
            incomplete, this option can significantly speed up the cross-device memory
            copy performance as long as it fits the memory.
            Note that this option is not something that should be
            enabled by default for unknown or very large models, since all Cuda pinned
            memory is unpageable, having too much pinned memory might negatively impact
            the overall host system performance.
            </summary>
        </member>
        <member name="F:Tensorflow.GPUOptions.ExperimentalFieldNumber">
            <summary>Field number for the "experimental" field.</summary>
        </member>
        <member name="P:Tensorflow.GPUOptions.Experimental">
            <summary>
            Everything inside experimental is subject to change and is not subject
            to API stability guarantees in
            https://www.tensorflow.org/guide/version_compat.
            </summary>
        </member>
        <member name="T:Tensorflow.GPUOptions.Types">
            <summary>Container for nested types declared in the GPUOptions message type.</summary>
        </member>
        <member name="F:Tensorflow.GPUOptions.Types.Experimental.VirtualDevicesFieldNumber">
            <summary>Field number for the "virtual_devices" field.</summary>
        </member>
        <member name="P:Tensorflow.GPUOptions.Types.Experimental.VirtualDevices">
             <summary>
             The multi virtual device settings. If empty (not set), it will create
             single virtual device on each visible GPU, according to the settings
             in "visible_device_list" above. Otherwise, the number of elements in the
             list must be the same as the number of visible GPUs (after
             "visible_device_list" filtering if it is set), and the string represented
             device names (e.g. /device:GPU:&lt;id>) will refer to the virtual
             devices and have the &lt;id> field assigned sequentially starting from 0,
             according to the order they appear in this list and the "memory_limit"
             list inside each element. For example,
               visible_device_list = "1,0"
               virtual_devices { memory_limit: 1GB memory_limit: 2GB }
               virtual_devices {}
             will create three virtual devices as:
               /device:GPU:0 -> visible GPU 1 with 1GB memory
               /device:GPU:1 -> visible GPU 1 with 2GB memory
               /device:GPU:2 -> visible GPU 0 with all available memory
            
             NOTE:
             1. It's invalid to set both this and "per_process_gpu_memory_fraction"
                at the same time.
             2. Currently this setting is per-process, not per-session. Using
                different settings in different sessions within same process will
                result in undefined behavior.
             </summary>
        </member>
        <member name="F:Tensorflow.GPUOptions.Types.Experimental.UseUnifiedMemoryFieldNumber">
            <summary>Field number for the "use_unified_memory" field.</summary>
        </member>
        <member name="P:Tensorflow.GPUOptions.Types.Experimental.UseUnifiedMemory">
            <summary>
            If true, uses CUDA unified memory for memory allocations. If
            per_process_gpu_memory_fraction option is greater than 1.0, then unified
            memory is used regardless of the value for this field. See comments for
            per_process_gpu_memory_fraction field for more details and requirements
            of the unified memory. This option is useful to oversubscribe memory if
            multiple processes are sharing a single GPU while individually using less
            than 1.0 per process memory fraction.
            </summary>
        </member>
        <member name="F:Tensorflow.GPUOptions.Types.Experimental.NumDevToDevCopyStreamsFieldNumber">
            <summary>Field number for the "num_dev_to_dev_copy_streams" field.</summary>
        </member>
        <member name="P:Tensorflow.GPUOptions.Types.Experimental.NumDevToDevCopyStreams">
            <summary>
            If > 1, the number of device-to-device copy streams to create
            for each GPUDevice.  Default value is 0, which is automatically
            converted to 1.
            </summary>
        </member>
        <member name="F:Tensorflow.GPUOptions.Types.Experimental.CollectiveRingOrderFieldNumber">
            <summary>Field number for the "collective_ring_order" field.</summary>
        </member>
        <member name="P:Tensorflow.GPUOptions.Types.Experimental.CollectiveRingOrder">
            <summary>
            If non-empty, defines a good GPU ring order on a single worker based on
            device interconnect.  This assumes that all workers have the same GPU
            topology.  Specify as a comma-separated string, e.g. "3,2,1,0,7,6,5,4".
            This ring order is used by the RingReducer implementation of
            CollectiveReduce, and serves as an override to automatic ring order
            generation in OrderTaskDeviceMap() during CollectiveParam resolution.
            </summary>
        </member>
        <member name="F:Tensorflow.GPUOptions.Types.Experimental.TimestampedAllocatorFieldNumber">
            <summary>Field number for the "timestamped_allocator" field.</summary>
        </member>
        <member name="P:Tensorflow.GPUOptions.Types.Experimental.TimestampedAllocator">
            <summary>
            If true then extra work is done by GPUDevice and GPUBFCAllocator to
            keep track of when GPU memory is freed and when kernels actually
            complete so that we can know when a nominally free memory chunk
            is really not subject to pending use.
            </summary>
        </member>
        <member name="F:Tensorflow.GPUOptions.Types.Experimental.KernelTrackerMaxIntervalFieldNumber">
            <summary>Field number for the "kernel_tracker_max_interval" field.</summary>
        </member>
        <member name="P:Tensorflow.GPUOptions.Types.Experimental.KernelTrackerMaxInterval">
             <summary>
             Parameters for GPUKernelTracker.  By default no kernel tracking is done.
             Note that timestamped_allocator is only effective if some tracking is
             specified.
            
             If kernel_tracker_max_interval = n > 0, then a tracking event
             is inserted after every n kernels without an event.
             </summary>
        </member>
        <member name="F:Tensorflow.GPUOptions.Types.Experimental.KernelTrackerMaxBytesFieldNumber">
            <summary>Field number for the "kernel_tracker_max_bytes" field.</summary>
        </member>
        <member name="P:Tensorflow.GPUOptions.Types.Experimental.KernelTrackerMaxBytes">
            <summary>
            If kernel_tracker_max_bytes = n > 0, then a tracking event is
            inserted after every series of kernels allocating a sum of
            memory >= n.  If one kernel allocates b * n bytes, then one
            event will be inserted after it, but it will count as b against
            the pending limit.
            </summary>
        </member>
        <member name="F:Tensorflow.GPUOptions.Types.Experimental.KernelTrackerMaxPendingFieldNumber">
            <summary>Field number for the "kernel_tracker_max_pending" field.</summary>
        </member>
        <member name="P:Tensorflow.GPUOptions.Types.Experimental.KernelTrackerMaxPending">
            <summary>
            If kernel_tracker_max_pending > 0 then no more than this many
            tracking events can be outstanding at a time.  An attempt to
            launch an additional kernel will stall until an event
            completes.
            </summary>
        </member>
        <member name="T:Tensorflow.GPUOptions.Types.Experimental.Types">
            <summary>Container for nested types declared in the Experimental message type.</summary>
        </member>
        <member name="T:Tensorflow.GPUOptions.Types.Experimental.Types.VirtualDevices">
            <summary>
            Configuration for breaking down a visible GPU into multiple "virtual"
            devices.
            </summary>
        </member>
        <member name="F:Tensorflow.GPUOptions.Types.Experimental.Types.VirtualDevices.MemoryLimitMbFieldNumber">
            <summary>Field number for the "memory_limit_mb" field.</summary>
        </member>
        <member name="P:Tensorflow.GPUOptions.Types.Experimental.Types.VirtualDevices.MemoryLimitMb">
             <summary>
             Per "virtual" device memory limit, in MB. The number of elements in
             the list is the number of virtual devices to create on the
             corresponding visible GPU (see "virtual_devices" below).
             If empty, it will create single virtual device taking all available
             memory from the device.
            
             For the concept of "visible" and "virtual" GPU, see the comments for
             "visible_device_list" above for more information.
             </summary>
        </member>
        <member name="F:Tensorflow.GPUOptions.Types.Experimental.Types.VirtualDevices.PriorityFieldNumber">
            <summary>Field number for the "priority" field.</summary>
        </member>
        <member name="P:Tensorflow.GPUOptions.Types.Experimental.Types.VirtualDevices.Priority">
             <summary>
             Priority values to use with the virtual devices. Use the cuda function
             cudaDeviceGetStreamPriorityRange to query for valid range of values for
             priority.
            
             On a P4000 GPU with cuda 10.1, the priority range reported was 0 for
             least priority and -1 for greatest priority.
            
             If this field is not specified, then the virtual devices will be
             created with the default. If this field has values set, then the size
             of this must match with the above memory_limit_mb.
             </summary>
        </member>
        <member name="T:Tensorflow.OptimizerOptions">
            <summary>
            Options passed to the graph optimizer
            </summary>
        </member>
        <member name="F:Tensorflow.OptimizerOptions.DoCommonSubexpressionEliminationFieldNumber">
            <summary>Field number for the "do_common_subexpression_elimination" field.</summary>
        </member>
        <member name="P:Tensorflow.OptimizerOptions.DoCommonSubexpressionElimination">
            <summary>
            If true, optimize the graph using common subexpression elimination.
            </summary>
        </member>
        <member name="F:Tensorflow.OptimizerOptions.DoConstantFoldingFieldNumber">
            <summary>Field number for the "do_constant_folding" field.</summary>
        </member>
        <member name="P:Tensorflow.OptimizerOptions.DoConstantFolding">
            <summary>
            If true, perform constant folding optimization on the graph.
            </summary>
        </member>
        <member name="F:Tensorflow.OptimizerOptions.MaxFoldedConstantInBytesFieldNumber">
            <summary>Field number for the "max_folded_constant_in_bytes" field.</summary>
        </member>
        <member name="P:Tensorflow.OptimizerOptions.MaxFoldedConstantInBytes">
            <summary>
            Constant folding optimization replaces tensors whose values can be
            predetermined, with constant nodes. To avoid inserting too large constants,
            the size of each constant created can be limited. If this value is zero, a
            default limit of 10 MiB will be applied. If constant folding optimization
            is disabled, this value is ignored.
            </summary>
        </member>
        <member name="F:Tensorflow.OptimizerOptions.DoFunctionInliningFieldNumber">
            <summary>Field number for the "do_function_inlining" field.</summary>
        </member>
        <member name="P:Tensorflow.OptimizerOptions.DoFunctionInlining">
            <summary>
            If true, perform function inlining on the graph.
            </summary>
        </member>
        <member name="F:Tensorflow.OptimizerOptions.OptLevelFieldNumber">
            <summary>Field number for the "opt_level" field.</summary>
        </member>
        <member name="P:Tensorflow.OptimizerOptions.OptLevel">
            <summary>
            Overall optimization level. The actual optimizations applied will be the
            logical OR of the flags that this level implies and any flags already set.
            </summary>
        </member>
        <member name="F:Tensorflow.OptimizerOptions.GlobalJitLevelFieldNumber">
            <summary>Field number for the "global_jit_level" field.</summary>
        </member>
        <member name="T:Tensorflow.OptimizerOptions.Types">
            <summary>Container for nested types declared in the OptimizerOptions message type.</summary>
        </member>
        <member name="T:Tensorflow.OptimizerOptions.Types.Level">
            <summary>
            Optimization level
            </summary>
        </member>
        <member name="F:Tensorflow.OptimizerOptions.Types.Level.L1">
            <summary>
            L1 is the default level.
            Optimization performed at L1 :
            1. Common subexpression elimination
            2. Constant folding
            </summary>
        </member>
        <member name="F:Tensorflow.OptimizerOptions.Types.Level.L0">
            <summary>
            No optimizations
            </summary>
        </member>
        <member name="T:Tensorflow.OptimizerOptions.Types.GlobalJitLevel">
            <summary>
            Control the use of the compiler/jit.  Experimental.
            </summary>
        </member>
        <member name="F:Tensorflow.OptimizerOptions.Types.GlobalJitLevel.Default">
            <summary>
            Default setting ("off" now, but later expected to be "on")
            </summary>
        </member>
        <member name="F:Tensorflow.OptimizerOptions.Types.GlobalJitLevel.On1">
            <summary>
            The following settings turn on compilation, with higher values being
            more aggressive.  Higher values may reduce opportunities for parallelism
            and may use more memory.  (At present, there is no distinction, but this
            is expected to change.)
            </summary>
        </member>
        <member name="F:Tensorflow.GraphOptions.EnableRecvSchedulingFieldNumber">
            <summary>Field number for the "enable_recv_scheduling" field.</summary>
        </member>
        <member name="P:Tensorflow.GraphOptions.EnableRecvScheduling">
            <summary>
            If true, use control flow to schedule the activation of Recv nodes.
            (Currently ignored.)
            </summary>
        </member>
        <member name="F:Tensorflow.GraphOptions.OptimizerOptionsFieldNumber">
            <summary>Field number for the "optimizer_options" field.</summary>
        </member>
        <member name="P:Tensorflow.GraphOptions.OptimizerOptions">
            <summary>
            Options controlling how graph is optimized.
            </summary>
        </member>
        <member name="F:Tensorflow.GraphOptions.BuildCostModelFieldNumber">
            <summary>Field number for the "build_cost_model" field.</summary>
        </member>
        <member name="P:Tensorflow.GraphOptions.BuildCostModel">
            <summary>
            The number of steps to run before returning a cost model detailing
            the memory usage and performance of each node of the graph. 0 means
            no cost model.
            </summary>
        </member>
        <member name="F:Tensorflow.GraphOptions.BuildCostModelAfterFieldNumber">
            <summary>Field number for the "build_cost_model_after" field.</summary>
        </member>
        <member name="P:Tensorflow.GraphOptions.BuildCostModelAfter">
            <summary>
            The number of steps to skip before collecting statistics for the
            cost model.
            </summary>
        </member>
        <member name="F:Tensorflow.GraphOptions.InferShapesFieldNumber">
            <summary>Field number for the "infer_shapes" field.</summary>
        </member>
        <member name="P:Tensorflow.GraphOptions.InferShapes">
            <summary>
            Annotate each Node with Op output shape data, to the extent it can
            be statically inferred.
            </summary>
        </member>
        <member name="F:Tensorflow.GraphOptions.PlacePrunedGraphFieldNumber">
            <summary>Field number for the "place_pruned_graph" field.</summary>
        </member>
        <member name="P:Tensorflow.GraphOptions.PlacePrunedGraph">
             <summary>
             Only place the subgraphs that are run, rather than the entire graph.
            
             This is useful for interactive graph building, where one might
             produce graphs that cannot be placed during the debugging
             process.  In particular, it allows the client to continue work in
             a session after adding a node to a graph whose placement
             constraints are unsatisfiable.
             </summary>
        </member>
        <member name="F:Tensorflow.GraphOptions.EnableBfloat16SendrecvFieldNumber">
            <summary>Field number for the "enable_bfloat16_sendrecv" field.</summary>
        </member>
        <member name="P:Tensorflow.GraphOptions.EnableBfloat16Sendrecv">
            <summary>
            If true, transfer float values between processes as bfloat16.
            </summary>
        </member>
        <member name="F:Tensorflow.GraphOptions.TimelineStepFieldNumber">
            <summary>Field number for the "timeline_step" field.</summary>
        </member>
        <member name="P:Tensorflow.GraphOptions.TimelineStep">
            <summary>
            If > 0, record a timeline every this many steps.
            EXPERIMENTAL: This currently has no effect in MasterSession.
            </summary>
        </member>
        <member name="F:Tensorflow.GraphOptions.RewriteOptionsFieldNumber">
            <summary>Field number for the "rewrite_options" field.</summary>
        </member>
        <member name="P:Tensorflow.GraphOptions.RewriteOptions">
            <summary>
            Options that control the type and amount of graph rewriting.
            Not currently configurable via the public Python API (i.e. there is no API
            stability guarantee if you import RewriterConfig explicitly).
            </summary>
        </member>
        <member name="F:Tensorflow.ThreadPoolOptionProto.NumThreadsFieldNumber">
            <summary>Field number for the "num_threads" field.</summary>
        </member>
        <member name="P:Tensorflow.ThreadPoolOptionProto.NumThreads">
             <summary>
             The number of threads in the pool.
            
             0 means the system picks a value based on where this option proto is used
             (see the declaration of the specific field for more info).
             </summary>
        </member>
        <member name="F:Tensorflow.ThreadPoolOptionProto.GlobalNameFieldNumber">
            <summary>Field number for the "global_name" field.</summary>
        </member>
        <member name="P:Tensorflow.ThreadPoolOptionProto.GlobalName">
             <summary>
             The global name of the threadpool.
            
             If empty, then the threadpool is made and used according to the scope it's
             in - e.g., for a session threadpool, it is used by that session only.
            
             If non-empty, then:
             - a global threadpool associated with this name is looked
               up or created. This allows, for example, sharing one threadpool across
               many sessions (e.g., like the default behavior, if
               inter_op_parallelism_threads is not configured), but still partitioning
               into a large and small pool.
             - if the threadpool for this global_name already exists, then it is an
               error if the existing pool was created using a different num_threads
               value as is specified on this call.
             - threadpools created this way are never garbage collected.
             </summary>
        </member>
        <member name="F:Tensorflow.RPCOptions.UseRpcForInprocessMasterFieldNumber">
            <summary>Field number for the "use_rpc_for_inprocess_master" field.</summary>
        </member>
        <member name="P:Tensorflow.RPCOptions.UseRpcForInprocessMaster">
             <summary>
             If true, always use RPC to contact the session target.
            
             If false (the default option), TensorFlow may use an optimized
             transport for client-master communication that avoids the RPC
             stack. This option is primarily for used testing the RPC stack.
             </summary>
        </member>
        <member name="F:Tensorflow.RPCOptions.CompressionAlgorithmFieldNumber">
            <summary>Field number for the "compression_algorithm" field.</summary>
        </member>
        <member name="P:Tensorflow.RPCOptions.CompressionAlgorithm">
            <summary>
            The compression algorithm to be used. One of "deflate", "gzip".
            </summary>
        </member>
        <member name="F:Tensorflow.RPCOptions.CompressionLevelFieldNumber">
            <summary>Field number for the "compression_level" field.</summary>
        </member>
        <member name="P:Tensorflow.RPCOptions.CompressionLevel">
            <summary>
            If compression_algorithm is set, the compression level to be used.
            From 0 (no compression), up to 3.
            </summary>
        </member>
        <member name="F:Tensorflow.RPCOptions.CacheRpcResponseFieldNumber">
            <summary>Field number for the "cache_rpc_response" field.</summary>
        </member>
        <member name="P:Tensorflow.RPCOptions.CacheRpcResponse">
            <summary>
            Setting cache_rpc_response to true will enable sender side caching of
            response for RecvTensorAsync and RecvBufAsync to allow receiver to retry
            requests . This is only necessary when the network fabric is experiencing a
            significant error rate.  Without it we'll fail a step on an network error,
            while with it we'll be able to complete long steps (like complex
            initializations) in the face of some network errors during RecvTensor.
            </summary>
        </member>
        <member name="F:Tensorflow.RPCOptions.DisableSessionConnectionSharingFieldNumber">
            <summary>Field number for the "disable_session_connection_sharing" field.</summary>
        </member>
        <member name="P:Tensorflow.RPCOptions.DisableSessionConnectionSharing">
            <summary>
            Disables TCP connection sharing when opening a new RPC channel.
            </summary>
        </member>
        <member name="T:Tensorflow.SessionMetadata">
             <summary>
             Metadata about the session.
            
             This can be used by the runtime and the Ops for debugging, monitoring, etc.
            
             The (name, version) tuple is expected to be a unique identifier for
             sessions within the same process.
            
             NOTE: This is currently used and propagated only by the direct session.
             </summary>
        </member>
        <member name="F:Tensorflow.SessionMetadata.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="F:Tensorflow.SessionMetadata.VersionFieldNumber">
            <summary>Field number for the "version" field.</summary>
        </member>
        <member name="P:Tensorflow.SessionMetadata.Version">
            <summary>
            The version is optional. If set, needs to be >= 0.
            </summary>
        </member>
        <member name="T:Tensorflow.ConfigProto">
            <summary>
            Session configuration parameters.
            The system picks appropriate values for fields that are not set.
            </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.DeviceCountFieldNumber">
            <summary>Field number for the "device_count" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.DeviceCount">
            <summary>
            Map from device type name (e.g., "CPU" or "GPU" ) to maximum
            number of devices of that type to use.  If a particular device
            type is not found in the map, the system picks an appropriate
            number.
            </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.IntraOpParallelismThreadsFieldNumber">
            <summary>Field number for the "intra_op_parallelism_threads" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.IntraOpParallelismThreads">
             <summary>
             The execution of an individual op (for some op types) can be
             parallelized on a pool of intra_op_parallelism_threads.
             0 means the system picks an appropriate number.
            
             If you create an ordinary session, e.g., from Python or C++,
             then there is exactly one intra op thread pool per process.
             The first session created determines the number of threads in this pool.
             All subsequent sessions reuse/share this one global pool.
            
             There are notable exceptions to the default behavior describe above:
             1. There is an environment variable  for overriding this thread pool,
                named TF_OVERRIDE_GLOBAL_THREADPOOL.
             2. When connecting to a server, such as a remote `tf.train.Server`
                instance, then this option will be ignored altogether.
             </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.InterOpParallelismThreadsFieldNumber">
            <summary>Field number for the "inter_op_parallelism_threads" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.InterOpParallelismThreads">
             <summary>
             Nodes that perform blocking operations are enqueued on a pool of
             inter_op_parallelism_threads available in each process.
            
             0 means the system picks an appropriate number.
             Negative means all operations are performed in caller's thread.
            
             Note that the first Session created in the process sets the
             number of threads for all future sessions unless use_per_session_threads is
             true or session_inter_op_thread_pool is configured.
             </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.UsePerSessionThreadsFieldNumber">
            <summary>Field number for the "use_per_session_threads" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.UsePerSessionThreads">
             <summary>
             If true, use a new set of threads for this session rather than the global
             pool of threads. Only supported by direct sessions.
            
             If false, use the global threads created by the first session, or the
             per-session thread pools configured by session_inter_op_thread_pool.
            
             This option is deprecated. The same effect can be achieved by setting
             session_inter_op_thread_pool to have one element, whose num_threads equals
             inter_op_parallelism_threads.
             </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.SessionInterOpThreadPoolFieldNumber">
            <summary>Field number for the "session_inter_op_thread_pool" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.SessionInterOpThreadPool">
             <summary>
             This option is experimental - it may be replaced with a different mechanism
             in the future.
            
             Configures session thread pools. If this is configured, then RunOptions for
             a Run call can select the thread pool to use.
            
             The intended use is for when some session invocations need to run in a
             background pool limited to a small number of threads:
             - For example, a session may be configured to have one large pool (for
             regular compute) and one small pool (for periodic, low priority work);
             using the small pool is currently the mechanism for limiting the inter-op
             parallelism of the low priority work.  Note that it does not limit the
             parallelism of work spawned by a single op kernel implementation.
             - Using this setting is normally not needed in training, but may help some
             serving use cases.
             - It is also generally recommended to set the global_name field of this
             proto, to avoid creating multiple large pools. It is typically better to
             run the non-low-priority work, even across sessions, in a single large
             pool.
             </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.PlacementPeriodFieldNumber">
            <summary>Field number for the "placement_period" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.PlacementPeriod">
            <summary>
            Assignment of Nodes to Devices is recomputed every placement_period
            steps until the system warms up (at which point the recomputation
            typically slows down automatically).
            </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.DeviceFiltersFieldNumber">
            <summary>Field number for the "device_filters" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.DeviceFilters">
            <summary>
            When any filters are present sessions will ignore all devices which do not
            match the filters. Each filter can be partially specified, e.g. "/job:ps"
            "/job:worker/replica:3", etc.
            </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.GpuOptionsFieldNumber">
            <summary>Field number for the "gpu_options" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.GpuOptions">
            <summary>
            Options that apply to all GPUs.
            </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.AllowSoftPlacementFieldNumber">
            <summary>Field number for the "allow_soft_placement" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.AllowSoftPlacement">
            <summary>
            Whether soft placement is allowed. If allow_soft_placement is true,
            an op will be placed on CPU if
              1. there's no GPU implementation for the OP
            or
              2. no GPU devices are known or registered
            or
              3. need to co-locate with reftype input(s) which are from CPU.
            </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.LogDevicePlacementFieldNumber">
            <summary>Field number for the "log_device_placement" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.LogDevicePlacement">
            <summary>
            Whether device placements should be logged.
            </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.GraphOptionsFieldNumber">
            <summary>Field number for the "graph_options" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.GraphOptions">
            <summary>
            Options that apply to all graphs.
            </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.OperationTimeoutInMsFieldNumber">
            <summary>Field number for the "operation_timeout_in_ms" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.OperationTimeoutInMs">
            <summary>
            Global timeout for all blocking operations in this session.  If non-zero,
            and not overridden on a per-operation basis, this value will be used as the
            deadline for all blocking operations.
            </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.RpcOptionsFieldNumber">
            <summary>Field number for the "rpc_options" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.RpcOptions">
            <summary>
            Options that apply when this session uses the distributed runtime.
            </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.ClusterDefFieldNumber">
            <summary>Field number for the "cluster_def" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.ClusterDef">
            <summary>
            Optional list of all workers to use in this session.
            </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.IsolateSessionStateFieldNumber">
            <summary>Field number for the "isolate_session_state" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.IsolateSessionState">
            <summary>
            If true, any resources such as Variables used in the session will not be
            shared with other sessions. However, when clusterspec propagation is
            enabled, this field is ignored and sessions are always isolated.
            </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.ShareClusterDevicesInSessionFieldNumber">
            <summary>Field number for the "share_cluster_devices_in_session" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.ShareClusterDevicesInSession">
            <summary>
            When true, WorkerSessions are created with device attributes from the
            full cluster.
            This is helpful when a worker wants to partition a graph
            (for example during a PartitionedCallOp).
            </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.ExperimentalFieldNumber">
            <summary>Field number for the "experimental" field.</summary>
        </member>
        <member name="T:Tensorflow.ConfigProto.Types">
            <summary>Container for nested types declared in the ConfigProto message type.</summary>
        </member>
        <member name="T:Tensorflow.ConfigProto.Types.Experimental">
            <summary>
            Everything inside Experimental is subject to change and is not subject
            to API stability guarantees in
            https://www.tensorflow.org/guide/version_compat.
            </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.Types.Experimental.CollectiveGroupLeaderFieldNumber">
            <summary>Field number for the "collective_group_leader" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.Types.Experimental.CollectiveGroupLeader">
            <summary>
            Task name for group resolution.
            </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.Types.Experimental.ExecutorTypeFieldNumber">
            <summary>Field number for the "executor_type" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.Types.Experimental.ExecutorType">
            <summary>
            Which executor to use, the default executor will be used
            if it is an empty string or "DEFAULT"
            </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.Types.Experimental.RecvBufMaxChunkFieldNumber">
            <summary>Field number for the "recv_buf_max_chunk" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.Types.Experimental.RecvBufMaxChunk">
            <summary>
            Guidance to formatting of large RecvBuf fields for transfer.
            Any positive value sets the max chunk size.  0 defaults to 4096.
            Any negative value indicates no max, i.e. one chunk only.
            </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.Types.Experimental.UseNumaAffinityFieldNumber">
            <summary>Field number for the "use_numa_affinity" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.Types.Experimental.UseNumaAffinity">
            <summary>
            If true, and supported by the platform, the runtime will attempt to
            use NUMA affinity where applicable.  One consequence will be the
            existence of as many CPU devices as there are available NUMA nodes.
            </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.Types.Experimental.CollectiveDeterministicSequentialExecutionFieldNumber">
            <summary>Field number for the "collective_deterministic_sequential_execution" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.Types.Experimental.CollectiveDeterministicSequentialExecution">
            <summary>
            If true, make collective op execution order sequential and deterministic
            for potentially concurrent collective instances.
            </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.Types.Experimental.CollectiveNcclFieldNumber">
            <summary>Field number for the "collective_nccl" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.Types.Experimental.CollectiveNccl">
            <summary>
            If true, use NCCL for CollectiveOps.  This feature is highly
            experimental.
            </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.Types.Experimental.ShareSessionStateInClusterspecPropagationFieldNumber">
            <summary>Field number for the "share_session_state_in_clusterspec_propagation" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.Types.Experimental.ShareSessionStateInClusterspecPropagation">
             <summary>
             In the following, session state means the value of a variable, elements
             in a hash table, or any other resource, accessible by worker sessions
             held by a TF server.
            
             When ClusterSpec propagation is enabled, the value of
             isolate_session_state is ignored when deciding whether to share session
             states in a TF server (for backwards compatibility reasons).
             - If share_session_state_in_clusterspec_propagation is true, the session
             states are shared.
             - If share_session_state_in_clusterspec_propagation is false, session
             states are isolated.
            
             When clusterspec propagation is not used, the value of
             share_session_state_in_clusterspec_propagation is ignored when deciding
             whether to share session states in a TF server.
             - If isolate_session_state is true, session states are isolated.
             - If isolate_session_state is false, session states are shared.
            
             TODO(b/129330037): Add a single API that consistently treats
             isolate_session_state and ClusterSpec propagation.
             </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.Types.Experimental.DisableThreadSpinningFieldNumber">
            <summary>Field number for the "disable_thread_spinning" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.Types.Experimental.DisableThreadSpinning">
            <summary>
            If using a direct session, disable spinning while waiting for work in
            the thread pool. This may result in higher latency for completing ops,
            but in the case where there is a lot of spinning may result in lower
            CPU usage.
            </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.Types.Experimental.ShareClusterDevicesInSessionFieldNumber">
            <summary>Field number for the "share_cluster_devices_in_session" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.Types.Experimental.ShareClusterDevicesInSession">
            <summary>
            This was promoted to a non-experimental API. Please use
            ConfigProto.share_cluster_devices_in_session instead.
            </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.Types.Experimental.SessionMetadataFieldNumber">
            <summary>Field number for the "session_metadata" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.Types.Experimental.SessionMetadata">
             <summary>
             Metadata about the session.
            
             If set, this can be used by the runtime and the Ops for debugging,
             monitoring, etc.
            
             NOTE: This is currently used and propagated only by the direct session.
             </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.Types.Experimental.OptimizeForStaticGraphFieldNumber">
            <summary>Field number for the "optimize_for_static_graph" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.Types.Experimental.OptimizeForStaticGraph">
             <summary>
             If true, the session may treat the graph as being static for optimization
             purposes.
            
             If this option is set to true when a session is created, the full
             GraphDef must be passed in a single call to Session::Create(), and
             Session::Extend() may not be supported.
             </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.Types.Experimental.EnableMlirBridgeFieldNumber">
            <summary>Field number for the "enable_mlir_bridge" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.Types.Experimental.EnableMlirBridge">
             <summary>
             Whether to enable the MLIR-based TF->XLA bridge.
            
             This is a replacement to the existing bridge, and not ready for
             production usage yet.
             If this option is set to true when a session is created, MLIR is used to
             perform the set of graph transformations to put the graph in a form that
             can be executed with delegation of some computations to an accelerator.
             This builds on the model of XLA where a subset of the graph is
             encapsulated and attached to a "compile" operation, whose result is fed
             to an "execute" operation. The kernel for these operations is responsible
             to lower the encapsulated graph to a particular device.
             </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.Types.Experimental.EnableMlirGraphOptimizationFieldNumber">
            <summary>Field number for the "enable_mlir_graph_optimization" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.Types.Experimental.EnableMlirGraphOptimization">
             <summary>
             Whether to enable the MLIR-based Graph optimizations.
            
             This will become a part of standard Tensorflow graph optimization
             pipeline, currently this is only used for gradual migration and testing
             new passes that are replacing existing optimizations in Grappler.
             </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.Types.Experimental.DisableOutputPartitionGraphsFieldNumber">
            <summary>Field number for the "disable_output_partition_graphs" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.Types.Experimental.DisableOutputPartitionGraphs">
             <summary>
             If true, the session will not store an additional copy of the graph for
             each subgraph.
            
             If this option is set to true when a session is created, the
             `RunOptions.output_partition_graphs` options must not be set.
             </summary>
        </member>
        <member name="F:Tensorflow.ConfigProto.Types.Experimental.XlaFusionAutotunerThreshFieldNumber">
            <summary>Field number for the "xla_fusion_autotuner_thresh" field.</summary>
        </member>
        <member name="P:Tensorflow.ConfigProto.Types.Experimental.XlaFusionAutotunerThresh">
             <summary>
             Minimum number of batches run through the XLA graph before XLA fusion
             autotuner is enabled. Default value of zero disables the autotuner.
            
             The XLA fusion autotuner can improve performance by executing a heuristic
             search on the compiler parameters.
             </summary>
        </member>
        <member name="T:Tensorflow.RunOptions">
            <summary>
            Options for a single Run() call.
            </summary>
        </member>
        <member name="F:Tensorflow.RunOptions.TraceLevelFieldNumber">
            <summary>Field number for the "trace_level" field.</summary>
        </member>
        <member name="F:Tensorflow.RunOptions.TimeoutInMsFieldNumber">
            <summary>Field number for the "timeout_in_ms" field.</summary>
        </member>
        <member name="P:Tensorflow.RunOptions.TimeoutInMs">
            <summary>
            Time to wait for operation to complete in milliseconds.
            </summary>
        </member>
        <member name="F:Tensorflow.RunOptions.InterOpThreadPoolFieldNumber">
            <summary>Field number for the "inter_op_thread_pool" field.</summary>
        </member>
        <member name="P:Tensorflow.RunOptions.InterOpThreadPool">
            <summary>
            The thread pool to use, if session_inter_op_thread_pool is configured.
            To use the caller thread set this to -1 - this uses the caller thread
            to execute Session::Run() and thus avoids a context switch. Using the
            caller thread to execute Session::Run() should be done ONLY for simple
            graphs, where the overhead of an additional context switch is
            comparable with the overhead of Session::Run().
            </summary>
        </member>
        <member name="F:Tensorflow.RunOptions.OutputPartitionGraphsFieldNumber">
            <summary>Field number for the "output_partition_graphs" field.</summary>
        </member>
        <member name="P:Tensorflow.RunOptions.OutputPartitionGraphs">
            <summary>
            Whether the partition graph(s) executed by the executor(s) should be
            outputted via RunMetadata.
            </summary>
        </member>
        <member name="F:Tensorflow.RunOptions.DebugOptionsFieldNumber">
            <summary>Field number for the "debug_options" field.</summary>
        </member>
        <member name="P:Tensorflow.RunOptions.DebugOptions">
            <summary>
            EXPERIMENTAL.  Options used to initialize DebuggerState, if enabled.
            </summary>
        </member>
        <member name="F:Tensorflow.RunOptions.ReportTensorAllocationsUponOomFieldNumber">
            <summary>Field number for the "report_tensor_allocations_upon_oom" field.</summary>
        </member>
        <member name="P:Tensorflow.RunOptions.ReportTensorAllocationsUponOom">
             <summary>
             When enabled, causes tensor allocation information to be included in
             the error message when the Run() call fails because the allocator ran
             out of memory (OOM).
            
             Enabling this option can slow down the Run() call.
             </summary>
        </member>
        <member name="F:Tensorflow.RunOptions.ExperimentalFieldNumber">
            <summary>Field number for the "experimental" field.</summary>
        </member>
        <member name="T:Tensorflow.RunOptions.Types">
            <summary>Container for nested types declared in the RunOptions message type.</summary>
        </member>
        <member name="T:Tensorflow.RunOptions.Types.TraceLevel">
            <summary>
            TODO(pbar) Turn this into a TraceOptions proto which allows
            tracing to be controlled in a more orthogonal manner?
            </summary>
        </member>
        <member name="T:Tensorflow.RunOptions.Types.Experimental">
            <summary>
            Everything inside Experimental is subject to change and is not subject
            to API stability guarantees in
            https://www.tensorflow.org/guide/version_compat.
            </summary>
        </member>
        <member name="F:Tensorflow.RunOptions.Types.Experimental.CollectiveGraphKeyFieldNumber">
            <summary>Field number for the "collective_graph_key" field.</summary>
        </member>
        <member name="P:Tensorflow.RunOptions.Types.Experimental.CollectiveGraphKey">
            <summary>
            If non-zero, declares that this graph is going to use collective
            ops and must synchronize step_ids with any other graph with this
            same group_key value (in a distributed computation where tasks
            run disjoint graphs).
            </summary>
        </member>
        <member name="F:Tensorflow.RunOptions.Types.Experimental.UseRunHandlerPoolFieldNumber">
            <summary>Field number for the "use_run_handler_pool" field.</summary>
        </member>
        <member name="P:Tensorflow.RunOptions.Types.Experimental.UseRunHandlerPool">
            <summary>
            If true, then operations (using the inter-op pool) across all
            session::run() calls will be centrally scheduled, optimizing for (median
            and tail) latency.
            Consider using this option for CPU-bound workloads like inference.
            </summary>
        </member>
        <member name="F:Tensorflow.RunOptions.Types.Experimental.RunHandlerPoolOptionsFieldNumber">
            <summary>Field number for the "run_handler_pool_options" field.</summary>
        </member>
        <member name="T:Tensorflow.RunOptions.Types.Experimental.Types">
            <summary>Container for nested types declared in the Experimental message type.</summary>
        </member>
        <member name="T:Tensorflow.RunOptions.Types.Experimental.Types.RunHandlerPoolOptions">
            <summary>
            Options for run handler thread pool.
            </summary>
        </member>
        <member name="F:Tensorflow.RunOptions.Types.Experimental.Types.RunHandlerPoolOptions.PriorityFieldNumber">
            <summary>Field number for the "priority" field.</summary>
        </member>
        <member name="P:Tensorflow.RunOptions.Types.Experimental.Types.RunHandlerPoolOptions.Priority">
            <summary>
            Priority of the request. The run handler thread pool will schedule ops
            based on the priority number. The larger number means higher priority.
            </summary>
        </member>
        <member name="T:Tensorflow.RunMetadata">
            <summary>
            Metadata output (i.e., non-Tensor) for a single Run() call.
            </summary>
        </member>
        <member name="F:Tensorflow.RunMetadata.StepStatsFieldNumber">
            <summary>Field number for the "step_stats" field.</summary>
        </member>
        <member name="P:Tensorflow.RunMetadata.StepStats">
            <summary>
            Statistics traced for this step. Populated if tracing is turned on via the
            "RunOptions" proto.
            EXPERIMENTAL: The format and set of events may change in future versions.
            </summary>
        </member>
        <member name="F:Tensorflow.RunMetadata.CostGraphFieldNumber">
            <summary>Field number for the "cost_graph" field.</summary>
        </member>
        <member name="P:Tensorflow.RunMetadata.CostGraph">
            <summary>
            The cost graph for the computation defined by the run call.
            </summary>
        </member>
        <member name="F:Tensorflow.RunMetadata.PartitionGraphsFieldNumber">
            <summary>Field number for the "partition_graphs" field.</summary>
        </member>
        <member name="P:Tensorflow.RunMetadata.PartitionGraphs">
            <summary>
            Graphs of the partitions executed by executors.
            </summary>
        </member>
        <member name="F:Tensorflow.RunMetadata.FunctionGraphsFieldNumber">
            <summary>Field number for the "function_graphs" field.</summary>
        </member>
        <member name="P:Tensorflow.RunMetadata.FunctionGraphs">
            <summary>
            This is only populated for graphs that are run as functions in TensorFlow
            V2. There will be an entry below for each function that is traced.
            The main use cases of the post_optimization_graph and the partition_graphs
            is to give the caller insight into the graphs that were actually run by the
            runtime. Additional information (such as those in step_stats) will match
            these graphs.
            We also include the pre_optimization_graph since it is usually easier to
            read, and is helpful in situations where the caller wants to get a high
            level idea of what the built graph looks like (since the various graph
            optimization passes might change the structure of the graph significantly).
            </summary>
        </member>
        <member name="T:Tensorflow.RunMetadata.Types">
            <summary>Container for nested types declared in the RunMetadata message type.</summary>
        </member>
        <member name="F:Tensorflow.RunMetadata.Types.FunctionGraphs.PartitionGraphsFieldNumber">
            <summary>Field number for the "partition_graphs" field.</summary>
        </member>
        <member name="P:Tensorflow.RunMetadata.Types.FunctionGraphs.PartitionGraphs">
            <summary>
            TODO(nareshmodi): Include some sort of function/cache-key identifier?
            </summary>
        </member>
        <member name="F:Tensorflow.RunMetadata.Types.FunctionGraphs.PreOptimizationGraphFieldNumber">
            <summary>Field number for the "pre_optimization_graph" field.</summary>
        </member>
        <member name="F:Tensorflow.RunMetadata.Types.FunctionGraphs.PostOptimizationGraphFieldNumber">
            <summary>Field number for the "post_optimization_graph" field.</summary>
        </member>
        <member name="T:Tensorflow.TensorConnection">
            <summary>
            Defines a connection between two tensors in a `GraphDef`.
            </summary>
        </member>
        <member name="F:Tensorflow.TensorConnection.FromTensorFieldNumber">
            <summary>Field number for the "from_tensor" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorConnection.FromTensor">
            <summary>
            A tensor name. The value of this tensor will be substituted for
            the tensor named in `to_tensor`.
            </summary>
        </member>
        <member name="F:Tensorflow.TensorConnection.ToTensorFieldNumber">
            <summary>Field number for the "to_tensor" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorConnection.ToTensor">
            <summary>
            A tensor name. The value of this tensor will be bound to the
            value of the tensor named in `from_tensor`.
            </summary>
        </member>
        <member name="T:Tensorflow.CallableOptions">
             <summary>
             Defines a subgraph in another `GraphDef` as a set of feed points and nodes
             to be fetched or executed.
            
             Compare with the arguments to `Session::Run()`.
             </summary>
        </member>
        <member name="F:Tensorflow.CallableOptions.FeedFieldNumber">
            <summary>Field number for the "feed" field.</summary>
        </member>
        <member name="P:Tensorflow.CallableOptions.Feed">
            <summary>
            Tensors to be fed in the callable. Each feed is the name of a tensor.
            </summary>
        </member>
        <member name="F:Tensorflow.CallableOptions.FetchFieldNumber">
            <summary>Field number for the "fetch" field.</summary>
        </member>
        <member name="P:Tensorflow.CallableOptions.Fetch">
            <summary>
            Fetches. A list of tensor names. The caller of the callable expects a
            tensor to be returned for each fetch[i] (see RunStepResponse.tensor). The
            order of specified fetches does not change the execution order.
            </summary>
        </member>
        <member name="F:Tensorflow.CallableOptions.TargetFieldNumber">
            <summary>Field number for the "target" field.</summary>
        </member>
        <member name="P:Tensorflow.CallableOptions.Target">
            <summary>
            Target Nodes. A list of node names. The named nodes will be run by the
            callable but their outputs will not be returned.
            </summary>
        </member>
        <member name="F:Tensorflow.CallableOptions.RunOptionsFieldNumber">
            <summary>Field number for the "run_options" field.</summary>
        </member>
        <member name="P:Tensorflow.CallableOptions.RunOptions">
            <summary>
            Options that will be applied to each run.
            </summary>
        </member>
        <member name="F:Tensorflow.CallableOptions.TensorConnectionFieldNumber">
            <summary>Field number for the "tensor_connection" field.</summary>
        </member>
        <member name="P:Tensorflow.CallableOptions.TensorConnection">
            <summary>
            Tensors to be connected in the callable. Each TensorConnection denotes
            a pair of tensors in the graph, between which an edge will be created
            in the callable.
            </summary>
        </member>
        <member name="F:Tensorflow.CallableOptions.FeedDevicesFieldNumber">
            <summary>Field number for the "feed_devices" field.</summary>
        </member>
        <member name="P:Tensorflow.CallableOptions.FeedDevices">
             <summary>
             The Tensor objects fed in the callable and fetched from the callable
             are expected to be backed by host (CPU) memory by default.
            
             The options below allow changing that - feeding tensors backed by
             device memory, or returning tensors that are backed by device memory.
            
             The maps below map the name of a feed/fetch tensor (which appears in
             'feed' or 'fetch' fields above), to the fully qualified name of the device
             owning the memory backing the contents of the tensor.
            
             For example, creating a callable with the following options:
            
             CallableOptions {
               feed: "a:0"
               feed: "b:0"
            
               fetch: "x:0"
               fetch: "y:0"
            
               feed_devices: {
                 "a:0": "/job:localhost/replica:0/task:0/device:GPU:0"
               }
            
               fetch_devices: {
                 "y:0": "/job:localhost/replica:0/task:0/device:GPU:0"
              }
             }
            
             means that the Callable expects:
             - The first argument ("a:0") is a Tensor backed by GPU memory.
             - The second argument ("b:0") is a Tensor backed by host memory.
             and of its return values:
             - The first output ("x:0") will be backed by host memory.
             - The second output ("y:0") will be backed by GPU memory.
            
             FEEDS:
             It is the responsibility of the caller to ensure that the memory of the fed
             tensors will be correctly initialized and synchronized before it is
             accessed by operations executed during the call to Session::RunCallable().
            
             This is typically ensured by using the TensorFlow memory allocators
             (Device::GetAllocator()) to create the Tensor to be fed.
            
             Alternatively, for CUDA-enabled GPU devices, this typically means that the
             operation that produced the contents of the tensor has completed, i.e., the
             CUDA stream has been synchronized (e.g., via cuCtxSynchronize() or
             cuStreamSynchronize()).
             </summary>
        </member>
        <member name="F:Tensorflow.CallableOptions.FetchDevicesFieldNumber">
            <summary>Field number for the "fetch_devices" field.</summary>
        </member>
        <member name="F:Tensorflow.CallableOptions.FetchSkipSyncFieldNumber">
            <summary>Field number for the "fetch_skip_sync" field.</summary>
        </member>
        <member name="P:Tensorflow.CallableOptions.FetchSkipSync">
             <summary>
             By default, RunCallable() will synchronize the GPU stream before returning
             fetched tensors on a GPU device, to ensure that the values in those tensors
             have been produced. This simplifies interacting with the tensors, but
             potentially incurs a performance hit.
            
             If this options is set to true, the caller is responsible for ensuring
             that the values in the fetched tensors have been produced before they are
             used. The caller can do this by invoking `Device::Sync()` on the underlying
             device(s), or by feeding the tensors back to the same Session using
             `feed_devices` with the same corresponding device name.
             </summary>
        </member>
        <member name="T:Tensorflow.ControlFlowReflection">
            <summary>Holder for reflection information generated from tensorflow/core/protobuf/control_flow.proto</summary>
        </member>
        <member name="P:Tensorflow.ControlFlowReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/protobuf/control_flow.proto</summary>
        </member>
        <member name="T:Tensorflow.ValuesDef">
            <summary>
            Protocol buffer representing the values in ControlFlowContext.
            </summary>
        </member>
        <member name="F:Tensorflow.ValuesDef.ValuesFieldNumber">
            <summary>Field number for the "values" field.</summary>
        </member>
        <member name="P:Tensorflow.ValuesDef.Values">
            <summary>
            Value names that have been seen in this context.
            </summary>
        </member>
        <member name="F:Tensorflow.ValuesDef.ExternalValuesFieldNumber">
            <summary>Field number for the "external_values" field.</summary>
        </member>
        <member name="P:Tensorflow.ValuesDef.ExternalValues">
            <summary>
            Value names referenced by but external to this context.
            </summary>
        </member>
        <member name="T:Tensorflow.ControlFlowContextDef">
            <summary>
            Container for any kind of control flow context. Any other control flow
            contexts that are added below should also be added here.
            </summary>
        </member>
        <member name="F:Tensorflow.ControlFlowContextDef.CondCtxtFieldNumber">
            <summary>Field number for the "cond_ctxt" field.</summary>
        </member>
        <member name="F:Tensorflow.ControlFlowContextDef.WhileCtxtFieldNumber">
            <summary>Field number for the "while_ctxt" field.</summary>
        </member>
        <member name="T:Tensorflow.ControlFlowContextDef.CtxtOneofCase">
            <summary>Enum of possible cases for the "ctxt" oneof.</summary>
        </member>
        <member name="T:Tensorflow.CondContextDef">
            <summary>
            Protocol buffer representing a CondContext object.
            </summary>
        </member>
        <member name="F:Tensorflow.CondContextDef.ContextNameFieldNumber">
            <summary>Field number for the "context_name" field.</summary>
        </member>
        <member name="P:Tensorflow.CondContextDef.ContextName">
            <summary>
            Name of the context.
            </summary>
        </member>
        <member name="F:Tensorflow.CondContextDef.PredNameFieldNumber">
            <summary>Field number for the "pred_name" field.</summary>
        </member>
        <member name="P:Tensorflow.CondContextDef.PredName">
            <summary>
            Name of the pred tensor.
            </summary>
        </member>
        <member name="F:Tensorflow.CondContextDef.PivotNameFieldNumber">
            <summary>Field number for the "pivot_name" field.</summary>
        </member>
        <member name="P:Tensorflow.CondContextDef.PivotName">
            <summary>
            Name of the pivot tensor.
            </summary>
        </member>
        <member name="F:Tensorflow.CondContextDef.BranchFieldNumber">
            <summary>Field number for the "branch" field.</summary>
        </member>
        <member name="P:Tensorflow.CondContextDef.Branch">
            <summary>
            Branch prediction. 0 or 1.
            </summary>
        </member>
        <member name="F:Tensorflow.CondContextDef.ValuesDefFieldNumber">
            <summary>Field number for the "values_def" field.</summary>
        </member>
        <member name="P:Tensorflow.CondContextDef.ValuesDef">
            <summary>
            Values and external values in control flow context.
            </summary>
        </member>
        <member name="F:Tensorflow.CondContextDef.NestedContextsFieldNumber">
            <summary>Field number for the "nested_contexts" field.</summary>
        </member>
        <member name="P:Tensorflow.CondContextDef.NestedContexts">
            <summary>
            Contexts contained inside this context (e.g. nested conds).
            </summary>
        </member>
        <member name="T:Tensorflow.WhileContextDef">
            <summary>
            Protocol buffer representing a WhileContext object.
            </summary>
        </member>
        <member name="F:Tensorflow.WhileContextDef.ContextNameFieldNumber">
            <summary>Field number for the "context_name" field.</summary>
        </member>
        <member name="P:Tensorflow.WhileContextDef.ContextName">
            <summary>
            Name of the context.
            </summary>
        </member>
        <member name="F:Tensorflow.WhileContextDef.ParallelIterationsFieldNumber">
            <summary>Field number for the "parallel_iterations" field.</summary>
        </member>
        <member name="P:Tensorflow.WhileContextDef.ParallelIterations">
            <summary>
            The number of iterations allowed to run in parallel.
            </summary>
        </member>
        <member name="F:Tensorflow.WhileContextDef.BackPropFieldNumber">
            <summary>Field number for the "back_prop" field.</summary>
        </member>
        <member name="P:Tensorflow.WhileContextDef.BackProp">
            <summary>
            Whether backprop is enabled for this while loop.
            </summary>
        </member>
        <member name="F:Tensorflow.WhileContextDef.SwapMemoryFieldNumber">
            <summary>Field number for the "swap_memory" field.</summary>
        </member>
        <member name="P:Tensorflow.WhileContextDef.SwapMemory">
            <summary>
            Whether GPU-CPU memory swap is enabled for this loop.
            </summary>
        </member>
        <member name="F:Tensorflow.WhileContextDef.PivotNameFieldNumber">
            <summary>Field number for the "pivot_name" field.</summary>
        </member>
        <member name="P:Tensorflow.WhileContextDef.PivotName">
            <summary>
            Name of the pivot tensor.
            </summary>
        </member>
        <member name="F:Tensorflow.WhileContextDef.PivotForPredNameFieldNumber">
            <summary>Field number for the "pivot_for_pred_name" field.</summary>
        </member>
        <member name="P:Tensorflow.WhileContextDef.PivotForPredName">
            <summary>
            Name of the pivot_for_pred tensor.
            </summary>
        </member>
        <member name="F:Tensorflow.WhileContextDef.PivotForBodyNameFieldNumber">
            <summary>Field number for the "pivot_for_body_name" field.</summary>
        </member>
        <member name="P:Tensorflow.WhileContextDef.PivotForBodyName">
            <summary>
            Name of the pivot_for_body tensor.
            </summary>
        </member>
        <member name="F:Tensorflow.WhileContextDef.LoopExitNamesFieldNumber">
            <summary>Field number for the "loop_exit_names" field.</summary>
        </member>
        <member name="P:Tensorflow.WhileContextDef.LoopExitNames">
            <summary>
            List of names for exit tensors.
            </summary>
        </member>
        <member name="F:Tensorflow.WhileContextDef.LoopEnterNamesFieldNumber">
            <summary>Field number for the "loop_enter_names" field.</summary>
        </member>
        <member name="P:Tensorflow.WhileContextDef.LoopEnterNames">
            <summary>
            List of names for enter tensors.
            </summary>
        </member>
        <member name="F:Tensorflow.WhileContextDef.ValuesDefFieldNumber">
            <summary>Field number for the "values_def" field.</summary>
        </member>
        <member name="P:Tensorflow.WhileContextDef.ValuesDef">
            <summary>
            Values and external values in control flow context.
            </summary>
        </member>
        <member name="F:Tensorflow.WhileContextDef.MaximumIterationsNameFieldNumber">
            <summary>Field number for the "maximum_iterations_name" field.</summary>
        </member>
        <member name="P:Tensorflow.WhileContextDef.MaximumIterationsName">
            <summary>
            Optional name of the maximum_iterations tensor.
            </summary>
        </member>
        <member name="F:Tensorflow.WhileContextDef.NestedContextsFieldNumber">
            <summary>Field number for the "nested_contexts" field.</summary>
        </member>
        <member name="P:Tensorflow.WhileContextDef.NestedContexts">
            <summary>
            Contexts contained inside this context (e.g. nested whiles).
            </summary>
        </member>
        <member name="T:Tensorflow.CostGraphReflection">
            <summary>Holder for reflection information generated from tensorflow/core/framework/cost_graph.proto</summary>
        </member>
        <member name="P:Tensorflow.CostGraphReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/framework/cost_graph.proto</summary>
        </member>
        <member name="F:Tensorflow.CostGraphDef.NodeFieldNumber">
            <summary>Field number for the "node" field.</summary>
        </member>
        <member name="F:Tensorflow.CostGraphDef.CostFieldNumber">
            <summary>Field number for the "cost" field.</summary>
        </member>
        <member name="T:Tensorflow.CostGraphDef.Types">
            <summary>Container for nested types declared in the CostGraphDef message type.</summary>
        </member>
        <member name="F:Tensorflow.CostGraphDef.Types.Node.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Tensorflow.CostGraphDef.Types.Node.Name">
            <summary>
            The name of the node. Names are globally unique.
            </summary>
        </member>
        <member name="F:Tensorflow.CostGraphDef.Types.Node.DeviceFieldNumber">
            <summary>Field number for the "device" field.</summary>
        </member>
        <member name="P:Tensorflow.CostGraphDef.Types.Node.Device">
            <summary>
            The device of the node. Can be empty if the node is mapped to the
            default partition or partitioning hasn't been run yet.
            </summary>
        </member>
        <member name="F:Tensorflow.CostGraphDef.Types.Node.IdFieldNumber">
            <summary>Field number for the "id" field.</summary>
        </member>
        <member name="P:Tensorflow.CostGraphDef.Types.Node.Id">
            <summary>
            The id of the node. Node ids are only unique inside a partition.
            </summary>
        </member>
        <member name="F:Tensorflow.CostGraphDef.Types.Node.InputInfoFieldNumber">
            <summary>Field number for the "input_info" field.</summary>
        </member>
        <member name="F:Tensorflow.CostGraphDef.Types.Node.OutputInfoFieldNumber">
            <summary>Field number for the "output_info" field.</summary>
        </member>
        <member name="F:Tensorflow.CostGraphDef.Types.Node.TemporaryMemorySizeFieldNumber">
            <summary>Field number for the "temporary_memory_size" field.</summary>
        </member>
        <member name="P:Tensorflow.CostGraphDef.Types.Node.TemporaryMemorySize">
            <summary>
            Temporary memory used by this node.
            </summary>
        </member>
        <member name="F:Tensorflow.CostGraphDef.Types.Node.PersistentMemorySizeFieldNumber">
            <summary>Field number for the "persistent_memory_size" field.</summary>
        </member>
        <member name="P:Tensorflow.CostGraphDef.Types.Node.PersistentMemorySize">
            <summary>
            Persistent memory used by this node.
            </summary>
        </member>
        <member name="F:Tensorflow.CostGraphDef.Types.Node.HostTempMemorySizeFieldNumber">
            <summary>Field number for the "host_temp_memory_size" field.</summary>
        </member>
        <member name="F:Tensorflow.CostGraphDef.Types.Node.DeviceTempMemorySizeFieldNumber">
            <summary>Field number for the "device_temp_memory_size" field.</summary>
        </member>
        <member name="F:Tensorflow.CostGraphDef.Types.Node.DevicePersistentMemorySizeFieldNumber">
            <summary>Field number for the "device_persistent_memory_size" field.</summary>
        </member>
        <member name="F:Tensorflow.CostGraphDef.Types.Node.ComputeCostFieldNumber">
            <summary>Field number for the "compute_cost" field.</summary>
        </member>
        <member name="P:Tensorflow.CostGraphDef.Types.Node.ComputeCost">
            <summary>
            Estimate of the computational cost of this node, in microseconds.
            </summary>
        </member>
        <member name="F:Tensorflow.CostGraphDef.Types.Node.ComputeTimeFieldNumber">
            <summary>Field number for the "compute_time" field.</summary>
        </member>
        <member name="P:Tensorflow.CostGraphDef.Types.Node.ComputeTime">
            <summary>
            Analytical estimate of the computational cost of this node, in
            microseconds.
            </summary>
        </member>
        <member name="F:Tensorflow.CostGraphDef.Types.Node.MemoryTimeFieldNumber">
            <summary>Field number for the "memory_time" field.</summary>
        </member>
        <member name="P:Tensorflow.CostGraphDef.Types.Node.MemoryTime">
            <summary>
            Analytical estimate of the memory access cost of this node, in
            microseconds.
            </summary>
        </member>
        <member name="F:Tensorflow.CostGraphDef.Types.Node.IsFinalFieldNumber">
            <summary>Field number for the "is_final" field.</summary>
        </member>
        <member name="P:Tensorflow.CostGraphDef.Types.Node.IsFinal">
            <summary>
            If true, the output is permanent: it can't be discarded, because this
            node is part of the "final output". Nodes may depend on final nodes.
            </summary>
        </member>
        <member name="F:Tensorflow.CostGraphDef.Types.Node.ControlInputFieldNumber">
            <summary>Field number for the "control_input" field.</summary>
        </member>
        <member name="P:Tensorflow.CostGraphDef.Types.Node.ControlInput">
            <summary>
            Ids of the control inputs for this node.
            </summary>
        </member>
        <member name="F:Tensorflow.CostGraphDef.Types.Node.InaccurateFieldNumber">
            <summary>Field number for the "inaccurate" field.</summary>
        </member>
        <member name="P:Tensorflow.CostGraphDef.Types.Node.Inaccurate">
            <summary>
            Are the costs inaccurate?
            </summary>
        </member>
        <member name="T:Tensorflow.CostGraphDef.Types.Node.Types">
            <summary>Container for nested types declared in the Node message type.</summary>
        </member>
        <member name="T:Tensorflow.CostGraphDef.Types.Node.Types.InputInfo">
            <summary>
            Inputs of this node. They must be executed before this node can be
            executed. An input is a particular output of another node, specified
            by the node id and the output index.
            </summary>
        </member>
        <member name="F:Tensorflow.CostGraphDef.Types.Node.Types.InputInfo.PrecedingNodeFieldNumber">
            <summary>Field number for the "preceding_node" field.</summary>
        </member>
        <member name="F:Tensorflow.CostGraphDef.Types.Node.Types.InputInfo.PrecedingPortFieldNumber">
            <summary>Field number for the "preceding_port" field.</summary>
        </member>
        <member name="T:Tensorflow.CostGraphDef.Types.Node.Types.OutputInfo">
            <summary>
            Outputs of this node.
            </summary>
        </member>
        <member name="F:Tensorflow.CostGraphDef.Types.Node.Types.OutputInfo.SizeFieldNumber">
            <summary>Field number for the "size" field.</summary>
        </member>
        <member name="F:Tensorflow.CostGraphDef.Types.Node.Types.OutputInfo.AliasInputPortFieldNumber">
            <summary>Field number for the "alias_input_port" field.</summary>
        </member>
        <member name="P:Tensorflow.CostGraphDef.Types.Node.Types.OutputInfo.AliasInputPort">
            <summary>
            If >= 0, the output is an alias of an input. Note that an alias input
            may itself be an alias. The algorithm will therefore need to follow
            those pointers.
            </summary>
        </member>
        <member name="F:Tensorflow.CostGraphDef.Types.Node.Types.OutputInfo.ShapeFieldNumber">
            <summary>Field number for the "shape" field.</summary>
        </member>
        <member name="F:Tensorflow.CostGraphDef.Types.Node.Types.OutputInfo.DtypeFieldNumber">
            <summary>Field number for the "dtype" field.</summary>
        </member>
        <member name="T:Tensorflow.CostGraphDef.Types.AggregatedCost">
            <summary>
            Total cost of this graph, typically used for balancing decisions.
            </summary>
        </member>
        <member name="F:Tensorflow.CostGraphDef.Types.AggregatedCost.CostFieldNumber">
            <summary>Field number for the "cost" field.</summary>
        </member>
        <member name="P:Tensorflow.CostGraphDef.Types.AggregatedCost.Cost">
            <summary>
            Aggregated cost value.
            </summary>
        </member>
        <member name="F:Tensorflow.CostGraphDef.Types.AggregatedCost.DimensionFieldNumber">
            <summary>Field number for the "dimension" field.</summary>
        </member>
        <member name="P:Tensorflow.CostGraphDef.Types.AggregatedCost.Dimension">
            <summary>
            Aggregated cost dimension (e.g. 'memory', 'compute', 'network').
            </summary>
        </member>
        <member name="T:Tensorflow.CppShapeInferenceReflection">
            <summary>Holder for reflection information generated from tensorflow/python/framework/cpp_shape_inference.proto</summary>
        </member>
        <member name="P:Tensorflow.CppShapeInferenceReflection.Descriptor">
            <summary>File descriptor for tensorflow/python/framework/cpp_shape_inference.proto</summary>
        </member>
        <member name="F:Tensorflow.CppShapeInferenceResult.ShapeFieldNumber">
            <summary>Field number for the "shape" field.</summary>
        </member>
        <member name="F:Tensorflow.CppShapeInferenceResult.HandleDataFieldNumber">
            <summary>Field number for the "handle_data" field.</summary>
        </member>
        <member name="T:Tensorflow.CppShapeInferenceResult.Types">
            <summary>Container for nested types declared in the CppShapeInferenceResult message type.</summary>
        </member>
        <member name="F:Tensorflow.CppShapeInferenceResult.Types.HandleShapeAndType.ShapeFieldNumber">
            <summary>Field number for the "shape" field.</summary>
        </member>
        <member name="F:Tensorflow.CppShapeInferenceResult.Types.HandleShapeAndType.DtypeFieldNumber">
            <summary>Field number for the "dtype" field.</summary>
        </member>
        <member name="F:Tensorflow.CppShapeInferenceResult.Types.HandleData.IsSetFieldNumber">
            <summary>Field number for the "is_set" field.</summary>
        </member>
        <member name="F:Tensorflow.CppShapeInferenceResult.Types.HandleData.ShapeAndTypeFieldNumber">
            <summary>Field number for the "shape_and_type" field.</summary>
        </member>
        <member name="P:Tensorflow.CppShapeInferenceResult.Types.HandleData.ShapeAndType">
            <summary>
            Only valid if &lt;is_set>.
            </summary>
        </member>
        <member name="F:Tensorflow.CppShapeInferenceInputsNeeded.InputTensorsNeededFieldNumber">
            <summary>Field number for the "input_tensors_needed" field.</summary>
        </member>
        <member name="F:Tensorflow.CppShapeInferenceInputsNeeded.InputTensorsAsShapesNeededFieldNumber">
            <summary>Field number for the "input_tensors_as_shapes_needed" field.</summary>
        </member>
        <member name="T:Tensorflow.DebugReflection">
            <summary>Holder for reflection information generated from tensorflow/core/protobuf/debug.proto</summary>
        </member>
        <member name="P:Tensorflow.DebugReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/protobuf/debug.proto</summary>
        </member>
        <member name="T:Tensorflow.DebugTensorWatch">
            <summary>
            Option for watching a node in TensorFlow Debugger (tfdbg).
            </summary>
        </member>
        <member name="F:Tensorflow.DebugTensorWatch.NodeNameFieldNumber">
            <summary>Field number for the "node_name" field.</summary>
        </member>
        <member name="P:Tensorflow.DebugTensorWatch.NodeName">
            <summary>
            Name of the node to watch.
            Use "*" for wildcard. But note: currently, regex is not supported in
            general.
            </summary>
        </member>
        <member name="F:Tensorflow.DebugTensorWatch.OutputSlotFieldNumber">
            <summary>Field number for the "output_slot" field.</summary>
        </member>
        <member name="P:Tensorflow.DebugTensorWatch.OutputSlot">
            <summary>
            Output slot to watch.
            The semantics of output_slot == -1 is that all outputs of the node
            will be watched (i.e., a wildcard).
            Other negative values of output_slot are invalid and will lead to
            errors currently.
            </summary>
        </member>
        <member name="F:Tensorflow.DebugTensorWatch.DebugOpsFieldNumber">
            <summary>Field number for the "debug_ops" field.</summary>
        </member>
        <member name="P:Tensorflow.DebugTensorWatch.DebugOps">
            <summary>
            Name(s) of the debugging op(s).
            One or more than one probes on a tensor.
            e.g., {"DebugIdentity", "DebugNanCount"}
            </summary>
        </member>
        <member name="F:Tensorflow.DebugTensorWatch.DebugUrlsFieldNumber">
            <summary>Field number for the "debug_urls" field.</summary>
        </member>
        <member name="P:Tensorflow.DebugTensorWatch.DebugUrls">
             <summary>
             URL(s) for debug targets(s).
            
             Supported URL formats are:
               - file:///foo/tfdbg_dump: Writes out Event content to file
                 /foo/tfdbg_dump.  Assumes all directories can be created if they don't
                 already exist.
               - grpc://localhost:11011: Sends an RPC request to an EventListener
                 service running at localhost:11011 with the event.
               - memcbk:///event_key: Routes tensors to clients using the
                 callback registered with the DebugCallbackRegistry for event_key.
            
             Each debug op listed in debug_ops will publish its output tensor (debug
             signal) to all URLs in debug_urls.
            
             N.B. Session::Run() supports concurrent invocations of the same inputs
             (feed keys), outputs and target nodes. If such concurrent invocations
             are to be debugged, the callers of Session::Run() must use distinct
             debug_urls to make sure that the streamed or dumped events do not overlap
             among the invocations.
             TODO(cais): More visible documentation of this in g3docs.
             </summary>
        </member>
        <member name="F:Tensorflow.DebugTensorWatch.TolerateDebugOpCreationFailuresFieldNumber">
            <summary>Field number for the "tolerate_debug_op_creation_failures" field.</summary>
        </member>
        <member name="P:Tensorflow.DebugTensorWatch.TolerateDebugOpCreationFailures">
            <summary>
            Do not error out if debug op creation fails (e.g., due to dtype
            incompatibility). Instead, just log the failure.
            </summary>
        </member>
        <member name="T:Tensorflow.DebugOptions">
            <summary>
            Options for initializing DebuggerState in TensorFlow Debugger (tfdbg).
            </summary>
        </member>
        <member name="F:Tensorflow.DebugOptions.DebugTensorWatchOptsFieldNumber">
            <summary>Field number for the "debug_tensor_watch_opts" field.</summary>
        </member>
        <member name="P:Tensorflow.DebugOptions.DebugTensorWatchOpts">
            <summary>
            Debugging options
            </summary>
        </member>
        <member name="F:Tensorflow.DebugOptions.GlobalStepFieldNumber">
            <summary>Field number for the "global_step" field.</summary>
        </member>
        <member name="P:Tensorflow.DebugOptions.GlobalStep">
            <summary>
            Caller-specified global step count.
            Note that this is distinct from the session run count and the executor
            step count.
            </summary>
        </member>
        <member name="F:Tensorflow.DebugOptions.ResetDiskByteUsageFieldNumber">
            <summary>Field number for the "reset_disk_byte_usage" field.</summary>
        </member>
        <member name="P:Tensorflow.DebugOptions.ResetDiskByteUsage">
            <summary>
            Whether the total disk usage of tfdbg is to be reset to zero
            in this Session.run call. This is used by wrappers and hooks
            such as the local CLI ones to indicate that the dumped tensors
            are cleaned up from the disk after each Session.run.
            </summary>
        </member>
        <member name="F:Tensorflow.DebuggedSourceFile.HostFieldNumber">
            <summary>Field number for the "host" field.</summary>
        </member>
        <member name="P:Tensorflow.DebuggedSourceFile.Host">
            <summary>
            The host name on which a source code file is located.
            </summary>
        </member>
        <member name="F:Tensorflow.DebuggedSourceFile.FilePathFieldNumber">
            <summary>Field number for the "file_path" field.</summary>
        </member>
        <member name="P:Tensorflow.DebuggedSourceFile.FilePath">
            <summary>
            Path to the source code file.
            </summary>
        </member>
        <member name="F:Tensorflow.DebuggedSourceFile.LastModifiedFieldNumber">
            <summary>Field number for the "last_modified" field.</summary>
        </member>
        <member name="P:Tensorflow.DebuggedSourceFile.LastModified">
            <summary>
            The timestamp at which the source code file is last modified.
            </summary>
        </member>
        <member name="F:Tensorflow.DebuggedSourceFile.BytesFieldNumber">
            <summary>Field number for the "bytes" field.</summary>
        </member>
        <member name="P:Tensorflow.DebuggedSourceFile.Bytes">
            <summary>
            Byte size of the file.
            </summary>
        </member>
        <member name="F:Tensorflow.DebuggedSourceFile.LinesFieldNumber">
            <summary>Field number for the "lines" field.</summary>
        </member>
        <member name="P:Tensorflow.DebuggedSourceFile.Lines">
            <summary>
            Line-by-line content of the source code file.
            </summary>
        </member>
        <member name="F:Tensorflow.DebuggedSourceFiles.SourceFilesFieldNumber">
            <summary>Field number for the "source_files" field.</summary>
        </member>
        <member name="P:Tensorflow.DebuggedSourceFiles.SourceFiles">
            <summary>
            A collection of source code files.
            </summary>
        </member>
        <member name="T:Tensorflow.DeviceAttributesReflection">
            <summary>Holder for reflection information generated from tensorflow/core/framework/device_attributes.proto</summary>
        </member>
        <member name="P:Tensorflow.DeviceAttributesReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/framework/device_attributes.proto</summary>
        </member>
        <member name="F:Tensorflow.InterconnectLink.DeviceIdFieldNumber">
            <summary>Field number for the "device_id" field.</summary>
        </member>
        <member name="F:Tensorflow.InterconnectLink.TypeFieldNumber">
            <summary>Field number for the "type" field.</summary>
        </member>
        <member name="F:Tensorflow.InterconnectLink.StrengthFieldNumber">
            <summary>Field number for the "strength" field.</summary>
        </member>
        <member name="F:Tensorflow.LocalLinks.LinkFieldNumber">
            <summary>Field number for the "link" field.</summary>
        </member>
        <member name="F:Tensorflow.DeviceLocality.BusIdFieldNumber">
            <summary>Field number for the "bus_id" field.</summary>
        </member>
        <member name="P:Tensorflow.DeviceLocality.BusId">
            <summary>
            Optional bus locality of device.  Default value of 0 means
            no specific locality.  Specific localities are indexed from 1.
            </summary>
        </member>
        <member name="F:Tensorflow.DeviceLocality.NumaNodeFieldNumber">
            <summary>Field number for the "numa_node" field.</summary>
        </member>
        <member name="P:Tensorflow.DeviceLocality.NumaNode">
            <summary>
            Optional NUMA locality of device.
            </summary>
        </member>
        <member name="F:Tensorflow.DeviceLocality.LinksFieldNumber">
            <summary>Field number for the "links" field.</summary>
        </member>
        <member name="P:Tensorflow.DeviceLocality.Links">
            <summary>
            Optional local interconnect links to other devices.
            </summary>
        </member>
        <member name="F:Tensorflow.DeviceAttributes.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Tensorflow.DeviceAttributes.Name">
            <summary>
            Fully specified name of the device within a cluster.
            </summary>
        </member>
        <member name="F:Tensorflow.DeviceAttributes.DeviceTypeFieldNumber">
            <summary>Field number for the "device_type" field.</summary>
        </member>
        <member name="P:Tensorflow.DeviceAttributes.DeviceType">
            <summary>
            String representation of device_type.
            </summary>
        </member>
        <member name="F:Tensorflow.DeviceAttributes.MemoryLimitFieldNumber">
            <summary>Field number for the "memory_limit" field.</summary>
        </member>
        <member name="P:Tensorflow.DeviceAttributes.MemoryLimit">
            <summary>
            Memory capacity of device in bytes.
            </summary>
        </member>
        <member name="F:Tensorflow.DeviceAttributes.LocalityFieldNumber">
            <summary>Field number for the "locality" field.</summary>
        </member>
        <member name="P:Tensorflow.DeviceAttributes.Locality">
            <summary>
            Platform-specific data about device that may be useful
            for supporting efficient data transfers.
            </summary>
        </member>
        <member name="F:Tensorflow.DeviceAttributes.IncarnationFieldNumber">
            <summary>Field number for the "incarnation" field.</summary>
        </member>
        <member name="P:Tensorflow.DeviceAttributes.Incarnation">
            <summary>
            A device is assigned a global unique number each time it is
            initialized. "incarnation" should never be 0.
            </summary>
        </member>
        <member name="F:Tensorflow.DeviceAttributes.PhysicalDeviceDescFieldNumber">
            <summary>Field number for the "physical_device_desc" field.</summary>
        </member>
        <member name="P:Tensorflow.DeviceAttributes.PhysicalDeviceDesc">
            <summary>
            String representation of the physical device that this device maps to.
            </summary>
        </member>
        <member name="T:Tensorflow.EventReflection">
            <summary>Holder for reflection information generated from tensorflow/core/util/event.proto</summary>
        </member>
        <member name="P:Tensorflow.EventReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/util/event.proto</summary>
        </member>
        <member name="T:Tensorflow.WorkerHealth">
            <summary>
            Current health status of a worker.
            </summary>
        </member>
        <member name="F:Tensorflow.WorkerHealth.Ok">
            <summary>
            By default a worker is healthy.
            </summary>
        </member>
        <member name="F:Tensorflow.WorkerHealth.ShuttingDown">
            <summary>
            Worker has been instructed to shutdown after a timeout.
            </summary>
        </member>
        <member name="T:Tensorflow.WorkerShutdownMode">
            <summary>
            Indicates the behavior of the worker when an internal error or shutdown
            signal is received.
            </summary>
        </member>
        <member name="T:Tensorflow.Event">
            <summary>
            Protocol buffer representing an event that happened during
            the execution of a Brain model.
            </summary>
        </member>
        <member name="F:Tensorflow.Event.WallTimeFieldNumber">
            <summary>Field number for the "wall_time" field.</summary>
        </member>
        <member name="P:Tensorflow.Event.WallTime">
            <summary>
            Timestamp of the event.
            </summary>
        </member>
        <member name="F:Tensorflow.Event.StepFieldNumber">
            <summary>Field number for the "step" field.</summary>
        </member>
        <member name="P:Tensorflow.Event.Step">
            <summary>
            Global step of the event.
            </summary>
        </member>
        <member name="F:Tensorflow.Event.FileVersionFieldNumber">
            <summary>Field number for the "file_version" field.</summary>
        </member>
        <member name="P:Tensorflow.Event.FileVersion">
            <summary>
            An event file was started, with the specified version.
            This is use to identify the contents of the record IO files
            easily.  Current version is "brain.Event:2".  All versions
            start with "brain.Event:".
            </summary>
        </member>
        <member name="F:Tensorflow.Event.GraphDefFieldNumber">
            <summary>Field number for the "graph_def" field.</summary>
        </member>
        <member name="P:Tensorflow.Event.GraphDef">
            <summary>
            An encoded version of a GraphDef.
            </summary>
        </member>
        <member name="F:Tensorflow.Event.SummaryFieldNumber">
            <summary>Field number for the "summary" field.</summary>
        </member>
        <member name="P:Tensorflow.Event.Summary">
            <summary>
            A summary was generated.
            </summary>
        </member>
        <member name="F:Tensorflow.Event.LogMessageFieldNumber">
            <summary>Field number for the "log_message" field.</summary>
        </member>
        <member name="P:Tensorflow.Event.LogMessage">
            <summary>
            The user output a log message. Not all messages are logged, only ones
            generated via the Python tensorboard_logging module.
            </summary>
        </member>
        <member name="F:Tensorflow.Event.SessionLogFieldNumber">
            <summary>Field number for the "session_log" field.</summary>
        </member>
        <member name="P:Tensorflow.Event.SessionLog">
            <summary>
            The state of the session which can be used for restarting after crashes.
            </summary>
        </member>
        <member name="F:Tensorflow.Event.TaggedRunMetadataFieldNumber">
            <summary>Field number for the "tagged_run_metadata" field.</summary>
        </member>
        <member name="P:Tensorflow.Event.TaggedRunMetadata">
            <summary>
            The metadata returned by running a session.run() call.
            </summary>
        </member>
        <member name="F:Tensorflow.Event.MetaGraphDefFieldNumber">
            <summary>Field number for the "meta_graph_def" field.</summary>
        </member>
        <member name="P:Tensorflow.Event.MetaGraphDef">
            <summary>
            An encoded version of a MetaGraphDef.
            </summary>
        </member>
        <member name="T:Tensorflow.Event.WhatOneofCase">
            <summary>Enum of possible cases for the "what" oneof.</summary>
        </member>
        <member name="T:Tensorflow.LogMessage">
            <summary>
            Protocol buffer used for logging messages to the events file.
            </summary>
        </member>
        <member name="F:Tensorflow.LogMessage.LevelFieldNumber">
            <summary>Field number for the "level" field.</summary>
        </member>
        <member name="F:Tensorflow.LogMessage.MessageFieldNumber">
            <summary>Field number for the "message" field.</summary>
        </member>
        <member name="T:Tensorflow.LogMessage.Types">
            <summary>Container for nested types declared in the LogMessage message type.</summary>
        </member>
        <member name="F:Tensorflow.LogMessage.Types.Level.Debugging">
            <summary>
            Note: The logging level 10 cannot be named DEBUG. Some software
            projects compile their C/C++ code with -DDEBUG in debug builds. So the
            C++ code generated from this file should not have an identifier named
            DEBUG.
            </summary>
        </member>
        <member name="T:Tensorflow.SessionLog">
            <summary>
            Protocol buffer used for logging session state.
            </summary>
        </member>
        <member name="F:Tensorflow.SessionLog.StatusFieldNumber">
            <summary>Field number for the "status" field.</summary>
        </member>
        <member name="F:Tensorflow.SessionLog.CheckpointPathFieldNumber">
            <summary>Field number for the "checkpoint_path" field.</summary>
        </member>
        <member name="P:Tensorflow.SessionLog.CheckpointPath">
            <summary>
            This checkpoint_path contains both the path and filename.
            </summary>
        </member>
        <member name="F:Tensorflow.SessionLog.MsgFieldNumber">
            <summary>Field number for the "msg" field.</summary>
        </member>
        <member name="T:Tensorflow.SessionLog.Types">
            <summary>Container for nested types declared in the SessionLog message type.</summary>
        </member>
        <member name="T:Tensorflow.TaggedRunMetadata">
            <summary>
            For logging the metadata output for a single session.run() call.
            </summary>
        </member>
        <member name="F:Tensorflow.TaggedRunMetadata.TagFieldNumber">
            <summary>Field number for the "tag" field.</summary>
        </member>
        <member name="P:Tensorflow.TaggedRunMetadata.Tag">
            <summary>
            Tag name associated with this metadata.
            </summary>
        </member>
        <member name="F:Tensorflow.TaggedRunMetadata.RunMetadataFieldNumber">
            <summary>Field number for the "run_metadata" field.</summary>
        </member>
        <member name="P:Tensorflow.TaggedRunMetadata.RunMetadata">
            <summary>
            Byte-encoded version of the `RunMetadata` proto in order to allow lazy
            deserialization.
            </summary>
        </member>
        <member name="F:Tensorflow.WatchdogConfig.TimeoutMsFieldNumber">
            <summary>Field number for the "timeout_ms" field.</summary>
        </member>
        <member name="F:Tensorflow.RequestedExitCode.ExitCodeFieldNumber">
            <summary>Field number for the "exit_code" field.</summary>
        </member>
        <member name="F:Tensorflow.WorkerHeartbeatRequest.ShutdownModeFieldNumber">
            <summary>Field number for the "shutdown_mode" field.</summary>
        </member>
        <member name="F:Tensorflow.WorkerHeartbeatRequest.WatchdogConfigFieldNumber">
            <summary>Field number for the "watchdog_config" field.</summary>
        </member>
        <member name="F:Tensorflow.WorkerHeartbeatRequest.ExitCodeFieldNumber">
            <summary>Field number for the "exit_code" field.</summary>
        </member>
        <member name="F:Tensorflow.WorkerHeartbeatResponse.HealthStatusFieldNumber">
            <summary>Field number for the "health_status" field.</summary>
        </member>
        <member name="F:Tensorflow.WorkerHeartbeatResponse.WorkerLogFieldNumber">
            <summary>Field number for the "worker_log" field.</summary>
        </member>
        <member name="F:Tensorflow.WorkerHeartbeatResponse.HostnameFieldNumber">
            <summary>Field number for the "hostname" field.</summary>
        </member>
        <member name="T:Tensorflow.FunctionReflection">
            <summary>Holder for reflection information generated from tensorflow/core/framework/function.proto</summary>
        </member>
        <member name="P:Tensorflow.FunctionReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/framework/function.proto</summary>
        </member>
        <member name="T:Tensorflow.FunctionDefLibrary">
            <summary>
            A library is a set of named functions.
            </summary>
        </member>
        <member name="F:Tensorflow.FunctionDefLibrary.FunctionFieldNumber">
            <summary>Field number for the "function" field.</summary>
        </member>
        <member name="F:Tensorflow.FunctionDefLibrary.GradientFieldNumber">
            <summary>Field number for the "gradient" field.</summary>
        </member>
        <member name="T:Tensorflow.FunctionDef">
             <summary>
             A function can be instantiated when the runtime can bind every attr
             with a value. When a GraphDef has a call to a function, it must
             have binding for every attr defined in the signature.
            
             TODO(zhifengc):
               * device spec, etc.
             </summary>
        </member>
        <member name="F:Tensorflow.FunctionDef.SignatureFieldNumber">
            <summary>Field number for the "signature" field.</summary>
        </member>
        <member name="P:Tensorflow.FunctionDef.Signature">
            <summary>
            The definition of the function's name, arguments, return values,
            attrs etc.
            </summary>
        </member>
        <member name="F:Tensorflow.FunctionDef.AttrFieldNumber">
            <summary>Field number for the "attr" field.</summary>
        </member>
        <member name="P:Tensorflow.FunctionDef.Attr">
            <summary>
            Attributes specific to this function definition.
            </summary>
        </member>
        <member name="F:Tensorflow.FunctionDef.ArgAttrFieldNumber">
            <summary>Field number for the "arg_attr" field.</summary>
        </member>
        <member name="F:Tensorflow.FunctionDef.ResourceArgUniqueIdFieldNumber">
            <summary>Field number for the "resource_arg_unique_id" field.</summary>
        </member>
        <member name="P:Tensorflow.FunctionDef.ResourceArgUniqueId">
             <summary>
             Unique IDs for each resource argument, used to track aliasing resources. If
             Argument A and Argument B alias each other, then
             resource_arg_unique_ids[A.index] == resource_arg_unique_ids[B.index].
            
             If this field is empty, none of the arguments could alias; otherwise, every
             resource argument should have an entry in this field.
            
             When instantiated, the unique IDs will be attached to the _Arg nodes'
             "_resource_arg_unique_id" attribute.
             </summary>
        </member>
        <member name="F:Tensorflow.FunctionDef.NodeDefFieldNumber">
            <summary>Field number for the "node_def" field.</summary>
        </member>
        <member name="P:Tensorflow.FunctionDef.NodeDef">
            <summary>
            By convention, "op" in node_def is resolved by consulting with a
            user-defined library first. If not resolved, "func" is assumed to
            be a builtin op.
            </summary>
        </member>
        <member name="F:Tensorflow.FunctionDef.RetFieldNumber">
            <summary>Field number for the "ret" field.</summary>
        </member>
        <member name="P:Tensorflow.FunctionDef.Ret">
            <summary>
            A mapping from the output arg names from `signature` to the
            outputs from `node_def` that should be returned by the function.
            </summary>
        </member>
        <member name="F:Tensorflow.FunctionDef.ControlRetFieldNumber">
            <summary>Field number for the "control_ret" field.</summary>
        </member>
        <member name="P:Tensorflow.FunctionDef.ControlRet">
            <summary>
            A mapping from control output names from `signature` to node names in
            `node_def` which should be control outputs of this function.
            </summary>
        </member>
        <member name="T:Tensorflow.FunctionDef.Types">
            <summary>Container for nested types declared in the FunctionDef message type.</summary>
        </member>
        <member name="T:Tensorflow.FunctionDef.Types.ArgAttrs">
            <summary>
            Attributes for function arguments. These attributes are the same set of
            valid attributes as to _Arg nodes.
            </summary>
        </member>
        <member name="F:Tensorflow.FunctionDef.Types.ArgAttrs.AttrFieldNumber">
            <summary>Field number for the "attr" field.</summary>
        </member>
        <member name="T:Tensorflow.GradientDef">
             <summary>
             GradientDef defines the gradient function of a function defined in
             a function library.
            
             A gradient function g (specified by gradient_func) for a function f
             (specified by function_name) must follow the following:
            
             The function 'f' must be a numerical function which takes N inputs
             and produces M outputs. Its gradient function 'g', which is a
             function taking N + M inputs and produces N outputs.
            
             I.e. if we have
                (y1, y2, ..., y_M) = f(x1, x2, ..., x_N),
             then, g is
                (dL/dx1, dL/dx2, ..., dL/dx_N) = g(x1, x2, ..., x_N,
                                                  dL/dy1, dL/dy2, ..., dL/dy_M),
             where L is a scalar-value function of (x1, x2, ..., xN) (e.g., the
             loss function). dL/dx_i is the partial derivative of L with respect
             to x_i.
             </summary>
        </member>
        <member name="F:Tensorflow.GradientDef.FunctionNameFieldNumber">
            <summary>Field number for the "function_name" field.</summary>
        </member>
        <member name="P:Tensorflow.GradientDef.FunctionName">
            <summary>
            The function name.
            </summary>
        </member>
        <member name="F:Tensorflow.GradientDef.GradientFuncFieldNumber">
            <summary>Field number for the "gradient_func" field.</summary>
        </member>
        <member name="P:Tensorflow.GradientDef.GradientFunc">
            <summary>
            The gradient function's name.
            </summary>
        </member>
        <member name="T:Tensorflow.GraphReflection">
            <summary>Holder for reflection information generated from tensorflow/core/framework/graph.proto</summary>
        </member>
        <member name="P:Tensorflow.GraphReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/framework/graph.proto</summary>
        </member>
        <member name="T:Tensorflow.GraphDef">
            <summary>
            Represents the graph of operations
            </summary>
        </member>
        <member name="F:Tensorflow.GraphDef.NodeFieldNumber">
            <summary>Field number for the "node" field.</summary>
        </member>
        <member name="F:Tensorflow.GraphDef.VersionsFieldNumber">
            <summary>Field number for the "versions" field.</summary>
        </member>
        <member name="P:Tensorflow.GraphDef.Versions">
            <summary>
            Compatibility versions of the graph.  See core/public/version.h for version
            history.  The GraphDef version is distinct from the TensorFlow version, and
            each release of TensorFlow will support a range of GraphDef versions.
            </summary>
        </member>
        <member name="F:Tensorflow.GraphDef.VersionFieldNumber">
            <summary>Field number for the "version" field.</summary>
        </member>
        <member name="P:Tensorflow.GraphDef.Version">
            <summary>
            Deprecated single version field; use versions above instead.  Since all
            GraphDef changes before "versions" was introduced were forward
            compatible, this field is entirely ignored.
            </summary>
        </member>
        <member name="F:Tensorflow.GraphDef.LibraryFieldNumber">
            <summary>Field number for the "library" field.</summary>
        </member>
        <member name="P:Tensorflow.GraphDef.Library">
             <summary>
             EXPERIMENTAL. DO NOT USE OR DEPEND ON THIS YET.
            
             "library" provides user-defined functions.
            
             Naming:
               * library.function.name are in a flat namespace.
                 NOTE: We may need to change it to be hierarchical to support
                 different orgs. E.g.,
                 { "/google/nn", { ... }},
                 { "/google/vision", { ... }}
                 { "/org_foo/module_bar", { ... }}
                 map&lt;string, FunctionDefLib> named_lib;
               * If node[i].op is the name of one function in "library",
                 node[i] is deemed as a function call. Otherwise, node[i].op
                 must be a primitive operation supported by the runtime.
            
             Function call semantics:
            
               * The callee may start execution as soon as some of its inputs
                 are ready. The caller may want to use Tuple() mechanism to
                 ensure all inputs are ready in the same time.
            
               * The consumer of return values may start executing as soon as
                 the return values the consumer depends on are ready.  The
                 consumer may want to use Tuple() mechanism to ensure the
                 consumer does not start until all return values of the callee
                 function are ready.
             </summary>
        </member>
        <member name="T:Tensorflow.GraphTransferInfoReflection">
            <summary>Holder for reflection information generated from tensorflow/core/framework/graph_transfer_info.proto</summary>
        </member>
        <member name="P:Tensorflow.GraphTransferInfoReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/framework/graph_transfer_info.proto</summary>
        </member>
        <member name="F:Tensorflow.GraphTransferNodeInput.NodeIdFieldNumber">
            <summary>Field number for the "node_id" field.</summary>
        </member>
        <member name="F:Tensorflow.GraphTransferNodeInput.OutputPortFieldNumber">
            <summary>Field number for the "output_port" field.</summary>
        </member>
        <member name="F:Tensorflow.GraphTransferNodeInfo.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="F:Tensorflow.GraphTransferNodeInfo.NodeIdFieldNumber">
            <summary>Field number for the "node_id" field.</summary>
        </member>
        <member name="F:Tensorflow.GraphTransferNodeInfo.TypeNameFieldNumber">
            <summary>Field number for the "type_name" field.</summary>
        </member>
        <member name="F:Tensorflow.GraphTransferNodeInfo.SocOpIdFieldNumber">
            <summary>Field number for the "soc_op_id" field.</summary>
        </member>
        <member name="F:Tensorflow.GraphTransferNodeInfo.PaddingIdFieldNumber">
            <summary>Field number for the "padding_id" field.</summary>
        </member>
        <member name="F:Tensorflow.GraphTransferNodeInfo.InputCountFieldNumber">
            <summary>Field number for the "input_count" field.</summary>
        </member>
        <member name="F:Tensorflow.GraphTransferNodeInfo.OutputCountFieldNumber">
            <summary>Field number for the "output_count" field.</summary>
        </member>
        <member name="F:Tensorflow.GraphTransferConstNodeInfo.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="F:Tensorflow.GraphTransferConstNodeInfo.NodeIdFieldNumber">
            <summary>Field number for the "node_id" field.</summary>
        </member>
        <member name="F:Tensorflow.GraphTransferConstNodeInfo.ShapeFieldNumber">
            <summary>Field number for the "shape" field.</summary>
        </member>
        <member name="F:Tensorflow.GraphTransferConstNodeInfo.DataFieldNumber">
            <summary>Field number for the "data" field.</summary>
        </member>
        <member name="F:Tensorflow.GraphTransferConstNodeInfo.DtypeFieldNumber">
            <summary>Field number for the "dtype" field.</summary>
        </member>
        <member name="F:Tensorflow.GraphTransferNodeInputInfo.NodeIdFieldNumber">
            <summary>Field number for the "node_id" field.</summary>
        </member>
        <member name="F:Tensorflow.GraphTransferNodeInputInfo.NodeInputFieldNumber">
            <summary>Field number for the "node_input" field.</summary>
        </member>
        <member name="F:Tensorflow.GraphTransferNodeOutputInfo.NodeIdFieldNumber">
            <summary>Field number for the "node_id" field.</summary>
        </member>
        <member name="F:Tensorflow.GraphTransferNodeOutputInfo.MaxByteSizeFieldNumber">
            <summary>Field number for the "max_byte_size" field.</summary>
        </member>
        <member name="F:Tensorflow.GraphTransferGraphInputNodeInfo.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="F:Tensorflow.GraphTransferGraphInputNodeInfo.ShapeFieldNumber">
            <summary>Field number for the "shape" field.</summary>
        </member>
        <member name="F:Tensorflow.GraphTransferGraphInputNodeInfo.DtypeFieldNumber">
            <summary>Field number for the "dtype" field.</summary>
        </member>
        <member name="F:Tensorflow.GraphTransferGraphOutputNodeInfo.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="F:Tensorflow.GraphTransferGraphOutputNodeInfo.ShapeFieldNumber">
            <summary>Field number for the "shape" field.</summary>
        </member>
        <member name="F:Tensorflow.GraphTransferGraphOutputNodeInfo.DtypeFieldNumber">
            <summary>Field number for the "dtype" field.</summary>
        </member>
        <member name="T:Tensorflow.GraphTransferInfo">
            <summary>
            Protocol buffer representing a handle to a tensorflow resource. Handles are
            not valid across executions, but can be serialized back and forth from within
            a single run.
            </summary>
        </member>
        <member name="F:Tensorflow.GraphTransferInfo.NodeInfoFieldNumber">
            <summary>Field number for the "node_info" field.</summary>
        </member>
        <member name="F:Tensorflow.GraphTransferInfo.ConstNodeInfoFieldNumber">
            <summary>Field number for the "const_node_info" field.</summary>
        </member>
        <member name="F:Tensorflow.GraphTransferInfo.NodeInputInfoFieldNumber">
            <summary>Field number for the "node_input_info" field.</summary>
        </member>
        <member name="F:Tensorflow.GraphTransferInfo.NodeOutputInfoFieldNumber">
            <summary>Field number for the "node_output_info" field.</summary>
        </member>
        <member name="F:Tensorflow.GraphTransferInfo.GraphInputNodeInfoFieldNumber">
            <summary>Field number for the "graph_input_node_info" field.</summary>
        </member>
        <member name="P:Tensorflow.GraphTransferInfo.GraphInputNodeInfo">
            <summary>
            Input Node parameters of transferred graph
            </summary>
        </member>
        <member name="F:Tensorflow.GraphTransferInfo.GraphOutputNodeInfoFieldNumber">
            <summary>Field number for the "graph_output_node_info" field.</summary>
        </member>
        <member name="F:Tensorflow.GraphTransferInfo.DestinationFieldNumber">
            <summary>Field number for the "destination" field.</summary>
        </member>
        <member name="P:Tensorflow.GraphTransferInfo.Destination">
            <summary>
            Destination of graph transfer
            </summary>
        </member>
        <member name="T:Tensorflow.GraphTransferInfo.Types">
            <summary>Container for nested types declared in the GraphTransferInfo message type.</summary>
        </member>
        <member name="T:Tensorflow.IProtoBuf`2">
            <summary>
            In order for a object to be serialized to and from MetaGraphDef, 
            the class must implement to_proto() and from_proto() methods
            </summary>
        </member>
        <member name="M:Tensorflow.IProtoBuf`2.to_proto(System.String)">
            <summary>
            Converts a `Variable` to a `VariableDef` protocol buffer.
            </summary>
            <param name="export_scope"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.IProtoBuf`2.from_proto(`0,System.String)">
            <summary>
            Returns a `Variable` object created from `variable_def`.
            </summary>
            <param name="proto"></param>
            <param name="import_scope"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.IteratorReflection">
            <summary>Holder for reflection information generated from tensorflow/core/framework/iterator.proto</summary>
        </member>
        <member name="P:Tensorflow.IteratorReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/framework/iterator.proto</summary>
        </member>
        <member name="T:Tensorflow.IteratorStateMetadata">
            <summary>
            Protocol buffer representing the metadata for an iterator's state stored
            as a Variant tensor.
            </summary>
        </member>
        <member name="F:Tensorflow.IteratorStateMetadata.VersionFieldNumber">
            <summary>Field number for the "version" field.</summary>
        </member>
        <member name="P:Tensorflow.IteratorStateMetadata.Version">
            <summary>
            A user-specified version string.
            </summary>
        </member>
        <member name="F:Tensorflow.IteratorStateMetadata.KeysFieldNumber">
            <summary>Field number for the "keys" field.</summary>
        </member>
        <member name="P:Tensorflow.IteratorStateMetadata.Keys">
            <summary>
            Keys for tensors in the VariantTensorDataProto.
            </summary>
        </member>
        <member name="T:Tensorflow.KernelDefReflection">
            <summary>Holder for reflection information generated from tensorflow/core/framework/kernel_def.proto</summary>
        </member>
        <member name="P:Tensorflow.KernelDefReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/framework/kernel_def.proto</summary>
        </member>
        <member name="F:Tensorflow.KernelDef.OpFieldNumber">
            <summary>Field number for the "op" field.</summary>
        </member>
        <member name="P:Tensorflow.KernelDef.Op">
            <summary>
            Must match the name of an Op.
            </summary>
        </member>
        <member name="F:Tensorflow.KernelDef.DeviceTypeFieldNumber">
            <summary>Field number for the "device_type" field.</summary>
        </member>
        <member name="P:Tensorflow.KernelDef.DeviceType">
            <summary>
            Type of device this kernel runs on.
            </summary>
        </member>
        <member name="F:Tensorflow.KernelDef.ConstraintFieldNumber">
            <summary>Field number for the "constraint" field.</summary>
        </member>
        <member name="F:Tensorflow.KernelDef.HostMemoryArgFieldNumber">
            <summary>Field number for the "host_memory_arg" field.</summary>
        </member>
        <member name="P:Tensorflow.KernelDef.HostMemoryArg">
            <summary>
            Names of the Op's input_/output_args that reside in host memory
            instead of device memory.
            </summary>
        </member>
        <member name="F:Tensorflow.KernelDef.LabelFieldNumber">
            <summary>Field number for the "label" field.</summary>
        </member>
        <member name="P:Tensorflow.KernelDef.Label">
            <summary>
            This allows experimental kernels to be registered for an op that
            won't be used unless the user specifies a "_kernel" attr with
            value matching this.
            </summary>
        </member>
        <member name="F:Tensorflow.KernelDef.PriorityFieldNumber">
            <summary>Field number for the "priority" field.</summary>
        </member>
        <member name="P:Tensorflow.KernelDef.Priority">
            <summary>
            Prioritization of kernel amongst different devices. By default we assume
            priority is 0. The higher the priority the better. By default (i.e. if
            this is not set), we prefer GPU kernels over CPU.
            </summary>
        </member>
        <member name="T:Tensorflow.KernelDef.Types">
            <summary>Container for nested types declared in the KernelDef message type.</summary>
        </member>
        <member name="F:Tensorflow.KernelDef.Types.AttrConstraint.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Tensorflow.KernelDef.Types.AttrConstraint.Name">
            <summary>
            Name of an attr from the Op.
            </summary>
        </member>
        <member name="F:Tensorflow.KernelDef.Types.AttrConstraint.AllowedValuesFieldNumber">
            <summary>Field number for the "allowed_values" field.</summary>
        </member>
        <member name="P:Tensorflow.KernelDef.Types.AttrConstraint.AllowedValues">
            <summary>
            A list of values that this kernel supports for this attr.
            Like OpDef.AttrDef.allowed_values, except for kernels instead of Ops.
            </summary>
        </member>
        <member name="T:Tensorflow.KernelList">
            <summary>
            A collection of KernelDefs
            </summary>
        </member>
        <member name="F:Tensorflow.KernelList.KernelFieldNumber">
            <summary>Field number for the "kernel" field.</summary>
        </member>
        <member name="T:Tensorflow.LogMemoryReflection">
            <summary>Holder for reflection information generated from tensorflow/core/framework/log_memory.proto</summary>
        </member>
        <member name="P:Tensorflow.LogMemoryReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/framework/log_memory.proto</summary>
        </member>
        <member name="F:Tensorflow.MemoryLogStep.StepIdFieldNumber">
            <summary>Field number for the "step_id" field.</summary>
        </member>
        <member name="P:Tensorflow.MemoryLogStep.StepId">
            <summary>
            Process-unique step id.
            </summary>
        </member>
        <member name="F:Tensorflow.MemoryLogStep.HandleFieldNumber">
            <summary>Field number for the "handle" field.</summary>
        </member>
        <member name="P:Tensorflow.MemoryLogStep.Handle">
            <summary>
            Handle describing the feeds and fetches of the step.
            </summary>
        </member>
        <member name="F:Tensorflow.MemoryLogTensorAllocation.StepIdFieldNumber">
            <summary>Field number for the "step_id" field.</summary>
        </member>
        <member name="P:Tensorflow.MemoryLogTensorAllocation.StepId">
            <summary>
            Process-unique step id.
            </summary>
        </member>
        <member name="F:Tensorflow.MemoryLogTensorAllocation.KernelNameFieldNumber">
            <summary>Field number for the "kernel_name" field.</summary>
        </member>
        <member name="P:Tensorflow.MemoryLogTensorAllocation.KernelName">
            <summary>
            Name of the kernel making the allocation as set in GraphDef,
            e.g., "affine2/weights/Assign".
            </summary>
        </member>
        <member name="F:Tensorflow.MemoryLogTensorAllocation.TensorFieldNumber">
            <summary>Field number for the "tensor" field.</summary>
        </member>
        <member name="P:Tensorflow.MemoryLogTensorAllocation.Tensor">
            <summary>
            Allocated tensor details.
            </summary>
        </member>
        <member name="F:Tensorflow.MemoryLogTensorDeallocation.AllocationIdFieldNumber">
            <summary>Field number for the "allocation_id" field.</summary>
        </member>
        <member name="P:Tensorflow.MemoryLogTensorDeallocation.AllocationId">
            <summary>
            Id of the tensor buffer being deallocated, used to match to a
            corresponding allocation.
            </summary>
        </member>
        <member name="F:Tensorflow.MemoryLogTensorDeallocation.AllocatorNameFieldNumber">
            <summary>Field number for the "allocator_name" field.</summary>
        </member>
        <member name="P:Tensorflow.MemoryLogTensorDeallocation.AllocatorName">
            <summary>
            Name of the allocator used.
            </summary>
        </member>
        <member name="F:Tensorflow.MemoryLogTensorOutput.StepIdFieldNumber">
            <summary>Field number for the "step_id" field.</summary>
        </member>
        <member name="P:Tensorflow.MemoryLogTensorOutput.StepId">
            <summary>
            Process-unique step id.
            </summary>
        </member>
        <member name="F:Tensorflow.MemoryLogTensorOutput.KernelNameFieldNumber">
            <summary>Field number for the "kernel_name" field.</summary>
        </member>
        <member name="P:Tensorflow.MemoryLogTensorOutput.KernelName">
            <summary>
            Name of the kernel producing an output as set in GraphDef, e.g.,
            "affine2/weights/Assign".
            </summary>
        </member>
        <member name="F:Tensorflow.MemoryLogTensorOutput.IndexFieldNumber">
            <summary>Field number for the "index" field.</summary>
        </member>
        <member name="P:Tensorflow.MemoryLogTensorOutput.Index">
            <summary>
            Index of the output being set.
            </summary>
        </member>
        <member name="F:Tensorflow.MemoryLogTensorOutput.TensorFieldNumber">
            <summary>Field number for the "tensor" field.</summary>
        </member>
        <member name="P:Tensorflow.MemoryLogTensorOutput.Tensor">
            <summary>
            Output tensor details.
            </summary>
        </member>
        <member name="F:Tensorflow.MemoryLogRawAllocation.StepIdFieldNumber">
            <summary>Field number for the "step_id" field.</summary>
        </member>
        <member name="P:Tensorflow.MemoryLogRawAllocation.StepId">
            <summary>
            Process-unique step id.
            </summary>
        </member>
        <member name="F:Tensorflow.MemoryLogRawAllocation.OperationFieldNumber">
            <summary>Field number for the "operation" field.</summary>
        </member>
        <member name="P:Tensorflow.MemoryLogRawAllocation.Operation">
            <summary>
            Name of the operation making the allocation.
            </summary>
        </member>
        <member name="F:Tensorflow.MemoryLogRawAllocation.NumBytesFieldNumber">
            <summary>Field number for the "num_bytes" field.</summary>
        </member>
        <member name="P:Tensorflow.MemoryLogRawAllocation.NumBytes">
            <summary>
            Number of bytes in the allocation.
            </summary>
        </member>
        <member name="F:Tensorflow.MemoryLogRawAllocation.PtrFieldNumber">
            <summary>Field number for the "ptr" field.</summary>
        </member>
        <member name="P:Tensorflow.MemoryLogRawAllocation.Ptr">
            <summary>
            Address of the allocation.
            </summary>
        </member>
        <member name="F:Tensorflow.MemoryLogRawAllocation.AllocationIdFieldNumber">
            <summary>Field number for the "allocation_id" field.</summary>
        </member>
        <member name="P:Tensorflow.MemoryLogRawAllocation.AllocationId">
            <summary>
            Id of the tensor buffer being allocated, used to match to a
            corresponding deallocation.
            </summary>
        </member>
        <member name="F:Tensorflow.MemoryLogRawAllocation.AllocatorNameFieldNumber">
            <summary>Field number for the "allocator_name" field.</summary>
        </member>
        <member name="P:Tensorflow.MemoryLogRawAllocation.AllocatorName">
            <summary>
            Name of the allocator used.
            </summary>
        </member>
        <member name="F:Tensorflow.MemoryLogRawDeallocation.StepIdFieldNumber">
            <summary>Field number for the "step_id" field.</summary>
        </member>
        <member name="P:Tensorflow.MemoryLogRawDeallocation.StepId">
            <summary>
            Process-unique step id.
            </summary>
        </member>
        <member name="F:Tensorflow.MemoryLogRawDeallocation.OperationFieldNumber">
            <summary>Field number for the "operation" field.</summary>
        </member>
        <member name="P:Tensorflow.MemoryLogRawDeallocation.Operation">
            <summary>
            Name of the operation making the deallocation.
            </summary>
        </member>
        <member name="F:Tensorflow.MemoryLogRawDeallocation.AllocationIdFieldNumber">
            <summary>Field number for the "allocation_id" field.</summary>
        </member>
        <member name="P:Tensorflow.MemoryLogRawDeallocation.AllocationId">
            <summary>
            Id of the tensor buffer being deallocated, used to match to a
            corresponding allocation.
            </summary>
        </member>
        <member name="F:Tensorflow.MemoryLogRawDeallocation.AllocatorNameFieldNumber">
            <summary>Field number for the "allocator_name" field.</summary>
        </member>
        <member name="P:Tensorflow.MemoryLogRawDeallocation.AllocatorName">
            <summary>
            Name of the allocator used.
            </summary>
        </member>
        <member name="F:Tensorflow.MemoryLogRawDeallocation.DeferredFieldNumber">
            <summary>Field number for the "deferred" field.</summary>
        </member>
        <member name="P:Tensorflow.MemoryLogRawDeallocation.Deferred">
            <summary>
            True if the deallocation is queued and will be performed later,
            e.g. for GPU lazy freeing of buffers.
            </summary>
        </member>
        <member name="T:Tensorflow.MetaGraphReflection">
            <summary>Holder for reflection information generated from tensorflow/core/protobuf/meta_graph.proto</summary>
        </member>
        <member name="P:Tensorflow.MetaGraphReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/protobuf/meta_graph.proto</summary>
        </member>
        <member name="T:Tensorflow.MetaGraphDef">
             <summary>
             NOTE: This protocol buffer is evolving, and will go through revisions in the
             coming months.
            
             Protocol buffer containing the following which are necessary to restart
             training, run inference. It can be used to serialize/de-serialize memory
             objects necessary for running computation in a graph when crossing the
             process boundary. It can be used for long term storage of graphs,
             cross-language execution of graphs, etc.
               MetaInfoDef
               GraphDef
               SaverDef
               CollectionDef
               TensorInfo
               SignatureDef
             </summary>
        </member>
        <member name="F:Tensorflow.MetaGraphDef.MetaInfoDefFieldNumber">
            <summary>Field number for the "meta_info_def" field.</summary>
        </member>
        <member name="F:Tensorflow.MetaGraphDef.GraphDefFieldNumber">
            <summary>Field number for the "graph_def" field.</summary>
        </member>
        <member name="P:Tensorflow.MetaGraphDef.GraphDef">
            <summary>
            GraphDef.
            </summary>
        </member>
        <member name="F:Tensorflow.MetaGraphDef.SaverDefFieldNumber">
            <summary>Field number for the "saver_def" field.</summary>
        </member>
        <member name="P:Tensorflow.MetaGraphDef.SaverDef">
            <summary>
            SaverDef.
            </summary>
        </member>
        <member name="F:Tensorflow.MetaGraphDef.CollectionDefFieldNumber">
            <summary>Field number for the "collection_def" field.</summary>
        </member>
        <member name="P:Tensorflow.MetaGraphDef.CollectionDef">
            <summary>
            collection_def: Map from collection name to collections.
            See CollectionDef section for details.
            </summary>
        </member>
        <member name="F:Tensorflow.MetaGraphDef.SignatureDefFieldNumber">
            <summary>Field number for the "signature_def" field.</summary>
        </member>
        <member name="P:Tensorflow.MetaGraphDef.SignatureDef">
            <summary>
            signature_def: Map from user supplied key for a signature to a single
            SignatureDef.
            </summary>
        </member>
        <member name="F:Tensorflow.MetaGraphDef.AssetFileDefFieldNumber">
            <summary>Field number for the "asset_file_def" field.</summary>
        </member>
        <member name="P:Tensorflow.MetaGraphDef.AssetFileDef">
            <summary>
            Asset file def to be used with the defined graph.
            </summary>
        </member>
        <member name="F:Tensorflow.MetaGraphDef.ObjectGraphDefFieldNumber">
            <summary>Field number for the "object_graph_def" field.</summary>
        </member>
        <member name="P:Tensorflow.MetaGraphDef.ObjectGraphDef">
            <summary>
            Extra information about the structure of functions and stateful objects.
            </summary>
        </member>
        <member name="T:Tensorflow.MetaGraphDef.Types">
            <summary>Container for nested types declared in the MetaGraphDef message type.</summary>
        </member>
        <member name="T:Tensorflow.MetaGraphDef.Types.MetaInfoDef">
            <summary>
            Meta information regarding the graph to be exported.  To be used by users
            of this protocol buffer to encode information regarding their meta graph.
            </summary>
        </member>
        <member name="F:Tensorflow.MetaGraphDef.Types.MetaInfoDef.MetaGraphVersionFieldNumber">
            <summary>Field number for the "meta_graph_version" field.</summary>
        </member>
        <member name="P:Tensorflow.MetaGraphDef.Types.MetaInfoDef.MetaGraphVersion">
            <summary>
            User specified Version string. Can be the name of the model and revision,
            steps this model has been trained to, etc.
            </summary>
        </member>
        <member name="F:Tensorflow.MetaGraphDef.Types.MetaInfoDef.StrippedOpListFieldNumber">
            <summary>Field number for the "stripped_op_list" field.</summary>
        </member>
        <member name="P:Tensorflow.MetaGraphDef.Types.MetaInfoDef.StrippedOpList">
            <summary>
            A copy of the OpDefs used by the producer of this graph_def.
            Descriptions and Ops not used in graph_def are stripped out.
            </summary>
        </member>
        <member name="F:Tensorflow.MetaGraphDef.Types.MetaInfoDef.AnyInfoFieldNumber">
            <summary>Field number for the "any_info" field.</summary>
        </member>
        <member name="P:Tensorflow.MetaGraphDef.Types.MetaInfoDef.AnyInfo">
            <summary>
            A serialized protobuf. Can be the time this meta graph is created, or
            modified, or name of the model.
            </summary>
        </member>
        <member name="F:Tensorflow.MetaGraphDef.Types.MetaInfoDef.TagsFieldNumber">
            <summary>Field number for the "tags" field.</summary>
        </member>
        <member name="P:Tensorflow.MetaGraphDef.Types.MetaInfoDef.Tags">
             <summary>
             User supplied tag(s) on the meta_graph and included graph_def.
            
             MetaGraphDefs should be tagged with their capabilities or use-cases.
             Examples: "train", "serve", "gpu", "tpu", etc.
             These tags enable loaders to access the MetaGraph(s) appropriate for a
             specific use-case or runtime environment.
             </summary>
        </member>
        <member name="F:Tensorflow.MetaGraphDef.Types.MetaInfoDef.TensorflowVersionFieldNumber">
            <summary>Field number for the "tensorflow_version" field.</summary>
        </member>
        <member name="P:Tensorflow.MetaGraphDef.Types.MetaInfoDef.TensorflowVersion">
            <summary>
            The __version__ string of the tensorflow build used to write this graph.
            This will be populated by the framework, which will overwrite any user
            supplied value.
            </summary>
        </member>
        <member name="F:Tensorflow.MetaGraphDef.Types.MetaInfoDef.TensorflowGitVersionFieldNumber">
            <summary>Field number for the "tensorflow_git_version" field.</summary>
        </member>
        <member name="P:Tensorflow.MetaGraphDef.Types.MetaInfoDef.TensorflowGitVersion">
            <summary>
            The __git_version__ string of the tensorflow build used to write this
            graph. This will be populated by the framework, which will overwrite any
            user supplied value.
            </summary>
        </member>
        <member name="F:Tensorflow.MetaGraphDef.Types.MetaInfoDef.StrippedDefaultAttrsFieldNumber">
            <summary>Field number for the "stripped_default_attrs" field.</summary>
        </member>
        <member name="P:Tensorflow.MetaGraphDef.Types.MetaInfoDef.StrippedDefaultAttrs">
            <summary>
            A flag to denote whether default-valued attrs have been stripped from
            the nodes in this graph_def.
            </summary>
        </member>
        <member name="F:Tensorflow.MetaGraphDef.Types.MetaInfoDef.FunctionAliasesFieldNumber">
            <summary>Field number for the "function_aliases" field.</summary>
        </member>
        <member name="P:Tensorflow.MetaGraphDef.Types.MetaInfoDef.FunctionAliases">
            <summary>
            FunctionDef name to aliases mapping.
            </summary>
        </member>
        <member name="T:Tensorflow.CollectionDef">
             <summary>
             CollectionDef should cover most collections.
             To add a user-defined collection, do one of the following:
             1. For simple data types, such as string, int, float:
                  tf.add_to_collection("your_collection_name", your_simple_value)
                strings will be stored as bytes_list.
            
             2. For Protobuf types, there are three ways to add them:
                1) tf.add_to_collection("your_collection_name",
                     your_proto.SerializeToString())
            
                   collection_def {
                     key: "user_defined_bytes_collection"
                     value {
                       bytes_list {
                         value: "queue_name: \"test_queue\"\n"
                       }
                     }
                   }
            
              or
            
                2) tf.add_to_collection("your_collection_name", str(your_proto))
            
                   collection_def {
                     key: "user_defined_string_collection"
                     value {
                      bytes_list {
                         value: "\n\ntest_queue"
                       }
                     }
                   }
            
              or
            
                3) any_buf = any_pb2.Any()
                   tf.add_to_collection("your_collection_name",
                     any_buf.Pack(your_proto))
            
                   collection_def {
                     key: "user_defined_any_collection"
                     value {
                       any_list {
                         value {
                           type_url: "type.googleapis.com/tensorflow.QueueRunnerDef"
                           value: "\n\ntest_queue"
                         }
                       }
                     }
                   }
            
             3. For Python objects, implement to_proto() and from_proto(), and register
                them in the following manner:
                ops.register_proto_function("your_collection_name",
                                            proto_type,
                                            to_proto=YourPythonObject.to_proto,
                                            from_proto=YourPythonObject.from_proto)
                These functions will be invoked to serialize and de-serialize the
                collection. For example,
                ops.register_proto_function(ops.GraphKeys.GLOBAL_VARIABLES,
                                            proto_type=variable_pb2.VariableDef,
                                            to_proto=Variable.to_proto,
                                            from_proto=Variable.from_proto)
             </summary>
        </member>
        <member name="F:Tensorflow.CollectionDef.NodeListFieldNumber">
            <summary>Field number for the "node_list" field.</summary>
        </member>
        <member name="F:Tensorflow.CollectionDef.BytesListFieldNumber">
            <summary>Field number for the "bytes_list" field.</summary>
        </member>
        <member name="F:Tensorflow.CollectionDef.Int64ListFieldNumber">
            <summary>Field number for the "int64_list" field.</summary>
        </member>
        <member name="F:Tensorflow.CollectionDef.FloatListFieldNumber">
            <summary>Field number for the "float_list" field.</summary>
        </member>
        <member name="F:Tensorflow.CollectionDef.AnyListFieldNumber">
            <summary>Field number for the "any_list" field.</summary>
        </member>
        <member name="T:Tensorflow.CollectionDef.KindOneofCase">
            <summary>Enum of possible cases for the "kind" oneof.</summary>
        </member>
        <member name="T:Tensorflow.CollectionDef.Types">
            <summary>Container for nested types declared in the CollectionDef message type.</summary>
        </member>
        <member name="T:Tensorflow.CollectionDef.Types.NodeList">
            <summary>
            NodeList is used for collecting nodes in graph. For example
            collection_def {
              key: "summaries"
              value {
                node_list {
                  value: "input_producer/ScalarSummary:0"
                  value: "shuffle_batch/ScalarSummary:0"
                  value: "ImageSummary:0"
                }
              }
            </summary>
        </member>
        <member name="F:Tensorflow.CollectionDef.Types.NodeList.ValueFieldNumber">
            <summary>Field number for the "value" field.</summary>
        </member>
        <member name="T:Tensorflow.CollectionDef.Types.BytesList">
            <summary>
            BytesList is used for collecting strings and serialized protobufs. For
            example:
            collection_def {
              key: "trainable_variables"
              value {
                bytes_list {
                  value: "\n\017conv1/weights:0\022\024conv1/weights/Assign
                         \032\024conv1/weights/read:0"
                  value: "\n\016conv1/biases:0\022\023conv1/biases/Assign\032
                         \023conv1/biases/read:0"
                }
              }
            }
            </summary>
        </member>
        <member name="F:Tensorflow.CollectionDef.Types.BytesList.ValueFieldNumber">
            <summary>Field number for the "value" field.</summary>
        </member>
        <member name="T:Tensorflow.CollectionDef.Types.Int64List">
            <summary>
            Int64List is used for collecting int, int64 and long values.
            </summary>
        </member>
        <member name="F:Tensorflow.CollectionDef.Types.Int64List.ValueFieldNumber">
            <summary>Field number for the "value" field.</summary>
        </member>
        <member name="T:Tensorflow.CollectionDef.Types.FloatList">
            <summary>
            FloatList is used for collecting float values.
            </summary>
        </member>
        <member name="F:Tensorflow.CollectionDef.Types.FloatList.ValueFieldNumber">
            <summary>Field number for the "value" field.</summary>
        </member>
        <member name="T:Tensorflow.CollectionDef.Types.AnyList">
            <summary>
            AnyList is used for collecting Any protos.
            </summary>
        </member>
        <member name="F:Tensorflow.CollectionDef.Types.AnyList.ValueFieldNumber">
            <summary>Field number for the "value" field.</summary>
        </member>
        <member name="T:Tensorflow.TensorInfo">
            <summary>
            Information about a Tensor necessary for feeding or retrieval.
            </summary>
        </member>
        <member name="F:Tensorflow.TensorInfo.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorInfo.Name">
            <summary>
            For dense `Tensor`s, the name of the tensor in the graph.
            </summary>
        </member>
        <member name="F:Tensorflow.TensorInfo.CooSparseFieldNumber">
            <summary>Field number for the "coo_sparse" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorInfo.CooSparse">
            <summary>
            There are many possible encodings of sparse matrices
            (https://en.wikipedia.org/wiki/Sparse_matrix).  Currently, TensorFlow
            uses only the COO encoding.  This is supported and documented in the
            SparseTensor Python class.
            </summary>
        </member>
        <member name="F:Tensorflow.TensorInfo.CompositeTensorFieldNumber">
            <summary>Field number for the "composite_tensor" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorInfo.CompositeTensor">
            <summary>
            Generic encoding for CompositeTensors.
            </summary>
        </member>
        <member name="F:Tensorflow.TensorInfo.DtypeFieldNumber">
            <summary>Field number for the "dtype" field.</summary>
        </member>
        <member name="F:Tensorflow.TensorInfo.TensorShapeFieldNumber">
            <summary>Field number for the "tensor_shape" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorInfo.TensorShape">
            <summary>
            The static shape should be recorded here, to the extent that it can
            be known in advance.  In the case of a SparseTensor, this field describes
            the logical shape of the represented tensor (aka dense_shape).
            </summary>
        </member>
        <member name="T:Tensorflow.TensorInfo.EncodingOneofCase">
            <summary>Enum of possible cases for the "encoding" oneof.</summary>
        </member>
        <member name="T:Tensorflow.TensorInfo.Types">
            <summary>Container for nested types declared in the TensorInfo message type.</summary>
        </member>
        <member name="T:Tensorflow.TensorInfo.Types.CooSparse">
            <summary>
            For sparse tensors, The COO encoding stores a triple of values, indices,
            and shape.
            </summary>
        </member>
        <member name="F:Tensorflow.TensorInfo.Types.CooSparse.ValuesTensorNameFieldNumber">
            <summary>Field number for the "values_tensor_name" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorInfo.Types.CooSparse.ValuesTensorName">
            <summary>
            The shape of the values Tensor is [?].  Its dtype must be the dtype of
            the SparseTensor as a whole, given in the enclosing TensorInfo.
            </summary>
        </member>
        <member name="F:Tensorflow.TensorInfo.Types.CooSparse.IndicesTensorNameFieldNumber">
            <summary>Field number for the "indices_tensor_name" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorInfo.Types.CooSparse.IndicesTensorName">
            <summary>
            The indices Tensor must have dtype int64 and shape [?, ?].
            </summary>
        </member>
        <member name="F:Tensorflow.TensorInfo.Types.CooSparse.DenseShapeTensorNameFieldNumber">
            <summary>Field number for the "dense_shape_tensor_name" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorInfo.Types.CooSparse.DenseShapeTensorName">
            <summary>
            The dynamic logical shape represented by the SparseTensor is recorded in
            the Tensor referenced here.  It must have dtype int64 and shape [?].
            </summary>
        </member>
        <member name="T:Tensorflow.TensorInfo.Types.CompositeTensor">
            <summary>
            Generic encoding for composite tensors.
            </summary>
        </member>
        <member name="F:Tensorflow.TensorInfo.Types.CompositeTensor.TypeSpecFieldNumber">
            <summary>Field number for the "type_spec" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorInfo.Types.CompositeTensor.TypeSpec">
            <summary>
            The serialized TypeSpec for the composite tensor.
            </summary>
        </member>
        <member name="F:Tensorflow.TensorInfo.Types.CompositeTensor.ComponentsFieldNumber">
            <summary>Field number for the "components" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorInfo.Types.CompositeTensor.Components">
            <summary>
            A TensorInfo for each flattened component tensor.
            </summary>
        </member>
        <member name="T:Tensorflow.SignatureDef">
             <summary>
             SignatureDef defines the signature of a computation supported by a TensorFlow
             graph.
            
             For example, a model with two loss computations, sharing a single input,
             might have the following signature_def map.
            
             Note that across the two SignatureDefs "loss_A" and "loss_B", the input key,
             output key, and method_name are identical, and will be used by system(s) that
             implement or rely upon this particular loss method. The output tensor names
             differ, demonstrating how different outputs can exist for the same method.
            
             signature_def {
               key: "loss_A"
               value {
                 inputs {
                   key: "input"
                   value {
                     name: "input:0"
                     dtype: DT_STRING
                     tensor_shape: ...
                   }
                 }
                 outputs {
                   key: "loss_output"
                   value {
                     name: "loss_output_A:0"
                     dtype: DT_FLOAT
                     tensor_shape: ...
                   }
                 }
               }
               ...
               method_name: "some/package/compute_loss"
             }
             signature_def {
               key: "loss_B"
               value {
                 inputs {
                   key: "input"
                   value {
                     name: "input:0"
                     dtype: DT_STRING
                     tensor_shape: ...
                   }
                 }
                 outputs {
                   key: "loss_output"
                   value {
                     name: "loss_output_B:0"
                     dtype: DT_FLOAT
                     tensor_shape: ...
                   }
                 }
               }
               ...
               method_name: "some/package/compute_loss"
             }
             </summary>
        </member>
        <member name="F:Tensorflow.SignatureDef.InputsFieldNumber">
            <summary>Field number for the "inputs" field.</summary>
        </member>
        <member name="P:Tensorflow.SignatureDef.Inputs">
            <summary>
            Named input parameters.
            </summary>
        </member>
        <member name="F:Tensorflow.SignatureDef.OutputsFieldNumber">
            <summary>Field number for the "outputs" field.</summary>
        </member>
        <member name="P:Tensorflow.SignatureDef.Outputs">
            <summary>
            Named output parameters.
            </summary>
        </member>
        <member name="F:Tensorflow.SignatureDef.MethodNameFieldNumber">
            <summary>Field number for the "method_name" field.</summary>
        </member>
        <member name="P:Tensorflow.SignatureDef.MethodName">
             <summary>
             Extensible method_name information enabling third-party users to mark a
             SignatureDef as supporting a particular method. This enables producers and
             consumers of SignatureDefs, e.g. a model definition library and a serving
             library to have a clear hand-off regarding the semantics of a computation.
            
             Note that multiple SignatureDefs in a single MetaGraphDef may have the same
             method_name. This is commonly used to support multi-headed computation,
             where a single graph computation may return multiple results.
             </summary>
        </member>
        <member name="T:Tensorflow.AssetFileDef">
            <summary>
            An asset file def for a single file or a set of sharded files with the same
            name.
            </summary>
        </member>
        <member name="F:Tensorflow.AssetFileDef.TensorInfoFieldNumber">
            <summary>Field number for the "tensor_info" field.</summary>
        </member>
        <member name="P:Tensorflow.AssetFileDef.TensorInfo">
            <summary>
            The tensor to bind the asset filename to.
            </summary>
        </member>
        <member name="F:Tensorflow.AssetFileDef.FilenameFieldNumber">
            <summary>Field number for the "filename" field.</summary>
        </member>
        <member name="P:Tensorflow.AssetFileDef.Filename">
            <summary>
            The filename within an assets directory. Note: does not include the path
            prefix, i.e. directories. For an asset at /tmp/path/vocab.txt, the filename
            would be "vocab.txt".
            </summary>
        </member>
        <member name="T:Tensorflow.NodeDefReflection">
            <summary>Holder for reflection information generated from tensorflow/core/framework/node_def.proto</summary>
        </member>
        <member name="P:Tensorflow.NodeDefReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/framework/node_def.proto</summary>
        </member>
        <member name="F:Tensorflow.NodeDef.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Tensorflow.NodeDef.Name">
            <summary>
            The name given to this operator. Used for naming inputs,
            logging, visualization, etc.  Unique within a single GraphDef.
            Must match the regexp "[A-Za-z0-9.][A-Za-z0-9_>./]*".
            </summary>
        </member>
        <member name="F:Tensorflow.NodeDef.OpFieldNumber">
            <summary>Field number for the "op" field.</summary>
        </member>
        <member name="P:Tensorflow.NodeDef.Op">
            <summary>
            The operation name.  There may be custom parameters in attrs.
            Op names starting with an underscore are reserved for internal use.
            </summary>
        </member>
        <member name="F:Tensorflow.NodeDef.InputFieldNumber">
            <summary>Field number for the "input" field.</summary>
        </member>
        <member name="P:Tensorflow.NodeDef.Input">
            <summary>
            Each input is "node:src_output" with "node" being a string name and
            "src_output" indicating which output tensor to use from "node". If
            "src_output" is 0 the ":0" suffix can be omitted.  Regular inputs
            may optionally be followed by control inputs that have the format
            "^node".
            </summary>
        </member>
        <member name="F:Tensorflow.NodeDef.DeviceFieldNumber">
            <summary>Field number for the "device" field.</summary>
        </member>
        <member name="P:Tensorflow.NodeDef.Device">
             <summary>
             A (possibly partial) specification for the device on which this
             node should be placed.
             The expected syntax for this string is as follows:
            
             DEVICE_SPEC ::= PARTIAL_SPEC
            
             PARTIAL_SPEC ::= ("/" CONSTRAINT) *
             CONSTRAINT ::= ("job:" JOB_NAME)
                          | ("replica:" [1-9][0-9]*)
                          | ("task:" [1-9][0-9]*)
                          | ("device:" [A-Za-z]* ":" ([1-9][0-9]* | "*") )
            
             Valid values for this string include:
             * "/job:worker/replica:0/task:1/device:GPU:3"  (full specification)
             * "/job:worker/device:GPU:3"                   (partial specification)
             * ""                                    (no specification)
            
             If the constraints do not resolve to a single device (or if this
             field is empty or not present), the runtime will attempt to
             choose a device automatically.
             </summary>
        </member>
        <member name="F:Tensorflow.NodeDef.AttrFieldNumber">
            <summary>Field number for the "attr" field.</summary>
        </member>
        <member name="P:Tensorflow.NodeDef.Attr">
            <summary>
            Operation-specific graph-construction-time configuration.
            Note that this should include all attrs defined in the
            corresponding OpDef, including those with a value matching
            the default -- this allows the default to change and makes
            NodeDefs easier to interpret on their own.  However, if
            an attr with a default is not specified in this list, the
            default will be used.
            The "names" (keys) must match the regexp "[a-z][a-z0-9_]+" (and
            one of the names from the corresponding OpDef's attr field).
            The values must have a type matching the corresponding OpDef
            attr's type field.
            TODO(josh11b): Add some examples here showing best practices.
            </summary>
        </member>
        <member name="F:Tensorflow.NodeDef.ExperimentalDebugInfoFieldNumber">
            <summary>Field number for the "experimental_debug_info" field.</summary>
        </member>
        <member name="P:Tensorflow.NodeDef.ExperimentalDebugInfo">
            <summary>
            This stores debug information associated with the node.
            </summary>
        </member>
        <member name="T:Tensorflow.NodeDef.Types">
            <summary>Container for nested types declared in the NodeDef message type.</summary>
        </member>
        <member name="F:Tensorflow.NodeDef.Types.ExperimentalDebugInfo.OriginalNodeNamesFieldNumber">
            <summary>Field number for the "original_node_names" field.</summary>
        </member>
        <member name="P:Tensorflow.NodeDef.Types.ExperimentalDebugInfo.OriginalNodeNames">
             <summary>
             Opaque string inserted into error messages created by the runtime.
            
             This is intended to store the list of names of the nodes from the
             original graph that this node was derived. For example if this node, say
             C, was result of a fusion of 2 nodes A and B, then 'original_node' would
             be {A, B}. This information can be used to map errors originating at the
             current node to some top level source code.
             </summary>
        </member>
        <member name="F:Tensorflow.NodeDef.Types.ExperimentalDebugInfo.OriginalFuncNamesFieldNumber">
            <summary>Field number for the "original_func_names" field.</summary>
        </member>
        <member name="P:Tensorflow.NodeDef.Types.ExperimentalDebugInfo.OriginalFuncNames">
            <summary>
            This is intended to store the list of names of the functions from the
            original graph that this node was derived. For example if this node, say
            C, was result of a fusion of node A in function FA and node B in function
            FB, then `original_funcs` would be {FA, FB}. If the node is in the top
            level graph, the `original_func` is empty. This information, with the
            `original_node_names` can be used to map errors originating at the
            current ndoe to some top level source code.
            </summary>
        </member>
        <member name="T:Tensorflow.OpDefReflection">
            <summary>Holder for reflection information generated from tensorflow/core/framework/op_def.proto</summary>
        </member>
        <member name="P:Tensorflow.OpDefReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/framework/op_def.proto</summary>
        </member>
        <member name="T:Tensorflow.OpDef">
            <summary>
            Defines an operation. A NodeDef in a GraphDef specifies an Op by
            using the "op" field which should match the name of a OpDef.
            LINT.IfChange
            </summary>
        </member>
        <member name="F:Tensorflow.OpDef.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Tensorflow.OpDef.Name">
            <summary>
            Op names starting with an underscore are reserved for internal use.
            Names should be CamelCase and match the regexp "[A-Z][a-zA-Z0-9>_]*".
            </summary>
        </member>
        <member name="F:Tensorflow.OpDef.InputArgFieldNumber">
            <summary>Field number for the "input_arg" field.</summary>
        </member>
        <member name="P:Tensorflow.OpDef.InputArg">
            <summary>
            Description of the input(s).
            </summary>
        </member>
        <member name="F:Tensorflow.OpDef.OutputArgFieldNumber">
            <summary>Field number for the "output_arg" field.</summary>
        </member>
        <member name="P:Tensorflow.OpDef.OutputArg">
            <summary>
            Description of the output(s).
            </summary>
        </member>
        <member name="F:Tensorflow.OpDef.ControlOutputFieldNumber">
            <summary>Field number for the "control_output" field.</summary>
        </member>
        <member name="P:Tensorflow.OpDef.ControlOutput">
            <summary>
            Named control outputs for this operation. Useful only for composite
            operations (i.e. functions) which want to name different control outputs.
            </summary>
        </member>
        <member name="F:Tensorflow.OpDef.AttrFieldNumber">
            <summary>Field number for the "attr" field.</summary>
        </member>
        <member name="F:Tensorflow.OpDef.DeprecationFieldNumber">
            <summary>Field number for the "deprecation" field.</summary>
        </member>
        <member name="P:Tensorflow.OpDef.Deprecation">
            <summary>
            Optional deprecation based on GraphDef versions.
            </summary>
        </member>
        <member name="F:Tensorflow.OpDef.SummaryFieldNumber">
            <summary>Field number for the "summary" field.</summary>
        </member>
        <member name="P:Tensorflow.OpDef.Summary">
            <summary>
            One-line human-readable description of what the Op does.
            </summary>
        </member>
        <member name="F:Tensorflow.OpDef.DescriptionFieldNumber">
            <summary>Field number for the "description" field.</summary>
        </member>
        <member name="P:Tensorflow.OpDef.Description">
            <summary>
            Additional, longer human-readable description of what the Op does.
            </summary>
        </member>
        <member name="F:Tensorflow.OpDef.IsCommutativeFieldNumber">
            <summary>Field number for the "is_commutative" field.</summary>
        </member>
        <member name="P:Tensorflow.OpDef.IsCommutative">
            <summary>
            True if the operation is commutative ("op(a,b) == op(b,a)" for all inputs)
            </summary>
        </member>
        <member name="F:Tensorflow.OpDef.IsAggregateFieldNumber">
            <summary>Field number for the "is_aggregate" field.</summary>
        </member>
        <member name="P:Tensorflow.OpDef.IsAggregate">
            <summary>
            If is_aggregate is true, then this operation accepts N >= 2
            inputs and produces 1 output all of the same type.  Should be
            associative and commutative, and produce output with the same
            shape as the input.  The optimizer may replace an aggregate op
            taking input from multiple devices with a tree of aggregate ops
            that aggregate locally within each device (and possibly within
            groups of nearby devices) before communicating.
            TODO(josh11b): Implement that optimization.
            </summary>
        </member>
        <member name="F:Tensorflow.OpDef.IsStatefulFieldNumber">
            <summary>Field number for the "is_stateful" field.</summary>
        </member>
        <member name="P:Tensorflow.OpDef.IsStateful">
             <summary>
             Ops are marked as stateful if their behavior depends on some state beyond
             their input tensors (e.g. variable reading op) or if they have
             a side-effect (e.g. printing or asserting ops). Equivalently, stateless ops
             must always produce the same output for the same input and have
             no side-effects.
            
             By default Ops may be moved between devices.  Stateful ops should
             either not be moved, or should only be moved if that state can also
             be moved (e.g. via some sort of save / restore).
             Stateful ops are guaranteed to never be optimized away by Common
             Subexpression Elimination (CSE).
             </summary>
        </member>
        <member name="F:Tensorflow.OpDef.AllowsUninitializedInputFieldNumber">
            <summary>Field number for the "allows_uninitialized_input" field.</summary>
        </member>
        <member name="P:Tensorflow.OpDef.AllowsUninitializedInput">
            <summary>
            By default, all inputs to an Op must be initialized Tensors.  Ops
            that may initialize tensors for the first time should set this
            field to true, to allow the Op to take an uninitialized Tensor as
            input.
            </summary>
        </member>
        <member name="T:Tensorflow.OpDef.Types">
            <summary>Container for nested types declared in the OpDef message type.</summary>
        </member>
        <member name="T:Tensorflow.OpDef.Types.ArgDef">
            <summary>
            For describing inputs and outputs.
            </summary>
        </member>
        <member name="F:Tensorflow.OpDef.Types.ArgDef.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Tensorflow.OpDef.Types.ArgDef.Name">
            <summary>
            Name for the input/output.  Should match the regexp "[a-z][a-z0-9_]*".
            </summary>
        </member>
        <member name="F:Tensorflow.OpDef.Types.ArgDef.DescriptionFieldNumber">
            <summary>Field number for the "description" field.</summary>
        </member>
        <member name="P:Tensorflow.OpDef.Types.ArgDef.Description">
            <summary>
            Human readable description.
            </summary>
        </member>
        <member name="F:Tensorflow.OpDef.Types.ArgDef.TypeFieldNumber">
            <summary>Field number for the "type" field.</summary>
        </member>
        <member name="P:Tensorflow.OpDef.Types.ArgDef.Type">
            <summary>
            Describes the type of one or more tensors that are accepted/produced
            by this input/output arg.  The only legal combinations are:
            * For a single tensor: either the "type" field is set or the
              "type_attr" field is set to the name of an attr with type "type".
            * For a sequence of tensors with the same type: the "number_attr"
              field will be set to the name of an attr with type "int", and
              either the "type" or "type_attr" field will be set as for
              single tensors.
            * For a sequence of tensors, the "type_list_attr" field will be set
              to the name of an attr with type "list(type)".
            </summary>
        </member>
        <member name="F:Tensorflow.OpDef.Types.ArgDef.TypeAttrFieldNumber">
            <summary>Field number for the "type_attr" field.</summary>
        </member>
        <member name="P:Tensorflow.OpDef.Types.ArgDef.TypeAttr">
            <summary>
            if specified, attr must have type "type"
            </summary>
        </member>
        <member name="F:Tensorflow.OpDef.Types.ArgDef.NumberAttrFieldNumber">
            <summary>Field number for the "number_attr" field.</summary>
        </member>
        <member name="P:Tensorflow.OpDef.Types.ArgDef.NumberAttr">
            <summary>
            if specified, attr must have type "int"
            </summary>
        </member>
        <member name="F:Tensorflow.OpDef.Types.ArgDef.TypeListAttrFieldNumber">
            <summary>Field number for the "type_list_attr" field.</summary>
        </member>
        <member name="P:Tensorflow.OpDef.Types.ArgDef.TypeListAttr">
            <summary>
            If specified, attr must have type "list(type)", and none of
            type, type_attr, and number_attr may be specified.
            </summary>
        </member>
        <member name="F:Tensorflow.OpDef.Types.ArgDef.IsRefFieldNumber">
            <summary>Field number for the "is_ref" field.</summary>
        </member>
        <member name="P:Tensorflow.OpDef.Types.ArgDef.IsRef">
            <summary>
            For inputs: if true, the inputs are required to be refs.
              By default, inputs can be either refs or non-refs.
            For outputs: if true, outputs are refs, otherwise they are not.
            </summary>
        </member>
        <member name="T:Tensorflow.OpDef.Types.AttrDef">
            <summary>
            Description of the graph-construction-time configuration of this
            Op.  That is to say, this describes the attr fields that will
            be specified in the NodeDef.
            </summary>
        </member>
        <member name="F:Tensorflow.OpDef.Types.AttrDef.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Tensorflow.OpDef.Types.AttrDef.Name">
            <summary>
            A descriptive name for the argument.  May be used, e.g. by the
            Python client, as a keyword argument name, and so should match
            the regexp "[a-z][a-z0-9_]+".
            </summary>
        </member>
        <member name="F:Tensorflow.OpDef.Types.AttrDef.TypeFieldNumber">
            <summary>Field number for the "type" field.</summary>
        </member>
        <member name="P:Tensorflow.OpDef.Types.AttrDef.Type">
            <summary>
            One of the type names from attr_value.proto ("string", "list(string)",
            "int", etc.).
            </summary>
        </member>
        <member name="F:Tensorflow.OpDef.Types.AttrDef.DefaultValueFieldNumber">
            <summary>Field number for the "default_value" field.</summary>
        </member>
        <member name="P:Tensorflow.OpDef.Types.AttrDef.DefaultValue">
            <summary>
            A reasonable default for this attribute if the user does not supply
            a value.  If not specified, the user must supply a value.
            </summary>
        </member>
        <member name="F:Tensorflow.OpDef.Types.AttrDef.DescriptionFieldNumber">
            <summary>Field number for the "description" field.</summary>
        </member>
        <member name="P:Tensorflow.OpDef.Types.AttrDef.Description">
            <summary>
            Human-readable description.
            </summary>
        </member>
        <member name="F:Tensorflow.OpDef.Types.AttrDef.HasMinimumFieldNumber">
            <summary>Field number for the "has_minimum" field.</summary>
        </member>
        <member name="P:Tensorflow.OpDef.Types.AttrDef.HasMinimum">
            <summary>
            For type == "int", this is a minimum value.  For "list(___)"
            types, this is the minimum length.
            </summary>
        </member>
        <member name="F:Tensorflow.OpDef.Types.AttrDef.MinimumFieldNumber">
            <summary>Field number for the "minimum" field.</summary>
        </member>
        <member name="F:Tensorflow.OpDef.Types.AttrDef.AllowedValuesFieldNumber">
            <summary>Field number for the "allowed_values" field.</summary>
        </member>
        <member name="P:Tensorflow.OpDef.Types.AttrDef.AllowedValues">
            <summary>
            The set of allowed values.  Has type that is the "list" version
            of the "type" field above (uses the "list" field of AttrValue).
            If type == "type" or "list(type)" above, then the "type" field
            of "allowed_values.list" has the set of allowed DataTypes.
            If type == "string" or "list(string)", then the "s" field of
            "allowed_values.list" has the set of allowed strings.
            </summary>
        </member>
        <member name="T:Tensorflow.OpDeprecation">
            <summary>
            Information about version-dependent deprecation of an op
            </summary>
        </member>
        <member name="F:Tensorflow.OpDeprecation.VersionFieldNumber">
            <summary>Field number for the "version" field.</summary>
        </member>
        <member name="P:Tensorflow.OpDeprecation.Version">
            <summary>
            First GraphDef version at which the op is disallowed.
            </summary>
        </member>
        <member name="F:Tensorflow.OpDeprecation.ExplanationFieldNumber">
            <summary>Field number for the "explanation" field.</summary>
        </member>
        <member name="P:Tensorflow.OpDeprecation.Explanation">
            <summary>
            Explanation of why it was deprecated and what to use instead.
            </summary>
        </member>
        <member name="T:Tensorflow.OpList">
            <summary>
            A collection of OpDefs
            </summary>
        </member>
        <member name="F:Tensorflow.OpList.OpFieldNumber">
            <summary>Field number for the "op" field.</summary>
        </member>
        <member name="T:Tensorflow.ReaderBaseReflection">
            <summary>Holder for reflection information generated from tensorflow/core/framework/reader_base.proto</summary>
        </member>
        <member name="P:Tensorflow.ReaderBaseReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/framework/reader_base.proto</summary>
        </member>
        <member name="T:Tensorflow.ReaderBaseState">
            <summary>
            For serializing and restoring the state of ReaderBase, see
            reader_base.h for details.
            </summary>
        </member>
        <member name="F:Tensorflow.ReaderBaseState.WorkStartedFieldNumber">
            <summary>Field number for the "work_started" field.</summary>
        </member>
        <member name="F:Tensorflow.ReaderBaseState.WorkFinishedFieldNumber">
            <summary>Field number for the "work_finished" field.</summary>
        </member>
        <member name="F:Tensorflow.ReaderBaseState.NumRecordsProducedFieldNumber">
            <summary>Field number for the "num_records_produced" field.</summary>
        </member>
        <member name="F:Tensorflow.ReaderBaseState.CurrentWorkFieldNumber">
            <summary>Field number for the "current_work" field.</summary>
        </member>
        <member name="T:Tensorflow.ResourceHandleReflection">
            <summary>Holder for reflection information generated from tensorflow/core/framework/resource_handle.proto</summary>
        </member>
        <member name="P:Tensorflow.ResourceHandleReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/framework/resource_handle.proto</summary>
        </member>
        <member name="T:Tensorflow.ResourceHandleProto">
            <summary>
            Protocol buffer representing a handle to a tensorflow resource. Handles are
            not valid across executions, but can be serialized back and forth from within
            a single run.
            </summary>
        </member>
        <member name="F:Tensorflow.ResourceHandleProto.DeviceFieldNumber">
            <summary>Field number for the "device" field.</summary>
        </member>
        <member name="P:Tensorflow.ResourceHandleProto.Device">
            <summary>
            Unique name for the device containing the resource.
            </summary>
        </member>
        <member name="F:Tensorflow.ResourceHandleProto.ContainerFieldNumber">
            <summary>Field number for the "container" field.</summary>
        </member>
        <member name="P:Tensorflow.ResourceHandleProto.Container">
            <summary>
            Container in which this resource is placed.
            </summary>
        </member>
        <member name="F:Tensorflow.ResourceHandleProto.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Tensorflow.ResourceHandleProto.Name">
            <summary>
            Unique name of this resource.
            </summary>
        </member>
        <member name="F:Tensorflow.ResourceHandleProto.HashCodeFieldNumber">
            <summary>Field number for the "hash_code" field.</summary>
        </member>
        <member name="P:Tensorflow.ResourceHandleProto.HashCode">
            <summary>
            Hash code for the type of the resource. Is only valid in the same device
            and in the same execution.
            </summary>
        </member>
        <member name="F:Tensorflow.ResourceHandleProto.MaybeTypeNameFieldNumber">
            <summary>Field number for the "maybe_type_name" field.</summary>
        </member>
        <member name="P:Tensorflow.ResourceHandleProto.MaybeTypeName">
            <summary>
            For debug-only, the name of the type pointed to by this handle, if
            available.
            </summary>
        </member>
        <member name="F:Tensorflow.ResourceHandleProto.DtypesAndShapesFieldNumber">
            <summary>Field number for the "dtypes_and_shapes" field.</summary>
        </member>
        <member name="P:Tensorflow.ResourceHandleProto.DtypesAndShapes">
            <summary>
            Data types and shapes for the underlying resource.
            </summary>
        </member>
        <member name="T:Tensorflow.ResourceHandleProto.Types">
            <summary>Container for nested types declared in the ResourceHandleProto message type.</summary>
        </member>
        <member name="T:Tensorflow.ResourceHandleProto.Types.DtypeAndShape">
            <summary>
            Protocol buffer representing a pair of (data type, tensor shape).
            </summary>
        </member>
        <member name="F:Tensorflow.ResourceHandleProto.Types.DtypeAndShape.DtypeFieldNumber">
            <summary>Field number for the "dtype" field.</summary>
        </member>
        <member name="F:Tensorflow.ResourceHandleProto.Types.DtypeAndShape.ShapeFieldNumber">
            <summary>Field number for the "shape" field.</summary>
        </member>
        <member name="T:Tensorflow.RewriterConfigReflection">
            <summary>Holder for reflection information generated from tensorflow/core/protobuf/rewriter_config.proto</summary>
        </member>
        <member name="P:Tensorflow.RewriterConfigReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/protobuf/rewriter_config.proto</summary>
        </member>
        <member name="F:Tensorflow.AutoParallelOptions.EnableFieldNumber">
            <summary>Field number for the "enable" field.</summary>
        </member>
        <member name="F:Tensorflow.AutoParallelOptions.NumReplicasFieldNumber">
            <summary>Field number for the "num_replicas" field.</summary>
        </member>
        <member name="F:Tensorflow.ScopedAllocatorOptions.EnableOpFieldNumber">
            <summary>Field number for the "enable_op" field.</summary>
        </member>
        <member name="P:Tensorflow.ScopedAllocatorOptions.EnableOp">
            <summary>
            If present, only perform optimization for these ops.
            </summary>
        </member>
        <member name="T:Tensorflow.RewriterConfig">
            <summary>
            Graph rewriting is experimental and subject to change, not covered by any
            API stability guarantees.
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.LayoutOptimizerFieldNumber">
            <summary>Field number for the "layout_optimizer" field.</summary>
        </member>
        <member name="P:Tensorflow.RewriterConfig.LayoutOptimizer">
            <summary>
            Optimize tensor layouts (default is ON)
            e.g. This will try to use NCHW layout on GPU which is faster.
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.ConstantFoldingFieldNumber">
            <summary>Field number for the "constant_folding" field.</summary>
        </member>
        <member name="P:Tensorflow.RewriterConfig.ConstantFolding">
            <summary>
            Fold constants (default is ON)
            Statically infer the value of tensors when possible, and materialize the
            result using constants.
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.ShapeOptimizationFieldNumber">
            <summary>Field number for the "shape_optimization" field.</summary>
        </member>
        <member name="P:Tensorflow.RewriterConfig.ShapeOptimization">
            <summary>
            Shape optimizations (default is ON)
            Simplify computations made on shapes.
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.RemappingFieldNumber">
            <summary>Field number for the "remapping" field.</summary>
        </member>
        <member name="P:Tensorflow.RewriterConfig.Remapping">
            <summary>
            Remapping (default is ON)
            Remap subgraphs onto more efficient implementations.
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.CommonSubgraphEliminationFieldNumber">
            <summary>Field number for the "common_subgraph_elimination" field.</summary>
        </member>
        <member name="P:Tensorflow.RewriterConfig.CommonSubgraphElimination">
            <summary>
            Common subgraph elimination (default is ON)
            e.g. Simplify arithmetic ops; merge ops with same value (like constants).
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.ArithmeticOptimizationFieldNumber">
            <summary>Field number for the "arithmetic_optimization" field.</summary>
        </member>
        <member name="P:Tensorflow.RewriterConfig.ArithmeticOptimization">
            <summary>
            Arithmetic optimizations (default is ON)
            e.g. Simplify arithmetic ops; merge ops with same value (like constants).
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.DependencyOptimizationFieldNumber">
            <summary>Field number for the "dependency_optimization" field.</summary>
        </member>
        <member name="P:Tensorflow.RewriterConfig.DependencyOptimization">
            <summary>
            Control dependency optimizations (default is ON).
            Remove redundant control dependencies, which may enable other optimization.
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.LoopOptimizationFieldNumber">
            <summary>Field number for the "loop_optimization" field.</summary>
        </member>
        <member name="P:Tensorflow.RewriterConfig.LoopOptimization">
            <summary>
            Loop optimizations (default is ON).
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.FunctionOptimizationFieldNumber">
            <summary>Field number for the "function_optimization" field.</summary>
        </member>
        <member name="P:Tensorflow.RewriterConfig.FunctionOptimization">
            <summary>
            Function optimizations (default is ON).
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.DebugStripperFieldNumber">
            <summary>Field number for the "debug_stripper" field.</summary>
        </member>
        <member name="P:Tensorflow.RewriterConfig.DebugStripper">
            <summary>
            Strips debug-related nodes from the graph (off by default).
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.DisableModelPruningFieldNumber">
            <summary>Field number for the "disable_model_pruning" field.</summary>
        </member>
        <member name="P:Tensorflow.RewriterConfig.DisableModelPruning">
            <summary>
            If true, don't remove unnecessary ops from the graph
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.ScopedAllocatorOptimizationFieldNumber">
            <summary>Field number for the "scoped_allocator_optimization" field.</summary>
        </member>
        <member name="P:Tensorflow.RewriterConfig.ScopedAllocatorOptimization">
            <summary>
            Try to allocate some independent Op outputs contiguously in order to
            merge or eliminate downstream Ops (off by default).
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.PinToHostOptimizationFieldNumber">
            <summary>Field number for the "pin_to_host_optimization" field.</summary>
        </member>
        <member name="P:Tensorflow.RewriterConfig.PinToHostOptimization">
            <summary>
            Force small ops onto the CPU (default is OFF).
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.ImplementationSelectorFieldNumber">
            <summary>Field number for the "implementation_selector" field.</summary>
        </member>
        <member name="P:Tensorflow.RewriterConfig.ImplementationSelector">
            <summary>
            Enable the swap of kernel implementations based on the device placement
            (default is ON).
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.AutoMixedPrecisionFieldNumber">
            <summary>Field number for the "auto_mixed_precision" field.</summary>
        </member>
        <member name="P:Tensorflow.RewriterConfig.AutoMixedPrecision">
            <summary>
            Optimize data types for CUDA (default is OFF).
            This will try to use float16 on GPU which is faster.
            Note that this can change the numerical stability of the graph and may
            require the use of loss scaling to maintain model convergence.
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.AutoMixedPrecisionMklFieldNumber">
            <summary>Field number for the "auto_mixed_precision_mkl" field.</summary>
        </member>
        <member name="P:Tensorflow.RewriterConfig.AutoMixedPrecisionMkl">
            <summary>
            Optimize data types for MKL (default is OFF).
            This will try to use bfloat16 on CPUs, which is faster.
            Note that this can change the numerical stability of the graph.
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.DisableMetaOptimizerFieldNumber">
            <summary>Field number for the "disable_meta_optimizer" field.</summary>
        </member>
        <member name="P:Tensorflow.RewriterConfig.DisableMetaOptimizer">
            <summary>
            Disable the entire meta optimizer (off by default).
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.MetaOptimizerIterationsFieldNumber">
            <summary>Field number for the "meta_optimizer_iterations" field.</summary>
        </member>
        <member name="P:Tensorflow.RewriterConfig.MetaOptimizerIterations">
            <summary>
            Controls how many times we run the optimizers in meta optimizer (default
            is once).
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.MinGraphNodesFieldNumber">
            <summary>Field number for the "min_graph_nodes" field.</summary>
        </member>
        <member name="P:Tensorflow.RewriterConfig.MinGraphNodes">
            <summary>
            The minimum number of nodes in a graph to optimizer. For smaller graphs,
            optimization is skipped.
            0 means the system picks an appropriate number.
            &lt; 0 means do not skip optimization.
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.MemoryOptimizationFieldNumber">
            <summary>Field number for the "memory_optimization" field.</summary>
        </member>
        <member name="P:Tensorflow.RewriterConfig.MemoryOptimization">
            <summary>
            Configures memory optimization passes through the meta-optimizer. Has no
            effect on manually requested memory optimization passes in the optimizers
            field.
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.MemoryOptimizerTargetNodeNameScopeFieldNumber">
            <summary>Field number for the "memory_optimizer_target_node_name_scope" field.</summary>
        </member>
        <member name="P:Tensorflow.RewriterConfig.MemoryOptimizerTargetNodeNameScope">
            <summary>
            A node name scope for node names which are valid outputs of recomputations.
            Inputs to nodes that match this scope may be recomputed (subject either to
            manual annotation of those input nodes or to manual annotation and
            heuristics depending on memory_optimization), but the nodes themselves will
            not be recomputed. This matches any sub-scopes as well, meaning the scope
            can appear not just as a top-level scope. For example, if the value is
            "gradients/", the default, it will match node name "gradients/foo",
            "foo/gradients/bar", but not "foo_gradients/"
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.MetaOptimizerTimeoutMsFieldNumber">
            <summary>Field number for the "meta_optimizer_timeout_ms" field.</summary>
        </member>
        <member name="P:Tensorflow.RewriterConfig.MetaOptimizerTimeoutMs">
            <summary>
            Maximum number of milliseconds to spend optimizing a single graph before
            timing out. If equal to 0 the system picks a default (currently 5 minutes).
            If less than 0 the optimizer will never time out.
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.AutoParallelFieldNumber">
            <summary>Field number for the "auto_parallel" field.</summary>
        </member>
        <member name="P:Tensorflow.RewriterConfig.AutoParallel">
            <summary>
            Configures AutoParallel optimization passes either through the
            meta-optimizer or when manually specified through the optimizers field.
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.FailOnOptimizerErrorsFieldNumber">
            <summary>Field number for the "fail_on_optimizer_errors" field.</summary>
        </member>
        <member name="P:Tensorflow.RewriterConfig.FailOnOptimizerErrors">
            <summary>
            If true, any optimization pass failing will cause the MetaOptimizer to
            stop with an error. By default - or when set to false, failing passes are
            skipped silently.
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.ScopedAllocatorOptsFieldNumber">
            <summary>Field number for the "scoped_allocator_opts" field.</summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.OptimizersFieldNumber">
            <summary>Field number for the "optimizers" field.</summary>
        </member>
        <member name="P:Tensorflow.RewriterConfig.Optimizers">
             <summary>
             If non-empty, will use this as an alternative way to specify a list of
             optimizations to turn on and the order of the optimizations (replacing the
             meta-optimizer).
            
             Of the RewriterConfig options, only the AutoParallel configuration options
             (the auto_parallel field) apply to manually requested optimization passes
             ("autoparallel"). Memory optimization passes ("memory") invoked here are
             not configurable (in contrast to memory optimization passes through the
             meta-optimizer) and act only on manual op annotations.
            
             Custom optimizers (see custom_optimizers) that are not part of this
             schedule will be run after - in the order that they were specified.
             </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.CustomOptimizersFieldNumber">
            <summary>Field number for the "custom_optimizers" field.</summary>
        </member>
        <member name="P:Tensorflow.RewriterConfig.CustomOptimizers">
            <summary>
            list of CustomGraphOptimizers to apply.
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.InterOptimizerVerifierConfigFieldNumber">
            <summary>Field number for the "inter_optimizer_verifier_config" field.</summary>
        </member>
        <member name="P:Tensorflow.RewriterConfig.InterOptimizerVerifierConfig">
            <summary>
            VerifierConfig specifying the verifiers to be run after every optimizer.
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.PostOptimizationVerifierConfigFieldNumber">
            <summary>Field number for the "post_optimization_verifier_config" field.</summary>
        </member>
        <member name="P:Tensorflow.RewriterConfig.PostOptimizationVerifierConfig">
            <summary>
            VerifierConfig specifying the verifiers to be run at the end, after all
            optimizers have run.
            </summary>
        </member>
        <member name="T:Tensorflow.RewriterConfig.Types">
            <summary>Container for nested types declared in the RewriterConfig message type.</summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.Types.Toggle.Aggressive">
            <summary>
            Enable some aggressive optimizations that use assumptions that TF graphs
            may break. For example, assume the shape of a placeholder matches its
            actual feed.
            </summary>
        </member>
        <member name="T:Tensorflow.RewriterConfig.Types.NumIterationsType">
            <summary>
            Enum controlling the number of times to run optimizers. The default is to
            run them twice.
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.Types.MemOptType.DefaultMemOpt">
            <summary>
            The default setting (SCHEDULING and SWAPPING HEURISTICS only)
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.Types.MemOptType.NoMemOpt">
            <summary>
            Disabled in the meta-optimizer.
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.Types.MemOptType.Manual">
            <summary>
            Driven by manual op-level annotations.
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.Types.MemOptType.SwappingHeuristics">
            <summary>
            Swapping heuristic will move a tensor from the GPU to the CPU and move
            it back when needed to reduce peak memory usage.
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.Types.MemOptType.RecomputationHeuristics">
            <summary>
            Recomputation heuristics will recompute ops (such as Relu activation)
            during backprop instead of storing them, reducing peak memory usage.
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.Types.MemOptType.SchedulingHeuristics">
            <summary>
            Scheduling will split big ops such as AddN and try to enforce a schedule
            of the new computations that decreases peak memory usage.
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.Types.MemOptType.Heuristics">
            <summary>
            Use any combination of swapping and recomputation heuristics.
            </summary>
        </member>
        <member name="T:Tensorflow.RewriterConfig.Types.CustomGraphOptimizer">
            <summary>
            Message to describe custom graph optimizer and its parameters
            </summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.Types.CustomGraphOptimizer.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="F:Tensorflow.RewriterConfig.Types.CustomGraphOptimizer.ParameterMapFieldNumber">
            <summary>Field number for the "parameter_map" field.</summary>
        </member>
        <member name="T:Tensorflow.SavedObjectGraphReflection">
            <summary>Holder for reflection information generated from tensorflow/core/protobuf/saved_object_graph.proto</summary>
        </member>
        <member name="P:Tensorflow.SavedObjectGraphReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/protobuf/saved_object_graph.proto</summary>
        </member>
        <member name="F:Tensorflow.SavedObjectGraph.NodesFieldNumber">
            <summary>Field number for the "nodes" field.</summary>
        </member>
        <member name="P:Tensorflow.SavedObjectGraph.Nodes">
             <summary>
             Flattened list of objects in the object graph.
            
             The position of the object in this list indicates its id.
             Nodes[0] is considered the root node.
             </summary>
        </member>
        <member name="F:Tensorflow.SavedObjectGraph.ConcreteFunctionsFieldNumber">
            <summary>Field number for the "concrete_functions" field.</summary>
        </member>
        <member name="P:Tensorflow.SavedObjectGraph.ConcreteFunctions">
            <summary>
            Information about captures and output structures in concrete functions.
            Referenced from SavedBareConcreteFunction and SavedFunction.
            </summary>
        </member>
        <member name="F:Tensorflow.SavedObject.ChildrenFieldNumber">
            <summary>Field number for the "children" field.</summary>
        </member>
        <member name="P:Tensorflow.SavedObject.Children">
             <summary>
             Objects which this object depends on: named edges in the dependency
             graph.
            
             Note: currently only valid if kind == "user_object".
             </summary>
        </member>
        <member name="F:Tensorflow.SavedObject.SlotVariablesFieldNumber">
            <summary>Field number for the "slot_variables" field.</summary>
        </member>
        <member name="P:Tensorflow.SavedObject.SlotVariables">
             <summary>
             Slot variables owned by this object. This describes the three-way
             (optimizer, variable, slot variable) relationship; none of the three
             depend on the others directly.
            
             Note: currently only valid if kind == "user_object".
             </summary>
        </member>
        <member name="F:Tensorflow.SavedObject.UserObjectFieldNumber">
            <summary>Field number for the "user_object" field.</summary>
        </member>
        <member name="F:Tensorflow.SavedObject.AssetFieldNumber">
            <summary>Field number for the "asset" field.</summary>
        </member>
        <member name="F:Tensorflow.SavedObject.FunctionFieldNumber">
            <summary>Field number for the "function" field.</summary>
        </member>
        <member name="F:Tensorflow.SavedObject.VariableFieldNumber">
            <summary>Field number for the "variable" field.</summary>
        </member>
        <member name="F:Tensorflow.SavedObject.BareConcreteFunctionFieldNumber">
            <summary>Field number for the "bare_concrete_function" field.</summary>
        </member>
        <member name="F:Tensorflow.SavedObject.ConstantFieldNumber">
            <summary>Field number for the "constant" field.</summary>
        </member>
        <member name="F:Tensorflow.SavedObject.ResourceFieldNumber">
            <summary>Field number for the "resource" field.</summary>
        </member>
        <member name="F:Tensorflow.SavedObject.SaveableObjectsFieldNumber">
            <summary>Field number for the "saveable_objects" field.</summary>
        </member>
        <member name="T:Tensorflow.SavedObject.KindOneofCase">
            <summary>Enum of possible cases for the "kind" oneof.</summary>
        </member>
        <member name="T:Tensorflow.SavedUserObject">
             <summary>
             A SavedUserObject is an object (in the object-oriented language of the
             TensorFlow program) of some user- or framework-defined class other than
             those handled specifically by the other kinds of SavedObjects.
            
             This object cannot be evaluated as a tensor, and therefore cannot be bound
             to an input of a function.
             </summary>
        </member>
        <member name="F:Tensorflow.SavedUserObject.IdentifierFieldNumber">
            <summary>Field number for the "identifier" field.</summary>
        </member>
        <member name="P:Tensorflow.SavedUserObject.Identifier">
            <summary>
            Corresponds to a registration of the type to use in the loading program.
            </summary>
        </member>
        <member name="F:Tensorflow.SavedUserObject.VersionFieldNumber">
            <summary>Field number for the "version" field.</summary>
        </member>
        <member name="P:Tensorflow.SavedUserObject.Version">
            <summary>
            Version information from the producer of this SavedUserObject.
            </summary>
        </member>
        <member name="F:Tensorflow.SavedUserObject.MetadataFieldNumber">
            <summary>Field number for the "metadata" field.</summary>
        </member>
        <member name="P:Tensorflow.SavedUserObject.Metadata">
            <summary>
            Initialization-related metadata.
            </summary>
        </member>
        <member name="T:Tensorflow.SavedAsset">
             <summary>
             A SavedAsset points to an asset in the MetaGraph.
            
             When bound to a function this object evaluates to a tensor with the absolute
             filename. Users should not depend on a particular part of the filename to
             remain stable (e.g. basename could be changed).
             </summary>
        </member>
        <member name="F:Tensorflow.SavedAsset.AssetFileDefIndexFieldNumber">
            <summary>Field number for the "asset_file_def_index" field.</summary>
        </member>
        <member name="P:Tensorflow.SavedAsset.AssetFileDefIndex">
             <summary>
             Index into `MetaGraphDef.asset_file_def[]` that describes the Asset.
            
             Only the field `AssetFileDef.filename` is used. Other fields, such as
             `AssetFileDef.tensor_info`, MUST be ignored.
             </summary>
        </member>
        <member name="T:Tensorflow.SavedFunction">
            <summary>
            A function with multiple signatures, possibly with non-Tensor arguments.
            </summary>
        </member>
        <member name="F:Tensorflow.SavedFunction.ConcreteFunctionsFieldNumber">
            <summary>Field number for the "concrete_functions" field.</summary>
        </member>
        <member name="F:Tensorflow.SavedFunction.FunctionSpecFieldNumber">
            <summary>Field number for the "function_spec" field.</summary>
        </member>
        <member name="T:Tensorflow.SavedConcreteFunction">
            <summary>
            Stores low-level information about a concrete function. Referenced in either
            a SavedFunction or a SavedBareConcreteFunction.
            </summary>
        </member>
        <member name="F:Tensorflow.SavedConcreteFunction.BoundInputsFieldNumber">
            <summary>Field number for the "bound_inputs" field.</summary>
        </member>
        <member name="P:Tensorflow.SavedConcreteFunction.BoundInputs">
            <summary>
            Bound inputs to the function. The SavedObjects identified by the node ids
            given here are appended as extra inputs to the caller-supplied inputs.
            The only types of SavedObjects valid here are SavedVariable, SavedResource
            and SavedAsset.
            </summary>
        </member>
        <member name="F:Tensorflow.SavedConcreteFunction.CanonicalizedInputSignatureFieldNumber">
            <summary>Field number for the "canonicalized_input_signature" field.</summary>
        </member>
        <member name="P:Tensorflow.SavedConcreteFunction.CanonicalizedInputSignature">
            <summary>
            Input in canonicalized form that was received to create this concrete
            function.
            </summary>
        </member>
        <member name="F:Tensorflow.SavedConcreteFunction.OutputSignatureFieldNumber">
            <summary>Field number for the "output_signature" field.</summary>
        </member>
        <member name="P:Tensorflow.SavedConcreteFunction.OutputSignature">
            <summary>
            Output that was the return value of this function after replacing all
            Tensors with TensorSpecs. This can be an arbitrary nested function and will
            be used to reconstruct the full structure from pure tensors.
            </summary>
        </member>
        <member name="F:Tensorflow.SavedBareConcreteFunction.ConcreteFunctionNameFieldNumber">
            <summary>Field number for the "concrete_function_name" field.</summary>
        </member>
        <member name="P:Tensorflow.SavedBareConcreteFunction.ConcreteFunctionName">
            <summary>
            Identifies a SavedConcreteFunction.
            </summary>
        </member>
        <member name="F:Tensorflow.SavedBareConcreteFunction.ArgumentKeywordsFieldNumber">
            <summary>Field number for the "argument_keywords" field.</summary>
        </member>
        <member name="P:Tensorflow.SavedBareConcreteFunction.ArgumentKeywords">
            <summary>
            A sequence of unique strings, one per Tensor argument.
            </summary>
        </member>
        <member name="F:Tensorflow.SavedBareConcreteFunction.AllowedPositionalArgumentsFieldNumber">
            <summary>Field number for the "allowed_positional_arguments" field.</summary>
        </member>
        <member name="P:Tensorflow.SavedBareConcreteFunction.AllowedPositionalArguments">
            <summary>
            The prefix of `argument_keywords` which may be identified by position.
            </summary>
        </member>
        <member name="F:Tensorflow.SavedConstant.OperationFieldNumber">
            <summary>Field number for the "operation" field.</summary>
        </member>
        <member name="P:Tensorflow.SavedConstant.Operation">
            <summary>
            An Operation name for a ConstantOp in this SavedObjectGraph's MetaGraph.
            </summary>
        </member>
        <member name="T:Tensorflow.SavedVariable">
            <summary>
            Represents a Variable that is initialized by loading the contents from the
            checkpoint.
            </summary>
        </member>
        <member name="F:Tensorflow.SavedVariable.DtypeFieldNumber">
            <summary>Field number for the "dtype" field.</summary>
        </member>
        <member name="F:Tensorflow.SavedVariable.ShapeFieldNumber">
            <summary>Field number for the "shape" field.</summary>
        </member>
        <member name="F:Tensorflow.SavedVariable.TrainableFieldNumber">
            <summary>Field number for the "trainable" field.</summary>
        </member>
        <member name="F:Tensorflow.SavedVariable.SynchronizationFieldNumber">
            <summary>Field number for the "synchronization" field.</summary>
        </member>
        <member name="F:Tensorflow.SavedVariable.AggregationFieldNumber">
            <summary>Field number for the "aggregation" field.</summary>
        </member>
        <member name="F:Tensorflow.SavedVariable.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="T:Tensorflow.FunctionSpec">
            <summary>
            Represents `FunctionSpec` used in `Function`. This represents a
            function that has been wrapped as a TensorFlow `Function`.
            </summary>
        </member>
        <member name="F:Tensorflow.FunctionSpec.FullargspecFieldNumber">
            <summary>Field number for the "fullargspec" field.</summary>
        </member>
        <member name="P:Tensorflow.FunctionSpec.Fullargspec">
            <summary>
            Full arg spec from inspect.getfullargspec().
            </summary>
        </member>
        <member name="F:Tensorflow.FunctionSpec.IsMethodFieldNumber">
            <summary>Field number for the "is_method" field.</summary>
        </member>
        <member name="P:Tensorflow.FunctionSpec.IsMethod">
            <summary>
            Whether this represents a class method.
            </summary>
        </member>
        <member name="F:Tensorflow.FunctionSpec.InputSignatureFieldNumber">
            <summary>Field number for the "input_signature" field.</summary>
        </member>
        <member name="P:Tensorflow.FunctionSpec.InputSignature">
            <summary>
            The input signature, if specified.
            </summary>
        </member>
        <member name="T:Tensorflow.SavedResource">
            <summary>
            A SavedResource represents a TF object that holds state during its lifetime.
            An object of this type can have a reference to a:
            create_resource() and an initialize() function.
            </summary>
        </member>
        <member name="F:Tensorflow.SavedResource.DeviceFieldNumber">
            <summary>Field number for the "device" field.</summary>
        </member>
        <member name="P:Tensorflow.SavedResource.Device">
            <summary>
            A device specification indicating a required placement for the resource
            creation function, e.g. "CPU". An empty string allows the user to select a
            device.
            </summary>
        </member>
        <member name="F:Tensorflow.SaveableObject.SaveFunctionFieldNumber">
            <summary>Field number for the "save_function" field.</summary>
        </member>
        <member name="P:Tensorflow.SaveableObject.SaveFunction">
            <summary>
            Node ids of concrete functions for saving and loading from a checkpoint.
            </summary>
        </member>
        <member name="F:Tensorflow.SaveableObject.RestoreFunctionFieldNumber">
            <summary>Field number for the "restore_function" field.</summary>
        </member>
        <member name="T:Tensorflow.SaverReflection">
            <summary>Holder for reflection information generated from tensorflow/core/protobuf/saver.proto</summary>
        </member>
        <member name="P:Tensorflow.SaverReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/protobuf/saver.proto</summary>
        </member>
        <member name="T:Tensorflow.SaverDef">
            <summary>
            Protocol buffer representing the configuration of a Saver.
            </summary>
        </member>
        <member name="F:Tensorflow.SaverDef.FilenameTensorNameFieldNumber">
            <summary>Field number for the "filename_tensor_name" field.</summary>
        </member>
        <member name="P:Tensorflow.SaverDef.FilenameTensorName">
            <summary>
            The name of the tensor in which to specify the filename when saving or
            restoring a model checkpoint.
            </summary>
        </member>
        <member name="F:Tensorflow.SaverDef.SaveTensorNameFieldNumber">
            <summary>Field number for the "save_tensor_name" field.</summary>
        </member>
        <member name="P:Tensorflow.SaverDef.SaveTensorName">
            <summary>
            The operation to run when saving a model checkpoint.
            </summary>
        </member>
        <member name="F:Tensorflow.SaverDef.RestoreOpNameFieldNumber">
            <summary>Field number for the "restore_op_name" field.</summary>
        </member>
        <member name="P:Tensorflow.SaverDef.RestoreOpName">
            <summary>
            The operation to run when restoring a model checkpoint.
            </summary>
        </member>
        <member name="F:Tensorflow.SaverDef.MaxToKeepFieldNumber">
            <summary>Field number for the "max_to_keep" field.</summary>
        </member>
        <member name="P:Tensorflow.SaverDef.MaxToKeep">
            <summary>
            Maximum number of checkpoints to keep.  If 0, no checkpoints are deleted.
            </summary>
        </member>
        <member name="F:Tensorflow.SaverDef.ShardedFieldNumber">
            <summary>Field number for the "sharded" field.</summary>
        </member>
        <member name="P:Tensorflow.SaverDef.Sharded">
            <summary>
            Shard the save files, one per device that has Variable nodes.
            </summary>
        </member>
        <member name="F:Tensorflow.SaverDef.KeepCheckpointEveryNHoursFieldNumber">
            <summary>Field number for the "keep_checkpoint_every_n_hours" field.</summary>
        </member>
        <member name="P:Tensorflow.SaverDef.KeepCheckpointEveryNHours">
            <summary>
            How often to keep an additional checkpoint. If not specified, only the last
            "max_to_keep" checkpoints are kept; if specified, in addition to keeping
            the last "max_to_keep" checkpoints, an additional checkpoint will be kept
            for every n hours of training.
            </summary>
        </member>
        <member name="F:Tensorflow.SaverDef.VersionFieldNumber">
            <summary>Field number for the "version" field.</summary>
        </member>
        <member name="T:Tensorflow.SaverDef.Types">
            <summary>Container for nested types declared in the SaverDef message type.</summary>
        </member>
        <member name="T:Tensorflow.SaverDef.Types.CheckpointFormatVersion">
            <summary>
            A version number that identifies a different on-disk checkpoint format.
            Usually, each subclass of BaseSaverBuilder works with a particular
            version/format.  However, it is possible that the same builder may be
            upgraded to support a newer checkpoint format in the future.
            </summary>
        </member>
        <member name="F:Tensorflow.SaverDef.Types.CheckpointFormatVersion.Legacy">
            <summary>
            Internal legacy format.
            </summary>
        </member>
        <member name="F:Tensorflow.SaverDef.Types.CheckpointFormatVersion.V1">
            <summary>
            Deprecated format: tf.Saver() which works with tensorflow::table::Table.
            </summary>
        </member>
        <member name="F:Tensorflow.SaverDef.Types.CheckpointFormatVersion.V2">
            <summary>
            Current format: more efficient.
            </summary>
        </member>
        <member name="T:Tensorflow.StepStatsReflection">
            <summary>Holder for reflection information generated from tensorflow/core/framework/step_stats.proto</summary>
        </member>
        <member name="P:Tensorflow.StepStatsReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/framework/step_stats.proto</summary>
        </member>
        <member name="T:Tensorflow.AllocationRecord">
            <summary>
            An allocation/de-allocation operation performed by the allocator.
            </summary>
        </member>
        <member name="F:Tensorflow.AllocationRecord.AllocMicrosFieldNumber">
            <summary>Field number for the "alloc_micros" field.</summary>
        </member>
        <member name="P:Tensorflow.AllocationRecord.AllocMicros">
            <summary>
            The timestamp of the operation.
            </summary>
        </member>
        <member name="F:Tensorflow.AllocationRecord.AllocBytesFieldNumber">
            <summary>Field number for the "alloc_bytes" field.</summary>
        </member>
        <member name="P:Tensorflow.AllocationRecord.AllocBytes">
            <summary>
            Number of bytes allocated, or de-allocated if negative.
            </summary>
        </member>
        <member name="F:Tensorflow.AllocatorMemoryUsed.AllocatorNameFieldNumber">
            <summary>Field number for the "allocator_name" field.</summary>
        </member>
        <member name="F:Tensorflow.AllocatorMemoryUsed.TotalBytesFieldNumber">
            <summary>Field number for the "total_bytes" field.</summary>
        </member>
        <member name="P:Tensorflow.AllocatorMemoryUsed.TotalBytes">
            <summary>
            These are per-node allocator memory stats.
            </summary>
        </member>
        <member name="F:Tensorflow.AllocatorMemoryUsed.PeakBytesFieldNumber">
            <summary>Field number for the "peak_bytes" field.</summary>
        </member>
        <member name="F:Tensorflow.AllocatorMemoryUsed.LiveBytesFieldNumber">
            <summary>Field number for the "live_bytes" field.</summary>
        </member>
        <member name="P:Tensorflow.AllocatorMemoryUsed.LiveBytes">
            <summary>
            The bytes that are not deallocated.
            </summary>
        </member>
        <member name="F:Tensorflow.AllocatorMemoryUsed.AllocationRecordsFieldNumber">
            <summary>Field number for the "allocation_records" field.</summary>
        </member>
        <member name="P:Tensorflow.AllocatorMemoryUsed.AllocationRecords">
            <summary>
            The allocation and deallocation timeline.
            </summary>
        </member>
        <member name="F:Tensorflow.AllocatorMemoryUsed.AllocatorBytesInUseFieldNumber">
            <summary>Field number for the "allocator_bytes_in_use" field.</summary>
        </member>
        <member name="P:Tensorflow.AllocatorMemoryUsed.AllocatorBytesInUse">
            <summary>
            These are snapshots of the overall allocator memory stats.
            The number of live bytes currently allocated by the allocator.
            </summary>
        </member>
        <member name="T:Tensorflow.NodeOutput">
            <summary>
            Output sizes recorded for a single execution of a graph node.
            </summary>
        </member>
        <member name="F:Tensorflow.NodeOutput.SlotFieldNumber">
            <summary>Field number for the "slot" field.</summary>
        </member>
        <member name="F:Tensorflow.NodeOutput.TensorDescriptionFieldNumber">
            <summary>Field number for the "tensor_description" field.</summary>
        </member>
        <member name="T:Tensorflow.MemoryStats">
            <summary>
            For memory tracking.
            </summary>
        </member>
        <member name="F:Tensorflow.MemoryStats.TempMemorySizeFieldNumber">
            <summary>Field number for the "temp_memory_size" field.</summary>
        </member>
        <member name="F:Tensorflow.MemoryStats.PersistentMemorySizeFieldNumber">
            <summary>Field number for the "persistent_memory_size" field.</summary>
        </member>
        <member name="F:Tensorflow.MemoryStats.PersistentTensorAllocIdsFieldNumber">
            <summary>Field number for the "persistent_tensor_alloc_ids" field.</summary>
        </member>
        <member name="F:Tensorflow.MemoryStats.DeviceTempMemorySizeFieldNumber">
            <summary>Field number for the "device_temp_memory_size" field.</summary>
        </member>
        <member name="F:Tensorflow.MemoryStats.DevicePersistentMemorySizeFieldNumber">
            <summary>Field number for the "device_persistent_memory_size" field.</summary>
        </member>
        <member name="F:Tensorflow.MemoryStats.DevicePersistentTensorAllocIdsFieldNumber">
            <summary>Field number for the "device_persistent_tensor_alloc_ids" field.</summary>
        </member>
        <member name="T:Tensorflow.NodeExecStats">
            <summary>
            Time/size stats recorded for a single execution of a graph node.
            </summary>
        </member>
        <member name="F:Tensorflow.NodeExecStats.NodeNameFieldNumber">
            <summary>Field number for the "node_name" field.</summary>
        </member>
        <member name="P:Tensorflow.NodeExecStats.NodeName">
            <summary>
            TODO(tucker): Use some more compact form of node identity than
            the full string name.  Either all processes should agree on a
            global id (cost_id?) for each node, or we should use a hash of
            the name.
            </summary>
        </member>
        <member name="F:Tensorflow.NodeExecStats.AllStartMicrosFieldNumber">
            <summary>Field number for the "all_start_micros" field.</summary>
        </member>
        <member name="F:Tensorflow.NodeExecStats.OpStartRelMicrosFieldNumber">
            <summary>Field number for the "op_start_rel_micros" field.</summary>
        </member>
        <member name="F:Tensorflow.NodeExecStats.OpEndRelMicrosFieldNumber">
            <summary>Field number for the "op_end_rel_micros" field.</summary>
        </member>
        <member name="F:Tensorflow.NodeExecStats.AllEndRelMicrosFieldNumber">
            <summary>Field number for the "all_end_rel_micros" field.</summary>
        </member>
        <member name="F:Tensorflow.NodeExecStats.MemoryFieldNumber">
            <summary>Field number for the "memory" field.</summary>
        </member>
        <member name="F:Tensorflow.NodeExecStats.OutputFieldNumber">
            <summary>Field number for the "output" field.</summary>
        </member>
        <member name="F:Tensorflow.NodeExecStats.TimelineLabelFieldNumber">
            <summary>Field number for the "timeline_label" field.</summary>
        </member>
        <member name="F:Tensorflow.NodeExecStats.ScheduledMicrosFieldNumber">
            <summary>Field number for the "scheduled_micros" field.</summary>
        </member>
        <member name="F:Tensorflow.NodeExecStats.ThreadIdFieldNumber">
            <summary>Field number for the "thread_id" field.</summary>
        </member>
        <member name="F:Tensorflow.NodeExecStats.ReferencedTensorFieldNumber">
            <summary>Field number for the "referenced_tensor" field.</summary>
        </member>
        <member name="F:Tensorflow.NodeExecStats.MemoryStatsFieldNumber">
            <summary>Field number for the "memory_stats" field.</summary>
        </member>
        <member name="F:Tensorflow.NodeExecStats.AllStartNanosFieldNumber">
            <summary>Field number for the "all_start_nanos" field.</summary>
        </member>
        <member name="F:Tensorflow.NodeExecStats.OpStartRelNanosFieldNumber">
            <summary>Field number for the "op_start_rel_nanos" field.</summary>
        </member>
        <member name="F:Tensorflow.NodeExecStats.OpEndRelNanosFieldNumber">
            <summary>Field number for the "op_end_rel_nanos" field.</summary>
        </member>
        <member name="F:Tensorflow.NodeExecStats.AllEndRelNanosFieldNumber">
            <summary>Field number for the "all_end_rel_nanos" field.</summary>
        </member>
        <member name="F:Tensorflow.NodeExecStats.ScheduledNanosFieldNumber">
            <summary>Field number for the "scheduled_nanos" field.</summary>
        </member>
        <member name="F:Tensorflow.DeviceStepStats.DeviceFieldNumber">
            <summary>Field number for the "device" field.</summary>
        </member>
        <member name="F:Tensorflow.DeviceStepStats.NodeStatsFieldNumber">
            <summary>Field number for the "node_stats" field.</summary>
        </member>
        <member name="F:Tensorflow.DeviceStepStats.ThreadNamesFieldNumber">
            <summary>Field number for the "thread_names" field.</summary>
        </member>
        <member name="P:Tensorflow.DeviceStepStats.ThreadNames">
            <summary>
            Its key is thread id.
            </summary>
        </member>
        <member name="F:Tensorflow.StepStats.DevStatsFieldNumber">
            <summary>Field number for the "dev_stats" field.</summary>
        </member>
        <member name="T:Tensorflow.StructReflection">
            <summary>Holder for reflection information generated from tensorflow/core/protobuf/struct.proto</summary>
        </member>
        <member name="P:Tensorflow.StructReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/protobuf/struct.proto</summary>
        </member>
        <member name="T:Tensorflow.StructuredValue">
             <summary>
             `StructuredValue` represents a dynamically typed value representing various
             data structures that are inspired by Python data structures typically used in
             TensorFlow functions as inputs and outputs.
            
             For example when saving a Layer there may be a `training` argument. If the
             user passes a boolean True/False, that switches between two concrete
             TensorFlow functions. In order to switch between them in the same way after
             loading the SavedModel, we need to represent "True" and "False".
            
             A more advanced example might be a function which takes a list of
             dictionaries mapping from strings to Tensors. In order to map from
             user-specified arguments `[{"a": tf.constant(1.)}, {"q": tf.constant(3.)}]`
             after load to the right saved TensorFlow function, we need to represent the
             nested structure and the strings, recording that we have a trace for anything
             matching `[{"a": tf.TensorSpec(None, tf.float32)}, {"q": tf.TensorSpec([],
             tf.float64)}]` as an example.
            
             Likewise functions may return nested structures of Tensors, for example
             returning a dictionary mapping from strings to Tensors. In order for the
             loaded function to return the same structure we need to serialize it.
            
             This is an ergonomic aid for working with loaded SavedModels, not a promise
             to serialize all possible function signatures. For example we do not expect
             to pickle generic Python objects, and ideally we'd stay language-agnostic.
             </summary>
        </member>
        <member name="F:Tensorflow.StructuredValue.NoneValueFieldNumber">
            <summary>Field number for the "none_value" field.</summary>
        </member>
        <member name="P:Tensorflow.StructuredValue.NoneValue">
            <summary>
            Represents None.
            </summary>
        </member>
        <member name="F:Tensorflow.StructuredValue.Float64ValueFieldNumber">
            <summary>Field number for the "float64_value" field.</summary>
        </member>
        <member name="P:Tensorflow.StructuredValue.Float64Value">
            <summary>
            Represents a double-precision floating-point value (a Python `float`).
            </summary>
        </member>
        <member name="F:Tensorflow.StructuredValue.Int64ValueFieldNumber">
            <summary>Field number for the "int64_value" field.</summary>
        </member>
        <member name="P:Tensorflow.StructuredValue.Int64Value">
            <summary>
            Represents a signed integer value, limited to 64 bits.
            Larger values from Python's arbitrary-precision integers are unsupported.
            </summary>
        </member>
        <member name="F:Tensorflow.StructuredValue.StringValueFieldNumber">
            <summary>Field number for the "string_value" field.</summary>
        </member>
        <member name="P:Tensorflow.StructuredValue.StringValue">
            <summary>
            Represents a string of Unicode characters stored in a Python `str`.
            In Python 3, this is exactly what type `str` is.
            In Python 2, this is the UTF-8 encoding of the characters.
            For strings with ASCII characters only (as often used in TensorFlow code)
            there is effectively no difference between the language versions.
            The obsolescent `unicode` type of Python 2 is not supported here.
            </summary>
        </member>
        <member name="F:Tensorflow.StructuredValue.BoolValueFieldNumber">
            <summary>Field number for the "bool_value" field.</summary>
        </member>
        <member name="P:Tensorflow.StructuredValue.BoolValue">
            <summary>
            Represents a boolean value.
            </summary>
        </member>
        <member name="F:Tensorflow.StructuredValue.TensorShapeValueFieldNumber">
            <summary>Field number for the "tensor_shape_value" field.</summary>
        </member>
        <member name="P:Tensorflow.StructuredValue.TensorShapeValue">
            <summary>
            Represents a TensorShape.
            </summary>
        </member>
        <member name="F:Tensorflow.StructuredValue.TensorDtypeValueFieldNumber">
            <summary>Field number for the "tensor_dtype_value" field.</summary>
        </member>
        <member name="P:Tensorflow.StructuredValue.TensorDtypeValue">
            <summary>
            Represents an enum value for dtype.
            </summary>
        </member>
        <member name="F:Tensorflow.StructuredValue.TensorSpecValueFieldNumber">
            <summary>Field number for the "tensor_spec_value" field.</summary>
        </member>
        <member name="P:Tensorflow.StructuredValue.TensorSpecValue">
            <summary>
            Represents a value for tf.TensorSpec.
            </summary>
        </member>
        <member name="F:Tensorflow.StructuredValue.TypeSpecValueFieldNumber">
            <summary>Field number for the "type_spec_value" field.</summary>
        </member>
        <member name="P:Tensorflow.StructuredValue.TypeSpecValue">
            <summary>
            Represents a value for tf.TypeSpec.
            </summary>
        </member>
        <member name="F:Tensorflow.StructuredValue.BoundedTensorSpecValueFieldNumber">
            <summary>Field number for the "bounded_tensor_spec_value" field.</summary>
        </member>
        <member name="P:Tensorflow.StructuredValue.BoundedTensorSpecValue">
            <summary>
            Represents a value for tf.BoundedTensorSpec.
            </summary>
        </member>
        <member name="F:Tensorflow.StructuredValue.ListValueFieldNumber">
            <summary>Field number for the "list_value" field.</summary>
        </member>
        <member name="P:Tensorflow.StructuredValue.ListValue">
            <summary>
            Represents a list of `Value`.
            </summary>
        </member>
        <member name="F:Tensorflow.StructuredValue.TupleValueFieldNumber">
            <summary>Field number for the "tuple_value" field.</summary>
        </member>
        <member name="P:Tensorflow.StructuredValue.TupleValue">
            <summary>
            Represents a tuple of `Value`.
            </summary>
        </member>
        <member name="F:Tensorflow.StructuredValue.DictValueFieldNumber">
            <summary>Field number for the "dict_value" field.</summary>
        </member>
        <member name="P:Tensorflow.StructuredValue.DictValue">
            <summary>
            Represents a dict `Value`.
            </summary>
        </member>
        <member name="F:Tensorflow.StructuredValue.NamedTupleValueFieldNumber">
            <summary>Field number for the "named_tuple_value" field.</summary>
        </member>
        <member name="P:Tensorflow.StructuredValue.NamedTupleValue">
            <summary>
            Represents Python's namedtuple.
            </summary>
        </member>
        <member name="T:Tensorflow.StructuredValue.KindOneofCase">
            <summary>Enum of possible cases for the "kind" oneof.</summary>
        </member>
        <member name="T:Tensorflow.NoneValue">
            <summary>
            Represents None.
            </summary>
        </member>
        <member name="T:Tensorflow.ListValue">
            <summary>
            Represents a Python list.
            </summary>
        </member>
        <member name="F:Tensorflow.ListValue.ValuesFieldNumber">
            <summary>Field number for the "values" field.</summary>
        </member>
        <member name="T:Tensorflow.TupleValue">
            <summary>
            Represents a Python tuple.
            </summary>
        </member>
        <member name="F:Tensorflow.TupleValue.ValuesFieldNumber">
            <summary>Field number for the "values" field.</summary>
        </member>
        <member name="T:Tensorflow.DictValue">
            <summary>
            Represents a Python dict keyed by `str`.
            The comment on Unicode from Value.string_value applies analogously.
            </summary>
        </member>
        <member name="F:Tensorflow.DictValue.FieldsFieldNumber">
            <summary>Field number for the "fields" field.</summary>
        </member>
        <member name="T:Tensorflow.PairValue">
            <summary>
            Represents a (key, value) pair.
            </summary>
        </member>
        <member name="F:Tensorflow.PairValue.KeyFieldNumber">
            <summary>Field number for the "key" field.</summary>
        </member>
        <member name="F:Tensorflow.PairValue.ValueFieldNumber">
            <summary>Field number for the "value" field.</summary>
        </member>
        <member name="T:Tensorflow.NamedTupleValue">
            <summary>
            Represents Python's namedtuple.
            </summary>
        </member>
        <member name="F:Tensorflow.NamedTupleValue.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="F:Tensorflow.NamedTupleValue.ValuesFieldNumber">
            <summary>Field number for the "values" field.</summary>
        </member>
        <member name="T:Tensorflow.TensorSpecProto">
            <summary>
            A protobuf to represent tf.TensorSpec.
            </summary>
        </member>
        <member name="F:Tensorflow.TensorSpecProto.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="F:Tensorflow.TensorSpecProto.ShapeFieldNumber">
            <summary>Field number for the "shape" field.</summary>
        </member>
        <member name="F:Tensorflow.TensorSpecProto.DtypeFieldNumber">
            <summary>Field number for the "dtype" field.</summary>
        </member>
        <member name="T:Tensorflow.BoundedTensorSpecProto">
            <summary>
            A protobuf to represent tf.BoundedTensorSpec.
            </summary>
        </member>
        <member name="F:Tensorflow.BoundedTensorSpecProto.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="F:Tensorflow.BoundedTensorSpecProto.ShapeFieldNumber">
            <summary>Field number for the "shape" field.</summary>
        </member>
        <member name="F:Tensorflow.BoundedTensorSpecProto.DtypeFieldNumber">
            <summary>Field number for the "dtype" field.</summary>
        </member>
        <member name="F:Tensorflow.BoundedTensorSpecProto.MinimumFieldNumber">
            <summary>Field number for the "minimum" field.</summary>
        </member>
        <member name="F:Tensorflow.BoundedTensorSpecProto.MaximumFieldNumber">
            <summary>Field number for the "maximum" field.</summary>
        </member>
        <member name="T:Tensorflow.TypeSpecProto">
            <summary>
            Represents a tf.TypeSpec
            </summary>
        </member>
        <member name="F:Tensorflow.TypeSpecProto.TypeSpecClassFieldNumber">
            <summary>Field number for the "type_spec_class" field.</summary>
        </member>
        <member name="F:Tensorflow.TypeSpecProto.TypeStateFieldNumber">
            <summary>Field number for the "type_state" field.</summary>
        </member>
        <member name="P:Tensorflow.TypeSpecProto.TypeState">
            <summary>
            The value returned by TypeSpec._serialize().
            </summary>
        </member>
        <member name="F:Tensorflow.TypeSpecProto.TypeSpecClassNameFieldNumber">
            <summary>Field number for the "type_spec_class_name" field.</summary>
        </member>
        <member name="P:Tensorflow.TypeSpecProto.TypeSpecClassName">
            <summary>
            This is currently redundant with the type_spec_class enum, and is only
            used for error reporting.  In particular, if you use an older binary to
            load a newer model, and the model uses a TypeSpecClass that the older
            binary doesn't support, then this lets us display a useful error message.
            </summary>
        </member>
        <member name="T:Tensorflow.TypeSpecProto.Types">
            <summary>Container for nested types declared in the TypeSpecProto message type.</summary>
        </member>
        <member name="F:Tensorflow.TypeSpecProto.Types.TypeSpecClass.SparseTensorSpec">
            <summary>
            tf.SparseTensorSpec
            </summary>
        </member>
        <member name="F:Tensorflow.TypeSpecProto.Types.TypeSpecClass.IndexedSlicesSpec">
            <summary>
            tf.IndexedSlicesSpec
            </summary>
        </member>
        <member name="F:Tensorflow.TypeSpecProto.Types.TypeSpecClass.RaggedTensorSpec">
            <summary>
            tf.RaggedTensorSpec
            </summary>
        </member>
        <member name="F:Tensorflow.TypeSpecProto.Types.TypeSpecClass.TensorArraySpec">
            <summary>
            tf.TensorArraySpec
            </summary>
        </member>
        <member name="F:Tensorflow.TypeSpecProto.Types.TypeSpecClass.DataDatasetSpec">
            <summary>
            tf.data.DatasetSpec
            </summary>
        </member>
        <member name="F:Tensorflow.TypeSpecProto.Types.TypeSpecClass.DataIteratorSpec">
            <summary>
            IteratorSpec from data/ops/iterator_ops.py
            </summary>
        </member>
        <member name="F:Tensorflow.TypeSpecProto.Types.TypeSpecClass.OptionalSpec">
            <summary>
            tf.OptionalSpec
            </summary>
        </member>
        <member name="F:Tensorflow.TypeSpecProto.Types.TypeSpecClass.PerReplicaSpec">
            <summary>
            PerReplicaSpec from distribute/values.py
            </summary>
        </member>
        <member name="F:Tensorflow.TypeSpecProto.Types.TypeSpecClass.VariableSpec">
            <summary>
            tf.VariableSpec
            </summary>
        </member>
        <member name="F:Tensorflow.TypeSpecProto.Types.TypeSpecClass.RowPartitionSpec">
            <summary>
            RowPartitionSpec from ragged/row_partition.py
            </summary>
        </member>
        <member name="T:Tensorflow.SummaryReflection">
            <summary>Holder for reflection information generated from tensorflow/core/framework/summary.proto</summary>
        </member>
        <member name="P:Tensorflow.SummaryReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/framework/summary.proto</summary>
        </member>
        <member name="F:Tensorflow.DataClass.Unknown">
            <summary>
            Unknown data class, used (implicitly) for legacy data. Will not be
            processed by data ingestion pipelines.
            </summary>
        </member>
        <member name="F:Tensorflow.DataClass.Scalar">
            <summary>
            Scalar time series. Each `Value` for the corresponding tag must have
            `tensor` set to a rank-0 tensor of floating-point dtype, which will be
            converted to float64.
            </summary>
        </member>
        <member name="F:Tensorflow.DataClass.Tensor">
            <summary>
            Tensor time series. Each `Value` for the corresponding tag must have
            `tensor` set. The tensor value is arbitrary, but should be small to
            accommodate direct storage in database backends: an upper bound of a few
            kilobytes is a reasonable rule of thumb.
            </summary>
        </member>
        <member name="F:Tensorflow.DataClass.BlobSequence">
            <summary>
            Blob sequence time series. Each `Value` for the corresponding tag must
            have `tensor` set to a rank-1 tensor of bytestring dtype.
            </summary>
        </member>
        <member name="T:Tensorflow.SummaryDescription">
            <summary>
            Metadata associated with a series of Summary data
            </summary>
        </member>
        <member name="F:Tensorflow.SummaryDescription.TypeHintFieldNumber">
            <summary>Field number for the "type_hint" field.</summary>
        </member>
        <member name="P:Tensorflow.SummaryDescription.TypeHint">
            <summary>
            Hint on how plugins should process the data in this series.
            Supported values include "scalar", "histogram", "image", "audio"
            </summary>
        </member>
        <member name="T:Tensorflow.HistogramProto">
            <summary>
            Serialization format for histogram module in
            core/lib/histogram/histogram.h
            </summary>
        </member>
        <member name="F:Tensorflow.HistogramProto.MinFieldNumber">
            <summary>Field number for the "min" field.</summary>
        </member>
        <member name="F:Tensorflow.HistogramProto.MaxFieldNumber">
            <summary>Field number for the "max" field.</summary>
        </member>
        <member name="F:Tensorflow.HistogramProto.NumFieldNumber">
            <summary>Field number for the "num" field.</summary>
        </member>
        <member name="F:Tensorflow.HistogramProto.SumFieldNumber">
            <summary>Field number for the "sum" field.</summary>
        </member>
        <member name="F:Tensorflow.HistogramProto.SumSquaresFieldNumber">
            <summary>Field number for the "sum_squares" field.</summary>
        </member>
        <member name="F:Tensorflow.HistogramProto.BucketLimitFieldNumber">
            <summary>Field number for the "bucket_limit" field.</summary>
        </member>
        <member name="P:Tensorflow.HistogramProto.BucketLimit">
            <summary>
            Parallel arrays encoding the bucket boundaries and the bucket values.
            bucket(i) is the count for the bucket i.  The range for
            a bucket is:
              i == 0:  -DBL_MAX .. bucket_limit(0)
              i != 0:  bucket_limit(i-1) .. bucket_limit(i)
            </summary>
        </member>
        <member name="F:Tensorflow.HistogramProto.BucketFieldNumber">
            <summary>Field number for the "bucket" field.</summary>
        </member>
        <member name="T:Tensorflow.SummaryMetadata">
            <summary>
            A SummaryMetadata encapsulates information on which plugins are able to make
            use of a certain summary value.
            </summary>
        </member>
        <member name="F:Tensorflow.SummaryMetadata.PluginDataFieldNumber">
            <summary>Field number for the "plugin_data" field.</summary>
        </member>
        <member name="P:Tensorflow.SummaryMetadata.PluginData">
            <summary>
            Data that associates a summary with a certain plugin.
            </summary>
        </member>
        <member name="F:Tensorflow.SummaryMetadata.DisplayNameFieldNumber">
            <summary>Field number for the "display_name" field.</summary>
        </member>
        <member name="P:Tensorflow.SummaryMetadata.DisplayName">
            <summary>
            Display name for viewing in TensorBoard.
            </summary>
        </member>
        <member name="F:Tensorflow.SummaryMetadata.SummaryDescriptionFieldNumber">
            <summary>Field number for the "summary_description" field.</summary>
        </member>
        <member name="P:Tensorflow.SummaryMetadata.SummaryDescription">
            <summary>
            Longform readable description of the summary sequence. Markdown supported.
            </summary>
        </member>
        <member name="F:Tensorflow.SummaryMetadata.DataClassFieldNumber">
            <summary>Field number for the "data_class" field.</summary>
        </member>
        <member name="P:Tensorflow.SummaryMetadata.DataClass">
            <summary>
            Class of data stored in this time series. Required for compatibility with
            TensorBoard's generic data facilities (`DataProvider`, et al.). This value
            imposes constraints on the dtype and shape of the corresponding tensor
            values. See `DataClass` docs for details.
            </summary>
        </member>
        <member name="T:Tensorflow.SummaryMetadata.Types">
            <summary>Container for nested types declared in the SummaryMetadata message type.</summary>
        </member>
        <member name="F:Tensorflow.SummaryMetadata.Types.PluginData.PluginNameFieldNumber">
            <summary>Field number for the "plugin_name" field.</summary>
        </member>
        <member name="P:Tensorflow.SummaryMetadata.Types.PluginData.PluginName">
            <summary>
            The name of the plugin this data pertains to.
            </summary>
        </member>
        <member name="F:Tensorflow.SummaryMetadata.Types.PluginData.ContentFieldNumber">
            <summary>Field number for the "content" field.</summary>
        </member>
        <member name="P:Tensorflow.SummaryMetadata.Types.PluginData.Content">
            <summary>
            The content to store for the plugin. The best practice is for this to be
            a binary serialized protocol buffer.
            </summary>
        </member>
        <member name="T:Tensorflow.Summary">
             <summary>
             A Summary is a set of named values to be displayed by the
             visualizer.
            
             Summaries are produced regularly during training, as controlled by
             the "summary_interval_secs" attribute of the training operation.
             Summaries are also produced at the end of an evaluation.
             </summary>
        </member>
        <member name="F:Tensorflow.Summary.ValueFieldNumber">
            <summary>Field number for the "value" field.</summary>
        </member>
        <member name="P:Tensorflow.Summary.Value">
            <summary>
            Set of values for the summary.
            </summary>
        </member>
        <member name="T:Tensorflow.Summary.Types">
            <summary>Container for nested types declared in the Summary message type.</summary>
        </member>
        <member name="F:Tensorflow.Summary.Types.Image.HeightFieldNumber">
            <summary>Field number for the "height" field.</summary>
        </member>
        <member name="P:Tensorflow.Summary.Types.Image.Height">
            <summary>
            Dimensions of the image.
            </summary>
        </member>
        <member name="F:Tensorflow.Summary.Types.Image.WidthFieldNumber">
            <summary>Field number for the "width" field.</summary>
        </member>
        <member name="F:Tensorflow.Summary.Types.Image.ColorspaceFieldNumber">
            <summary>Field number for the "colorspace" field.</summary>
        </member>
        <member name="P:Tensorflow.Summary.Types.Image.Colorspace">
            <summary>
            Valid colorspace values are
              1 - grayscale
              2 - grayscale + alpha
              3 - RGB
              4 - RGBA
              5 - DIGITAL_YUV
              6 - BGRA
            </summary>
        </member>
        <member name="F:Tensorflow.Summary.Types.Image.EncodedImageStringFieldNumber">
            <summary>Field number for the "encoded_image_string" field.</summary>
        </member>
        <member name="P:Tensorflow.Summary.Types.Image.EncodedImageString">
            <summary>
            Image data in encoded format.  All image formats supported by
            image_codec::CoderUtil can be stored here.
            </summary>
        </member>
        <member name="F:Tensorflow.Summary.Types.Audio.SampleRateFieldNumber">
            <summary>Field number for the "sample_rate" field.</summary>
        </member>
        <member name="P:Tensorflow.Summary.Types.Audio.SampleRate">
            <summary>
            Sample rate of the audio in Hz.
            </summary>
        </member>
        <member name="F:Tensorflow.Summary.Types.Audio.NumChannelsFieldNumber">
            <summary>Field number for the "num_channels" field.</summary>
        </member>
        <member name="P:Tensorflow.Summary.Types.Audio.NumChannels">
            <summary>
            Number of channels of audio.
            </summary>
        </member>
        <member name="F:Tensorflow.Summary.Types.Audio.LengthFramesFieldNumber">
            <summary>Field number for the "length_frames" field.</summary>
        </member>
        <member name="P:Tensorflow.Summary.Types.Audio.LengthFrames">
            <summary>
            Length of the audio in frames (samples per channel).
            </summary>
        </member>
        <member name="F:Tensorflow.Summary.Types.Audio.EncodedAudioStringFieldNumber">
            <summary>Field number for the "encoded_audio_string" field.</summary>
        </member>
        <member name="P:Tensorflow.Summary.Types.Audio.EncodedAudioString">
            <summary>
            Encoded audio data and its associated RFC 2045 content type (e.g.
            "audio/wav").
            </summary>
        </member>
        <member name="F:Tensorflow.Summary.Types.Audio.ContentTypeFieldNumber">
            <summary>Field number for the "content_type" field.</summary>
        </member>
        <member name="F:Tensorflow.Summary.Types.Value.NodeNameFieldNumber">
            <summary>Field number for the "node_name" field.</summary>
        </member>
        <member name="P:Tensorflow.Summary.Types.Value.NodeName">
            <summary>
            This field is deprecated and will not be set.
            </summary>
        </member>
        <member name="F:Tensorflow.Summary.Types.Value.TagFieldNumber">
            <summary>Field number for the "tag" field.</summary>
        </member>
        <member name="P:Tensorflow.Summary.Types.Value.Tag">
            <summary>
            Tag name for the data. Used by TensorBoard plugins to organize data. Tags
            are often organized by scope (which contains slashes to convey
            hierarchy). For example: foo/bar/0
            </summary>
        </member>
        <member name="F:Tensorflow.Summary.Types.Value.MetadataFieldNumber">
            <summary>Field number for the "metadata" field.</summary>
        </member>
        <member name="P:Tensorflow.Summary.Types.Value.Metadata">
            <summary>
            Contains metadata on the summary value such as which plugins may use it.
            Take note that many summary values may lack a metadata field. This is
            because the FileWriter only keeps a metadata object on the first summary
            value with a certain tag for each tag. TensorBoard then remembers which
            tags are associated with which plugins. This saves space.
            </summary>
        </member>
        <member name="F:Tensorflow.Summary.Types.Value.SimpleValueFieldNumber">
            <summary>Field number for the "simple_value" field.</summary>
        </member>
        <member name="F:Tensorflow.Summary.Types.Value.ObsoleteOldStyleHistogramFieldNumber">
            <summary>Field number for the "obsolete_old_style_histogram" field.</summary>
        </member>
        <member name="F:Tensorflow.Summary.Types.Value.ImageFieldNumber">
            <summary>Field number for the "image" field.</summary>
        </member>
        <member name="F:Tensorflow.Summary.Types.Value.HistoFieldNumber">
            <summary>Field number for the "histo" field.</summary>
        </member>
        <member name="F:Tensorflow.Summary.Types.Value.AudioFieldNumber">
            <summary>Field number for the "audio" field.</summary>
        </member>
        <member name="F:Tensorflow.Summary.Types.Value.TensorFieldNumber">
            <summary>Field number for the "tensor" field.</summary>
        </member>
        <member name="T:Tensorflow.Summary.Types.Value.ValueOneofCase">
            <summary>Enum of possible cases for the "value" oneof.</summary>
        </member>
        <member name="T:Tensorflow.TensorReflection">
            <summary>Holder for reflection information generated from tensorflow/core/framework/tensor.proto</summary>
        </member>
        <member name="P:Tensorflow.TensorReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/framework/tensor.proto</summary>
        </member>
        <member name="T:Tensorflow.TensorProto">
            <summary>
            Protocol buffer representing a tensor.
            </summary>
        </member>
        <member name="F:Tensorflow.TensorProto.DtypeFieldNumber">
            <summary>Field number for the "dtype" field.</summary>
        </member>
        <member name="F:Tensorflow.TensorProto.TensorShapeFieldNumber">
            <summary>Field number for the "tensor_shape" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorProto.TensorShape">
            <summary>
            Shape of the tensor.  TODO(touts): sort out the 0-rank issues.
            </summary>
        </member>
        <member name="F:Tensorflow.TensorProto.VersionNumberFieldNumber">
            <summary>Field number for the "version_number" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorProto.VersionNumber">
             <summary>
             Version number.
            
             In version 0, if the "repeated xxx" representations contain only one
             element, that element is repeated to fill the shape.  This makes it easy
             to represent a constant Tensor with a single value.
             </summary>
        </member>
        <member name="F:Tensorflow.TensorProto.TensorContentFieldNumber">
            <summary>Field number for the "tensor_content" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorProto.TensorContent">
            <summary>
            Serialized raw tensor content from either Tensor::AsProtoTensorContent or
            memcpy in tensorflow::grpc::EncodeTensorToByteBuffer. This representation
            can be used for all tensor types. The purpose of this representation is to
            reduce serialization overhead during RPC call by avoiding serialization of
            many repeated small items.
            </summary>
        </member>
        <member name="F:Tensorflow.TensorProto.HalfValFieldNumber">
            <summary>Field number for the "half_val" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorProto.HalfVal">
            <summary>
            DT_HALF, DT_BFLOAT16. Note that since protobuf has no int16 type, we'll
            have some pointless zero padding for each value here.
            </summary>
        </member>
        <member name="F:Tensorflow.TensorProto.FloatValFieldNumber">
            <summary>Field number for the "float_val" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorProto.FloatVal">
            <summary>
            DT_FLOAT.
            </summary>
        </member>
        <member name="F:Tensorflow.TensorProto.DoubleValFieldNumber">
            <summary>Field number for the "double_val" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorProto.DoubleVal">
            <summary>
            DT_DOUBLE.
            </summary>
        </member>
        <member name="F:Tensorflow.TensorProto.IntValFieldNumber">
            <summary>Field number for the "int_val" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorProto.IntVal">
            <summary>
            DT_INT32, DT_INT16, DT_INT8, DT_UINT8.
            </summary>
        </member>
        <member name="F:Tensorflow.TensorProto.StringValFieldNumber">
            <summary>Field number for the "string_val" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorProto.StringVal">
            <summary>
            DT_STRING
            </summary>
        </member>
        <member name="F:Tensorflow.TensorProto.ScomplexValFieldNumber">
            <summary>Field number for the "scomplex_val" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorProto.ScomplexVal">
            <summary>
            DT_COMPLEX64. scomplex_val(2*i) and scomplex_val(2*i+1) are real
            and imaginary parts of i-th single precision complex.
            </summary>
        </member>
        <member name="F:Tensorflow.TensorProto.Int64ValFieldNumber">
            <summary>Field number for the "int64_val" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorProto.Int64Val">
            <summary>
            DT_INT64
            </summary>
        </member>
        <member name="F:Tensorflow.TensorProto.BoolValFieldNumber">
            <summary>Field number for the "bool_val" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorProto.BoolVal">
            <summary>
            DT_BOOL
            </summary>
        </member>
        <member name="F:Tensorflow.TensorProto.DcomplexValFieldNumber">
            <summary>Field number for the "dcomplex_val" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorProto.DcomplexVal">
            <summary>
            DT_COMPLEX128. dcomplex_val(2*i) and dcomplex_val(2*i+1) are real
            and imaginary parts of i-th double precision complex.
            </summary>
        </member>
        <member name="F:Tensorflow.TensorProto.ResourceHandleValFieldNumber">
            <summary>Field number for the "resource_handle_val" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorProto.ResourceHandleVal">
            <summary>
            DT_RESOURCE
            </summary>
        </member>
        <member name="F:Tensorflow.TensorProto.VariantValFieldNumber">
            <summary>Field number for the "variant_val" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorProto.VariantVal">
            <summary>
            DT_VARIANT
            </summary>
        </member>
        <member name="F:Tensorflow.TensorProto.Uint32ValFieldNumber">
            <summary>Field number for the "uint32_val" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorProto.Uint32Val">
            <summary>
            DT_UINT32
            </summary>
        </member>
        <member name="F:Tensorflow.TensorProto.Uint64ValFieldNumber">
            <summary>Field number for the "uint64_val" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorProto.Uint64Val">
            <summary>
            DT_UINT64
            </summary>
        </member>
        <member name="T:Tensorflow.VariantTensorDataProto">
            <summary>
            Protocol buffer representing the serialization format of DT_VARIANT tensors.
            </summary>
        </member>
        <member name="F:Tensorflow.VariantTensorDataProto.TypeNameFieldNumber">
            <summary>Field number for the "type_name" field.</summary>
        </member>
        <member name="P:Tensorflow.VariantTensorDataProto.TypeName">
            <summary>
            Name of the type of objects being serialized.
            </summary>
        </member>
        <member name="F:Tensorflow.VariantTensorDataProto.MetadataFieldNumber">
            <summary>Field number for the "metadata" field.</summary>
        </member>
        <member name="P:Tensorflow.VariantTensorDataProto.Metadata">
            <summary>
            Portions of the object that are not Tensors.
            </summary>
        </member>
        <member name="F:Tensorflow.VariantTensorDataProto.TensorsFieldNumber">
            <summary>Field number for the "tensors" field.</summary>
        </member>
        <member name="P:Tensorflow.VariantTensorDataProto.Tensors">
            <summary>
            Tensors contained within objects being serialized.
            </summary>
        </member>
        <member name="T:Tensorflow.TensorDescriptionReflection">
            <summary>Holder for reflection information generated from tensorflow/core/framework/tensor_description.proto</summary>
        </member>
        <member name="P:Tensorflow.TensorDescriptionReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/framework/tensor_description.proto</summary>
        </member>
        <member name="F:Tensorflow.TensorDescription.DtypeFieldNumber">
            <summary>Field number for the "dtype" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorDescription.Dtype">
            <summary>
            Data type of tensor elements
            </summary>
        </member>
        <member name="F:Tensorflow.TensorDescription.ShapeFieldNumber">
            <summary>Field number for the "shape" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorDescription.Shape">
            <summary>
            Shape of the tensor.
            </summary>
        </member>
        <member name="F:Tensorflow.TensorDescription.AllocationDescriptionFieldNumber">
            <summary>Field number for the "allocation_description" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorDescription.AllocationDescription">
            <summary>
            Information about the size and allocator used for the data
            </summary>
        </member>
        <member name="T:Tensorflow.TensorShapeReflection">
            <summary>Holder for reflection information generated from tensorflow/core/framework/tensor_shape.proto</summary>
        </member>
        <member name="P:Tensorflow.TensorShapeReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/framework/tensor_shape.proto</summary>
        </member>
        <member name="T:Tensorflow.TensorShapeProto">
            <summary>
            Dimensions of a tensor.
            </summary>
        </member>
        <member name="F:Tensorflow.TensorShapeProto.DimFieldNumber">
            <summary>Field number for the "dim" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorShapeProto.Dim">
             <summary>
             Dimensions of the tensor, such as {"input", 30}, {"output", 40}
             for a 30 x 40 2D tensor.  If an entry has size -1, this
             corresponds to a dimension of unknown size. The names are
             optional.
            
             The order of entries in "dim" matters: It indicates the layout of the
             values in the tensor in-memory representation.
            
             The first entry in "dim" is the outermost dimension used to layout the
             values, the last entry is the innermost dimension.  This matches the
             in-memory layout of RowMajor Eigen tensors.
            
             If "dim.size()" > 0, "unknown_rank" must be false.
             </summary>
        </member>
        <member name="F:Tensorflow.TensorShapeProto.UnknownRankFieldNumber">
            <summary>Field number for the "unknown_rank" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorShapeProto.UnknownRank">
             <summary>
             If true, the number of dimensions in the shape is unknown.
            
             If true, "dim.size()" must be 0.
             </summary>
        </member>
        <member name="T:Tensorflow.TensorShapeProto.Types">
            <summary>Container for nested types declared in the TensorShapeProto message type.</summary>
        </member>
        <member name="T:Tensorflow.TensorShapeProto.Types.Dim">
            <summary>
            One dimension of the tensor.
            </summary>
        </member>
        <member name="F:Tensorflow.TensorShapeProto.Types.Dim.SizeFieldNumber">
            <summary>Field number for the "size" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorShapeProto.Types.Dim.Size">
            <summary>
            Size of the tensor in that dimension.
            This value must be >= -1, but values of -1 are reserved for "unknown"
            shapes (values of -1 mean "unknown" dimension).  Certain wrappers
            that work with TensorShapeProto may fail at runtime when deserializing
            a TensorShapeProto containing a dim value of -1.
            </summary>
        </member>
        <member name="F:Tensorflow.TensorShapeProto.Types.Dim.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorShapeProto.Types.Dim.Name">
            <summary>
            Optional name of the tensor dimension.
            </summary>
        </member>
        <member name="T:Tensorflow.TensorSliceReflection">
            <summary>Holder for reflection information generated from tensorflow/core/framework/tensor_slice.proto</summary>
        </member>
        <member name="P:Tensorflow.TensorSliceReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/framework/tensor_slice.proto</summary>
        </member>
        <member name="T:Tensorflow.TensorSliceProto">
            <summary>
            Can only be interpreted if you know the corresponding TensorShape.
            </summary>
        </member>
        <member name="F:Tensorflow.TensorSliceProto.ExtentFieldNumber">
            <summary>Field number for the "extent" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorSliceProto.Extent">
             <summary>
             Extent of the slice in all tensor dimensions.
            
             Must have one entry for each of the dimension of the tensor that this
             slice belongs to.  The order of sizes is the same as the order of
             dimensions in the TensorShape.
             </summary>
        </member>
        <member name="T:Tensorflow.TensorSliceProto.Types">
            <summary>Container for nested types declared in the TensorSliceProto message type.</summary>
        </member>
        <member name="T:Tensorflow.TensorSliceProto.Types.Extent">
            <summary>
            Extent of the slice in one dimension.
            </summary>
        </member>
        <member name="F:Tensorflow.TensorSliceProto.Types.Extent.StartFieldNumber">
            <summary>Field number for the "start" field.</summary>
        </member>
        <member name="P:Tensorflow.TensorSliceProto.Types.Extent.Start">
            <summary>
            Start index of the slice, starting at 0.
            </summary>
        </member>
        <member name="F:Tensorflow.TensorSliceProto.Types.Extent.LengthFieldNumber">
            <summary>Field number for the "length" field.</summary>
        </member>
        <member name="T:Tensorflow.TensorSliceProto.Types.Extent.HasLengthOneofCase">
            <summary>Enum of possible cases for the "has_length" oneof.</summary>
        </member>
        <member name="T:Tensorflow.TrackableObjectGraphReflection">
            <summary>Holder for reflection information generated from tensorflow/core/protobuf/trackable_object_graph.proto</summary>
        </member>
        <member name="P:Tensorflow.TrackableObjectGraphReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/protobuf/trackable_object_graph.proto</summary>
        </member>
        <member name="F:Tensorflow.TrackableObjectGraph.NodesFieldNumber">
            <summary>Field number for the "nodes" field.</summary>
        </member>
        <member name="T:Tensorflow.TrackableObjectGraph.Types">
            <summary>Container for nested types declared in the TrackableObjectGraph message type.</summary>
        </member>
        <member name="F:Tensorflow.TrackableObjectGraph.Types.TrackableObject.ChildrenFieldNumber">
            <summary>Field number for the "children" field.</summary>
        </member>
        <member name="P:Tensorflow.TrackableObjectGraph.Types.TrackableObject.Children">
            <summary>
            Objects which this object depends on.
            </summary>
        </member>
        <member name="F:Tensorflow.TrackableObjectGraph.Types.TrackableObject.AttributesFieldNumber">
            <summary>Field number for the "attributes" field.</summary>
        </member>
        <member name="P:Tensorflow.TrackableObjectGraph.Types.TrackableObject.Attributes">
            <summary>
            Serialized data specific to this object.
            </summary>
        </member>
        <member name="F:Tensorflow.TrackableObjectGraph.Types.TrackableObject.SlotVariablesFieldNumber">
            <summary>Field number for the "slot_variables" field.</summary>
        </member>
        <member name="P:Tensorflow.TrackableObjectGraph.Types.TrackableObject.SlotVariables">
            <summary>
            Slot variables owned by this object.
            </summary>
        </member>
        <member name="T:Tensorflow.TrackableObjectGraph.Types.TrackableObject.Types">
            <summary>Container for nested types declared in the TrackableObject message type.</summary>
        </member>
        <member name="F:Tensorflow.TrackableObjectGraph.Types.TrackableObject.Types.ObjectReference.NodeIdFieldNumber">
            <summary>Field number for the "node_id" field.</summary>
        </member>
        <member name="P:Tensorflow.TrackableObjectGraph.Types.TrackableObject.Types.ObjectReference.NodeId">
            <summary>
            An index into `TrackableObjectGraph.nodes`, indicating the object
            being referenced.
            </summary>
        </member>
        <member name="F:Tensorflow.TrackableObjectGraph.Types.TrackableObject.Types.ObjectReference.LocalNameFieldNumber">
            <summary>Field number for the "local_name" field.</summary>
        </member>
        <member name="P:Tensorflow.TrackableObjectGraph.Types.TrackableObject.Types.ObjectReference.LocalName">
            <summary>
            A user-provided name for the edge.
            </summary>
        </member>
        <member name="F:Tensorflow.TrackableObjectGraph.Types.TrackableObject.Types.SerializedTensor.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Tensorflow.TrackableObjectGraph.Types.TrackableObject.Types.SerializedTensor.Name">
            <summary>
            A name for the Tensor. Simple variables have only one
            `SerializedTensor` named "VARIABLE_VALUE" by convention. This value may
            be restored on object creation as an optimization.
            </summary>
        </member>
        <member name="F:Tensorflow.TrackableObjectGraph.Types.TrackableObject.Types.SerializedTensor.FullNameFieldNumber">
            <summary>Field number for the "full_name" field.</summary>
        </member>
        <member name="P:Tensorflow.TrackableObjectGraph.Types.TrackableObject.Types.SerializedTensor.FullName">
            <summary>
            The full name of the variable/tensor, if applicable. Used to allow
            name-based loading of checkpoints which were saved using an
            object-based API. Should match the checkpoint key which would have been
            assigned by tf.train.Saver.
            </summary>
        </member>
        <member name="F:Tensorflow.TrackableObjectGraph.Types.TrackableObject.Types.SerializedTensor.CheckpointKeyFieldNumber">
            <summary>Field number for the "checkpoint_key" field.</summary>
        </member>
        <member name="P:Tensorflow.TrackableObjectGraph.Types.TrackableObject.Types.SerializedTensor.CheckpointKey">
            <summary>
            The generated name of the Tensor in the checkpoint.
            </summary>
        </member>
        <member name="F:Tensorflow.TrackableObjectGraph.Types.TrackableObject.Types.SerializedTensor.OptionalRestoreFieldNumber">
            <summary>Field number for the "optional_restore" field.</summary>
        </member>
        <member name="P:Tensorflow.TrackableObjectGraph.Types.TrackableObject.Types.SerializedTensor.OptionalRestore">
            <summary>
            Whether checkpoints should be considered as matching even without this
            value restored. Used for non-critical values which don't affect the
            TensorFlow graph, such as layer configurations.
            </summary>
        </member>
        <member name="F:Tensorflow.TrackableObjectGraph.Types.TrackableObject.Types.SlotVariableReference.OriginalVariableNodeIdFieldNumber">
            <summary>Field number for the "original_variable_node_id" field.</summary>
        </member>
        <member name="P:Tensorflow.TrackableObjectGraph.Types.TrackableObject.Types.SlotVariableReference.OriginalVariableNodeId">
            <summary>
            An index into `TrackableObjectGraph.nodes`, indicating the
            variable object this slot was created for.
            </summary>
        </member>
        <member name="F:Tensorflow.TrackableObjectGraph.Types.TrackableObject.Types.SlotVariableReference.SlotNameFieldNumber">
            <summary>Field number for the "slot_name" field.</summary>
        </member>
        <member name="P:Tensorflow.TrackableObjectGraph.Types.TrackableObject.Types.SlotVariableReference.SlotName">
            <summary>
            The name of the slot (e.g. "m"/"v").
            </summary>
        </member>
        <member name="F:Tensorflow.TrackableObjectGraph.Types.TrackableObject.Types.SlotVariableReference.SlotVariableNodeIdFieldNumber">
            <summary>Field number for the "slot_variable_node_id" field.</summary>
        </member>
        <member name="P:Tensorflow.TrackableObjectGraph.Types.TrackableObject.Types.SlotVariableReference.SlotVariableNodeId">
            <summary>
            An index into `TrackableObjectGraph.nodes`, indicating the
            `Object` with the value of the slot variable.
            </summary>
        </member>
        <member name="T:Tensorflow.TypesReflection">
            <summary>Holder for reflection information generated from tensorflow/core/framework/types.proto</summary>
        </member>
        <member name="P:Tensorflow.TypesReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/framework/types.proto</summary>
        </member>
        <member name="T:Tensorflow.DataType">
            <summary>
            (== suppress_warning documentation-presence ==)
            LINT.IfChange
            </summary>
        </member>
        <member name="F:Tensorflow.DataType.DtInvalid">
            <summary>
            Not a legal value for DataType.  Used to indicate a DataType field
            has not been set.
            </summary>
        </member>
        <member name="F:Tensorflow.DataType.DtFloat">
            <summary>
            Data types that all computation devices are expected to be
            capable to support.
            </summary>
        </member>
        <member name="F:Tensorflow.DataType.DtComplex64">
            <summary>
            Single-precision complex
            </summary>
        </member>
        <member name="F:Tensorflow.DataType.DtQint8">
            <summary>
            Quantized int8
            </summary>
        </member>
        <member name="F:Tensorflow.DataType.DtQuint8">
            <summary>
            Quantized uint8
            </summary>
        </member>
        <member name="F:Tensorflow.DataType.DtQint32">
            <summary>
            Quantized int32
            </summary>
        </member>
        <member name="F:Tensorflow.DataType.DtBfloat16">
            <summary>
            Float32 truncated to 16 bits.  Only for cast ops.
            </summary>
        </member>
        <member name="F:Tensorflow.DataType.DtQint16">
            <summary>
            Quantized int16
            </summary>
        </member>
        <member name="F:Tensorflow.DataType.DtQuint16">
            <summary>
            Quantized uint16
            </summary>
        </member>
        <member name="F:Tensorflow.DataType.DtComplex128">
            <summary>
            Double-precision complex
            </summary>
        </member>
        <member name="F:Tensorflow.DataType.DtVariant">
            <summary>
            Arbitrary C++ data types
            </summary>
        </member>
        <member name="F:Tensorflow.DataType.DtFloatRef">
            <summary>
            Do not use!  These are only for parameters.  Every enum above
            should have a corresponding value below (verified by types_test).
            </summary>
        </member>
        <member name="T:Tensorflow.VariableReflection">
            <summary>Holder for reflection information generated from tensorflow/core/framework/variable.proto</summary>
        </member>
        <member name="P:Tensorflow.VariableReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/framework/variable.proto</summary>
        </member>
        <member name="T:Tensorflow.VariableSynchronization">
            <summary>
            Indicates when a distributed variable will be synced.
            </summary>
        </member>
        <member name="F:Tensorflow.VariableSynchronization.Auto">
            <summary>
            `AUTO`: Indicates that the synchronization will be determined by the
            current `DistributionStrategy` (eg. With `MirroredStrategy` this would be
            `ON_WRITE`).
            </summary>
        </member>
        <member name="F:Tensorflow.VariableSynchronization.None">
            <summary>
            `NONE`: Indicates that there will only be one copy of the variable, so
            there is no need to sync.
            </summary>
        </member>
        <member name="F:Tensorflow.VariableSynchronization.OnWrite">
            <summary>
            `ON_WRITE`: Indicates that the variable will be updated across devices
            every time it is written.
            </summary>
        </member>
        <member name="F:Tensorflow.VariableSynchronization.OnRead">
            <summary>
            `ON_READ`: Indicates that the variable will be aggregated across devices
            when it is read (eg. when checkpointing or when evaluating an op that uses
            the variable).
            </summary>
        </member>
        <member name="T:Tensorflow.VariableAggregation">
            <summary>
            Indicates how a distributed variable will be aggregated.
            </summary>
        </member>
        <member name="F:Tensorflow.VariableAggregation.None">
            <summary>
            `NONE`: This is the default, giving an error if you use a
            variable-update operation with multiple replicas.
            </summary>
        </member>
        <member name="F:Tensorflow.VariableAggregation.Sum">
            <summary>
            `SUM`: Add the updates across replicas.
            </summary>
        </member>
        <member name="F:Tensorflow.VariableAggregation.Mean">
            <summary>
            `MEAN`: Take the arithmetic mean ("average") of the updates across
            replicas.
            </summary>
        </member>
        <member name="F:Tensorflow.VariableAggregation.OnlyFirstReplica">
            <summary>
            `ONLY_FIRST_REPLICA`: This is for when every replica is performing the same
            update, but we only want to perform the update once. Used, e.g., for the
            global step counter.
            </summary>
        </member>
        <member name="T:Tensorflow.VariableDef">
            <summary>
            Protocol buffer representing a Variable.
            </summary>
        </member>
        <member name="F:Tensorflow.VariableDef.VariableNameFieldNumber">
            <summary>Field number for the "variable_name" field.</summary>
        </member>
        <member name="P:Tensorflow.VariableDef.VariableName">
            <summary>
            Name of the variable tensor.
            </summary>
        </member>
        <member name="F:Tensorflow.VariableDef.InitialValueNameFieldNumber">
            <summary>Field number for the "initial_value_name" field.</summary>
        </member>
        <member name="P:Tensorflow.VariableDef.InitialValueName">
            <summary>
            Name of the tensor holding the variable's initial value.
            </summary>
        </member>
        <member name="F:Tensorflow.VariableDef.InitializerNameFieldNumber">
            <summary>Field number for the "initializer_name" field.</summary>
        </member>
        <member name="P:Tensorflow.VariableDef.InitializerName">
            <summary>
            Name of the initializer op.
            </summary>
        </member>
        <member name="F:Tensorflow.VariableDef.SnapshotNameFieldNumber">
            <summary>Field number for the "snapshot_name" field.</summary>
        </member>
        <member name="P:Tensorflow.VariableDef.SnapshotName">
            <summary>
            Name of the snapshot tensor.
            </summary>
        </member>
        <member name="F:Tensorflow.VariableDef.SaveSliceInfoDefFieldNumber">
            <summary>Field number for the "save_slice_info_def" field.</summary>
        </member>
        <member name="P:Tensorflow.VariableDef.SaveSliceInfoDef">
            <summary>
            Support for saving variables as slices of a larger variable.
            </summary>
        </member>
        <member name="F:Tensorflow.VariableDef.IsResourceFieldNumber">
            <summary>Field number for the "is_resource" field.</summary>
        </member>
        <member name="P:Tensorflow.VariableDef.IsResource">
            <summary>
            Whether to represent this as a ResourceVariable.
            </summary>
        </member>
        <member name="F:Tensorflow.VariableDef.TrainableFieldNumber">
            <summary>Field number for the "trainable" field.</summary>
        </member>
        <member name="P:Tensorflow.VariableDef.Trainable">
            <summary>
            Whether this variable should be trained.
            </summary>
        </member>
        <member name="F:Tensorflow.VariableDef.SynchronizationFieldNumber">
            <summary>Field number for the "synchronization" field.</summary>
        </member>
        <member name="P:Tensorflow.VariableDef.Synchronization">
            <summary>
            Indicates when a distributed variable will be synced.
            </summary>
        </member>
        <member name="F:Tensorflow.VariableDef.AggregationFieldNumber">
            <summary>Field number for the "aggregation" field.</summary>
        </member>
        <member name="P:Tensorflow.VariableDef.Aggregation">
            <summary>
            Indicates how a distributed variable will be aggregated.
            </summary>
        </member>
        <member name="F:Tensorflow.SaveSliceInfoDef.FullNameFieldNumber">
            <summary>Field number for the "full_name" field.</summary>
        </member>
        <member name="P:Tensorflow.SaveSliceInfoDef.FullName">
            <summary>
            Name of the full variable of which this is a slice.
            </summary>
        </member>
        <member name="F:Tensorflow.SaveSliceInfoDef.FullShapeFieldNumber">
            <summary>Field number for the "full_shape" field.</summary>
        </member>
        <member name="P:Tensorflow.SaveSliceInfoDef.FullShape">
            <summary>
            Shape of the full variable.
            </summary>
        </member>
        <member name="F:Tensorflow.SaveSliceInfoDef.VarOffsetFieldNumber">
            <summary>Field number for the "var_offset" field.</summary>
        </member>
        <member name="P:Tensorflow.SaveSliceInfoDef.VarOffset">
            <summary>
            Offset of this variable into the full variable.
            </summary>
        </member>
        <member name="F:Tensorflow.SaveSliceInfoDef.VarShapeFieldNumber">
            <summary>Field number for the "var_shape" field.</summary>
        </member>
        <member name="P:Tensorflow.SaveSliceInfoDef.VarShape">
            <summary>
            Shape of this variable.
            </summary>
        </member>
        <member name="T:Tensorflow.VerifierConfigReflection">
            <summary>Holder for reflection information generated from tensorflow/core/protobuf/verifier_config.proto</summary>
        </member>
        <member name="P:Tensorflow.VerifierConfigReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/protobuf/verifier_config.proto</summary>
        </member>
        <member name="T:Tensorflow.VerifierConfig">
            <summary>
            The config for graph verifiers.
            </summary>
        </member>
        <member name="F:Tensorflow.VerifierConfig.VerificationTimeoutInMsFieldNumber">
            <summary>Field number for the "verification_timeout_in_ms" field.</summary>
        </member>
        <member name="P:Tensorflow.VerifierConfig.VerificationTimeoutInMs">
            <summary>
            Deadline for completion of all verification i.e. all the Toggle ON
            verifiers must complete execution within this time.
            </summary>
        </member>
        <member name="F:Tensorflow.VerifierConfig.StructureVerifierFieldNumber">
            <summary>Field number for the "structure_verifier" field.</summary>
        </member>
        <member name="P:Tensorflow.VerifierConfig.StructureVerifier">
            <summary>
            Perform structural validation on a tensorflow graph. Default is OFF.
            </summary>
        </member>
        <member name="T:Tensorflow.VerifierConfig.Types">
            <summary>Container for nested types declared in the VerifierConfig message type.</summary>
        </member>
        <member name="T:Tensorflow.VersionsReflection">
            <summary>Holder for reflection information generated from tensorflow/core/framework/versions.proto</summary>
        </member>
        <member name="P:Tensorflow.VersionsReflection.Descriptor">
            <summary>File descriptor for tensorflow/core/framework/versions.proto</summary>
        </member>
        <member name="T:Tensorflow.VersionDef">
             <summary>
             Version information for a piece of serialized data
            
             There are different types of versions for each type of data
             (GraphDef, etc.), but they all have the same common shape
             described here.
            
             Each consumer has "consumer" and "min_producer" versions (specified
             elsewhere).  A consumer is allowed to consume this data if
            
               producer >= min_producer
               consumer >= min_consumer
               consumer not in bad_consumers
             </summary>
        </member>
        <member name="F:Tensorflow.VersionDef.ProducerFieldNumber">
            <summary>Field number for the "producer" field.</summary>
        </member>
        <member name="P:Tensorflow.VersionDef.Producer">
            <summary>
            The version of the code that produced this data.
            </summary>
        </member>
        <member name="F:Tensorflow.VersionDef.MinConsumerFieldNumber">
            <summary>Field number for the "min_consumer" field.</summary>
        </member>
        <member name="P:Tensorflow.VersionDef.MinConsumer">
            <summary>
            Any consumer below this version is not allowed to consume this data.
            </summary>
        </member>
        <member name="F:Tensorflow.VersionDef.BadConsumersFieldNumber">
            <summary>Field number for the "bad_consumers" field.</summary>
        </member>
        <member name="P:Tensorflow.VersionDef.BadConsumers">
            <summary>
            Specific consumer versions which are disallowed (e.g. due to bugs).
            </summary>
        </member>
        <member name="M:Tensorflow.BaseSession._do_run(System.Collections.Generic.List{Tensorflow.Operation},System.Collections.Generic.List{Tensorflow.Tensor},System.Collections.Generic.Dictionary{System.Object,System.Object})">
            <summary>
            Runs a step based on the given fetches and feeds.
            </summary>
            <param name="target_list">A list of operations to be run, but not fetched.</param>
            <param name="fetch_list"></param>
            <param name="feed_dict"></param>
            <returns>
            A list of numpy ndarrays, corresponding to the elements of
            `fetch_list`.  If the ith element of `fetch_list` contains the
            name of an operation, the first Tensor output of that operation
            will be returned for that element.
            </returns>
        </member>
        <member name="M:Tensorflow.BaseSession._update_with_movers">
            <summary>
            If a tensor handle that is fed to a device incompatible placeholder, 
            we move the tensor to the right device, generate a new tensor handle, 
            and update feed_dict to use the new handle.
            </summary>
        </member>
        <member name="T:Tensorflow.FeedItem">
            <summary>
            Feed dictionary item
            </summary>
        </member>
        <member name="T:Tensorflow._ElementFetchMapper">
            <summary>
            Fetch mapper for singleton tensors and ops.
            </summary>
        </member>
        <member name="M:Tensorflow._ElementFetchMapper.build_results(System.Collections.Generic.List{NumSharp.NDArray})">
            <summary>
            Build results matching the original fetch shape.
            </summary>
            <param name="values"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow._FetchHandler">
            <summary>
            Handler for structured fetches.
            </summary>
        </member>
        <member name="T:Tensorflow.Status">
            <summary>
            TF_Status holds error information. It either has an OK code, or
            else an error code with an associated error message.
            </summary>
        </member>
        <member name="P:Tensorflow.Status.Message">
            <summary>
            Error message
            </summary>
        </member>
        <member name="P:Tensorflow.Status.Code">
            <summary>
            Error code
            </summary>
        </member>
        <member name="M:Tensorflow.Status.Check(System.Boolean)">
            <summary>
            Check status 
            Throw exception with error message if code != TF_OK
            </summary>
            <exception cref="T:Tensorflow.TensorflowException">When the returned check is not TF_Code.TF_OK</exception>
        </member>
        <member name="T:Tensorflow.Summaries.EventFileWriter">
            <summary>
            Creates a `EventFileWriter` and an event file to write to.
            </summary>
        </member>
        <member name="T:Tensorflow.Summaries.EventLoggerThread">
            <summary>
            Thread that logs events.
            </summary>
        </member>
        <member name="T:Tensorflow.Summaries.FileWriter">
            <summary>
            Writes `Summary` protocol buffers to event files.
            </summary>
        </member>
        <member name="M:Tensorflow.Summaries.Summary.merge(Tensorflow.Tensor[],System.String[],System.String)">
            <summary>
            Merges summaries.
            </summary>
            <param name="inputs"></param>
            <param name="collections"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Summaries.Summary.collect(Tensorflow.ITensorOrOperation,System.Collections.Generic.List{System.String},System.Collections.Generic.List{System.String})">
            <summary>
            Adds keys to a collection.
            </summary>
            <param name="val">The value to add per each key.</param>
            <param name="collections">A collection of keys to add.</param>
            <param name="default_collections">Used if collections is None.</param>
        </member>
        <member name="T:Tensorflow.Summaries.SummaryToEventTransformer">
            <summary>
            Abstractly implements the SummaryWriter API.
            </summary>
        </member>
        <member name="T:Tensorflow.AllocationType">
            <summary>
                Used internally to 
            </summary>
        </member>
        <member name="F:Tensorflow.AllocationType.FromPointer">
            <summary>
                Allocation was done by passing in a pointer, might be also holding reference to a C# object.
            </summary>
        </member>
        <member name="F:Tensorflow.AllocationType.Tensorflow">
            <summary>
                Allocation was done by calling c_api.TF_AllocateTensor or TF decided it has to copy data during c_api.TF_NewTensor. <br></br>
                Deallocation is handled solely by Tensorflow.
            </summary>
        </member>
        <member name="F:Tensorflow.AllocationType.Marshal">
            <summary>
                Allocation was done by Marshal.AllocateHGlobal
            </summary>
        </member>
        <member name="F:Tensorflow.AllocationType.GCHandle">
            <summary>
                Allocation was done by GCHandle.Alloc
            </summary>
        </member>
        <member name="M:Tensorflow.constant_op.constant(System.Object,Tensorflow.TF_DataType,System.Int32[],System.String)">
            <summary>
            Creates a constant tensor.
            
            The resulting tensor is populated with values of type `dtype`, as
            specified by arguments `value` and (optionally) `shape`
            </summary>
            <param name="value">A constant value (or list) of output type `dtype`.</param>
            <param name="dtype">The type of the elements of the resulting tensor.</param>
            <param name="shape">Optional dimensions of resulting tensor.</param>
            <param name="name">Optional name for the tensor.</param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.constant_op._constant_impl(System.Object,Tensorflow.TF_DataType,Tensorflow.TensorShape,System.String,System.Boolean,System.Boolean)">
            <param name="verify_shape">Boolean that enables verification of a shape of values.</param>
        </member>
        <member name="M:Tensorflow.constant_op._tensor_shape_tensor_conversion_function(Tensorflow.TensorShape,Tensorflow.TF_DataType,System.String,System.Boolean)">
            <summary>
            Function to convert TensorShape to Tensor.
            </summary>
            <param name="s"></param>
            <param name="dtype"></param>
            <param name="name"></param>
            <param name="as_ref"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.dtypes.as_numpy_dtype(Tensorflow.TF_DataType)">
            <summary>
            
            </summary>
            <param name="type"></param>
            <returns><see cref="T:System.Type"/> equivalent to <paramref name="type"/>, if none exists, returns null.</returns>
        </member>
        <member name="M:Tensorflow.dtypes.as_numpy_typecode(Tensorflow.TF_DataType)">
            <summary>
            
            </summary>
            <param name="type"></param>
            <returns></returns>
            <exception cref="T:System.ArgumentException">When <paramref name="type"/> has no equivalent <see cref="T:NumSharp.NPTypeCode"/></exception>
        </member>
        <member name="M:Tensorflow.dtypes.as_dtype(System.Type,System.Nullable{Tensorflow.TF_DataType})">
            <summary>
            
            </summary>
            <param name="type"></param>
            <param name="dtype"></param>
            <returns></returns>
            <exception cref="T:System.ArgumentException">When <paramref name="type"/> has no equivalent <see cref="T:Tensorflow.TF_DataType"/></exception>
        </member>
        <member name="T:Tensorflow.Tensor">
            <summary>
            A tensor is a generalization of vectors and matrices to potentially higher dimensions. 
            Internally, TensorFlow represents tensors as n-dimensional arrays of base datatypes.
            </summary>
        </member>
        <member name="F:Tensorflow.Tensor.AllocationReferenceHolder">
            <summary>
                When Tensor was created from an object that is managed by C#'s GC - this will hold reference to prevent it from being collected.
            </summary>
        </member>
        <member name="F:Tensorflow.Tensor.AllocationHandle">
            <summary>
                The handle that was used to allocate this tensor, dependent on <see cref="P:Tensorflow.Tensor.AllocationType"/>.
            </summary>
        </member>
        <member name="P:Tensorflow.Tensor.IsMemoryOwner">
            <summary>
                True if this Tensor holds data allocated by C#.
            </summary>
        </member>
        <member name="P:Tensorflow.Tensor.AllocationType">
            <summary>
                The allocation method used to create this Tensor.
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.IntPtr)">
            <summary>
                Create a Tensor object from an existing TF handle
            </summary>
            <param name="handle">Handle to a <see cref="T:Tensorflow.Tensor"/> object.</param>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.IntPtr,System.Int64[],Tensorflow.TF_DataType,System.Int32)">
            <summary>
            Create a new Tensor from the given unmanaged memory pointer (which must be allocated, fixed or pinned by the caller)
            Note: the caller is responsible for freeing the memory. Calling Dispose on this object will dispose the TensorFlow tensor
            but not the memory itself!
            </summary>
            <param name="data_ptr">Pointer to unmanaged, fixed or pinned memory which the caller owns</param>
            <param name="shape">Tensor shape</param>
            <param name="dType">TF data type</param>
            <param name="num_bytes">Size of the tensor in memory</param>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.Void*,System.Int64[],Tensorflow.TF_DataType,System.Int32)">
            <summary>
            Create a new Tensor from the given unmanaged memory pointer (which must be allocated, fixed or pinned by the caller)
            Note: the caller is responsible for freeing the memory. Calling Dispose on this object will dispose the TensorFlow tensor
            but not the memory itself!
            </summary>
            <param name="data_ptr">Pointer to unmanaged, fixed or pinned memory which the caller owns</param>
            <param name="shape">Tensor shape</param>
            <param name="dType">TF data type</param>
            <param name="num_bytes">Size of the tensor in memory</param>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.SByte[],System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a 1d Tensor from the given linear array and shape
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.SByte[],System.Int64[],System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a N-dimensional Tensor from the given array
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.SByte,System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a scalar Tensor from the given value
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.Boolean[],System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a 1d Tensor from the given linear array and shape
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.Boolean[],System.Int64[],System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a N-dimensional Tensor from the given array
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.Boolean,System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a scalar Tensor from the given value
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.Byte[],System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a 1d Tensor from the given linear array and shape
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.Byte[],System.Int64[],System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a N-dimensional Tensor from the given array
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.Byte,System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a scalar Tensor from the given value
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.Int16[],System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a 1d Tensor from the given linear array and shape
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.Int16[],System.Int64[],System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a N-dimensional Tensor from the given array
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.Int16,System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a scalar Tensor from the given value
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.UInt16[],System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a 1d Tensor from the given linear array and shape
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.UInt16[],System.Int64[],System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a N-dimensional Tensor from the given array
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.UInt16,System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a scalar Tensor from the given value
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.Int32[],System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a 1d Tensor from the given linear array and shape
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.Int32[],System.Int64[],System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a N-dimensional Tensor from the given array
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.Int32,System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a scalar Tensor from the given value
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.UInt32[],System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a 1d Tensor from the given linear array and shape
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.UInt32[],System.Int64[],System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a N-dimensional Tensor from the given array
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.UInt32,System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a scalar Tensor from the given value
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.Int64[],System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a 1d Tensor from the given linear array and shape
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.Int64[],System.Int64[],System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a N-dimensional Tensor from the given array
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.Int64,System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a scalar Tensor from the given value
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.UInt64[],System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a 1d Tensor from the given linear array and shape
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.UInt64[],System.Int64[],System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a N-dimensional Tensor from the given array
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.UInt64,System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a scalar Tensor from the given value
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.Single[])">
            <summary>
                Create a 1d Tensor from the given linear array and shape
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.Single[],System.Int64[],System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a N-dimensional Tensor from the given array
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.Single,System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a scalar Tensor from the given value
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.Double[],System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a 1d Tensor from the given linear array and shape
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.Double[],System.Int64[],System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a N-dimensional Tensor from the given array
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.Double,System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a scalar Tensor from the given value
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.Numerics.Complex[],System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a 1d Tensor from the given linear array and shape
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.Numerics.Complex[],System.Int64[],System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a N-dimensional Tensor from the given array
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.Numerics.Complex,System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Create a scalar Tensor from the given value
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.#ctor(System.String)">
            <summary>
                Create a string Tensor from the given string
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.CreateTensorFromArray(Tensorflow.TF_DataType,System.Int64[],System.Array,System.Int32)">
            <summary>
            Creates a new tensor from the given array without copying memory. The array is pinned down and the pointer passed on.
            </summary>
            <param name="shape">Represents the tensor shape.</param>
            <param name="data">The linear array of data, the data must fit in the tensor with the specified dimensions.</param>
            <param name="element_size">The number of bytes in memory of a single array element</param>
            <remarks>
            Use the FromBuffer method to create a tensor that has the specified dimensions
            and is initialized with data from the data array.   The data is copied starting
            at the start offset, for count bytes and is laid out into the tensor following the
            specified dimensions.
            </remarks>
        </member>
        <member name="M:Tensorflow.Tensor.CreateTensorFromArray(Tensorflow.TF_DataType,System.Int64[],System.Array,System.Int32,System.Int32,System.Int32)">
            <summary>
            Creates a new tensor from a subsection of the given array without copying memory. The array is pinned down and the pointer passed on.
            </summary>
            <param name="shape">Represents the tensor shape.</param>
            <param name="data">The linear array of data, the data must fit in the tensor with the specified dimensions.</param>
            <param name="start">The offset into the provided data array where the data resides.</param>
            <param name="count">The number of elements to copy from data.</param>
            <param name="element_size">The number of bytes in memory of a single array element</param>
            <remarks>
            Use the FromBuffer method to create a tensor that has the specified dimensions
            and is initialized with data from the data array.   The data is copied starting
            at the start offset, for count bytes and is laid out into the tensor following the
            specified dimensions.
            </remarks>
        </member>
        <member name="P:Tensorflow.Tensor.graph">
            <summary>
                The Graph that contains this tensor.
            </summary>
        </member>
        <member name="P:Tensorflow.Tensor.op">
            <summary>
                The Operation that produces this tensor as an output.
            </summary>
        </member>
        <member name="P:Tensorflow.Tensor.name">
            <summary>
            The string name of this tensor.<br/>
            Tensor.name is meaningless when eager execution is enabled.
            </summary>
        </member>
        <member name="P:Tensorflow.Tensor.value_index">
            <summary>
                The index of this tensor in the outputs of its Operation.
            </summary>
        </member>
        <member name="P:Tensorflow.Tensor.dtype">
            <summary>
                The DType of elements in this tensor.
            </summary>
        </member>
        <member name="P:Tensorflow.Tensor.Device">
            <summary>
                The name of the device on which this tensor will be produced, or null.
            </summary>
        </member>
        <member name="P:Tensorflow.Tensor.Tag">
            <summary>
                Used for keep other pointer when do implicit operating
            </summary>
        </member>
        <member name="P:Tensorflow.Tensor.EagerTensorHandle">
            <summary>
            TFE_TensorHandle
            </summary>
        </member>
        <member name="P:Tensorflow.Tensor.shape">
            <summary>
                Returns the shape of a tensor.
            </summary>
            <remarks>https://www.tensorflow.org/api_docs/python/tf/shape</remarks>
        </member>
        <member name="F:Tensorflow.Tensor.KerasHistory">
            <summary>
            Keras History: (Layer, (node_index, tensor_index))
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.set_shape(Tensorflow.TensorShape)">
            <summary>
                Updates the shape of this tensor.
            </summary>
        </member>
        <member name="M:Tensorflow.Tensor.set_shape(Tensorflow.Tensor)">
            <summary>
                Updates the shape of this tensor.
            </summary>
        </member>
        <member name="P:Tensorflow.Tensor.rank">
            <summary>
            number of dimensions <br></br>
            -1 Unknown  <br></br>
            0	Scalar (magnitude only) <br></br>
            1	Vector (magnitude and direction) <br></br>
            2	Matrix (table of numbers) <br></br>
            3	3-Tensor (cube of numbers) <br></br>
            n	n-Tensor (you get the idea)
            </summary>
            <remarks>https://www.tensorflow.org/api_docs/python/tf/rank</remarks>
        </member>
        <member name="M:Tensorflow.Tensor.consumers">
            <summary>
                Returns a list of Operations that consume this tensor.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Tensor.eval(Tensorflow.FeedItem[])">
            <summary>
                Evaluates this tensor in a `Session`.
            </summary>
            <param name="feed_dict">A dictionary that maps `Tensor` objects to feed values.</param>
            <returns>A <see cref="N:NumSharp"/> array corresponding to the value of this tensor.</returns>
        </member>
        <member name="M:Tensorflow.Tensor.eval(Tensorflow.Session,Tensorflow.FeedItem[])">
            <summary>
                Evaluates this tensor in a `Session`.
            </summary>
            <param name="feed_dict">A dictionary that maps `Tensor` objects to feed values.</param>
            <param name="session">The `Session` to be used to evaluate this tensor.</param>
            <returns>A <see cref="N:NumSharp"/> array corresponding to the value of this tensor.</returns>
        </member>
        <member name="M:Tensorflow.Tensor.DisposeManagedResources">
            <summary>
                Dispose any managed resources.
            </summary>
            <remarks>Equivalent to what you would perform inside <see cref="M:Tensorflow.DisposableObject.Dispose"/></remarks>
        </member>
        <member name="M:Tensorflow.Tensor.ToArray``1">
            <summary>
                
            </summary>
            <typeparam name="T"></typeparam>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Tensor.numpy">
            <summary>
            Copy of the contents of this Tensor into a NumPy array or scalar.
            </summary>
            <returns>
            A NumPy array of the same shape and dtype or a NumPy scalar, if this
            Tensor has rank 0.
            </returns>
        </member>
        <member name="M:Tensorflow.Tensor.BufferToArray">
            <summary>
            Copies the memory of current buffer onto newly allocated array.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Tensor.StringData">
            <summary>
                Extracts string array from current Tensor.
            </summary>
            <exception cref="T:System.InvalidOperationException">When <see cref="P:Tensorflow.Tensor.dtype"/> != TF_DataType.TF_STRING</exception>
        </member>
        <member name="T:Tensorflow.TensorArray">
             <summary>
             TensorArray is designed to hide an underlying implementation object
             and as such accesses many of that object's hidden fields.
            
             "Class wrapping dynamic-sized, per-time-step, write-once Tensor arrays.
             This class is meant to be used with dynamic iteration primitives such as
             `while_loop` and `map_fn`.  It supports gradient back-propagation via special
             "flow" control flow dependencies.
             </summary>
        </member>
        <member name="T:Tensorflow.TensorConverter">
            <summary>
                Provides various methods to conversion between types and <see cref="T:Tensorflow.Tensor"/>.
            </summary>
        </member>
        <member name="M:Tensorflow.TensorConverter.ToTensor(NumSharp.NDArray,System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Convert given <see cref="T:System.Array"/> to <see cref="T:Tensorflow.Tensor"/>.
            </summary>
            <param name="nd">The ndarray to convert, can be regular, jagged or multi-dim array.</param>
            <param name="astype">Convert <see cref="T:System.Array"/> to given <paramref name="astype"/> before inserting it into a <see cref="T:Tensorflow.Tensor"/>.</param>
            <exception cref="T:System.NotSupportedException"></exception>
        </member>
        <member name="M:Tensorflow.TensorConverter.ToTensor(NumSharp.NDArray,System.Nullable{NumSharp.NPTypeCode})">
            <summary>
                Convert given <see cref="T:NumSharp.NDArray"/> to <see cref="T:Tensorflow.Tensor"/>.
            </summary>
            <param name="nd">The ndarray to convert.</param>
            <param name="astype">Convert <see cref="T:System.Array"/> to given <paramref name="astype"/> before inserting it into a <see cref="T:Tensorflow.Tensor"/>.</param>
            <exception cref="T:System.NotSupportedException"></exception>
        </member>
        <member name="M:Tensorflow.TensorConverter.ToTensor(System.Array,System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Convert given <see cref="T:System.Array"/> to <see cref="T:Tensorflow.Tensor"/>.
            </summary>
            <param name="array">The array to convert, can be regular, jagged or multi-dim array.</param>
            <param name="astype">Convert <see cref="T:System.Array"/> to given <paramref name="astype"/> before inserting it into a <see cref="T:Tensorflow.Tensor"/>.</param>
            <exception cref="T:System.NotSupportedException"></exception>
        </member>
        <member name="M:Tensorflow.TensorConverter.ToTensor``1(``0,System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Convert given <see cref="T:System.Array"/> to <see cref="T:Tensorflow.Tensor"/>.
            </summary>
            <param name="constant">The constant scalar to convert</param>
            <param name="astype">Convert <paramref name="constant"/> to given <paramref name="astype"/> before inserting it into a <see cref="T:Tensorflow.Tensor"/>.</param>
            <exception cref="T:System.NotSupportedException"></exception>
        </member>
        <member name="M:Tensorflow.TensorConverter.ToTensor(System.String,System.Nullable{Tensorflow.TF_DataType})">
            <summary>
                Convert given <see cref="T:System.Array"/> to <see cref="T:Tensorflow.Tensor"/>.
            </summary>
            <param name="constant">The constant scalar to convert</param>
            <param name="astype">Convert <paramref name="constant"/> to given <paramref name="astype"/> before inserting it into a <see cref="T:Tensorflow.Tensor"/>.</param>
            <exception cref="T:System.NotSupportedException"></exception>
        </member>
        <member name="T:Tensorflow.TensorShape">
            <summary>
                Represents the shape of a `Tensor`.
            </summary>
            <remarks>https://www.tensorflow.org/api_docs/python/tf/TensorShape</remarks>
        </member>
        <member name="P:Tensorflow.TensorShape.dims">
            <summary>
                Returns a list of Dimensions, or None if the shape is unspecified.
            </summary>
        </member>
        <member name="P:Tensorflow.TensorShape.ndim">
            <summary>
                Returns the rank of this shape.
            </summary>
        </member>
        <member name="P:Tensorflow.TensorShape.rank">
            <summary>
                Returns the rank of this shape.
            </summary>
        </member>
        <member name="P:Tensorflow.TensorShape.size">
            <summary>
                Returns the size this shape represents.
            </summary>
        </member>
        <member name="P:Tensorflow.TensorShape.Item(NumSharp.Slice)">
            <summary>
            
            </summary>
            <param name="slice"></param>
            <returns></returns>
            <exception cref="T:System.ArgumentException">When <see cref="T:NumSharp.Slice"/> is not an Index.</exception>
        </member>
        <member name="M:Tensorflow.TensorShape.is_fully_defined">
            <summary>
                Returns True iff `self` is fully defined in every dimension.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.TensorShape.unknown_shape(System.Int32)">
            <summary>
            Returns an unknown TensorShape, optionally with a known rank.
            </summary>
            <param name="rank"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.TensorShape.concatenate(System.Int32[])">
            <summary>
                Returns the concatenation of the dimension in `self` and `other`.
            </summary>
            <param name="other"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.TensorShape.concatenate(Tensorflow.TensorShape)">
            <summary>
                Returns the concatenation of the dimension in `self` and `other`.
            </summary>
            <param name="other"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.TensorShape.merge_with(Tensorflow.TensorShape)">
            <summary>
            Returns a `TensorShape` combining the information in `self` and `other`.
            </summary>
            <param name="other"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.TensorShape.as_list">
            <summary>
                Returns a cloned array from <see cref="P:Tensorflow.TensorShape.dims"/>.
            </summary>
        </member>
        <member name="M:Tensorflow.tensor_util.constant_value(Tensorflow.Tensor,System.Boolean)">
            <summary>
            Returns the constant value of the given tensor, if efficiently calculable.
            </summary>
            <param name="tensor"></param>
            <param name="partial"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.tensor_util.make_tensor_proto(System.Object,Tensorflow.TF_DataType,System.Int32[],System.Boolean,System.Boolean)">
            <summary>
            Create a TensorProto.
            </summary>
            <param name="values"></param>
            <param name="dtype"></param>
            <param name="shape"></param>
            <param name="verify_shape"></param>
            <param name="allow_broadcast"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.TF_DataType">
            <summary>
            TF_DataType holds the type for a scalar value.  E.g., one slot in a tensor.
            The enum values here are identical to corresponding values in types.proto.
            </summary>
        </member>
        <member name="T:Tensorflow.Train.AdamOptimizer">
            <summary>
            Optimizer that implements the Adam algorithm.
            http://arxiv.org/abs/1412.6980
            </summary>
        </member>
        <member name="M:Tensorflow.Train.ExponentialMovingAverage.apply(Tensorflow.RefVariable[])">
            <summary>
            Maintains moving averages of variables.
            </summary>
            <param name="var_list"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Train.GradientDescentOptimizer">
            <summary>
            Optimizer that implements the gradient descent algorithm.
            </summary>
        </member>
        <member name="M:Tensorflow.Train.GradientDescentOptimizer.#ctor(System.Single,System.Boolean,System.String)">
            <summary>
            Construct a new gradient descent optimizer.
            </summary>
            <param name="learning_rate">A Tensor or a floating point value.  The learning
            rate to use.</param>
            <param name="use_locking">If true use locks for update operations.</param>
            <param name="name">Optional name prefix for the operations created when applying
            gradients.Defaults to "GradientDescent".</param>
            <remarks>
            When eager execution is enabled, `learning_rate` can be a callable that
            takes no arguments and returns the actual value to use.This can be useful
            for changing these values across different invocations of optimizer
            functions.
            </remarks>
        </member>
        <member name="M:Tensorflow.Train.moving_averages.assign_moving_average(Tensorflow.IVariableV1,Tensorflow.IVariableV1,Tensorflow.Tensor,System.Boolean,System.String)">
            <summary>
            Compute the moving average of a variable.
            </summary>
            <param name="variable"></param>
            <param name="value"></param>
            <param name="decay"></param>
            <param name="zero_debias"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Train.QueueRunner">
            <summary>
            Holds a list of enqueue operations for a queue, each to be run in a thread.
            </summary>
        </member>
        <member name="M:Tensorflow.Train.SlotCreator.create_slot(Tensorflow.RefVariable,Tensorflow.Tensor,System.String,System.Boolean)">
            <summary>
            Create a slot initialized to the given value.
            </summary>
            <param name="primary"></param>
            <param name="val"></param>
            <param name="name"></param>
            <param name="colocate_with_primary"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Train.SlotCreator.create_zeros_slot(Tensorflow.IVariableV1,System.String,Tensorflow.TF_DataType,System.Boolean)">
            <summary>
            Create a slot initialized to 0 with same shape as the primary object.
            </summary>
            <param name="primary"></param>
            <param name="name"></param>
            <param name="dtype"></param>
            <param name="colocate_with_primary"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Train.SlotCreator.create_slot_with_initializer(Tensorflow.IVariableV1,Tensorflow.IInitializer,Tensorflow.TensorShape,Tensorflow.TF_DataType,System.String,System.Boolean)">
            <summary>
            Creates a slot initialized using an `Initializer`.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Train.SlotCreator._create_slot_var(Tensorflow.IVariableV1,System.Object,System.String,System.Boolean,Tensorflow.TensorShape,Tensorflow.TF_DataType)">
            <summary>
            Helper function for creating a slot variable.
            </summary>
            <param name="primary"></param>
            <param name="val"></param>
            <param name="scope"></param>
            <param name="validate_shape"></param>
            <param name="shape"></param>
            <param name="dtype"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Train.Trackable._add_variable_with_custom_getter(Tensorflow.VariableArgs)">
            <summary>
            Restore-on-create for a variable be saved with this `Checkpointable`.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Train.Trackable._handle_deferred_dependencies(System.String,Tensorflow.IVariableV1)">
            <summary>
            Pop and load any deferred checkpoint restores into `trackable`.
            </summary>
            <param name="name"></param>
            <param name="trackable"></param>
        </member>
        <member name="M:Tensorflow.Train.Trackable._maybe_initialize_trackable">
            <summary>
            Initialize dependency management.
            </summary>
        </member>
        <member name="T:Tensorflow.Training.Coordinator">
            <summary>
            A coordinator for threads
            </summary>
        </member>
        <member name="M:Tensorflow.Training.learning_rate_decay.polynomial_decay(System.Single,Tensorflow.RefVariable,System.Single,System.Single,System.Single,System.Boolean,System.String)">
            <summary>
            Applies a polynomial decay to the learning rate.
            </summary>
            <param name="learning_rate"></param>
            <param name="global_step"></param>
            <param name="decay_steps"></param>
            <param name="end_learning_rate"></param>
            <param name="power"></param>
            <param name="cycle"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Training.SessionRunHook">
            <summary>
            Hook to extend calls to MonitoredSession.run().
            </summary>
        </member>
        <member name="M:Tensorflow.Training.SessionRunHook.begin">
            <summary>
            Called once before using the session.
            </summary>
        </member>
        <member name="M:Tensorflow.Training.SessionRunHook.after_create_session(Tensorflow.Session,Tensorflow.Training.Coordinator)">
            <summary>
            Called when new TensorFlow session is created.
            </summary>
            <param name="session"></param>
            <param name="coord"></param>
        </member>
        <member name="M:Tensorflow.Training.SessionRunHook.before_run(Tensorflow.Training.SessionRunContext)">
            <summary>
            Called before each call to run().
            </summary>
            <param name="run_context"></param>
        </member>
        <member name="M:Tensorflow.Training.SessionRunHook.after_run(Tensorflow.Training.SessionRunContext,Tensorflow.Training.SessionRunValues)">
            <summary>
            Called after each call to run().
            </summary>
        </member>
        <member name="M:Tensorflow.Training.SessionRunHook.end(Tensorflow.Session)">
            <summary>
            Called at the end of session.
            </summary>
        </member>
        <member name="T:Tensorflow.Training._HookTimer">
            <summary>
            Base timer for determining when Hooks should trigger.
            </summary>
        </member>
        <member name="M:Tensorflow.Training._HookTimer.reset">
            <summary>
            Resets the timer.
            </summary>
        </member>
        <member name="M:Tensorflow.Training._HookTimer.should_trigger_for_step(System.Int32)">
            <summary>
            Return true if the timer should trigger for the specified step.
            </summary>
            <param name="step"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Training._HookTimer.update_last_triggered_step(System.Int32)">
            <summary>
            Update the last triggered time and step number.
            </summary>
            <param name="step"></param>
        </member>
        <member name="M:Tensorflow.Training._HookTimer.last_triggered_step">
            <summary>
            Returns the last triggered time step or None if never triggered.
            </summary>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Optimizer">
            <summary>
            Base class for optimizers.
            This class defines the API to add Ops to train a model.  You never use this
            class directly, but instead instantiate one of its subclasses such as
            `GradientDescentOptimizer`, `AdagradOptimizer`, or `MomentumOptimizer`.
            </summary>
        </member>
        <member name="M:Tensorflow.Optimizer.minimize(Tensorflow.Tensor,Tensorflow.IVariableV1,System.Collections.Generic.List{Tensorflow.IVariableV1},Tensorflow.GateGradientType,System.Nullable{System.Int32},System.Boolean,System.String,Tensorflow.Tensor)">
            <summary>
            Add operations to minimize `loss` by updating `var_list`
             
             This method simply combines calls `compute_gradients()` and
             `apply_gradients()`. If you want to process the gradient before applying
             them call `compute_gradients()` and `apply_gradients()` explicitly instead
             of using this function.
            </summary>
            <param name="loss">A `Tensor` containing the value to minimize.</param>
            <param name="global_step">Optional `Variable` to increment by one after the
            variables have been updated.</param>
            <param name="var_list">Optional list or tuple of `Variable` objects to update to
            minimize `loss`.  Defaults to the list of variables collected in
            the graph under the key `GraphKeys.TRAINABLE_VARIABLES`.</param>
            <param name="gate_gradients">
            How to gate the computation of gradients.  Can be
            `GATE_NONE`, `GATE_OP`, or  `GATE_GRAPH`.
            </param>
            <param name="aggregation_method">
            Specifies the method used to combine gradient terms.
            Valid values are defined in the class `AggregationMethod`.
            </param>
            <param name="colocate_gradients_with_ops"></param>
            <param name="name">Optional name for the returned operation.</param>
            <param name="grad_loss">Optional. A `Tensor` holding the gradient computed for `loss`.</param>
            <returns>
            An Operation that updates the variables in `var_list`.  If `global_step`
            was not `None`, that operation also increments `global_step`.
            </returns>
        </member>
        <member name="M:Tensorflow.Optimizer.apply_gradients(System.Tuple{Tensorflow.Tensor,Tensorflow.IVariableV1}[],Tensorflow.IVariableV1,System.String)">
            <summary>
            Apply gradients to variables.
            
            This is the second part of `minimize()`. It returns an `Operation` that
            applies gradients.
            </summary>
            <param name="grads_and_vars">List of (gradient, variable) pairs as returned by
            `compute_gradients()`.</param>
            <param name="global_step">Optional `Variable` to increment by one after the
            variables have been updated.</param>
            <param name="name">Optional name for the returned operation.  Default to the
            name passed to the `Optimizer` constructor.</param>
            <returns>
            An `Operation` that applies the specified gradients. If `global_step`
            was not None, that operation also increments `global_step`.</returns>
        </member>
        <member name="M:Tensorflow.Optimizer._create_slots(Tensorflow.IVariableV1[])">
            <summary>
            Create the beta1 and beta2 accumulators on the same device as the first
            variable. Sort the var_list to make sure this device is consistent across
            workers (these need to go on the same PS, otherwise some updates are
            silently ignored).
            </summary>
            <param name="var_list"></param>
        </member>
        <member name="M:Tensorflow.Optimizer._create_non_slot_variable(System.Single,System.String,Tensorflow.IVariableV1)">
            <summary>
            Add an extra variable, not associated with a slot.
            </summary>
            <param name="initial_value"></param>
            <param name="name"></param>
            <param name="colocate_with"></param>
        </member>
        <member name="M:Tensorflow.Optimizer._apply_sparse_duplicate_indices(Tensorflow.Framework.IndexedSlices,Tensorflow.RefVariable)">
            <summary>
            Add ops to apply sparse gradients to `var`, with repeated sparse indices.
            </summary>
            <param name="grad"></param>
            <param name="var"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Optimizer.get_slot(Tensorflow.IVariableV1,System.String)">
            <summary>
            Return a slot named `name` created for `var` by the Optimizer.
            </summary>
            <param name="var"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Optimizer.compute_gradients(Tensorflow.Tensor,System.Collections.Generic.List{Tensorflow.IVariableV1},System.Nullable{System.Int32},Tensorflow.GateGradientType,System.Boolean,Tensorflow.Tensor)">
            <summary>
            Compute gradients of `loss` for the variables in `var_list`.
            </summary>
            <param name="loss"></param>
            <param name="gate_gradients"></param>
            <returns>
            A list of (gradient, variable) pairs. Variable is always present, but
            gradient can be `None`.
            </returns>
        </member>
        <member name="M:Tensorflow.Optimizer._zeros_slot(Tensorflow.IVariableV1,System.String,System.String)">
            <summary>
            Find or create a slot initialized with 0.0.
            </summary>
            <param name="var"></param>
            <param name="slot_name"></param>
            <param name="op_name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Optimizer._restore_slot_variable(System.String,Tensorflow.IVariableV1,Tensorflow.IVariableV1)">
            <summary>
            Restore a newly created slot variable's value.
            </summary>
        </member>
        <member name="M:Tensorflow.BaseSaverBuilder.save_op(Tensorflow.Tensor,Tensorflow.MySaveableObject[])">
            <summary>
            Create an Op to save 'saveables'.
            </summary>
            <param name="filename_tensor"></param>
            <param name="saveables"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.BaseSaverBuilder._AddRestoreOps(Tensorflow.Tensor,Tensorflow.MySaveableObject[],System.Boolean,System.Boolean,System.Int32,System.String)">
            <summary>
            Add operations to restore saveables.
            </summary>
            <param name="filename_tensor"></param>
            <param name="saveables"></param>
            <param name="restore_sequentially"></param>
            <param name="reshape"></param>
            <param name="preferred_shard"></param>
            <param name="name"></param>
            <returns>An Operation that restores the variables.</returns>
        </member>
        <member name="M:Tensorflow.checkpoint_management.update_checkpoint_state_internal(System.String,System.String,System.Collections.Generic.List{System.String},System.String,System.Boolean,System.Collections.Generic.List{System.Single},System.Nullable{System.Single})">
            <summary>
            Updates the content of the 'checkpoint' file.
            </summary>
            <param name="save_dir">Directory where the model was saved.</param>
            <param name="model_checkpoint_path">The checkpoint file.</param>
            <param name="all_model_checkpoint_paths">List of strings.</param>
            <param name="latest_filename"></param>
            <param name="save_relative_paths"></param>
            <param name="all_model_checkpoint_timestamps"></param>
            <param name="last_preserved_timestamp"></param>
        </member>
        <member name="M:Tensorflow.checkpoint_management._GetCheckpointFilename(System.String,System.String)">
            <summary>
            Returns a filename for storing the CheckpointState.
            </summary>
            <param name="save_dir">The directory for saving and restoring checkpoints.</param>
            <param name="latest_filename">
            Name of the file in 'save_dir' that is used
            to store the CheckpointState.
            </param>
            <returns>he path of the file that contains the CheckpointState proto.</returns>
        </member>
        <member name="M:Tensorflow.checkpoint_management.meta_graph_filename(System.String,System.String)">
            <summary>
            Returns the meta graph filename.
            </summary>
            <param name="checkpoint_filename"></param>
            <param name="meta_graph_suffix"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.checkpoint_management.latest_checkpoint(System.String,System.String)">
            <summary>
            Finds the filename of latest saved checkpoint file.
            </summary>
            <param name="checkpoint_dir"></param>
            <param name="latest_filename"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.saveable_object_util.validate_and_slice_inputs(Tensorflow.IVariableV1[])">
            <summary>
            Returns the variables and names that will be used for a Saver.
            </summary>
            <param name="names_to_saveables"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.saveable_object_util.saveable_objects_for_op(Tensorflow.Tensor,System.String)">
            <summary>
            Create `SaveableObject`s from an operation.
            </summary>
            <param name="op"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Saver">
            <summary>
            Saves and restores variables.
            </summary>
        </member>
        <member name="M:Tensorflow.Saver.restore(Tensorflow.Session,System.String)">
            <summary>
            Restores previously saved variables.
            
            This method runs the ops added by the constructor for restoring variables.
            It requires a session in which the graph was launched.  The variables to
            restore do not have to have been initialized, as restoring is itself a way
            to initialize variables.
            </summary>
            <param name="sess">A `Session` to use to restore the parameters. None in eager mode.</param>
            <param name="save_path">Path where parameters were previously saved.</param>
        </member>
        <member name="M:Tensorflow.Saver.export_meta_graph(System.String,System.String[],System.String,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Writes `MetaGraphDef` to save_path/filename.
            </summary>
            <param name="filename"></param>
            <param name="collection_list"></param>
            <param name="as_text"></param>
            <param name="export_scope"></param>
            <param name="clear_devices"></param>
            <param name="clear_extraneous_savers"></param>
            <param name="strip_default_attrs"></param>
        </member>
        <member name="M:Tensorflow.Saver._RecordLastCheckpoint(System.String)">
            <summary>
            Manages the list of the latest checkpoints.
            </summary>
            <param name="latest_save_path"></param>
        </member>
        <member name="M:Tensorflow.Saver._MaybeDeleteOldCheckpoints(System.String)">
            <summary>
            Deletes old checkpoints if necessary.
            </summary>
            <param name="meta_graph_suffix"></param>
        </member>
        <member name="M:Tensorflow.saver._create_saver_from_imported_meta_graph(Tensorflow.MetaGraphDef,System.String,System.Collections.Generic.Dictionary{System.String,Tensorflow.IVariableV1})">
            <summary>
            Return a saver for restoring variable values to an imported MetaGraph.
            </summary>
            <param name="meta_graph_def"></param>
            <param name="import_scope"></param>
            <param name="imported_vars"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.SaveSpec">
            <summary>
            Class used to describe tensor slices that need to be saved.
            </summary>
        </member>
        <member name="T:Tensorflow.Util.Locks">
            <summary>
                Provides a set of locks on different shared levels.
            </summary>
        </member>
        <member name="P:Tensorflow.Util.Locks.ThreadWide">
            <summary>
                A seperate lock for every requesting thread.
            </summary>
            <remarks>This property is thread-safe.</remarks>
        </member>
        <member name="M:Tensorflow.Util.nest.zip_many(System.Collections.Generic.IEnumerable{System.Object}[])">
            <summary>
            Untyped implementation of zip for arbitrary data
            
            Converts an list of lists or arrays [[1,2,3], [4,5,6], [7,8,9]] into a list of arrays 
            representing tuples of the same index of all source arrays [[1,4,7], [2,5,9], [3,6,9]]
            </summary>
            <param name="lists">one or multiple sequences to be zipped</param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Util.nest._sorted(System.Collections.IDictionary)">
            <summary>
            Returns a sorted list of the dict keys, with error if keys not sortable.
            </summary>
        </member>
        <member name="M:Tensorflow.Util.nest._sequence_like(System.Object,System.Collections.Generic.IEnumerable{System.Object})">
            <summary>
            Converts the sequence `args` to the same type as `instance`.
            </summary>
            <param name="instance">an instance of `tuple`, `list`, `namedtuple`, `dict`, or
            `collections.OrderedDict`.</param>
            <param name="args">elements to be converted to the `instance` type.</param>
            <returns>`args` with the type of `instance`.</returns>
        </member>
        <member name="M:Tensorflow.Util.nest._yield_value(System.Object)">
            <summary>
            Yields the next value from the given iterable.
            </summary>
        </member>
        <member name="M:Tensorflow.Util.nest._packed_nest_with_indices(System.Object,System.Collections.Generic.List{System.Object},System.Int32)">
            <summary>
            Helper function for pack_sequence_as.
            </summary>
            <param name="structure">Substructure (list / tuple / dict) to mimic.</param>
            <param name="flat">Flattened values to output substructure for.</param>
            <param name="index">Index at which to start reading from flat.</param>
            <returns>
            The tuple(new_index, child), where:
             * new_index - the updated index into `flat` having processed `structure`.
             * packed - the subset of `flat` corresponding to `structure`,
            having started at `index`, and packed into the same nested
            format.</returns>
        </member>
        <member name="M:Tensorflow.Util.nest.pack_sequence_as(System.Object,System.Collections.Generic.IEnumerable{System.Object},System.Boolean)">
            <summary>
            Returns a given flattened sequence packed into a given structure.
            If `structure` is a scalar, `flat_sequence` must be a single-element list;
            in this case the return value is `flat_sequence[0]`.
            
            If `structure` is or contains a dict instance, the keys will be sorted to
            pack the flat sequence in deterministic order. This is true also for
            `OrderedDict` instances: their sequence order is ignored, the sorting order of
            keys is used instead. The same convention is followed in `flatten`.
            This correctly repacks dicts and `OrderedDict`s after they have been
            flattened, and also allows flattening an `OrderedDict` and then repacking it
            back using a corresponding plain dict, or vice-versa.
            Dictionaries with non-sortable keys cannot be flattened.
            </summary>
            <param name="structure">
            Nested structure, whose structure is given by nested lists,
            tuples, and dicts. Note: numpy arrays and strings are considered
            scalars.
            </param>
            <param name="flat_sequence"> flat sequence to pack.</param>
            <returns> `flat_sequence` converted to have the same recursive structure as
            `structure`.
            </returns>
        </member>
        <member name="M:Tensorflow.Util.nest.map_structure(System.Func{System.Object[],System.Object},System.Collections.Generic.IEnumerable{System.Object}[])">
             <summary>
             Applies `func` to each entry in `structure` and returns a new structure.
            
              Applies `func(x[0], x[1], ...)` where x[i] is an entry in
              `structure[i]`.  All structures in `structure` must have the same arity,
              and the return value will contain the results in the same structure.
             </summary>
             <param name="func"> A callable that accepts as many arguments as there are structures.</param>
             <param name="structure">one or many IEnumerable of object</param>
             <returns>
                A new structure with the same arity as `structure`, whose values correspond
                to `func(x[0], x[1], ...)` where `x[i]` is a value in the corresponding
                location in `structure[i]`. If there are different sequence types and
                `check_types` is `False` the sequence types of the first structure will be
                used.
             </returns>
        </member>
        <member name="M:Tensorflow.Util.nest.map_structure(System.Func{System.Object,System.Object},System.Collections.Generic.IEnumerable{System.Object})">
            <summary>
            Same as map_structure, but with only one structure (no combining of multiple structures)
            </summary>
            <param name="func"></param>
            <param name="structure"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Util.SafeHandleExtensions.Lease(System.Runtime.InteropServices.SafeHandle)">
            <summary>
            Acquires a lease on a safe handle. The lease increments the reference count of the <see cref="T:System.Runtime.InteropServices.SafeHandle"/>
            to ensure the handle is not released prior to the lease being released.
            </summary>
            <remarks>
            This method is intended to be used in the initializer of a <c>using</c> statement. Failing to release the
            lease will permanently prevent the underlying <see cref="T:System.Runtime.InteropServices.SafeHandle"/> from being released by the garbage
            collector.
            </remarks>
            <param name="handle">The <see cref="T:System.Runtime.InteropServices.SafeHandle"/> to lease.</param>
            <returns>A <see cref="T:Tensorflow.Util.SafeHandleLease"/>, which must be disposed to release the resource.</returns>
            <exception cref="T:System.ObjectDisposedException">If the lease could not be acquired.</exception>
        </member>
        <member name="T:Tensorflow.Util.SafeHandleLease">
             <summary>
             Represents a lease of a <see cref="T:System.Runtime.InteropServices.SafeHandle"/>.
             </summary>
             <seealso cref="M:Tensorflow.Util.SafeHandleExtensions.Lease(System.Runtime.InteropServices.SafeHandle)"/>
             <devdoc>
             <para>Elements in this section may be referenced by <c>&lt;inheritdoc&gt;</c> elements to provide common
             language in documentation remarks.</para>
            
             <usage>
             <para>The result of this method is only valid when the underlying handle has not been disposed. If the lifetime
             of the object is unclear, a lease may be used to prevent disposal while the object is in use. See
             <see cref="M:Tensorflow.Util.SafeHandleExtensions.Lease(System.Runtime.InteropServices.SafeHandle)"/>.</para>
             </usage>
             </devdoc>
        </member>
        <member name="M:Tensorflow.Util.UnmanagedExtensions.Stream(NumSharp.Backends.Unmanaged.UnmanagedMemoryBlock{System.Byte})">
            <summary>
                Creates a memory stream based on given <paramref name="block"/>.
            </summary>
            <param name="block">The block to stream. Can be default/null.</param>
            <remarks>There is no need to dispose the returned <see cref="T:System.IO.UnmanagedMemoryStream"/></remarks>
        </member>
        <member name="M:Tensorflow.Util.UnmanagedExtensions.Stream(NumSharp.Backends.Unmanaged.UnmanagedMemoryBlock{System.Byte},System.Int64)">
            <summary>
                Creates a memory stream based on given <paramref name="block"/>.
            </summary>
            <param name="block">The block to stream. Can be default/null.</param>
            <param name="offset">Offset from the start of the block.</param>
            <remarks>There is no need to dispose the returned <see cref="T:System.IO.UnmanagedMemoryStream"/></remarks>
        </member>
        <member name="M:Tensorflow.Util.UnmanagedExtensions.Stream(System.IntPtr,System.Int64)">
            <summary>
                Creates a memory stream based on given <paramref name="address"/>.
            </summary>
            <param name="address">The block to stream. Can be IntPtr.Zero.</param>
            <param name="length">The length of the block in bytes.</param>
            <remarks>There is no need to dispose the returned <see cref="T:System.IO.UnmanagedMemoryStream"/></remarks>
        </member>
        <member name="M:Tensorflow.Util.UnmanagedExtensions.Stream(System.IntPtr,System.Int64,System.Int64)">
            <summary>
                Creates a memory stream based on given <paramref name="address"/>.
            </summary>
            <param name="address">The block to stream. Can be IntPtr.Zero.</param>
            <param name="offset">Offset from the start of the block.</param>
            <param name="length">The length of the block in bytes.</param>
            <remarks>There is no need to dispose the returned <see cref="T:System.IO.UnmanagedMemoryStream"/></remarks>
        </member>
        <member name="P:Tensorflow.Util.UnorderedMap`2.Item(`0)">
            <summary>
            Avoid null when accessing not existed element
            </summary>
            <param name="key"></param>
            <returns></returns>
        </member>
        <member name="F:Tensorflow.BaseResourceVariable.handle">
            <summary>
            Tensor handle
            </summary>
        </member>
        <member name="M:Tensorflow.BaseResourceVariable.variable_accessed(Tensorflow.BaseResourceVariable)">
            <summary>
            Records that `variable` was accessed for the tape and FuncGraph.
            </summary>
        </member>
        <member name="M:Tensorflow.BaseResourceVariable.read_value">
            <summary>
            Constructs an op which reads the value of this variable.
            
            Should be used when there are multiple reads, or when it is desirable to
            read the value only after some condition is true.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_state_ops.variable_v2(System.Int32[],Tensorflow.TF_DataType,System.String,System.String,System.String)">
            <summary>
            Holds state in the form of a tensor that persists across steps.
            Outputs a ref to the tensor state so it may be read or modified.
            </summary>
            <param name="shape">The shape of the variable tensor.</param>
            <param name="dtype">The type of elements in the variable tensor.</param>
            <param name="name"></param>
            <param name="container"></param>
            <param name="shared_name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.gen_state_ops.assign``1(``0,System.Object,System.Boolean,System.Boolean,System.String)">
            <summary>
            Update 'ref' by assigning 'value' to it
            </summary>
            <param name="ref"></param>
            <param name="value"></param>
            <param name="validate_shape"></param>
            <param name="use_locking"></param>
            <param name="name"></param>
        </member>
        <member name="M:Tensorflow.gen_state_ops.scatter_add(Tensorflow.IVariableV1,Tensorflow.Tensor,Tensorflow.Tensor,System.Boolean,System.String)">
            <summary>
            Adds sparse updates to a variable reference.
            </summary>
            <param name="ref"></param>
            <param name="indices"></param>
            <param name="updates"></param>
            <param name="use_locking"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.IVariableV1">
            <summary>
            A variable maintains state in the graph across calls to `run()`. You add a
            variable to the graph by constructing an instance of the class `Variable`.
            
            The `Variable()` constructor requires an initial value for the variable,
            which can be a `Tensor` of any type and shape. The initial value defines the
            type and shape of the variable. After construction, the type and shape of
            the variable are fixed. The value can be changed using one of the assign methods.
            https://tensorflow.org/guide/variables
            </summary>
        </member>
        <member name="P:Tensorflow.IVariableV1.Handle">
            <summary>
            Handle is ref type
            </summary>
        </member>
        <member name="P:Tensorflow.IVariableV1.GraphElement">
            <summary>
            GraphElement is a copy of Handle
            </summary>
        </member>
        <member name="M:Tensorflow.RefVariable._try_guard_against_uninitialized_dependencies(System.String,Tensorflow.Tensor)">
            <summary>
            Attempt to guard against dependencies on uninitialized variables.
            </summary>
            <param name="initial_value"></param>
        </member>
        <member name="M:Tensorflow.RefVariable._safe_initial_value_from_tensor(System.String,Tensorflow.Tensor,System.Collections.Generic.Dictionary{System.String,Tensorflow.Operation})">
            <summary>
            Replace dependencies on variables with their initialized values.
            </summary>
            <param name="tensor">A `Tensor`. The tensor to replace.</param>
            <param name="op_cache">A dict mapping operation names to `Operation`s.</param>
            <returns>A `Tensor` compatible with `tensor`.</returns>
        </member>
        <member name="M:Tensorflow.RefVariable.assign``1(``0,System.Boolean,System.String,System.Boolean)">
            <summary>
            Assigns a new value to the variable.
            </summary>
            <param name="value">The new value for this variable.</param>
            <param name="use_locking">If `True`, use locking during the assignment.</param>
            <param name="name">The name of the operation to be created</param>
            <param name="read_value">
            if True, will return something which evaluates to the
            new value of the variable; if False will return the assign op.
            </param>
            <returns>
            A `Tensor` that will hold the new value of this variable after
            the assignment has completed.
            </returns>
        </member>
        <member name="M:Tensorflow.RefVariable.read_value">
            <summary>
            Returns the value of this variable, read in the current context.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.RefVariable.initial_value">
            <summary>
            Returns the Tensor used as the initial value for the variable.
            </summary>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.ResourceVariable">
            <summary>
            Variable based on resource handles.
            </summary>
        </member>
        <member name="M:Tensorflow.ResourceVariable.assign_sub(Tensorflow.Tensor,System.Boolean,System.String,System.Boolean)">
            <summary>
            Subtracts a value from this variable.
            </summary>
            <param name="delta"></param>
            <param name="use_locking"></param>
            <param name="name"></param>
            <param name="read_value"></param>
        </member>
        <member name="M:Tensorflow.ResourceVariable.assign_add(Tensorflow.Tensor,System.Boolean,System.String,System.Boolean)">
            <summary>
            Adds a value to this variable.
            </summary>
            <param name="delta"></param>
            <param name="use_locking"></param>
            <param name="name"></param>
            <param name="read_value"></param>
        </member>
        <member name="M:Tensorflow.state_ops.variable_op_v2(System.Int32[],Tensorflow.TF_DataType,System.String,System.String,System.String)">
            <summary>
            Create a variable Operation.
            </summary>
            <param name="shape"></param>
            <param name="dtype"></param>
            <param name="name"></param>
            <param name="container"></param>
            <param name="shared_name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.variables.trainable_variables">
            <summary>
            Returns all variables created with `trainable=True`
            </summary>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.variables._all_saveable_objects(System.String)">
            <summary>
            Returns all variables and `SaveableObject`s that must be checkpointed.
            </summary>
            <param name="scope"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.variables.global_variables(System.String)">
            <summary>
            Returns global variables.
            </summary>
            <param name="scope">
            (Optional.) A string. If supplied, the resulting list is filtered
            to include only items whose `name` attribute matches `scope` using
            `re.match`. Items without a `name` attribute are never returned if a
            scope is supplied. The choice of `re.match` means that a `scope` without
            special tokens filters by prefix.
            </param>
            <returns>A list of `Variable` objects.</returns>
        </member>
        <member name="M:Tensorflow.variables.variables_initializer(Tensorflow.IVariableV1[],System.String)">
            <summary>
            Returns an Op that initializes a list of variables.
            </summary>
            <param name="var_list">List of `Variable` objects to initialize.</param>
            <param name="name">Optional name for the returned operation.</param>
            <returns>An Op that run the initializers of all the specified variables.</returns>
        </member>
        <member name="M:Tensorflow.variables._safe_initial_value_from_op(System.String,Tensorflow.Operation,System.Collections.Generic.Dictionary{System.String,Tensorflow.Operation})">
            <summary>
            Replace dependencies on variables with their initialized values.
            </summary>
            <param name="name"></param>
            <param name="op"></param>
            <param name="op_cache"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.VariableScope">
            <summary>
            Variable scope object to carry defaults to provide to `get_variable`
            </summary>
        </member>
        <member name="T:Tensorflow.variable_scope">
            <summary>
            A context manager for defining ops that creates variables (layers).
            </summary>
        </member>
        <member name="M:Tensorflow.variable_scope._get_unique_variable_scope(System.String)">
            <summary>
            Get a name with the given prefix unique in the current variable scope.
            </summary>
            <param name="prefix"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow._ReuseMode">
            <summary>
            Mode for variable access within a variable scope.
            </summary>
        </member>
        <member name="T:Tensorflow._UnreadVariable">
            <summary>
            Represents a future for a read of a variable.
            Pretends to be the tensor if anyone looks.
            </summary>
        </member>
        <member name="T:Tensorflow._VariableStore">
            <summary>
            Variable store that carries a number of named Variables.
            </summary>
        </member>
        <member name="T:System.Index">
            <summary>Represent a type can be used to index a collection either from the start or the end.</summary>
            <remarks>
            Index is used by the C# compiler to support the new index syntax
            <code>
            int[] someArray = new int[5] { 1, 2, 3, 4, 5 } ;
            int lastElement = someArray[^1]; // lastElement = 5
            </code>
            </remarks>
        </member>
        <member name="M:System.Index.#ctor(System.Int32,System.Boolean)">
            <summary>Construct an Index using a value and indicating if the index is from the start or from the end.</summary>
            <param name="value">The index value. it has to be zero or positive number.</param>
            <param name="fromEnd">Indicating if the index is from the start or from the end.</param>
            <remarks>
            If the Index constructed from the end, index value 1 means pointing at the last element and index value 0 means pointing at beyond last element.
            </remarks>
        </member>
        <member name="P:System.Index.Start">
            <summary>Create an Index pointing at first element.</summary>
        </member>
        <member name="P:System.Index.End">
            <summary>Create an Index pointing at beyond last element.</summary>
        </member>
        <member name="M:System.Index.FromStart(System.Int32)">
            <summary>Create an Index from the start at the position indicated by the value.</summary>
            <param name="value">The index value from the start.</param>
        </member>
        <member name="M:System.Index.FromEnd(System.Int32)">
            <summary>Create an Index from the end at the position indicated by the value.</summary>
            <param name="value">The index value from the end.</param>
        </member>
        <member name="P:System.Index.Value">
            <summary>Returns the index value.</summary>
        </member>
        <member name="P:System.Index.IsFromEnd">
            <summary>Indicates whether the index is from the start or the end.</summary>
        </member>
        <member name="M:System.Index.GetOffset(System.Int32)">
            <summary>Calculate the offset from the start using the giving collection length.</summary>
            <param name="length">The length of the collection that the Index will be used with. length has to be a positive value</param>
            <remarks>
            For performance reason, we don't validate the input length parameter and the returned offset value against negative values.
            we don't validate either the returned offset is greater than the input length.
            It is expected Index will be used with collections which always have non negative length/count. If the returned offset is negative and
            then used to index a collection will get out of range exception which will be same affect as the validation.
            </remarks>
        </member>
        <member name="M:System.Index.Equals(System.Object)">
            <summary>Indicates whether the current Index object is equal to another object of the same type.</summary>
            <param name="value">An object to compare with this object</param>
        </member>
        <member name="M:System.Index.Equals(System.Index)">
            <summary>Indicates whether the current Index object is equal to another Index object.</summary>
            <param name="other">An object to compare with this object</param>
        </member>
        <member name="M:System.Index.GetHashCode">
            <summary>Returns the hash code for this instance.</summary>
        </member>
        <member name="M:System.Index.op_Implicit(System.Int32)~System.Index">
            <summary>Converts integer number to an Index.</summary>
        </member>
        <member name="M:System.Index.ToString">
            <summary>Converts the value of the current Index object to its equivalent string representation.</summary>
        </member>
        <member name="T:System.Range">
            <summary>Represent a range has start and end indexes.</summary>
            <remarks>
            Range is used by the C# compiler to support the range syntax.
            <code>
            int[] someArray = new int[5] { 1, 2, 3, 4, 5 };
            int[] subArray1 = someArray[0..2]; // { 1, 2 }
            int[] subArray2 = someArray[1..^0]; // { 2, 3, 4, 5 }
            </code>
            </remarks>
        </member>
        <member name="P:System.Range.Start">
            <summary>Represent the inclusive start index of the Range.</summary>
        </member>
        <member name="P:System.Range.End">
            <summary>Represent the exclusive end index of the Range.</summary>
        </member>
        <member name="M:System.Range.#ctor(System.Index,System.Index)">
            <summary>Construct a Range object using the start and end indexes.</summary>
            <param name="start">Represent the inclusive start index of the range.</param>
            <param name="end">Represent the exclusive end index of the range.</param>
        </member>
        <member name="M:System.Range.Equals(System.Object)">
            <summary>Indicates whether the current Range object is equal to another object of the same type.</summary>
            <param name="value">An object to compare with this object</param>
        </member>
        <member name="M:System.Range.Equals(System.Range)">
            <summary>Indicates whether the current Range object is equal to another Range object.</summary>
            <param name="other">An object to compare with this object</param>
        </member>
        <member name="M:System.Range.GetHashCode">
            <summary>Returns the hash code for this instance.</summary>
        </member>
        <member name="M:System.Range.ToString">
            <summary>Converts the value of the current Range object to its equivalent string representation.</summary>
        </member>
        <member name="M:System.Range.StartAt(System.Index)">
            <summary>Create a Range object starting from start index to the end of the collection.</summary>
        </member>
        <member name="M:System.Range.EndAt(System.Index)">
            <summary>Create a Range object starting from first element in the collection to the end Index.</summary>
        </member>
        <member name="P:System.Range.All">
            <summary>Create a Range object starting from first element to the end.</summary>
        </member>
        <member name="M:System.Range.GetOffsetAndLength(System.Int32)">
            <summary>Calculate the start offset and length of range object using a collection length.</summary>
            <param name="length">The length of the collection that the range will be used with. length has to be a positive value.</param>
            <remarks>
            For performance reason, we don't validate the input length parameter against negative values.
            It is expected Range will be used with collections which always have non negative length/count.
            We validate the range is inside the length scope though.
            </remarks>
        </member>
        <member name="M:System.Runtime.CompilerServices.RuntimeHelpers.GetSubArray``1(``0[],System.Range)">
            <summary>
            Slices the specified array using the specified range.
            </summary>
        </member>
    </members>
</doc>
